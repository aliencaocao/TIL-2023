{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:50:38.755052Z",
     "start_time": "2023-05-12T09:50:38.730714600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import contextlib\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "\n",
    "os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n",
    "\n",
    "class TRTInference:\n",
    "    def __init__(self, engine_path, ouput_names_mapping: dict = None, device='cuda:0', backend='torch', max_batch_size=32, verbose=False):\n",
    "        self.engine_path = engine_path\n",
    "        self.output_names_mapping = ouput_names_mapping or {}\n",
    "        self.device = device\n",
    "        self.backend = backend\n",
    "        self.max_batch_size = max_batch_size\n",
    "\n",
    "        self.logger = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "        self.engine = self.load_engine(engine_path)\n",
    "\n",
    "        if self.backend == 'cuda':\n",
    "            cuda.init()\n",
    "            device = cuda.Device(0)\n",
    "            self.context = device.make_context()\n",
    "        else:\n",
    "            self.context = self.engine.create_execution_context()\n",
    "\n",
    "        self.bindings = self.get_bindings(self.engine, self.context, self.max_batch_size, self.device)\n",
    "        self.bindings_addr = OrderedDict((n, v.ptr) for n, v in self.bindings.items())\n",
    "\n",
    "        self.input_names = self.get_input_names()\n",
    "        self.output_names = self.get_output_names()\n",
    "\n",
    "        if self.backend == 'cuda':\n",
    "            self.stream = cuda.Stream()\n",
    "\n",
    "    def init(self, ):\n",
    "        self.dynamic = False\n",
    "\n",
    "    def load_engine(self, path):\n",
    "        '''load engine\n",
    "        '''\n",
    "        trt.init_libnvinfer_plugins(self.logger, '')\n",
    "        with open(path, 'rb') as f, trt.Runtime(self.logger) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "    def get_input_names(self):\n",
    "        names = []\n",
    "        for _, name in enumerate(self.engine):\n",
    "            if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
    "                names.append(name)\n",
    "        return names\n",
    "\n",
    "    def get_output_names(self):\n",
    "        names = []\n",
    "        for _, name in enumerate(self.engine):\n",
    "            if self.engine.get_tensor_mode(name) == trt.TensorIOMode.OUTPUT:\n",
    "                names.append(name)\n",
    "        return names\n",
    "\n",
    "    def get_bindings(self, engine, context, max_batch_size=32, device=None):\n",
    "        '''build binddings\n",
    "        '''\n",
    "        Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "        bindings = OrderedDict()\n",
    "        # max_batch_size = 1\n",
    "\n",
    "        for i, name in enumerate(engine):\n",
    "            shape = engine.get_tensor_shape(name)\n",
    "            dtype = trt.nptype(engine.get_tensor_dtype(name))\n",
    "\n",
    "            if shape[0] == -1:\n",
    "                shape[0] = max_batch_size\n",
    "                if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:  # dynamic\n",
    "                    context.set_input_shape(name, shape)\n",
    "\n",
    "            if self.backend == 'cuda':\n",
    "                if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
    "                    data = np.random.randn(*shape).astype(dtype)\n",
    "                    ptr = cuda.mem_alloc(data.nbytes)\n",
    "                    bindings[name] = Binding(name, dtype, shape, data, ptr)\n",
    "                else:\n",
    "                    data = cuda.pagelocked_empty(trt.volume(shape), dtype)\n",
    "                    ptr = cuda.mem_alloc(data.nbytes)\n",
    "                    bindings[name] = Binding(name, dtype, shape, data, ptr)\n",
    "\n",
    "            else:\n",
    "                data = torch.from_numpy(np.empty(shape, dtype=dtype)).to(device)\n",
    "                bindings[name] = Binding(name, dtype, shape, data, data.data_ptr())\n",
    "\n",
    "        return bindings\n",
    "\n",
    "    def run_torch(self, blob):\n",
    "        '''torch input\n",
    "        '''\n",
    "        for n in self.input_names:\n",
    "            if self.bindings[n].shape != blob[n].shape:\n",
    "                self.context.set_input_shape(n, blob[n].shape)\n",
    "                self.bindings[n] = self.bindings[n]._replace(shape=blob[n].shape)\n",
    "\n",
    "        self.bindings_addr.update({n: blob[n].data_ptr() for n in self.input_names})\n",
    "        self.context.execute_v2(list(self.bindings_addr.values()))\n",
    "        outputs = {self.output_names_mapping.get(n, n): self.bindings[n].data for n in self.output_names}\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def async_run_cuda(self, blob):\n",
    "        '''numpy input\n",
    "        '''\n",
    "        blob = {n: np.ascontiguousarray(v) for n, v in blob.items()}\n",
    "        for n in self.input_names:\n",
    "            print(n)\n",
    "            cuda.memcpy_htod_async(self.bindings_addr[n], blob[n], self.stream)\n",
    "\n",
    "        bindings_addr = [int(v) for _, v in self.bindings_addr.items()]\n",
    "        self.context.execute_async_v2(bindings=bindings_addr, stream_handle=self.stream.handle)\n",
    "\n",
    "        outputs = {}\n",
    "        for n in self.output_names:\n",
    "            cuda.memcpy_dtoh_async(self.bindings[n].data, self.bindings[n].ptr, self.stream)\n",
    "            outputs[self.output_names_mapping.get(n, n)] = self.bindings[n].data\n",
    "\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def __call__(self, blob):\n",
    "        if self.backend == 'torch':\n",
    "            return self.run_torch(blob)\n",
    "\n",
    "        elif self.backend == 'cuda':\n",
    "            return self.async_run_cuda(blob)\n",
    "\n",
    "    def synchronize(self, ):\n",
    "        if self.backend == 'torch' and torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        elif self.backend == 'cuda':\n",
    "            self.stream.synchronize()\n",
    "\n",
    "    def warmup(self, blob, n):\n",
    "        for _ in range(n):\n",
    "            _ = self(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "class ToTensor(T.ToTensor):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, pic):\n",
    "        if isinstance(pic, torch.Tensor):\n",
    "            return pic\n",
    "        return super().__call__(pic)\n",
    "\n",
    "\n",
    "class PadToSize(T.Pad):\n",
    "    def __init__(self, size, fill=0, padding_mode='constant'):\n",
    "        super().__init__(0, fill, padding_mode)\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image or Tensor): Image to be padded.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image or Tensor: Padded image.\n",
    "        \"\"\"\n",
    "        w, h = F.get_image_size(img)\n",
    "        padding = (0, 0, self.size[0] - w, self.size[1] - h)\n",
    "        return F.pad(img, padding, self.fill, self.padding_mode)\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, img_dir: str='', preprocess: T.Compose=None, device='cuda:0', backend='torch') -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.backend = backend\n",
    "        self.size = 640\n",
    "\n",
    "        self.im_path_list = list(glob.glob(os.path.join(img_dir, '*.jpg')))\n",
    "\n",
    "        if preprocess is None:\n",
    "            self.preprocess = T.Compose([\n",
    "                    T.Resize(size=639, max_size=640),\n",
    "                    PadToSize(size=(640, 640), fill=114),\n",
    "                    ToTensor(),\n",
    "                    T.ConvertImageDtype(torch.float),\n",
    "            ])\n",
    "        else:\n",
    "            self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self, ):\n",
    "        return len(self.im_path_list)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # im = Image.open(self.img_path_list[index]).convert('RGB')\n",
    "        im = torchvision.io.read_file(self.im_path_list[index])\n",
    "        im = torchvision.io.decode_jpeg(im, mode=torchvision.io.ImageReadMode.RGB).to(self.device)\n",
    "        _, h, w = im.shape # c,h,w\n",
    "\n",
    "        im = self.preprocess(im)\n",
    "        if self.backend == 'cuda':  # numpy input\n",
    "            blob = {\n",
    "            'image': im.cpu().numpy(),\n",
    "            'im_shape': np.array([self.size, self.size]),\n",
    "            'scale_factor': np.array([h / self.size, w / self.size]),\n",
    "            'orig_size': np.array([w, h]),\n",
    "            }\n",
    "        else:\n",
    "            blob = {\n",
    "            'image': im,\n",
    "            'im_shape': torch.tensor([self.size, self.size]).to(im.device),\n",
    "            'scale_factor': torch.tensor([h / self.size, w / self.size]).to(im.device),\n",
    "            'orig_size': torch.tensor([w, h]).to(im.device),\n",
    "            }\n",
    "        return blob\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def post_process():\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn():\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:58:06.047540Z",
     "start_time": "2023-05-12T09:58:06.016172100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model = TRTInference('rtdetr_r50vd_6x_coco.trt', ouput_names_mapping={'tile_3.tmp_0': 'bbox_num', 'reshape2_83.tmp_0': 'bbox'}, backend='torch', verbose=True)\n",
    "data = Dataset(img_dir='.', backend='torch')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:58:07.982087400Z",
     "start_time": "2023-05-12T09:58:07.793921400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'image': tensor([[[0.4471, 0.4471, 0.4510,  ..., 0.8588, 0.8627, 0.8588],\n          [0.4588, 0.4588, 0.4471,  ..., 0.8588, 0.8588, 0.8627],\n          [0.4588, 0.4667, 0.4549,  ..., 0.8627, 0.8588, 0.8627],\n          ...,\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]],\n \n         [[0.6745, 0.6902, 0.6824,  ..., 0.8784, 0.8824, 0.8784],\n          [0.6863, 0.6863, 0.6784,  ..., 0.8784, 0.8784, 0.8784],\n          [0.6824, 0.6824, 0.6784,  ..., 0.8784, 0.8784, 0.8784],\n          ...,\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]],\n \n         [[0.9922, 0.9961, 0.9961,  ..., 0.8510, 0.8549, 0.8510],\n          [0.9961, 0.9961, 0.9922,  ..., 0.8510, 0.8510, 0.8510],\n          [0.9961, 0.9961, 0.9961,  ..., 0.8549, 0.8510, 0.8510],\n          ...,\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n          [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]]],\n        device='cuda:0'),\n 'im_shape': tensor([640, 640], device='cuda:0'),\n 'scale_factor': tensor([1.2000, 1.6000], device='cuda:0'),\n 'orig_size': tensor([1024,  768], device='cuda:0')}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:58:24.323214Z",
     "start_time": "2023-05-12T09:58:24.271166400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model.warmup(data[0], 100)\n",
    "result = model(data[0])\n",
    "if model.backend == 'cuda':\n",
    "    model.context.pop()  # clears CUDA context, to use model again, need to reintialize the model instance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:58:30.959528800Z",
     "start_time": "2023-05-12T09:58:30.179170900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([300, 6])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bbox_num: number of bbox in each image\n",
    "# bbox: shape=[bbox_num, 6], 6 is [class_id, score, x1, y1, x2, y2]\n",
    "# find classes that have predictions\n",
    "indices = torch.where(~torch.isnan(result['bbox'][:, 1]))[0]\n",
    "indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T09:58:50.176270800Z",
     "start_time": "2023-05-12T09:58:50.155198800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
