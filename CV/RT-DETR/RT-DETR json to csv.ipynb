{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import orjson\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.ops import box_convert\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "json_path = 'dataset/test/result/bbox.json'\n",
    "conf_thresh = 0.8\n",
    "images = os.listdir('dataset/test/images')\n",
    "h, w  = 720, 1280\n",
    "with open(json_path, 'rb') as f:\n",
    "    json_data = orjson.loads(f.read())\n",
    "results = []\n",
    "same_image_results = []\n",
    "last_seen_img_id = None\n",
    "for result in json_data:\n",
    "    if not last_seen_img_id:\n",
    "        last_seen_img_id = result['image_id']\n",
    "    img_id = result['image_id']\n",
    "\n",
    "    if last_seen_img_id and img_id != last_seen_img_id:  # if not None (first run) and a different image\n",
    "        same_image_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        results.extend(same_image_results[:4])  # 1 image at most 4 bbox\n",
    "        same_image_results = []\n",
    "        last_seen_img_id = result['image_id']\n",
    "    if result['score'] > conf_thresh:\n",
    "        result['bbox'] = box_convert(torch.tensor([result['bbox']]), 'xywh', 'xyxy')[0].tolist()  # raw RT-DETR checkpoint uses COCO format which is xywh, convert to xyxy. Note exported RT-DETR uses xyxy\n",
    "        same_image_results.append({\n",
    "            'Image_ID': images[int(img_id)].split('.')[0],\n",
    "            'class': 0,  # TODO: replace with actual ReID model results, but for now can just submit bbox and see map, 1: suspect, 0: not suspect\n",
    "            'confidence': result['score'],\n",
    "            'ymin': result['bbox'][1] / h,\n",
    "            'xmin': result['bbox'][0] / w,\n",
    "            'ymax': result['bbox'][3] / h,\n",
    "            'xmax': result['bbox'][2] / w\n",
    "        })\n",
    "else:  # when for loop exhausts, do 1 last merge\n",
    "    same_image_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    results.extend(same_image_results[:4])  # 1 image at most 4 bbox\n",
    "    same_image_results = []\n",
    "assert len(set(r['Image_ID'] for r in results)) == len(images)  # check all image have at least 1 bbox"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T07:01:17.460135800Z",
     "start_time": "2023-05-21T07:01:16.302618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-21T07:01:18.405653600Z",
     "start_time": "2023-05-21T07:01:18.372325300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
