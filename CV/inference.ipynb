{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:49.040831300Z",
     "start_time": "2023-05-11T16:02:49.006886800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import contextlib\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "\n",
    "class TRTInference:\n",
    "    def __init__(self, engine_path, device='cuda:0', backend='torch', max_batch_size=32, verbose=False):\n",
    "        self.engine_path = engine_path\n",
    "        self.device = device\n",
    "        self.backend = backend\n",
    "        self.max_batch_size = max_batch_size\n",
    "\n",
    "        self.logger = trt.Logger(trt.Logger.VERBOSE) if verbose else trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "        self.engine = self.load_engine(engine_path)\n",
    "\n",
    "        if self.backend == 'cuda':\n",
    "            cuda.init()\n",
    "            device = cuda.Device(0)\n",
    "            self.context = device.make_context()\n",
    "        else:\n",
    "            self.context = self.engine.create_execution_context()\n",
    "\n",
    "        self.bindings = self.get_bindings(self.engine, self.context, self.max_batch_size, self.device)\n",
    "        self.bindings_addr = OrderedDict((n, v.ptr) for n, v in self.bindings.items())\n",
    "\n",
    "        self.input_names = self.get_input_names()\n",
    "        self.output_names = self.get_output_names()\n",
    "\n",
    "        if self.backend == 'cuda':\n",
    "            self.stream = cuda.Stream()\n",
    "\n",
    "    def init(self, ):\n",
    "        self.dynamic = False\n",
    "\n",
    "    def load_engine(self, path):\n",
    "        '''load engine\n",
    "        '''\n",
    "        trt.init_libnvinfer_plugins(self.logger, '')\n",
    "        with open(path, 'rb') as f, trt.Runtime(self.logger) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "\n",
    "    def get_input_names(self, ):\n",
    "        names = []\n",
    "        for _, name in enumerate(self.engine):\n",
    "            if self.engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
    "                names.append(name)\n",
    "        return names\n",
    "\n",
    "    def get_output_names(self, ):\n",
    "        names = []\n",
    "        for _, name in enumerate(self.engine):\n",
    "            if self.engine.get_tensor_mode(name) == trt.TensorIOMode.OUTPUT:\n",
    "                names.append(name)\n",
    "        return names\n",
    "\n",
    "    def get_bindings(self, engine, context, max_batch_size=32, device=None):\n",
    "        '''build binddings\n",
    "        '''\n",
    "        Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "        bindings = OrderedDict()\n",
    "        # max_batch_size = 1\n",
    "\n",
    "        for i, name in enumerate(engine):\n",
    "            shape = engine.get_tensor_shape(name)\n",
    "            dtype = trt.nptype(engine.get_tensor_dtype(name))\n",
    "\n",
    "            if shape[0] == -1:\n",
    "                dynamic = True\n",
    "                shape[0] = max_batch_size\n",
    "                if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:  # dynamic\n",
    "                    context.set_input_shape(name, shape)\n",
    "\n",
    "            if self.backend == 'cuda':\n",
    "                if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:\n",
    "                    data = np.random.randn(*shape).astype(dtype)\n",
    "                    ptr = cuda.mem_alloc(data.nbytes)\n",
    "                    bindings[name] = Binding(name, dtype, shape, data, ptr)\n",
    "                else:\n",
    "                    data = cuda.pagelocked_empty(trt.volume(shape), dtype)\n",
    "                    ptr = cuda.mem_alloc(data.nbytes)\n",
    "                    bindings[name] = Binding(name, dtype, shape, data, ptr)\n",
    "\n",
    "            else:\n",
    "                data = torch.from_numpy(np.empty(shape, dtype=dtype)).to(device)\n",
    "                bindings[name] = Binding(name, dtype, shape, data, data.data_ptr())\n",
    "\n",
    "        return bindings\n",
    "\n",
    "    def run_torch(self, blob):\n",
    "        '''torch input\n",
    "        '''\n",
    "        for n in self.input_names:\n",
    "            if self.bindings[n].shape != blob[n].shape:\n",
    "                self.context.set_input_shape(n, blob[n].shape)\n",
    "                self.bindings[n] = self.bindings[n]._replace(shape=blob[n].shape)\n",
    "\n",
    "        self.bindings_addr.update({n: blob[n].data_ptr() for n in self.input_names})\n",
    "        self.context.execute_v2(list(self.bindings_addr.values()))\n",
    "        outputs = {n: self.bindings[n].data for n in self.output_names}\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def async_run_cuda(self, blob):\n",
    "        '''numpy input\n",
    "        '''\n",
    "        for n in self.input_names:\n",
    "            cuda.memcpy_htod_async(self.bindings_addr[n], blob[n], self.stream)\n",
    "\n",
    "        bindings_addr = [int(v) for _, v in self.bindings_addr.items()]\n",
    "        self.context.execute_async_v2(bindings=bindings_addr, stream_handle=self.stream.handle)\n",
    "\n",
    "        outputs = {}\n",
    "        for n in self.output_names:\n",
    "            cuda.memcpy_dtoh_async(self.bindings[n].data, self.bindings[n].ptr, self.stream)\n",
    "            outputs[n] = self.bindings[n].data\n",
    "\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def __call__(self, blob):\n",
    "        if self.backend == 'torch':\n",
    "            return self.run_torch(blob)\n",
    "\n",
    "        elif self.backend == 'cuda':\n",
    "            return self.async_run_cuda(blob)\n",
    "\n",
    "    def synchronize(self, ):\n",
    "        if self.backend == 'torch' and torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        elif self.backend == 'cuda':\n",
    "            self.stream.synchronize()\n",
    "\n",
    "    def warmup(self, blob, n):\n",
    "        for _ in range(n):\n",
    "            _ = self(blob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = TRTInference('rtdetr_r50vd_6x_coco.trt', backend='cuda', verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:51.631492500Z",
     "start_time": "2023-05-11T16:02:51.404306300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bytes must be in range(0, 256)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [20], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m image \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(image, (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))  \u001B[38;5;66;03m# channels first\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# create input dictionary\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m input_dict \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m: image, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mim_shape\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mbytes\u001B[39m((\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m640\u001B[39m, \u001B[38;5;241m640\u001B[39m)), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscale_factor\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1.0\u001B[39m}\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# create TRTInference object and perform inference\u001B[39;00m\n\u001B[0;32m     16\u001B[0m output_dict \u001B[38;5;241m=\u001B[39m model(input_dict)\n",
      "\u001B[1;31mValueError\u001B[0m: bytes must be in range(0, 256)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# load image and resize\n",
    "image = cv2.imread('cv_sample.png')\n",
    "image = cv2.resize(image, (640, 640))\n",
    "\n",
    "# convert image to numpy array and normalize\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = image.astype(np.float32) / 255.0\n",
    "image = np.transpose(image, (2, 0, 1))  # channels first\n",
    "\n",
    "# create input dictionary\n",
    "input_dict = {'image': image, 'im_shape': , 'scale_factor': 1.0}\n",
    "\n",
    "# create TRTInference object and perform inference\n",
    "output_dict = model(input_dict)\n",
    "\n",
    "# get output tensor(s)\n",
    "output_tensor = output_dict['output']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-11T16:15:37.236176200Z",
     "start_time": "2023-05-11T16:15:37.206146600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
