{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:34.691332Z",
     "start_time": "2023-05-16T14:55:27.127355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'huggingface'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = 'True'\n",
    "import math\n",
    "from datasets import Audio, Dataset, DatasetDict\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_optimizer import Ranger21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:34.706335100Z",
     "start_time": "2023-05-16T14:55:34.692332800Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name= 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.920137300Z",
     "start_time": "2023-05-16T14:55:34.708333800Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.921136900Z",
     "start_time": "2023-05-16T14:55:35.904137600Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_df = pd.read_csv('Train.csv')\n",
    "train_df, val_df = train_test_split(ds_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.944137300Z",
     "start_time": "2023-05-16T14:55:35.920137300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:56.053230Z",
     "start_time": "2023-05-16T14:55:35.931137400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d1906816ac4afea07ffe0c60fa6a7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ea9df791f543ada59ff462882d644f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "val_ds = val_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "ds = DatasetDict({'train': train_ds, 'val': val_ds})\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    model_name = 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'\n",
    "    from transformers import Wav2Vec2Processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    audio = batch[\"path\"]\n",
    "    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"annotation\"])\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(prepare_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:56.069237800Z",
     "start_time": "2023-05-16T14:55:56.053230Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:57.519937600Z",
     "start_time": "2023-05-16T14:55:56.071238100Z"
    }
   },
   "outputs": [],
   "source": [
    "wer = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    return {\"wer\": wer.compute(predictions=pred_str, references=label_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.251015Z",
     "start_time": "2023-05-16T14:55:57.527939400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Wav2Vec2ConformerForCTC.from_pretrained(\n",
    "    model_name,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.266015800Z",
     "start_time": "2023-05-16T14:56:01.254015900Z"
    }
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.342014700Z",
     "start_time": "2023-05-16T14:56:01.282015800Z"
    }
   },
   "outputs": [],
   "source": [
    "per_gpu_bs = 8\n",
    "effective_bs = 32\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    overwrite_output_dir =True,\n",
    "    per_device_train_batch_size=per_gpu_bs,\n",
    "    gradient_accumulation_steps=math.ceil(effective_bs/per_gpu_bs),\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=100,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='no',  # epoch\n",
    "    save_safetensors=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_steps=1,\n",
    "    eval_steps=1,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=3,\n",
    "    lr_scheduler_type='cosine',\n",
    "    load_best_model_at_end=False,  # True\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,  # follow fairseq fintuning config\n",
    "    warmup_ratio=0.22, # follow Ranger21\n",
    "    weight_decay=1e-4,  # follow Ranger21\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    fp16_full_eval=True,\n",
    "    torch_compile=os.name!='nt',\n",
    "    report_to=['tensorboard'],\n",
    "    torch_compile_backend='inductor' if os.name != 'nt' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.349014400Z",
     "start_time": "2023-05-16T14:56:01.332230700Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTCTrainer(Trainer):\n",
    "    def training_step(self, model: torch.nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a training step on a batch of inputs.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to train.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "\n",
    "        Return:\n",
    "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "        \"\"\"\n",
    "\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "        if os.name != 'nt':\n",
    "            accelerator.backward(self.scaler.scale(loss))\n",
    "        else:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        return loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.361016700Z",
     "start_time": "2023-05-16T14:56:01.346015500Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name != 'nt':\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision='fp16', dynamo_backend='eager')  # FP8 needs transformer_engine package which is only on Linux with Hopper GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.386016400Z",
     "start_time": "2023-05-16T14:56:01.362017200Z"
    }
   },
   "outputs": [],
   "source": [
    "def tri_stage_schedule(epoch: int, max_epoch = training_args.num_train_epochs, stage_ratio = [0.1, 0.4, 0.5], peak_lr = training_args.learning_rate, initial_lr_scale=0.01, final_lr_scale=0.05):\n",
    "    \"\"\"https://github.com/facebookresearch/fairseq/blob/5ecbbf58d6e80b917340bcbf9d7bdbb539f0f92b/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py#L51\"\"\"\n",
    "    assert sum(stage_ratio) == 1\n",
    "    current_ratio = epoch / max_epoch\n",
    "    if current_ratio < stage_ratio[0]:  # linear warmup\n",
    "        lrs = torch.linspace(initial_lr_scale * peak_lr, peak_lr, int(stage_ratio[0] * max_epoch))\n",
    "        return lrs[epoch]\n",
    "    elif stage_ratio[0] <= current_ratio <= stage_ratio[1]:  # constant\n",
    "        return peak_lr\n",
    "    else:  # exponential decay\n",
    "        decay_factor = -math.log(final_lr_scale) / (stage_ratio[2] * max_epoch)\n",
    "        return peak_lr * math.exp(-decay_factor * stage_ratio[2] * max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:05.797000500Z",
     "start_time": "2023-05-16T14:56:01.381015600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m────────────────────────────── \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m ───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_5312\\3519010244.py\u001B[0m:\u001B[94m20\u001B[0m in \u001B[92m<module>\u001B[0m                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5312\\\\3519010244.py'\u001B[0m                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1664\u001B[0m in \u001B[92mtrain\u001B[0m                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1661 \u001B[0m\u001B[2m│   │   \u001B[0minner_training_loop = find_executable_batch_size(                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1662 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._inner_training_loop, \u001B[96mself\u001B[0m._train_batch_size, args.auto_find_batch_size  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1663 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1664 \u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m inner_training_loop(                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1665 \u001B[0m\u001B[2m│   │   │   \u001B[0margs=args,                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1666 \u001B[0m\u001B[2m│   │   │   \u001B[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1667 \u001B[0m\u001B[2m│   │   │   \u001B[0mtrial=trial,                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1940\u001B[0m in \u001B[92m_inner_training_loop\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1937 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mwith\u001B[0m model.no_sync():                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1938 \u001B[0m\u001B[2m│   │   │   │   │   │   \u001B[0mtr_loss_step = \u001B[96mself\u001B[0m.training_step(model, inputs)                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1939 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1940 \u001B[2m│   │   │   │   │   \u001B[0mtr_loss_step = \u001B[96mself\u001B[0m.training_step(model, inputs)                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1941 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1942 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m (                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1943 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0margs.logging_nan_inf_filter                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_5312\\3610558995.py\u001B[0m:\u001B[94m23\u001B[0m in \u001B[92mtraining_step\u001B[0m               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5312\\\\3610558995.py'\u001B[0m                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m2767\u001B[0m in \u001B[92mcompute_loss\u001B[0m         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2764 \u001B[0m\u001B[2m│   │   │   \u001B[0mlabels = inputs.pop(\u001B[33m\"\u001B[0m\u001B[33mlabels\u001B[0m\u001B[33m\"\u001B[0m)                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2765 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2766 \u001B[0m\u001B[2m│   │   │   \u001B[0mlabels = \u001B[94mNone\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m2767 \u001B[2m│   │   \u001B[0moutputs = model(**inputs)                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2768 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Save past state if it exists\u001B[0m                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2769 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# TODO: this needs to be fixed and made cleaner later.\u001B[0m                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m2770 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m.args.past_index >= \u001B[94m0\u001B[0m:                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mFiles\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mmer.py\u001B[0m:\u001B[94m1660\u001B[0m in \u001B[92mforward\u001B[0m                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1657 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1658 \u001B[0m\u001B[2m│   │   \u001B[0mreturn_dict = return_dict \u001B[94mif\u001B[0m return_dict \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[94melse\u001B[0m \u001B[96mself\u001B[0m.config.use_return  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1659 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1660 \u001B[2m│   │   \u001B[0moutputs = \u001B[96mself\u001B[0m.wav2vec2_conformer(                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1661 \u001B[0m\u001B[2m│   │   │   \u001B[0minput_values,                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1662 \u001B[0m\u001B[2m│   │   │   \u001B[0mattention_mask=attention_mask,                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1663 \u001B[0m\u001B[2m│   │   │   \u001B[0moutput_attentions=output_attentions,                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mFiles\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mmer.py\u001B[0m:\u001B[94m1339\u001B[0m in \u001B[92mforward\u001B[0m                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1336 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1337 \u001B[0m\u001B[2m│   │   \u001B[0mreturn_dict = return_dict \u001B[94mif\u001B[0m return_dict \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[94melse\u001B[0m \u001B[96mself\u001B[0m.config.use_return  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1338 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1339 \u001B[2m│   │   \u001B[0mextract_features = \u001B[96mself\u001B[0m.feature_extractor(input_values)                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1340 \u001B[0m\u001B[2m│   │   \u001B[0mextract_features = extract_features.transpose(\u001B[94m1\u001B[0m, \u001B[94m2\u001B[0m)                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1341 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1342 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m attention_mask \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mFiles\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mmer.py\u001B[0m:\u001B[94m527\u001B[0m in \u001B[92mforward\u001B[0m                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 524 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mhidden_states,                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 525 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m)                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 526 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 527 \u001B[2m│   │   │   │   \u001B[0mhidden_states = conv_layer(hidden_states)                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 528 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 529 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m hidden_states                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 530 \u001B[0m                                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py\u001B[0m:\u001B[94m88\u001B[0m in                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[92mmasked_conv_forward\u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m85 \u001B[0m\u001B[2m│   \u001B[0m                                                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m86 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m.layer_norm \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m87 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96misinstance\u001B[0m(\u001B[96mself\u001B[0m.layer_norm, MaskedGroupNorm):                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m88 \u001B[2m│   │   │   \u001B[0mx = \u001B[96mself\u001B[0m.layer_norm(x, length)                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m89 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m90 \u001B[0m\u001B[2m│   │   │   \u001B[0mx = \u001B[96mself\u001B[0m.layer_norm(x)                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m91 \u001B[0m\u001B[2m│   \u001B[0mx = nn.functional.gelu(x)                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m:\u001B[94m1501\u001B[0m in \u001B[92m_call_impl\u001B[0m        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1498 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[95mnot\u001B[0m (\u001B[96mself\u001B[0m._backward_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._backward_pre_hooks \u001B[95mor\u001B[0m \u001B[96mself\u001B[0m._forward_hooks   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1499 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_backward_pre_hooks \u001B[95mor\u001B[0m _global_backward_hooks                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1500 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[95mor\u001B[0m _global_forward_hooks \u001B[95mor\u001B[0m _global_forward_pre_hooks):                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1501 \u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m forward_call(*args, **kwargs)                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1502 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Do not call functions when jit is used\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1503 \u001B[0m\u001B[2m│   │   \u001B[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1504 \u001B[0m\u001B[2m│   │   \u001B[0mbackward_pre_hooks = []                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py\u001B[0m:\u001B[94m46\u001B[0m in \u001B[92mforward\u001B[0m           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m43 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m44 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94massert\u001B[0m inp.shape[\u001B[94m1\u001B[0m] % \u001B[96mself\u001B[0m.num_groups == \u001B[94m0\u001B[0m, \u001B[33m'\u001B[0m\u001B[33mFeature size not divisible by group\u001B[0m    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m45 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m46 \u001B[2m│   │   \u001B[0mmask = lengths_to_mask(lengths, max_len=inp.shape[-\u001B[94m1\u001B[0m], dtype=inp.dtype)             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m47 \u001B[0m\u001B[2m│   │   \u001B[0mave_mask = mask / lengths[:, \u001B[94mNone\u001B[0m] / (inp.shape[-\u001B[94m2\u001B[0m] / \u001B[96mself\u001B[0m.num_groups)  \u001B[2m# also f\u001B[0m    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m48 \u001B[0m\u001B[2m│   │   \u001B[0mave_mask = ave_mask.unsqueeze(\u001B[94m1\u001B[0m)  \u001B[2m# .expand(inp.shape)\u001B[0m                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m49 \u001B[0m                                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py\u001B[0m:\u001B[94m17\u001B[0m in \u001B[92mlengths_to_mask\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m14 \u001B[0m\u001B[2;33m│   \u001B[0m\u001B[33m:lengths: N-dimensional tensor\u001B[0m                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m15 \u001B[0m\u001B[2;33m│   \u001B[0m\u001B[33m:returns: N*max_len dimensional tensor. If max_len==None, max_len=max(lengtsh)\u001B[0m          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m16 \u001B[0m\u001B[2;33m│   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m17 \u001B[2m│   \u001B[0m\u001B[94massert\u001B[0m \u001B[96mlen\u001B[0m(lengths.shape) == \u001B[94m1\u001B[0m, \u001B[33m'\u001B[0m\u001B[33mLength shape should be 1 dimensional.\u001B[0m\u001B[33m'\u001B[0m                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m18 \u001B[0m\u001B[2m│   \u001B[0mmax_len = max_len \u001B[95mor\u001B[0m lengths.max().item()                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m19 \u001B[0m\u001B[2m│   \u001B[0mmask = torch.arange(max_len, device=lengths.device, dtype=lengths.dtype).expand(\u001B[96mlen\u001B[0m(    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m20 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mif\u001B[0m dtype \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m:                                                                   \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mAttributeError: \u001B[0m\u001B[32m'NoneType'\u001B[0m object has no attribute \u001B[32m'shape'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_5312\\3519010244.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5312\\\\3519010244.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1938 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1940 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1943 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_5312\\3610558995.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">23</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_5312\\\\3610558995.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2767</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2764 │   │   │   </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2765 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2766 │   │   │   </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2767 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2768 │   │   # Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2769 │   │   # TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2770 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">Files\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">mer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1660</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1657 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1658 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1659 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1660 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wav2vec2_conformer(                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   │   </span>input_values,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   │   </span>output_attentions=output_attentions,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">Files\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">mer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1339</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1336 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1337 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1338 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1339 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>extract_features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.feature_extractor(input_values)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1340 │   │   </span>extract_features = extract_features.transpose(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1341 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1342 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> attention_mask <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">Files\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_confor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">mer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">527</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 524 │   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 525 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 527 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>hidden_states = conv_layer(hidden_states)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> hidden_states                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">88</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">masked_conv_forward</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">86 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer_norm <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer_norm, MaskedGroupNorm):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>88 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer_norm(x, length)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90 │   │   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer_norm(x)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91 │   </span>x = nn.functional.gelu(x)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">46</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43 │   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> inp.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] % <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_groups == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Feature size not divisible by group</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 │   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>46 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mask = lengths_to_mask(lengths, max_len=inp.shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], dtype=inp.dtype)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 │   │   </span>ave_mask = mask / lengths[:, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>] / (inp.shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_groups)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># also f</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   </span>ave_mask = ave_mask.unsqueeze(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># .expand(inp.shape)</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\Documents\\PyCharm-Projects\\TIL-2023\\ASR\\group_norm_fix.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">lengths_to_mask</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">:lengths: N-dimensional tensor</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">:returns: N*max_len dimensional tensor. If max_len==None, max_len=max(lengtsh)</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(lengths.shape) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'Length shape should be 1 dimensional.'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   </span>max_len = max_len <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> lengths.max().item()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 │   </span>mask = torch.arange(max_len, device=lengths.device, dtype=lengths.dtype).expand(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'NoneType'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'shape'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_steps = math.ceil(training_args.num_train_epochs * len(ds['train']) / training_args.gradient_accumulation_steps / min(training_args.per_device_train_batch_size, len(ds['train'])))\n",
    "# optimizer = Ranger21(model.parameters(), num_iterations=max_steps)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-8, foreach=False)  # https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/finetuning/base_960h.yaml\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_steps)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=tri_stage_schedule)  # following FAIR finetuning settings\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: x)  # constant LR, stays same throughout, for Ranger21\n",
    "\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds['val'],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # optimizers=(optimizer, scheduler),\n",
    ")\n",
    "if os.name != 'nt':  # windows does not support torch.compile yet\n",
    "    trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler = accelerator.prepare(trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler)\n",
    "trainer.train()\n",
    "if os.name != 'nt':\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T02:59:21.148781100Z",
     "start_time": "2023-05-15T02:59:19.861964700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wav2vec2-conformer\\\\tokenizer_config.json',\n",
       " 'wav2vec2-conformer\\\\special_tokens_map.json',\n",
       " 'wav2vec2-conformer\\\\vocab.json',\n",
       " 'wav2vec2-conformer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if os.name != 'nt':\n",
    "#     trainer.model_wrapped = accelerator.unwrap_model(trainer.model_wrapped)\n",
    "trainer.save_model('wav2vec2-conformer')\n",
    "processor.tokenizer.save_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T10:54:22.540466800Z",
     "start_time": "2023-05-15T10:54:10.025365900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type wav2vec2 to instantiate a model of type wav2vec2-conformer. This is not supported for all configurations of models and can yield errors.\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2777</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2774 │   │   │   │   </span>mismatched_keys,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2775 │   │   │   │   </span>offload_index,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2776 │   │   │   │   </span>error_msgs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2777 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._load_pretrained_model(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2778 │   │   │   │   </span>model,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2779 │   │   │   │   </span>state_dict,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2780 │   │   │   │   </span>loaded_state_dict_keys,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># XXX: rename?</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3003</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_pretrained_model</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3000 │   │   │   </span>model_to_load = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.base_model_prefix)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3001 │   │   │   </span>base_model_expected_keys = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(model_to_load.state_dict().keys())            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3002 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">any</span>(key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> expected_keys_not_prefixed <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> base_model_expected_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3003 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3004 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The state dictionary of the model you are trying to load is corrupt</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3005 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"properly saved?\"</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[31m╭─\u001B[0m\u001B[31m────────────────────────────── \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m ───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py\u001B[0m:\u001B[94m2\u001B[0m in \u001B[92m<module>\u001B[0m                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'\u001B[0m                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001B[0m:\u001B[94m2777\u001B[0m in               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[92mfrom_pretrained\u001B[0m                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2774 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mmismatched_keys,                                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2775 \u001B[0m\u001B[2m│   │   │   │   \u001B[0moffload_index,                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2776 \u001B[0m\u001B[2m│   │   │   │   \u001B[0merror_msgs,                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m2777 \u001B[2m│   │   │   \u001B[0m) = \u001B[96mcls\u001B[0m._load_pretrained_model(                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2778 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mmodel,                                                                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2779 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mstate_dict,                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2780 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mloaded_state_dict_keys,  \u001B[2m# XXX: rename?\u001B[0m                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001B[0m:\u001B[94m3003\u001B[0m in               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[92m_load_pretrained_model\u001B[0m                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3000 \u001B[0m\u001B[2m│   │   │   \u001B[0mmodel_to_load = \u001B[96mgetattr\u001B[0m(model, \u001B[96mcls\u001B[0m.base_model_prefix)                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3001 \u001B[0m\u001B[2m│   │   │   \u001B[0mbase_model_expected_keys = \u001B[96mlist\u001B[0m(model_to_load.state_dict().keys())            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3002 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96many\u001B[0m(key \u001B[95min\u001B[0m expected_keys_not_prefixed \u001B[95mand\u001B[0m key \u001B[95mnot\u001B[0m \u001B[95min\u001B[0m base_model_expected_  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m3003 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mValueError\u001B[0m(                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3004 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mThe state dictionary of the model you are trying to load is corrupt\u001B[0m  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3005 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mproperly saved?\u001B[0m\u001B[33m\"\u001B[0m                                                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3006 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m)                                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mValueError: \u001B[0mThe state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ConformerForCTC\n",
    "model = Wav2Vec2ConformerForCTC.from_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:28.955063300Z",
     "start_time": "2023-05-14T17:20:25.712694400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    }
   ],
   "source": [
    "# Infer\n",
    "from transformers import pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"wav2vec2-conformer\")\n",
    "def predict(audio_file):\n",
    "    r = transcriber(audio_file)['text'].upper()\n",
    "    if \"'\" in r:\n",
    "        print(audio_file, f'has \\' in {r}, removing')\n",
    "        r = r.replace(\"'\", '')  # Tokenizer includes \"'\" but TIL dataset does not\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:34.398434200Z",
     "start_time": "2023-05-14T17:20:28.957065400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv('Test_Advanced.csv')\n",
    "test_ds['annotation'] = test_ds['path'].map(predict)\n",
    "test_ds.to_csv('Test_Advanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
