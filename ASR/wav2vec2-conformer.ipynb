{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:34.691332Z",
     "start_time": "2023-05-16T14:55:27.127355Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'huggingface'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = 'True'\n",
    "import math\n",
    "from datasets import Audio, Dataset, DatasetDict\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC, TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_optimizer import Ranger21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:34.706335100Z",
     "start_time": "2023-05-16T14:55:34.692332800Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name= 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.920137300Z",
     "start_time": "2023-05-16T14:55:34.708333800Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.921136900Z",
     "start_time": "2023-05-16T14:55:35.904137600Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_df = pd.read_csv('Train.csv')\n",
    "train_df, val_df = train_test_split(ds_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:35.944137300Z",
     "start_time": "2023-05-16T14:55:35.920137300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:56.053230Z",
     "start_time": "2023-05-16T14:55:35.931137400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d1906816ac4afea07ffe0c60fa6a7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ea9df791f543ada59ff462882d644f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "val_ds = val_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "ds = DatasetDict({'train': train_ds, 'val': val_ds})\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    model_name = 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'\n",
    "    from transformers import Wav2Vec2Processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    audio = batch[\"path\"]\n",
    "    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"annotation\"])\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(prepare_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:56.069237800Z",
     "start_time": "2023-05-16T14:55:56.053230Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:55:57.519937600Z",
     "start_time": "2023-05-16T14:55:56.071238100Z"
    }
   },
   "outputs": [],
   "source": [
    "wer = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    return {\"wer\": wer.compute(predictions=pred_str, references=label_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.251015Z",
     "start_time": "2023-05-16T14:55:57.527939400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Wav2Vec2ConformerForCTC.from_pretrained(\n",
    "    model_name,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.266015800Z",
     "start_time": "2023-05-16T14:56:01.254015900Z"
    }
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.342014700Z",
     "start_time": "2023-05-16T14:56:01.282015800Z"
    }
   },
   "outputs": [],
   "source": [
    "per_gpu_bs = 8\n",
    "effective_bs = 32\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    overwrite_output_dir =True,\n",
    "    per_device_train_batch_size=per_gpu_bs,\n",
    "    gradient_accumulation_steps=math.ceil(effective_bs/per_gpu_bs),\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=70,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=True,\n",
    "    # bf16=True,  # for A100\n",
    "    fp16_full_eval=True,\n",
    "    # bf16_full_eval=True,  # for A100\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='epoch',  # epoch\n",
    "    save_safetensors=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_steps=1,\n",
    "    eval_steps=1,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=3,\n",
    "    lr_scheduler_type='cosine',\n",
    "    load_best_model_at_end=True,  # True\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,  # follow fairseq fintuning config\n",
    "    warmup_ratio=0.22, # follow Ranger21\n",
    "    weight_decay=1e-4,  # follow Ranger21\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    report_to=['tensorboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.349014400Z",
     "start_time": "2023-05-16T14:56:01.332230700Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTCTrainer(Trainer):\n",
    "    def training_step(self, model: torch.nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a training step on a batch of inputs.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to train.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "\n",
    "        Return:\n",
    "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "        \"\"\"\n",
    "\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "        if os.name != 'nt':\n",
    "            accelerator.backward(self.scaler.scale(loss))\n",
    "        else:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        return loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.361016700Z",
     "start_time": "2023-05-16T14:56:01.346015500Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name != 'nt':\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision='fp16', dynamo_backend='eager')  # FP8 needs transformer_engine package which is only on Linux with Hopper GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T14:56:01.386016400Z",
     "start_time": "2023-05-16T14:56:01.362017200Z"
    }
   },
   "outputs": [],
   "source": [
    "def tri_stage_schedule(epoch: int, max_epoch = training_args.num_train_epochs, stage_ratio = [0.1, 0.4, 0.5], peak_lr = training_args.learning_rate, initial_lr_scale=0.01, final_lr_scale=0.05):\n",
    "    \"\"\"https://github.com/facebookresearch/fairseq/blob/5ecbbf58d6e80b917340bcbf9d7bdbb539f0f92b/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py#L51\"\"\"\n",
    "    assert sum(stage_ratio) == 1\n",
    "    current_ratio = epoch / max_epoch\n",
    "    if current_ratio < stage_ratio[0]:  # linear warmup\n",
    "        lrs = torch.linspace(initial_lr_scale * peak_lr, peak_lr, int(stage_ratio[0] * max_epoch))\n",
    "        return lrs[epoch]\n",
    "    elif stage_ratio[0] <= current_ratio <= stage_ratio[1]:  # constant\n",
    "        return peak_lr\n",
    "    else:  # exponential decay\n",
    "        decay_factor = -math.log(final_lr_scale) / (stage_ratio[2] * max_epoch)\n",
    "        return peak_lr * math.exp(-decay_factor * stage_ratio[2] * max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = math.ceil(training_args.num_train_epochs * len(ds['train']) / training_args.gradient_accumulation_steps / min(training_args.per_device_train_batch_size, len(ds['train'])))\n",
    "optimizer = Ranger21(model.parameters(), num_iterations=max_steps, lr=1e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-8, foreach=False)  # https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/finetuning/base_960h.yaml\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_steps)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=tri_stage_schedule)  # following FAIR finetuning settings\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: x)  # constant LR, stays same throughout, for Ranger21\n",
    "\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds['val'],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n",
    "if os.name != 'nt':  # windows does not support torch.compile yet\n",
    "    trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler = accelerator.prepare(trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler)\n",
    "trainer.train()\n",
    "if os.name != 'nt':\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T02:59:21.148781100Z",
     "start_time": "2023-05-15T02:59:19.861964700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wav2vec2-conformer\\\\tokenizer_config.json',\n",
       " 'wav2vec2-conformer\\\\special_tokens_map.json',\n",
       " 'wav2vec2-conformer\\\\vocab.json',\n",
       " 'wav2vec2-conformer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if os.name != 'nt':\n",
    "#     trainer.model_wrapped = accelerator.unwrap_model(trainer.model_wrapped)\n",
    "trainer.save_model('wav2vec2-conformer')\n",
    "processor.tokenizer.save_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T10:54:22.540466800Z",
     "start_time": "2023-05-15T10:54:10.025365900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type wav2vec2 to instantiate a model of type wav2vec2-conformer. This is not supported for all configurations of models and can yield errors.\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2777</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2774 │   │   │   │   </span>mismatched_keys,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2775 │   │   │   │   </span>offload_index,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2776 │   │   │   │   </span>error_msgs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2777 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._load_pretrained_model(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2778 │   │   │   │   </span>model,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2779 │   │   │   │   </span>state_dict,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2780 │   │   │   │   </span>loaded_state_dict_keys,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># XXX: rename?</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3003</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_pretrained_model</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3000 │   │   │   </span>model_to_load = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.base_model_prefix)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3001 │   │   │   </span>base_model_expected_keys = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(model_to_load.state_dict().keys())            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3002 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">any</span>(key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> expected_keys_not_prefixed <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> base_model_expected_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3003 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3004 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The state dictionary of the model you are trying to load is corrupt</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3005 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"properly saved?\"</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[31m╭─\u001B[0m\u001B[31m────────────────────────────── \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m ───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py\u001B[0m:\u001B[94m2\u001B[0m in \u001B[92m<module>\u001B[0m                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'\u001B[0m                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001B[0m:\u001B[94m2777\u001B[0m in               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[92mfrom_pretrained\u001B[0m                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2774 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mmismatched_keys,                                                          \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2775 \u001B[0m\u001B[2m│   │   │   │   \u001B[0moffload_index,                                                            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2776 \u001B[0m\u001B[2m│   │   │   │   \u001B[0merror_msgs,                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m2777 \u001B[2m│   │   │   \u001B[0m) = \u001B[96mcls\u001B[0m._load_pretrained_model(                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2778 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mmodel,                                                                    \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2779 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mstate_dict,                                                               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m2780 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mloaded_state_dict_keys,  \u001B[2m# XXX: rename?\u001B[0m                                   \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001B[0m:\u001B[94m3003\u001B[0m in               \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[92m_load_pretrained_model\u001B[0m                                                                           \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3000 \u001B[0m\u001B[2m│   │   │   \u001B[0mmodel_to_load = \u001B[96mgetattr\u001B[0m(model, \u001B[96mcls\u001B[0m.base_model_prefix)                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3001 \u001B[0m\u001B[2m│   │   │   \u001B[0mbase_model_expected_keys = \u001B[96mlist\u001B[0m(model_to_load.state_dict().keys())            \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3002 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96many\u001B[0m(key \u001B[95min\u001B[0m expected_keys_not_prefixed \u001B[95mand\u001B[0m key \u001B[95mnot\u001B[0m \u001B[95min\u001B[0m base_model_expected_  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m3003 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mValueError\u001B[0m(                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3004 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mThe state dictionary of the model you are trying to load is corrupt\u001B[0m  \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3005 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mproperly saved?\u001B[0m\u001B[33m\"\u001B[0m                                                     \u001B[31m│\u001B[0m\n",
       "\u001B[31m│\u001B[0m   \u001B[2m3006 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m)                                                                         \u001B[31m│\u001B[0m\n",
       "\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n",
       "\u001B[1;91mValueError: \u001B[0mThe state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ConformerForCTC\n",
    "model = Wav2Vec2ConformerForCTC.from_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:28.955063300Z",
     "start_time": "2023-05-14T17:20:25.712694400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    }
   ],
   "source": [
    "# Infer\n",
    "from transformers import pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"wav2vec2-conformer\")\n",
    "def predict(audio_file):\n",
    "    r = transcriber(audio_file)['text'].upper()\n",
    "    if \"'\" in r:\n",
    "        print(audio_file, f'has \\' in {r}, removing')\n",
    "        r = r.replace(\"'\", '')  # Tokenizer includes \"'\" but TIL dataset does not\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:34.398434200Z",
     "start_time": "2023-05-14T17:20:28.957065400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv('Test_Advanced.csv')\n",
    "test_ds['annotation'] = test_ds['path'].map(predict)\n",
    "test_ds.to_csv('Test_Advanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
