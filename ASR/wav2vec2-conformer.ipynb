{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:13:49.868054200Z",
     "start_time": "2023-05-20T12:13:41.166540800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'huggingface'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = 'True'\n",
    "import math\n",
    "from datasets import Audio, Dataset, DatasetDict, load_dataset\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC, TrainingArguments, Trainer, Wav2Vec2ConformerConfig\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:13:49.883054300Z",
     "start_time": "2023-05-20T12:13:49.869054200Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name= 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'\n",
    "checkpoint_name= 'model/checkpoint-2250 aug lb 0.0267/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:13:50.440798100Z",
     "start_time": "2023-05-20T12:13:49.884054100Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T12:13:54.491564500Z",
     "start_time": "2023-05-20T12:13:50.442798900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/3750 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16223deacbe149ac9b58518ddc6662d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset audiofolder (C:/Users/alien/Documents/PyCharm-Projects/TIL-2023/ASR/huggingface/datasets/audiofolder/default-4153b0bcbc8c448b/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('audiofolder', data_dir='TIL_data_folder', split='train')  # specify split to return a Dataset object instead of a DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T12:13:54.521564700Z",
     "start_time": "2023-05-20T12:13:54.448566200Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-19T06:48:01.998601400Z",
     "start_time": "2023-05-19T06:47:53.727631900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/home/cheongalc/Documents/til2023/ASR/audio_augmented_folder/audio_augmented/train_00227_1.1.wav',\n",
       " 'array': array([ 0.00036621,  0.00027466,  0.00027466, ..., -0.01113892,\n",
       "        -0.05032349, -0.04394531]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']['audio'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:08.564777800Z",
     "start_time": "2023-05-20T12:13:54.509565700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/3000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe6d6f2e7aa24f75aa8f3b374484c759"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map (num_proc=4):   0%|          | 0/750 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fec3f794a076489abf0a46d5dc093477"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    model_name = 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'\n",
    "    from transformers import Wav2Vec2Processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    batch[\"input_values\"] = [processor(audio[\"array\"], sampling_rate=16000).input_values for audio in batch[\"audio\"]]\n",
    "    batch[\"input_length\"] = [len(b) for b in batch[\"input_values\"]]\n",
    "    batch['length'] = batch[\"input_length\"]\n",
    "    batch[\"labels\"] = processor(text=batch[\"annotation\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "\n",
    "ds = ds.map(prepare_dataset, num_proc=4, batched=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:08.578777700Z",
     "start_time": "2023-05-20T12:15:08.564777800Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:09.976695100Z",
     "start_time": "2023-05-20T12:15:08.581778400Z"
    }
   },
   "outputs": [],
   "source": [
    "wer = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    return {\"wer\": wer.compute(predictions=pred_str, references=label_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:17.579019Z",
     "start_time": "2023-05-20T12:15:13.863470600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Wav2Vec2ConformerForCTC.from_pretrained(\n",
    "    checkpoint_name,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    mask_time_prob=0.5,  # 0.05\n",
    "    mask_time_length=10, # 10\n",
    "    mask_feature_prob=0.5, # 0\n",
    "    mask_feature_length=10, # 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:17.589020600Z",
     "start_time": "2023-05-20T12:15:17.567020Z"
    }
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:17.641019900Z",
     "start_time": "2023-05-20T12:15:17.583020300Z"
    }
   },
   "outputs": [],
   "source": [
    "per_gpu_bs = 4\n",
    "effective_bs = 32\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    overwrite_output_dir =True,\n",
    "    per_device_train_batch_size=per_gpu_bs,\n",
    "    gradient_accumulation_steps=math.ceil(effective_bs/per_gpu_bs),\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=20,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=True,\n",
    "    # bf16=True,  # for A100\n",
    "    fp16_full_eval=True,\n",
    "    # bf16_full_eval=True,  # for A100\n",
    "    group_by_length=True,  # slows down\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='epoch',  # epoch\n",
    "    save_safetensors=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_steps=1,\n",
    "    eval_steps=1,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=3,\n",
    "    lr_scheduler_type='cosine',\n",
    "    load_best_model_at_end=True,  # True\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,  # follow fairseq fintuning config\n",
    "    warmup_ratio=0.22, # follow Ranger21\n",
    "    weight_decay=1e-4,  # follow Ranger21\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    report_to=['tensorboard'],\n",
    "    dataloader_num_workers=24 if os.name != 'nt' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:19.461630800Z",
     "start_time": "2023-05-20T12:15:19.440063300Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTCTrainer(Trainer):\n",
    "    def training_step(self, model: torch.nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a training step on a batch of inputs.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to train.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "\n",
    "        Return:\n",
    "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "        \"\"\"\n",
    "\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "        if os.name != 'nt':\n",
    "            # accelerator.backward(self.scaler.scale(loss))\n",
    "            self.scaler.scale(loss).backward()\n",
    "        else:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        return loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:20.178706800Z",
     "start_time": "2023-05-20T12:15:20.170706800Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name != 'nt':\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision='fp16', dynamo_backend='eager')  # FP8 needs transformer_engine package which is only on Linux with Hopper GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:21.107534Z",
     "start_time": "2023-05-20T12:15:21.086535600Z"
    }
   },
   "outputs": [],
   "source": [
    "def tri_stage_schedule(epoch: int, max_epoch = training_args.num_train_epochs, stage_ratio = [0.1, 0.4, 0.5], peak_lr = training_args.learning_rate, initial_lr_scale=0.01, final_lr_scale=0.05):\n",
    "    \"\"\"https://github.com/facebookresearch/fairseq/blob/5ecbbf58d6e80b917340bcbf9d7bdbb539f0f92b/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py#L51\"\"\"\n",
    "    assert sum(stage_ratio) == 1\n",
    "    current_ratio = epoch / max_epoch\n",
    "    if current_ratio < stage_ratio[0]:  # linear warmup\n",
    "        lrs = torch.linspace(initial_lr_scale * peak_lr, peak_lr, int(stage_ratio[0] * max_epoch))\n",
    "        return lrs[epoch]\n",
    "    elif stage_ratio[0] <= current_ratio <= stage_ratio[1]:  # constant\n",
    "        return peak_lr\n",
    "    else:  # exponential decay\n",
    "        decay_factor = -math.log(final_lr_scale) / (stage_ratio[2] * max_epoch)\n",
    "        return peak_lr * math.exp(-decay_factor * stage_ratio[2] * max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T12:15:31.059528900Z",
     "start_time": "2023-05-20T12:15:23.443773400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m────────────────────────────── \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m ───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m:\u001B[94m1132\u001B[0m in \u001B[92m_try_get_data\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1129 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# Returns a 2-tuple:\u001B[0m                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1130 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1131 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1132 \u001B[2m│   │   │   \u001B[0mdata = \u001B[96mself\u001B[0m._data_queue.get(timeout=timeout)                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1133 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m (\u001B[94mTrue\u001B[0m, data)                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1134 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mexcept\u001B[0m \u001B[96mException\u001B[0m \u001B[94mas\u001B[0m e:                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1135 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# At timeout and error, we manually check whether any worker has\u001B[0m              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\queue.py\u001B[0m:\u001B[94m179\u001B[0m in \u001B[92mget\u001B[0m                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m176 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mwhile\u001B[0m \u001B[95mnot\u001B[0m \u001B[96mself\u001B[0m._qsize():                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m177 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mremaining = endtime - time()                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m178 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mif\u001B[0m remaining <= \u001B[94m0.0\u001B[0m:                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m179 \u001B[2m│   │   │   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m Empty                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m180 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.not_empty.wait(remaining)                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m181 \u001B[0m\u001B[2m│   │   │   \u001B[0mitem = \u001B[96mself\u001B[0m._get()                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m182 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.not_full.notify()                                                         \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mEmpty\u001B[0m\n\n\u001B[3mThe above exception was the direct cause of the following exception:\u001B[0m\n\n\u001B[31m╭─\u001B[0m\u001B[31m────────────────────────────── \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m ───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_36612\\1868896236.py\u001B[0m:\u001B[94m21\u001B[0m in \u001B[92m<module>\u001B[0m                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: \u001B[0m                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_36612\\\\1868896236.py'\u001B[0m                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1664\u001B[0m in \u001B[92mtrain\u001B[0m                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1661 \u001B[0m\u001B[2m│   │   \u001B[0minner_training_loop = find_executable_batch_size(                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1662 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._inner_training_loop, \u001B[96mself\u001B[0m._train_batch_size, args.auto_find_batch_size  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1663 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1664 \u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m inner_training_loop(                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1665 \u001B[0m\u001B[2m│   │   │   \u001B[0margs=args,                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1666 \u001B[0m\u001B[2m│   │   │   \u001B[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1667 \u001B[0m\u001B[2m│   │   │   \u001B[0mtrial=trial,                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py\u001B[0m:\u001B[94m1909\u001B[0m in \u001B[92m_inner_training_loop\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1906 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mrng_to_sync = \u001B[94mTrue\u001B[0m                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1907 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1908 \u001B[0m\u001B[2m│   │   │   \u001B[0mstep = -\u001B[94m1\u001B[0m                                                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1909 \u001B[2m│   │   │   \u001B[0m\u001B[94mfor\u001B[0m step, inputs \u001B[95min\u001B[0m \u001B[96menumerate\u001B[0m(epoch_iterator):                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1910 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mtotal_batched_samples += \u001B[94m1\u001B[0m                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1911 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m rng_to_sync:                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1912 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._load_rng_state(resume_from_checkpoint)                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m:\u001B[94m633\u001B[0m in \u001B[92m__next__\u001B[0m       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 630 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._sampler_iter \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 631 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 632 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._reset()  \u001B[2m# type: ignore[call-arg]\u001B[0m                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 633 \u001B[2m│   │   │   \u001B[0mdata = \u001B[96mself\u001B[0m._next_data()                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 634 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._num_yielded += \u001B[94m1\u001B[0m                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 635 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._dataset_kind == _DatasetKind.Iterable \u001B[95mand\u001B[0m \\                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 636 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._IterableDataset_len_called \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[95mand\u001B[0m \\                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m:\u001B[94m1328\u001B[0m in \u001B[92m_next_data\u001B[0m    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1325 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._process_data(data)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1326 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1327 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94massert\u001B[0m \u001B[95mnot\u001B[0m \u001B[96mself\u001B[0m._shutdown \u001B[95mand\u001B[0m \u001B[96mself\u001B[0m._tasks_outstanding > \u001B[94m0\u001B[0m                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1328 \u001B[2m│   │   │   \u001B[0midx, data = \u001B[96mself\u001B[0m._get_data()                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1329 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._tasks_outstanding -= \u001B[94m1\u001B[0m                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1330 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m._dataset_kind == _DatasetKind.Iterable:                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1331 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# Check for _IterableDatasetStopIteration\u001B[0m                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m:\u001B[94m1284\u001B[0m in \u001B[92m_get_data\u001B[0m     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1281 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mRuntimeError\u001B[0m(\u001B[33m'\u001B[0m\u001B[33mDataLoader timed out after \u001B[0m\u001B[33m{}\u001B[0m\u001B[33m seconds\u001B[0m\u001B[33m'\u001B[0m.format(\u001B[96mself\u001B[0m._  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1282 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melif\u001B[0m \u001B[96mself\u001B[0m._pin_memory:                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1283 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwhile\u001B[0m \u001B[96mself\u001B[0m._pin_memory_thread.is_alive():                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1284 \u001B[2m│   │   │   │   \u001B[0msuccess, data = \u001B[96mself\u001B[0m._try_get_data()                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1285 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m success:                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1286 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m data                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1287 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[33mC:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m:\u001B[94m1145\u001B[0m in \u001B[92m_try_get_data\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1142 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._mark_worker_as_unavailable(worker_id)                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1143 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mlen\u001B[0m(failed_workers) > \u001B[94m0\u001B[0m:                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1144 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mpids_str = \u001B[33m'\u001B[0m\u001B[33m, \u001B[0m\u001B[33m'\u001B[0m.join(\u001B[96mstr\u001B[0m(w.pid) \u001B[94mfor\u001B[0m w \u001B[95min\u001B[0m failed_workers)                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1145 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mRuntimeError\u001B[0m(\u001B[33m'\u001B[0m\u001B[33mDataLoader worker (pid(s) \u001B[0m\u001B[33m{}\u001B[0m\u001B[33m) exited unexpectedly\u001B[0m\u001B[33m'\u001B[0m.f  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1146 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96misinstance\u001B[0m(e, queue.Empty):                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1147 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m (\u001B[94mFalse\u001B[0m, \u001B[94mNone\u001B[0m)                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1148 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mimport\u001B[0m \u001B[4;96mtempfile\u001B[0m                                                               \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mRuntimeError: \u001B[0mDataLoader worker \u001B[1m(\u001B[0m\u001B[1;35mpid\u001B[0m\u001B[1m(\u001B[0ms\u001B[1m)\u001B[0m \u001B[1;36m15792\u001B[0m\u001B[1m)\u001B[0m exited unexpectedly\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1132</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_get_data</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   # Returns a 2-tuple:</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   #   (bool: whether successfully get data, any: data if successful else None)</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1132 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_queue.get(timeout=timeout)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, data)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1135 │   │   │   # At timeout and error, we manually check whether any worker has</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\queue.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">179</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._qsize():                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   │   │   │   </span>remaining = endtime - time()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> remaining &lt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span>:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>179 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> Empty                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.not_empty.wait(remaining)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 │   │   │   </span>item = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.not_full.notify()                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Empty</span>\n\n<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n\n<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_36612\\1868896236.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_36612\\\\1868896236.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1909</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1906 │   │   │   │   </span>rng_to_sync = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1907 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1908 │   │   │   </span>step = -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1909 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> step, inputs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(epoch_iterator):                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1910 │   │   │   │   </span>total_batched_samples += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1911 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> rng_to_sync:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1912 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._load_rng_state(resume_from_checkpoint)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 632 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 636 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1328</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1325 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_data(data)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1326 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1327 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._shutdown <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1328 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>idx, data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_data()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1329 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding -= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1330 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable:                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1331 │   │   │   │   # Check for _IterableDatasetStopIteration</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1284</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_data</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1281 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'DataLoader timed out after {} seconds'</span>.format(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1282 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1283 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_thread.is_alive():                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1284 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>success, data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._try_get_data()                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1285 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> success:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1286 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1287 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_get_data</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._mark_worker_as_unavailable(worker_id)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(failed_workers) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 │   │   │   │   </span>pids_str = <span style=\"color: #808000; text-decoration-color: #808000\">', '</span>.join(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(w.pid) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> w <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> failed_workers)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'DataLoader worker (pid(s) {}) exited unexpectedly'</span>.f  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(e, queue.Empty):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tempfile</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>DataLoader worker <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">pid</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15792</span><span style=\"font-weight: bold\">)</span> exited unexpectedly\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_steps = math.ceil(training_args.num_train_epochs * len(ds['train']) / training_args.gradient_accumulation_steps / min(training_args.per_device_train_batch_size, len(ds['train'])))\n",
    "# optimizer = Ranger21(model.parameters(), num_iterations=max_steps, lr=1e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-8, foreach=False)  # https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/finetuning/base_960h.yaml\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_steps)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=tri_stage_schedule)  # following FAIR finetuning settings\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: x)  # constant LR, stays same throughout, for Ranger21\n",
    "\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds['test'],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # optimizers=(optimizer, scheduler),\n",
    ")\n",
    "if os.name != 'nt':  # windows does not support torch.compile yet\n",
    "    # pass\n",
    "    trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler = accelerator.prepare(trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler)\n",
    "trainer.train()\n",
    "if os.name != 'nt':\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T02:59:21.148781100Z",
     "start_time": "2023-05-15T02:59:19.861964700Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name != 'nt':\n",
    "    trainer.model_wrapped = accelerator.unwrap_model(trainer.model_wrapped)\n",
    "trainer.save_model('wav2vec2-conformer')\n",
    "processor.tokenizer.save_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T10:54:22.540466800Z",
     "start_time": "2023-05-15T10:54:10.025365900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('checkpoints/checkpoint-7500/tokenizer_config.json',\n",
       " 'checkpoints/checkpoint-7500/special_tokens_map.json',\n",
       " 'checkpoints/checkpoint-7500/vocab.json',\n",
       " 'checkpoints/checkpoint-7500/added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "processor = Wav2Vec2Processor.from_pretrained('wav2vec2-conformer')\n",
    "processor.tokenizer.save_pretrained('checkpoints/checkpoint-7500/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T10:52:01.892552800Z",
     "start_time": "2023-05-20T10:51:54.231627400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheongalc/venvs/til2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Infer\n",
    "import os\n",
    "os.environ['HF_HOME'] = 'huggingface'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = 'True'\n",
    "import torch\n",
    "import datasets\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T10:52:10.801055200Z",
     "start_time": "2023-05-20T10:52:01.894553400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 12000/12000 [00:00<00:00, 33704.82it/s] \n",
      "Found cached dataset audiofolder (/home/cheongalc/Documents/til2023/ASR/huggingface/datasets/audiofolder/test-8dce195738f280cb/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"test\", split=\"train\")\n",
    "dataset = KeyDataset(KeyDataset(dataset, \"audio\"), \"array\")\n",
    "test_ds = pd.read_csv('Test_Advanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-20T10:52:10.814054900Z",
     "start_time": "2023-05-20T10:52:10.799056200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(annotation):\n",
    "    if \"'\" in annotation:\n",
    "        # print(annotation, f'has \\' in {annotation}, removing')\n",
    "        annotation = annotation.split(\"'\")[0] + annotation.split(\"'\")[1][1:]  # Tokenizer includes \"'\" but TIL dataset does not, remove the S following '\n",
    "    return annotation\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_values = processor(batch, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    return {\"input_values\": input_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-20T10:52:10.817055400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 46/375 [01:38<12:37,  2.30s/it]"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2-conformer\")\n",
    "data_loader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn, pin_memory=True, num_workers=4 if os.name == 'nt' else 0)\n",
    "checkpoint1 = 'checkpoints/checkpoint-2250 aug lb 0.0267'\n",
    "checkpoint2 = 'checkpoints/checkpoint-7500'\n",
    "model1 = Wav2Vec2ConformerForCTC.from_pretrained(checkpoint1).to('cuda')\n",
    "model2 = Wav2Vec2ConformerForCTC.from_pretrained(checkpoint2).to('cuda')\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "logits1 = []\n",
    "logits2 = []\n",
    "logits = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(data_loader):\n",
    "        inputs = batch['input_values'].to('cuda')\n",
    "        outputs1 = model1(**inputs).logits\n",
    "        outputs2 = model2(**inputs).logits\n",
    "        logits1.append(outputs1)\n",
    "        logits2.append(outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = [(l1 + l2) / 2 for l1, l2 in zip(logits1, logits2)]\n",
    "results = []\n",
    "for l in logits:\n",
    "    results.extend(processor.batch_decode(torch.argmax(l, dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ds['annotation'] = list(map(clean, results))\n",
    "test_ds['path'] = test_ds['path'].apply(lambda x: x.split('/')[-1])\n",
    "test_ds.to_csv('Test_Advanced_6750_0.0205.csv', index=False)  # change file name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
