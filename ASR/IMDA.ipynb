{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:47:38.234578600Z",
     "start_time": "2023-05-18T13:47:37.817578800Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "from string import ascii_uppercase\n",
    "import pydub\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def clean(annotation):\n",
    "    annotation = annotation.replace(\"'\", '').upper()  # removes ' as TIL data does not include it, change to all upper case as Wav2Vec2 tokenizer requires\n",
    "    for c in annotation:  # replace all non ascii uppercase characters per TIL dataset\n",
    "        if c not in ascii_uppercase + ' ':\n",
    "            annotation = annotation.replace(c, '')\n",
    "    return annotation.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:47:38.297045400Z",
     "start_time": "2023-05-18T13:47:38.282578Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def IMDA_part12_to_TIL(part: int):\n",
    "    PART_PATH = f'IMDA/part{part}/DATA/CHANNEL0'\n",
    "    if part == 1:\n",
    "        part = 0  # IMDA names all part 1 files with leading 0\n",
    "    WAVE_PATH = os.path.join(PART_PATH, 'WAVE')\n",
    "    SCRIPT_PATH = os.path.join(PART_PATH, 'SCRIPT')\n",
    "\n",
    "    script_files = glob.glob(os.path.join(SCRIPT_PATH, '*.TXT'))\n",
    "\n",
    "    for script in tqdm.tqdm(script_files):\n",
    "        speaker = os.path.basename(script).split('.')[0][-2]\n",
    "        session = os.path.basename(script).split('.')[0][-1]\n",
    "        speaker_prefix = f'SPEAKER{part}{speaker.zfill(3)}'\n",
    "        zip_file = speaker_prefix + '.zip'\n",
    "        wav_root = os.path.join(speaker_prefix, f'SESSION{session}')\n",
    "        with open(script, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            processed_lines = []\n",
    "            for i in range(0, len(lines), 2):\n",
    "                processed_lines.append(lines[i].split('\\t')[0] + ' ' + lines[i+1].replace('\\t', ' ').strip())\n",
    "            processed_lines = [l.replace(chr(0xfeff), '').strip() for l in processed_lines]  # remove \\ufeff which appears at the start of txt\n",
    "        with ZipFile(os.path.join(WAVE_PATH, zip_file), 'r') as zip:\n",
    "            for line in processed_lines:\n",
    "                wav_fname = line.split(' ')[0] + '.WAV'\n",
    "                data = zip.read(os.path.join(wav_root, wav_fname).replace('\\\\', '/'))\n",
    "                audio = pydub.AudioSegment(data)\n",
    "                annotation = ' '.join(line.split(' ')[1:])\n",
    "                annotation = clean(annotation)\n",
    "                if len(annotation.split()) >= 2 and 16000 * 2 < len(audio) < 16000 * 10:  # ignore all audio longer than 10 seconds and shorter than 2 second and single word audio\n",
    "                    os.makedirs(f'IMDA_TIL/audio_part{part}', exist_ok=True)\n",
    "                    target_path = os.path.join(f'IMDA_TIL/audio_part{part}', wav_fname).replace('\\\\', '/')\n",
    "                    audio.export(target_path, format='wav')\n",
    "                    dataset.append({'path': target_path, 'annotation': annotation})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:18:06.848891900Z",
     "start_time": "2023-05-18T13:18:06.832890400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dataset = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:47:46.028583200Z",
     "start_time": "2023-05-18T13:47:46.017735500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "IMDA_part12_to_TIL(1)\n",
    "# IMDA_part12_to_TIL(2)  # part 2 is full of SG names, not considered english"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:18:31.204224300Z",
     "start_time": "2023-05-18T13:18:31.197225500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def TextGridToTIL(wav_path, script_path, part: int):\n",
    "    WAV_PATH = wav_path\n",
    "    SCRIPT_PATH = script_path\n",
    "    script_files = glob.glob(os.path.join(SCRIPT_PATH, '*.TextGrid'))\n",
    "    for script in tqdm.tqdm(script_files):\n",
    "        base_name = os.path.basename(script).split('.')[0]\n",
    "        wav_fname = base_name + '.wav'\n",
    "        wav_path = os.path.join(WAV_PATH, wav_fname)\n",
    "        textgrid = textgrids.TextGrid(script)\n",
    "        for _ in textgrid.keys():  # just get the first key since there is only 1 all the time but name changes\n",
    "            textgrid = textgrid[_]\n",
    "            break\n",
    "        timeline = []\n",
    "        for interval in textgrid:\n",
    "            if interval.text != '<Z>':\n",
    "                text = interval.text\n",
    "                text = clean(text)\n",
    "                if len(text.split()) >= 2 and 2 < interval.xmax - interval.xmin < 10:  # ignore all audio longer than 10 seconds and shorter than 2 second and single word audio\n",
    "                    timeline.append({'start': interval.xmin, 'end': interval.xmax, 'text': text})\n",
    "        if not os.path.isfile(wav_path):\n",
    "            if part == 6:\n",
    "                continue  # part 6 folder structure means not all audio files can be found within the same wav folder that this function is being called with\n",
    "            else:\n",
    "                raise FileNotFoundError(f'{wav_path} not found')\n",
    "\n",
    "        audio = pydub.AudioSegment.from_wav(wav_path)\n",
    "        i = 0\n",
    "        for interval in timeline:\n",
    "            start = int(interval['start'] * 1000)\n",
    "            end = int(interval['end'] * 1000)\n",
    "            annotation = interval['text']\n",
    "            os.makedirs(f'IMDA_TIL/audio_part{part}', exist_ok=True)\n",
    "            target_path = os.path.join(f'IMDA_TIL/audio_part{part}', base_name + str(i) + '.wav').replace('\\\\', '/')\n",
    "            audio[start:end].export(target_path, format='wav')\n",
    "            dataset.append({'path': target_path, 'annotation': annotation})\n",
    "            i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:04:31.916595900Z",
     "start_time": "2023-05-18T14:04:31.897755100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TextGridToTIL('IMDA/PART3/Audio Separate StandingMic', 'IMDA/PART3/Scripts Separate', 3)\n",
    "TextGridToTIL('IMDA/PART3/Audio Same CloseMic', 'IMDA/PART3/Scripts Same', 3)\n",
    "TextGridToTIL('IMDA/PART5/Debate Audio', 'IMDA/PART5/Debate Scripts', 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.60it/s]\u001B[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# part 5 finance + emotion is a bit different audio folder structure\n",
    "def IMDA_part5_to_TIL(wav_path, script_path):\n",
    "    speaker_folders = os.listdir(wav_path)\n",
    "    for speaker_folder in tqdm.tqdm(speaker_folders):\n",
    "        speaker_path = os.path.join(wav_path, speaker_folder)\n",
    "        TextGridToTIL(speaker_path, script_path, 5)\n",
    "\n",
    "IMDA_part5_to_TIL('IMDA/PART5/Finance + Emotion Audio', 'IMDA/PART5/Finance + Emotion Scripts')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:47:48.441802600Z",
     "start_time": "2023-05-18T13:47:48.315241500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 104.14it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 50.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 29.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# part 6 different audio folder structure\n",
    "wav_folders = glob.glob('IMDA/PART6/Call Centre Design */Audio/*/*/')\n",
    "for wav_folder in tqdm.tqdm(wav_folders):\n",
    "    wav_folder = wav_folder.replace('\\\\', '/')\n",
    "    script_folder = wav_folder.split('Audio')[0] + 'Scripts/'\n",
    "    TextGridToTIL(wav_folder, script_folder, 6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:04:34.997727700Z",
     "start_time": "2023-05-18T14:04:34.919884700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "print(len(df))\n",
    "df.to_csv('IMDA_TIL/IMDA_TIL.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T14:04:44.489805800Z",
     "start_time": "2023-05-18T14:04:44.485806600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
