{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:15:55.035400300Z",
     "start_time": "2023-05-15T05:15:47.954973100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:42:23.058216: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = 'huggingface'\n",
    "os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = 'True'\n",
    "import math\n",
    "from datasets import Audio, Dataset, DatasetDict\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC, TrainingArguments, Trainer, Wav2Vec2ForCTC\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_optimizer import Ranger21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:15:55.050538300Z",
     "start_time": "2023-05-15T05:15:55.037401300Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name= 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:15:55.612522900Z",
     "start_time": "2023-05-15T05:15:55.050538300Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:15:55.627522400Z",
     "start_time": "2023-05-15T05:15:55.613523700Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_df = pd.read_csv('Train.csv')\n",
    "train_df, val_df = train_test_split(ds_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:15:55.647539900Z",
     "start_time": "2023-05-15T05:15:55.629524200Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:15.590680100Z",
     "start_time": "2023-05-15T05:15:55.644537600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
      "  warnings.warn(\n",
      "num_proc must be <= 2. Reducing num_proc to 2 for dataset of size 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = train_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "val_ds = val_ds.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "ds = DatasetDict({'train': train_ds, 'val': val_ds})\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    model_name = 'facebook/wav2vec2-conformer-rel-pos-large-960h-ft'\n",
    "    from transformers import Wav2Vec2Processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    audio = batch[\"path\"]\n",
    "    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"annotation\"])\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n",
    "    return batch\n",
    "\n",
    "ds = ds.map(prepare_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:15.605693300Z",
     "start_time": "2023-05-15T05:16:15.590680100Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = \"longest\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:16.955935600Z",
     "start_time": "2023-05-15T05:16:15.605693300Z"
    }
   },
   "outputs": [],
   "source": [
    "wer = evaluate.load(\"wer\")\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    return {\"wer\": wer.compute(predictions=pred_str, references=label_str)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.256218Z",
     "start_time": "2023-05-15T05:16:16.955935600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Wav2Vec2ConformerForCTC.from_pretrained(\n",
    "    model_name,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.269230400Z",
     "start_time": "2023-05-15T05:16:21.257219100Z"
    }
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.318269600Z",
     "start_time": "2023-05-15T05:16:21.270230500Z"
    }
   },
   "outputs": [],
   "source": [
    "per_gpu_bs = 8\n",
    "effective_bs = 32\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    overwrite_output_dir =True,\n",
    "    per_device_train_batch_size=per_gpu_bs,\n",
    "    gradient_accumulation_steps=math.ceil(effective_bs/per_gpu_bs),\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=100,\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='no',  # epoch\n",
    "    save_safetensors=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_steps=1,\n",
    "    eval_steps=1,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=3,\n",
    "    lr_scheduler_type='cosine',\n",
    "    load_best_model_at_end=False,  # True\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,  # follow fairseq fintuning config\n",
    "    warmup_ratio=0.22, # follow Ranger21\n",
    "    weight_decay=1e-4,  # follow Ranger21\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    fp16_full_eval=True,\n",
    "    torch_compile=os.name!='nt',\n",
    "    report_to=['tensorboard'],\n",
    "    torch_compile_backend='inductor' if os.name != 'nt' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.333283300Z",
     "start_time": "2023-05-15T05:16:21.318269600Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTCTrainer(Trainer):\n",
    "    def training_step(self, model: torch.nn.Module, inputs: Dict[str, Union[torch.Tensor, Any]]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a training step on a batch of inputs.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to train.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "\n",
    "        Return:\n",
    "            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n",
    "        \"\"\"\n",
    "\n",
    "        model.train()\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "\n",
    "        if self.args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "        if os.name != 'nt':\n",
    "            accelerator.backward(self.scaler.scale(loss))\n",
    "        else:\n",
    "            self.scaler.scale(loss).backward()\n",
    "        return loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.353301700Z",
     "start_time": "2023-05-15T05:16:21.333283300Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.name != 'nt':\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision='fp16', dynamo_backend='eager')  # FP8 needs transformer_engine package which is only on Linux with Hopper GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:16:21.365312Z",
     "start_time": "2023-05-15T05:16:21.353301700Z"
    }
   },
   "outputs": [],
   "source": [
    "def tri_stage_schedule(epoch: int, max_epoch = training_args.num_train_epochs, stage_ratio = [0.1, 0.4, 0.5], peak_lr = training_args.learning_rate, initial_lr_scale=0.01, final_lr_scale=0.05):\n",
    "    \"\"\"https://github.com/facebookresearch/fairseq/blob/5ecbbf58d6e80b917340bcbf9d7bdbb539f0f92b/fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py#L51\"\"\"\n",
    "    assert sum(stage_ratio) == 1\n",
    "    current_ratio = epoch / max_epoch\n",
    "    if current_ratio < stage_ratio[0]:  # linear warmup\n",
    "        lrs = torch.linspace(initial_lr_scale * peak_lr, peak_lr, int(stage_ratio[0] * max_epoch))\n",
    "        return lrs[epoch]\n",
    "    elif stage_ratio[0] <= current_ratio <= stage_ratio[1]:  # constant\n",
    "        return peak_lr\n",
    "    else:  # exponential decay\n",
    "        decay_factor = -math.log(final_lr_scale) / (stage_ratio[2] * max_epoch)\n",
    "        return peak_lr * math.exp(-decay_factor * stage_ratio[2] * max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T05:17:09.004018400Z",
     "start_time": "2023-05-15T05:16:21.366312500Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# windows does not support torch.compile yet\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mmodel, trainer\u001b[38;5;241m.\u001b[39moptimizer, trainer\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;241m=\u001b[39m accelerator\u001b[38;5;241m.\u001b[39mprepare(trainer\u001b[38;5;241m.\u001b[39mmodel_wrapped, trainer\u001b[38;5;241m.\u001b[39moptimizer, trainer\u001b[38;5;241m.\u001b[39mlr_scheduler)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     22\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mwait_for_everyone()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1664\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1661\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1662\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1663\u001b[0m )\n\u001b[0;32m-> 1664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1909\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1910\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mDataCollatorCTCWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Union[List[\u001b[38;5;28mint\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# split inputs and labels since they have to be of different lengths and need\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# different padding methods\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     10\u001b[0m     label_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     12\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mpad(input_features, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Union[List[\u001b[38;5;28mint\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# split inputs and labels since they have to be of different lengths and need\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# different padding methods\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfeature\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     10\u001b[0m     label_features \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]} \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     12\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mpad(input_features, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'input_values'"
     ]
    }
   ],
   "source": [
    "max_steps = math.ceil(training_args.num_train_epochs * len(ds['train']) / training_args.gradient_accumulation_steps / min(training_args.per_device_train_batch_size, len(ds['train'])))\n",
    "# optimizer = Ranger21(model.parameters(), num_iterations=max_steps)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-8, foreach=False)  # https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/finetuning/base_960h.yaml\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_steps)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=tri_stage_schedule)  # following FAIR finetuning settings\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: x)  # constant LR, stays same throughout, for Ranger21\n",
    "\n",
    "trainer = CTCTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds['val'],\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n",
    "if os.name != 'nt':  # windows does not support torch.compile yet\n",
    "    trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler = accelerator.prepare(trainer.model_wrapped, trainer.optimizer, trainer.lr_scheduler)\n",
    "trainer.train()\n",
    "if os.name != 'nt':\n",
    "    accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T02:59:21.148781100Z",
     "start_time": "2023-05-15T02:59:19.861964700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wav2vec2-conformer\\\\tokenizer_config.json',\n",
       " 'wav2vec2-conformer\\\\special_tokens_map.json',\n",
       " 'wav2vec2-conformer\\\\vocab.json',\n",
       " 'wav2vec2-conformer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if os.name != 'nt':\n",
    "#     trainer.model_wrapped = accelerator.unwrap_model(trainer.model_wrapped)\n",
    "trainer.save_model('wav2vec2-conformer')\n",
    "processor.tokenizer.save_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-15T10:54:22.540466800Z",
     "start_time": "2023-05-15T10:54:10.025365900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type wav2vec2 to instantiate a model of type wav2vec2-conformer. This is not supported for all configurations of models and can yield errors.\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2777</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2774 │   │   │   │   </span>mismatched_keys,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2775 │   │   │   │   </span>offload_index,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2776 │   │   │   │   </span>error_msgs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2777 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._load_pretrained_model(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2778 │   │   │   │   </span>model,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2779 │   │   │   │   </span>state_dict,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2780 │   │   │   │   </span>loaded_state_dict_keys,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># XXX: rename?</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3003</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_pretrained_model</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3000 │   │   │   </span>model_to_load = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.base_model_prefix)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3001 │   │   │   </span>base_model_expected_keys = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(model_to_load.state_dict().keys())            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3002 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">any</span>(key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> expected_keys_not_prefixed <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> base_model_expected_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3003 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3004 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The state dictionary of the model you are trying to load is corrupt</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3005 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"properly saved?\"</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\alien\\AppData\\Local\\Temp\\ipykernel_6308\\2135182543.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\alien\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6308\\\\2135182543.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m:\u001b[94m2777\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2774 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmismatched_keys,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2775 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moffload_index,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2776 \u001b[0m\u001b[2m│   │   │   │   \u001b[0merror_msgs,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2777 \u001b[2m│   │   │   \u001b[0m) = \u001b[96mcls\u001b[0m._load_pretrained_model(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2778 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2779 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstate_dict,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2780 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mloaded_state_dict_keys,  \u001b[2m# XXX: rename?\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m:\u001b[94m3003\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_load_pretrained_model\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3000 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_to_load = \u001b[96mgetattr\u001b[0m(model, \u001b[96mcls\u001b[0m.base_model_prefix)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3001 \u001b[0m\u001b[2m│   │   │   \u001b[0mbase_model_expected_keys = \u001b[96mlist\u001b[0m(model_to_load.state_dict().keys())            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3002 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96many\u001b[0m(key \u001b[95min\u001b[0m expected_keys_not_prefixed \u001b[95mand\u001b[0m key \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m base_model_expected_  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3003 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3004 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe state dictionary of the model you are trying to load is corrupt\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3005 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mproperly saved?\u001b[0m\u001b[33m\"\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3006 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mThe state dictionary of the model you are trying to load is corrupted. Are you sure it was properly \n",
       "saved?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ConformerForCTC\n",
    "model = Wav2Vec2ConformerForCTC.from_pretrained('wav2vec2-conformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:28.955063300Z",
     "start_time": "2023-05-14T17:20:25.712694400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    }
   ],
   "source": [
    "# Infer\n",
    "from transformers import pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"wav2vec2-conformer\")\n",
    "def predict(audio_file):\n",
    "    r = transcriber(audio_file)['text'].upper()\n",
    "    if \"'\" in r:\n",
    "        print(audio_file, f'has \\' in {r}, removing')\n",
    "        r = r.replace(\"'\", '')  # Tokenizer includes \"'\" but TIL dataset does not\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T17:20:34.398434200Z",
     "start_time": "2023-05-14T17:20:28.957065400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv('Test_Advanced.csv')\n",
    "test_ds['annotation'] = test_ds['path'].map(predict)\n",
    "test_ds.to_csv('Test_Advanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
