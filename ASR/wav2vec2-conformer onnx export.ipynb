{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-28T10:35:23.009157700Z",
     "start_time": "2023-05-28T10:35:22.993158200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ConformerForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    },
    {
     "data": {
      "text/plain": "Wav2Vec2ConformerForCTC(\n  (wav2vec2_conformer): Wav2Vec2ConformerModel(\n    (feature_extractor): Wav2Vec2ConformerFeatureEncoder(\n      (conv_layers): ModuleList(\n        (0): Wav2Vec2ConformerLayerNormConvLayer(\n          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (1-4): 4 x Wav2Vec2ConformerLayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n        (5-6): 2 x Wav2Vec2ConformerLayerNormConvLayer(\n          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation): GELUActivation()\n        )\n      )\n    )\n    (feature_projection): Wav2Vec2ConformerFeatureProjection(\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (projection): Linear(in_features=512, out_features=1024, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): Wav2Vec2ConformerEncoder(\n      (embed_positions): Wav2Vec2ConformerRelPositionalEmbedding()\n      (pos_conv_embed): Wav2Vec2ConformerPositionalConvEmbedding(\n        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n        (padding): Wav2Vec2ConformerSamePadLayer()\n        (activation): GELUActivation()\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (layers): ModuleList(\n        (0-23): 24 x Wav2Vec2ConformerEncoderLayer(\n          (ffn1_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (ffn1): Wav2Vec2ConformerFeedForward(\n            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): SiLUActivation()\n            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (output_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (self_attn_dropout): Dropout(p=0.1, inplace=False)\n          (self_attn): Wav2Vec2ConformerSelfAttention(\n            (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n            (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n            (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n            (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (linear_pos): Linear(in_features=1024, out_features=1024, bias=False)\n          )\n          (conv_module): Wav2Vec2ConformerConvolutionModule(\n            (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n            (glu): GLU(dim=1)\n            (depthwise_conv): Conv1d(1024, 1024, kernel_size=(31,), stride=(1,), padding=(15,), groups=1024, bias=False)\n            (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (activation): SiLUActivation()\n            (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ffn2_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (ffn2): Wav2Vec2ConformerFeedForward(\n            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): SiLUActivation()\n            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (output_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (lm_head): Linear(in_features=1024, out_features=32, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model/checkpoint-1781 lb 0.01351'\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ConformerForCTC.from_pretrained(model_path).to('cuda')\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T10:33:03.665041Z",
     "start_time": "2023-05-28T10:32:59.958039Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 499, 32])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1, 16000*10).cuda()).logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T10:33:03.998038800Z",
     "start_time": "2023-05-28T10:33:03.665041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\transformers\\models\\wav2vec2_conformer\\modeling_wav2vec2_conformer.py:430: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.pe.size(1) >= x.size(1) * 2 - 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 16000*10).cuda()\n",
    "os.makedirs('onnx_model', exist_ok=True)\n",
    "torch.onnx.export(model, x, 'onnx_model/wav2vec2-conformer.onnx',  # will produce many small files due to 2GB limit\n",
    "                  export_params=True,\n",
    "                  verbose=True,\n",
    "                  opset_version=18,  # TensorRT 8.6 supports up to 17, Torch 2.0.1 supports up to 18\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes={'input' : {1 : 'audio_len'}, 'output' : {1 : 'text_len'}},\n",
    "                  keep_initializers_as_inputs=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-28T10:36:08.464632700Z",
     "start_time": "2023-05-28T10:35:37.040624100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
