{
  "best_metric": 0.0028169014084507044,
  "best_model_checkpoint": "/content/drive/MyDrive/TIL 2023/ASR/wav2vec2-checkpoints-a100/checkpoint-9751",
  "epoch": 98.99492385786802,
  "global_step": 9751,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 6.802721088435373e-08,
      "loss": 1.0791,
      "step": 1
    },
    {
      "epoch": 0.02,
      "learning_rate": 1.3605442176870747e-07,
      "loss": 1.2221,
      "step": 2
    },
    {
      "epoch": 0.03,
      "learning_rate": 2.0408163265306124e-07,
      "loss": 0.9894,
      "step": 3
    },
    {
      "epoch": 0.04,
      "learning_rate": 2.7210884353741493e-07,
      "loss": 1.0768,
      "step": 4
    },
    {
      "epoch": 0.05,
      "learning_rate": 3.4013605442176873e-07,
      "loss": 1.0667,
      "step": 5
    },
    {
      "epoch": 0.06,
      "learning_rate": 4.081632653061225e-07,
      "loss": 0.9691,
      "step": 6
    },
    {
      "epoch": 0.07,
      "learning_rate": 4.761904761904763e-07,
      "loss": 1.0753,
      "step": 7
    },
    {
      "epoch": 0.08,
      "learning_rate": 5.442176870748299e-07,
      "loss": 1.0278,
      "step": 8
    },
    {
      "epoch": 0.09,
      "learning_rate": 6.122448979591837e-07,
      "loss": 1.0498,
      "step": 9
    },
    {
      "epoch": 0.1,
      "learning_rate": 6.802721088435375e-07,
      "loss": 0.9078,
      "step": 10
    },
    {
      "epoch": 0.11,
      "learning_rate": 7.482993197278912e-07,
      "loss": 1.1469,
      "step": 11
    },
    {
      "epoch": 0.12,
      "learning_rate": 8.16326530612245e-07,
      "loss": 1.1626,
      "step": 12
    },
    {
      "epoch": 0.13,
      "learning_rate": 8.843537414965988e-07,
      "loss": 1.173,
      "step": 13
    },
    {
      "epoch": 0.14,
      "learning_rate": 9.523809523809526e-07,
      "loss": 1.1268,
      "step": 14
    },
    {
      "epoch": 0.15,
      "learning_rate": 1.020408163265306e-06,
      "loss": 1.1137,
      "step": 15
    },
    {
      "epoch": 0.16,
      "learning_rate": 1.0884353741496597e-06,
      "loss": 1.0949,
      "step": 16
    },
    {
      "epoch": 0.17,
      "learning_rate": 1.1564625850340136e-06,
      "loss": 1.162,
      "step": 17
    },
    {
      "epoch": 0.18,
      "learning_rate": 1.2244897959183673e-06,
      "loss": 1.1959,
      "step": 18
    },
    {
      "epoch": 0.19,
      "learning_rate": 1.292517006802721e-06,
      "loss": 1.2469,
      "step": 19
    },
    {
      "epoch": 0.2,
      "learning_rate": 1.360544217687075e-06,
      "loss": 1.1868,
      "step": 20
    },
    {
      "epoch": 0.21,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 1.3614,
      "step": 21
    },
    {
      "epoch": 0.22,
      "learning_rate": 1.4965986394557823e-06,
      "loss": 1.3097,
      "step": 22
    },
    {
      "epoch": 0.23,
      "learning_rate": 1.5646258503401362e-06,
      "loss": 1.3295,
      "step": 23
    },
    {
      "epoch": 0.24,
      "learning_rate": 1.63265306122449e-06,
      "loss": 1.3799,
      "step": 24
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.7006802721088438e-06,
      "loss": 0.767,
      "step": 25
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.7687074829931975e-06,
      "loss": 0.839,
      "step": 26
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.8367346938775512e-06,
      "loss": 1.025,
      "step": 27
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.9047619047619051e-06,
      "loss": 0.8564,
      "step": 28
    },
    {
      "epoch": 0.29,
      "learning_rate": 1.9727891156462586e-06,
      "loss": 0.8552,
      "step": 29
    },
    {
      "epoch": 0.3,
      "learning_rate": 2.040816326530612e-06,
      "loss": 0.8804,
      "step": 30
    },
    {
      "epoch": 0.31,
      "learning_rate": 2.108843537414966e-06,
      "loss": 0.853,
      "step": 31
    },
    {
      "epoch": 0.32,
      "learning_rate": 2.1768707482993195e-06,
      "loss": 0.9689,
      "step": 32
    },
    {
      "epoch": 0.34,
      "learning_rate": 2.2448979591836734e-06,
      "loss": 0.7779,
      "step": 33
    },
    {
      "epoch": 0.35,
      "learning_rate": 2.3129251700680273e-06,
      "loss": 0.9344,
      "step": 34
    },
    {
      "epoch": 0.36,
      "learning_rate": 2.3809523809523808e-06,
      "loss": 1.1059,
      "step": 35
    },
    {
      "epoch": 0.37,
      "learning_rate": 2.4489795918367347e-06,
      "loss": 0.9511,
      "step": 36
    },
    {
      "epoch": 0.38,
      "learning_rate": 2.5170068027210886e-06,
      "loss": 0.8816,
      "step": 37
    },
    {
      "epoch": 0.39,
      "learning_rate": 2.585034013605442e-06,
      "loss": 0.9186,
      "step": 38
    },
    {
      "epoch": 0.4,
      "learning_rate": 2.653061224489796e-06,
      "loss": 0.8893,
      "step": 39
    },
    {
      "epoch": 0.41,
      "learning_rate": 2.72108843537415e-06,
      "loss": 0.9116,
      "step": 40
    },
    {
      "epoch": 0.42,
      "learning_rate": 2.7891156462585034e-06,
      "loss": 0.8174,
      "step": 41
    },
    {
      "epoch": 0.43,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.9391,
      "step": 42
    },
    {
      "epoch": 0.44,
      "learning_rate": 2.9251700680272107e-06,
      "loss": 0.8812,
      "step": 43
    },
    {
      "epoch": 0.45,
      "learning_rate": 2.9931972789115646e-06,
      "loss": 0.9843,
      "step": 44
    },
    {
      "epoch": 0.46,
      "learning_rate": 3.0612244897959185e-06,
      "loss": 0.9024,
      "step": 45
    },
    {
      "epoch": 0.47,
      "learning_rate": 3.1292517006802725e-06,
      "loss": 1.0521,
      "step": 46
    },
    {
      "epoch": 0.48,
      "learning_rate": 3.197278911564626e-06,
      "loss": 1.0656,
      "step": 47
    },
    {
      "epoch": 0.49,
      "learning_rate": 3.26530612244898e-06,
      "loss": 1.2955,
      "step": 48
    },
    {
      "epoch": 0.5,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.6675,
      "step": 49
    },
    {
      "epoch": 0.51,
      "learning_rate": 3.4013605442176877e-06,
      "loss": 0.5296,
      "step": 50
    },
    {
      "epoch": 0.52,
      "learning_rate": 3.469387755102041e-06,
      "loss": 0.7144,
      "step": 51
    },
    {
      "epoch": 0.53,
      "learning_rate": 3.537414965986395e-06,
      "loss": 0.7357,
      "step": 52
    },
    {
      "epoch": 0.54,
      "learning_rate": 3.6054421768707485e-06,
      "loss": 0.7718,
      "step": 53
    },
    {
      "epoch": 0.55,
      "learning_rate": 3.6734693877551024e-06,
      "loss": 0.6012,
      "step": 54
    },
    {
      "epoch": 0.56,
      "learning_rate": 3.741496598639456e-06,
      "loss": 0.7628,
      "step": 55
    },
    {
      "epoch": 0.57,
      "learning_rate": 3.8095238095238102e-06,
      "loss": 0.8439,
      "step": 56
    },
    {
      "epoch": 0.58,
      "learning_rate": 3.877551020408164e-06,
      "loss": 0.6939,
      "step": 57
    },
    {
      "epoch": 0.59,
      "learning_rate": 3.945578231292517e-06,
      "loss": 0.7669,
      "step": 58
    },
    {
      "epoch": 0.6,
      "learning_rate": 4.013605442176871e-06,
      "loss": 0.8668,
      "step": 59
    },
    {
      "epoch": 0.61,
      "learning_rate": 4.081632653061224e-06,
      "loss": 0.6705,
      "step": 60
    },
    {
      "epoch": 0.62,
      "learning_rate": 4.1496598639455785e-06,
      "loss": 0.7621,
      "step": 61
    },
    {
      "epoch": 0.63,
      "learning_rate": 4.217687074829932e-06,
      "loss": 0.6273,
      "step": 62
    },
    {
      "epoch": 0.64,
      "learning_rate": 4.285714285714286e-06,
      "loss": 0.6344,
      "step": 63
    },
    {
      "epoch": 0.65,
      "learning_rate": 4.353741496598639e-06,
      "loss": 0.7017,
      "step": 64
    },
    {
      "epoch": 0.66,
      "learning_rate": 4.421768707482993e-06,
      "loss": 0.7973,
      "step": 65
    },
    {
      "epoch": 0.67,
      "learning_rate": 4.489795918367347e-06,
      "loss": 0.787,
      "step": 66
    },
    {
      "epoch": 0.68,
      "learning_rate": 4.557823129251701e-06,
      "loss": 0.7971,
      "step": 67
    },
    {
      "epoch": 0.69,
      "learning_rate": 4.6258503401360546e-06,
      "loss": 0.834,
      "step": 68
    },
    {
      "epoch": 0.7,
      "learning_rate": 4.693877551020408e-06,
      "loss": 0.7681,
      "step": 69
    },
    {
      "epoch": 0.71,
      "learning_rate": 4.7619047619047615e-06,
      "loss": 0.7806,
      "step": 70
    },
    {
      "epoch": 0.72,
      "learning_rate": 4.829931972789116e-06,
      "loss": 0.8588,
      "step": 71
    },
    {
      "epoch": 0.73,
      "learning_rate": 4.897959183673469e-06,
      "loss": 1.2474,
      "step": 72
    },
    {
      "epoch": 0.74,
      "learning_rate": 4.965986394557824e-06,
      "loss": 0.3916,
      "step": 73
    },
    {
      "epoch": 0.75,
      "learning_rate": 5.034013605442177e-06,
      "loss": 0.5555,
      "step": 74
    },
    {
      "epoch": 0.76,
      "learning_rate": 5.102040816326531e-06,
      "loss": 0.4776,
      "step": 75
    },
    {
      "epoch": 0.77,
      "learning_rate": 5.170068027210884e-06,
      "loss": 0.5803,
      "step": 76
    },
    {
      "epoch": 0.78,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 0.5676,
      "step": 77
    },
    {
      "epoch": 0.79,
      "learning_rate": 5.306122448979592e-06,
      "loss": 0.5852,
      "step": 78
    },
    {
      "epoch": 0.8,
      "learning_rate": 5.374149659863946e-06,
      "loss": 0.5678,
      "step": 79
    },
    {
      "epoch": 0.81,
      "learning_rate": 5.4421768707483e-06,
      "loss": 0.5978,
      "step": 80
    },
    {
      "epoch": 0.82,
      "learning_rate": 5.510204081632653e-06,
      "loss": 0.5321,
      "step": 81
    },
    {
      "epoch": 0.83,
      "learning_rate": 5.578231292517007e-06,
      "loss": 0.667,
      "step": 82
    },
    {
      "epoch": 0.84,
      "learning_rate": 5.646258503401361e-06,
      "loss": 0.5445,
      "step": 83
    },
    {
      "epoch": 0.85,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.6206,
      "step": 84
    },
    {
      "epoch": 0.86,
      "learning_rate": 5.782312925170069e-06,
      "loss": 0.5985,
      "step": 85
    },
    {
      "epoch": 0.87,
      "learning_rate": 5.8503401360544215e-06,
      "loss": 0.4379,
      "step": 86
    },
    {
      "epoch": 0.88,
      "learning_rate": 5.918367346938776e-06,
      "loss": 0.5666,
      "step": 87
    },
    {
      "epoch": 0.89,
      "learning_rate": 5.986394557823129e-06,
      "loss": 0.6202,
      "step": 88
    },
    {
      "epoch": 0.9,
      "learning_rate": 6.054421768707484e-06,
      "loss": 0.685,
      "step": 89
    },
    {
      "epoch": 0.91,
      "learning_rate": 6.122448979591837e-06,
      "loss": 0.738,
      "step": 90
    },
    {
      "epoch": 0.92,
      "learning_rate": 6.190476190476191e-06,
      "loss": 0.6748,
      "step": 91
    },
    {
      "epoch": 0.93,
      "learning_rate": 6.258503401360545e-06,
      "loss": 0.6282,
      "step": 92
    },
    {
      "epoch": 0.94,
      "learning_rate": 6.3265306122448975e-06,
      "loss": 0.6257,
      "step": 93
    },
    {
      "epoch": 0.95,
      "learning_rate": 6.394557823129252e-06,
      "loss": 0.7045,
      "step": 94
    },
    {
      "epoch": 0.96,
      "learning_rate": 6.462585034013606e-06,
      "loss": 0.814,
      "step": 95
    },
    {
      "epoch": 0.97,
      "learning_rate": 6.53061224489796e-06,
      "loss": 1.0417,
      "step": 96
    },
    {
      "epoch": 0.98,
      "learning_rate": 6.598639455782313e-06,
      "loss": 0.5208,
      "step": 97
    },
    {
      "epoch": 0.99,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.6041,
      "step": 98
    },
    {
      "epoch": 0.99,
      "eval_loss": 0.47040557861328125,
      "eval_runtime": 32.024,
      "eval_samples_per_second": 98.364,
      "eval_steps_per_second": 6.152,
      "eval_wer": 0.15803457106274008,
      "step": 98
    },
    {
      "epoch": 1.01,
      "learning_rate": 6.734693877551021e-06,
      "loss": 0.5757,
      "step": 99
    },
    {
      "epoch": 1.02,
      "learning_rate": 6.802721088435375e-06,
      "loss": 0.4474,
      "step": 100
    },
    {
      "epoch": 1.03,
      "learning_rate": 6.870748299319728e-06,
      "loss": 0.3955,
      "step": 101
    },
    {
      "epoch": 1.04,
      "learning_rate": 6.938775510204082e-06,
      "loss": 0.4903,
      "step": 102
    },
    {
      "epoch": 1.05,
      "learning_rate": 7.006802721088436e-06,
      "loss": 0.4357,
      "step": 103
    },
    {
      "epoch": 1.06,
      "learning_rate": 7.07482993197279e-06,
      "loss": 0.562,
      "step": 104
    },
    {
      "epoch": 1.07,
      "learning_rate": 7.142857142857143e-06,
      "loss": 0.5759,
      "step": 105
    },
    {
      "epoch": 1.08,
      "learning_rate": 7.210884353741497e-06,
      "loss": 0.6123,
      "step": 106
    },
    {
      "epoch": 1.09,
      "learning_rate": 7.278911564625851e-06,
      "loss": 0.5531,
      "step": 107
    },
    {
      "epoch": 1.1,
      "learning_rate": 7.346938775510205e-06,
      "loss": 0.5527,
      "step": 108
    },
    {
      "epoch": 1.11,
      "learning_rate": 7.4149659863945575e-06,
      "loss": 0.5677,
      "step": 109
    },
    {
      "epoch": 1.12,
      "learning_rate": 7.482993197278912e-06,
      "loss": 0.4973,
      "step": 110
    },
    {
      "epoch": 1.13,
      "learning_rate": 7.551020408163266e-06,
      "loss": 0.4679,
      "step": 111
    },
    {
      "epoch": 1.14,
      "learning_rate": 7.6190476190476205e-06,
      "loss": 0.5065,
      "step": 112
    },
    {
      "epoch": 1.15,
      "learning_rate": 7.687074829931972e-06,
      "loss": 0.6345,
      "step": 113
    },
    {
      "epoch": 1.16,
      "learning_rate": 7.755102040816327e-06,
      "loss": 0.6151,
      "step": 114
    },
    {
      "epoch": 1.17,
      "learning_rate": 7.823129251700681e-06,
      "loss": 0.5974,
      "step": 115
    },
    {
      "epoch": 1.18,
      "learning_rate": 7.891156462585034e-06,
      "loss": 0.6575,
      "step": 116
    },
    {
      "epoch": 1.19,
      "learning_rate": 7.959183673469388e-06,
      "loss": 0.6187,
      "step": 117
    },
    {
      "epoch": 1.2,
      "learning_rate": 8.027210884353741e-06,
      "loss": 0.7009,
      "step": 118
    },
    {
      "epoch": 1.21,
      "learning_rate": 8.095238095238097e-06,
      "loss": 0.6455,
      "step": 119
    },
    {
      "epoch": 1.22,
      "learning_rate": 8.163265306122448e-06,
      "loss": 0.603,
      "step": 120
    },
    {
      "epoch": 1.23,
      "learning_rate": 8.231292517006804e-06,
      "loss": 0.7142,
      "step": 121
    },
    {
      "epoch": 1.24,
      "learning_rate": 8.299319727891157e-06,
      "loss": 0.7862,
      "step": 122
    },
    {
      "epoch": 1.25,
      "learning_rate": 8.36734693877551e-06,
      "loss": 0.6421,
      "step": 123
    },
    {
      "epoch": 1.26,
      "learning_rate": 8.435374149659864e-06,
      "loss": 0.3609,
      "step": 124
    },
    {
      "epoch": 1.27,
      "learning_rate": 8.503401360544217e-06,
      "loss": 0.4462,
      "step": 125
    },
    {
      "epoch": 1.28,
      "learning_rate": 8.571428571428573e-06,
      "loss": 0.4592,
      "step": 126
    },
    {
      "epoch": 1.29,
      "learning_rate": 8.639455782312926e-06,
      "loss": 0.3298,
      "step": 127
    },
    {
      "epoch": 1.3,
      "learning_rate": 8.707482993197278e-06,
      "loss": 0.4774,
      "step": 128
    },
    {
      "epoch": 1.31,
      "learning_rate": 8.775510204081633e-06,
      "loss": 0.6049,
      "step": 129
    },
    {
      "epoch": 1.32,
      "learning_rate": 8.843537414965987e-06,
      "loss": 0.401,
      "step": 130
    },
    {
      "epoch": 1.33,
      "learning_rate": 8.911564625850342e-06,
      "loss": 0.4465,
      "step": 131
    },
    {
      "epoch": 1.34,
      "learning_rate": 8.979591836734694e-06,
      "loss": 0.4723,
      "step": 132
    },
    {
      "epoch": 1.35,
      "learning_rate": 9.047619047619047e-06,
      "loss": 0.4357,
      "step": 133
    },
    {
      "epoch": 1.36,
      "learning_rate": 9.115646258503402e-06,
      "loss": 0.5771,
      "step": 134
    },
    {
      "epoch": 1.37,
      "learning_rate": 9.183673469387756e-06,
      "loss": 0.4599,
      "step": 135
    },
    {
      "epoch": 1.38,
      "learning_rate": 9.251700680272109e-06,
      "loss": 0.4092,
      "step": 136
    },
    {
      "epoch": 1.39,
      "learning_rate": 9.319727891156463e-06,
      "loss": 0.4029,
      "step": 137
    },
    {
      "epoch": 1.4,
      "learning_rate": 9.387755102040816e-06,
      "loss": 0.3849,
      "step": 138
    },
    {
      "epoch": 1.41,
      "learning_rate": 9.455782312925171e-06,
      "loss": 0.5455,
      "step": 139
    },
    {
      "epoch": 1.42,
      "learning_rate": 9.523809523809523e-06,
      "loss": 0.5287,
      "step": 140
    },
    {
      "epoch": 1.43,
      "learning_rate": 9.591836734693878e-06,
      "loss": 0.7029,
      "step": 141
    },
    {
      "epoch": 1.44,
      "learning_rate": 9.659863945578232e-06,
      "loss": 0.4908,
      "step": 142
    },
    {
      "epoch": 1.45,
      "learning_rate": 9.727891156462585e-06,
      "loss": 0.4808,
      "step": 143
    },
    {
      "epoch": 1.46,
      "learning_rate": 9.795918367346939e-06,
      "loss": 0.5594,
      "step": 144
    },
    {
      "epoch": 1.47,
      "learning_rate": 9.863945578231292e-06,
      "loss": 0.7668,
      "step": 145
    },
    {
      "epoch": 1.48,
      "learning_rate": 9.931972789115647e-06,
      "loss": 0.5883,
      "step": 146
    },
    {
      "epoch": 1.49,
      "learning_rate": 1e-05,
      "loss": 0.729,
      "step": 147
    },
    {
      "epoch": 1.5,
      "learning_rate": 1.0068027210884354e-05,
      "loss": 0.4647,
      "step": 148
    },
    {
      "epoch": 1.51,
      "learning_rate": 1.0136054421768708e-05,
      "loss": 0.4825,
      "step": 149
    },
    {
      "epoch": 1.52,
      "learning_rate": 1.0204081632653061e-05,
      "loss": 0.3366,
      "step": 150
    },
    {
      "epoch": 1.53,
      "learning_rate": 1.0272108843537416e-05,
      "loss": 0.3255,
      "step": 151
    },
    {
      "epoch": 1.54,
      "learning_rate": 1.0340136054421768e-05,
      "loss": 0.3106,
      "step": 152
    },
    {
      "epoch": 1.55,
      "learning_rate": 1.0408163265306123e-05,
      "loss": 0.4766,
      "step": 153
    },
    {
      "epoch": 1.56,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 0.4255,
      "step": 154
    },
    {
      "epoch": 1.57,
      "learning_rate": 1.054421768707483e-05,
      "loss": 0.4328,
      "step": 155
    },
    {
      "epoch": 1.58,
      "learning_rate": 1.0612244897959184e-05,
      "loss": 0.4777,
      "step": 156
    },
    {
      "epoch": 1.59,
      "learning_rate": 1.0680272108843537e-05,
      "loss": 0.3838,
      "step": 157
    },
    {
      "epoch": 1.6,
      "learning_rate": 1.0748299319727893e-05,
      "loss": 0.488,
      "step": 158
    },
    {
      "epoch": 1.61,
      "learning_rate": 1.0816326530612246e-05,
      "loss": 0.4514,
      "step": 159
    },
    {
      "epoch": 1.62,
      "learning_rate": 1.08843537414966e-05,
      "loss": 0.4419,
      "step": 160
    },
    {
      "epoch": 1.63,
      "learning_rate": 1.0952380952380953e-05,
      "loss": 0.3481,
      "step": 161
    },
    {
      "epoch": 1.64,
      "learning_rate": 1.1020408163265306e-05,
      "loss": 0.463,
      "step": 162
    },
    {
      "epoch": 1.65,
      "learning_rate": 1.1088435374149662e-05,
      "loss": 0.4756,
      "step": 163
    },
    {
      "epoch": 1.66,
      "learning_rate": 1.1156462585034013e-05,
      "loss": 0.4221,
      "step": 164
    },
    {
      "epoch": 1.68,
      "learning_rate": 1.1224489795918369e-05,
      "loss": 0.4153,
      "step": 165
    },
    {
      "epoch": 1.69,
      "learning_rate": 1.1292517006802722e-05,
      "loss": 0.4297,
      "step": 166
    },
    {
      "epoch": 1.7,
      "learning_rate": 1.1360544217687076e-05,
      "loss": 0.4473,
      "step": 167
    },
    {
      "epoch": 1.71,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.4659,
      "step": 168
    },
    {
      "epoch": 1.72,
      "learning_rate": 1.1496598639455783e-05,
      "loss": 0.5006,
      "step": 169
    },
    {
      "epoch": 1.73,
      "learning_rate": 1.1564625850340138e-05,
      "loss": 0.6104,
      "step": 170
    },
    {
      "epoch": 1.74,
      "learning_rate": 1.163265306122449e-05,
      "loss": 0.5087,
      "step": 171
    },
    {
      "epoch": 1.75,
      "learning_rate": 1.1700680272108843e-05,
      "loss": 0.36,
      "step": 172
    },
    {
      "epoch": 1.76,
      "learning_rate": 1.1768707482993198e-05,
      "loss": 0.3457,
      "step": 173
    },
    {
      "epoch": 1.77,
      "learning_rate": 1.1836734693877552e-05,
      "loss": 0.3016,
      "step": 174
    },
    {
      "epoch": 1.78,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 0.2776,
      "step": 175
    },
    {
      "epoch": 1.79,
      "learning_rate": 1.1972789115646259e-05,
      "loss": 0.3092,
      "step": 176
    },
    {
      "epoch": 1.8,
      "learning_rate": 1.2040816326530612e-05,
      "loss": 0.3499,
      "step": 177
    },
    {
      "epoch": 1.81,
      "learning_rate": 1.2108843537414967e-05,
      "loss": 0.4448,
      "step": 178
    },
    {
      "epoch": 1.82,
      "learning_rate": 1.2176870748299319e-05,
      "loss": 0.3318,
      "step": 179
    },
    {
      "epoch": 1.83,
      "learning_rate": 1.2244897959183674e-05,
      "loss": 0.3597,
      "step": 180
    },
    {
      "epoch": 1.84,
      "learning_rate": 1.2312925170068028e-05,
      "loss": 0.3478,
      "step": 181
    },
    {
      "epoch": 1.85,
      "learning_rate": 1.2380952380952381e-05,
      "loss": 0.4067,
      "step": 182
    },
    {
      "epoch": 1.86,
      "learning_rate": 1.2448979591836735e-05,
      "loss": 0.4163,
      "step": 183
    },
    {
      "epoch": 1.87,
      "learning_rate": 1.251700680272109e-05,
      "loss": 0.2651,
      "step": 184
    },
    {
      "epoch": 1.88,
      "learning_rate": 1.2585034013605443e-05,
      "loss": 0.3088,
      "step": 185
    },
    {
      "epoch": 1.89,
      "learning_rate": 1.2653061224489795e-05,
      "loss": 0.4143,
      "step": 186
    },
    {
      "epoch": 1.9,
      "learning_rate": 1.272108843537415e-05,
      "loss": 0.4858,
      "step": 187
    },
    {
      "epoch": 1.91,
      "learning_rate": 1.2789115646258504e-05,
      "loss": 0.3952,
      "step": 188
    },
    {
      "epoch": 1.92,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.3509,
      "step": 189
    },
    {
      "epoch": 1.93,
      "learning_rate": 1.2925170068027212e-05,
      "loss": 0.2929,
      "step": 190
    },
    {
      "epoch": 1.94,
      "learning_rate": 1.2993197278911564e-05,
      "loss": 0.477,
      "step": 191
    },
    {
      "epoch": 1.95,
      "learning_rate": 1.306122448979592e-05,
      "loss": 0.3894,
      "step": 192
    },
    {
      "epoch": 1.96,
      "learning_rate": 1.3129251700680273e-05,
      "loss": 0.3796,
      "step": 193
    },
    {
      "epoch": 1.97,
      "learning_rate": 1.3197278911564626e-05,
      "loss": 0.5531,
      "step": 194
    },
    {
      "epoch": 1.98,
      "learning_rate": 1.3265306122448982e-05,
      "loss": 0.3886,
      "step": 195
    },
    {
      "epoch": 1.99,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.3261,
      "step": 196
    },
    {
      "epoch": 2.0,
      "learning_rate": 1.3401360544217687e-05,
      "loss": 0.558,
      "step": 197
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2664516866207123,
      "eval_runtime": 32.1413,
      "eval_samples_per_second": 98.005,
      "eval_steps_per_second": 6.129,
      "eval_wer": 0.10790653008962868,
      "step": 197
    },
    {
      "epoch": 2.01,
      "learning_rate": 1.3469387755102042e-05,
      "loss": 0.2745,
      "step": 198
    },
    {
      "epoch": 2.02,
      "learning_rate": 1.3537414965986395e-05,
      "loss": 0.356,
      "step": 199
    },
    {
      "epoch": 2.03,
      "learning_rate": 1.360544217687075e-05,
      "loss": 0.3656,
      "step": 200
    },
    {
      "epoch": 2.04,
      "learning_rate": 1.3673469387755102e-05,
      "loss": 0.2371,
      "step": 201
    },
    {
      "epoch": 2.05,
      "learning_rate": 1.3741496598639456e-05,
      "loss": 0.3519,
      "step": 202
    },
    {
      "epoch": 2.06,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 0.247,
      "step": 203
    },
    {
      "epoch": 2.07,
      "learning_rate": 1.3877551020408165e-05,
      "loss": 0.3174,
      "step": 204
    },
    {
      "epoch": 2.08,
      "learning_rate": 1.3945578231292516e-05,
      "loss": 0.3325,
      "step": 205
    },
    {
      "epoch": 2.09,
      "learning_rate": 1.4013605442176872e-05,
      "loss": 0.3451,
      "step": 206
    },
    {
      "epoch": 2.1,
      "learning_rate": 1.4081632653061225e-05,
      "loss": 0.2899,
      "step": 207
    },
    {
      "epoch": 2.11,
      "learning_rate": 1.414965986394558e-05,
      "loss": 0.338,
      "step": 208
    },
    {
      "epoch": 2.12,
      "learning_rate": 1.4217687074829934e-05,
      "loss": 0.4227,
      "step": 209
    },
    {
      "epoch": 2.13,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.3772,
      "step": 210
    },
    {
      "epoch": 2.14,
      "learning_rate": 1.435374149659864e-05,
      "loss": 0.2569,
      "step": 211
    },
    {
      "epoch": 2.15,
      "learning_rate": 1.4421768707482994e-05,
      "loss": 0.3591,
      "step": 212
    },
    {
      "epoch": 2.16,
      "learning_rate": 1.4489795918367346e-05,
      "loss": 0.2978,
      "step": 213
    },
    {
      "epoch": 2.17,
      "learning_rate": 1.4557823129251703e-05,
      "loss": 0.2628,
      "step": 214
    },
    {
      "epoch": 2.18,
      "learning_rate": 1.4625850340136055e-05,
      "loss": 0.3194,
      "step": 215
    },
    {
      "epoch": 2.19,
      "learning_rate": 1.469387755102041e-05,
      "loss": 0.2785,
      "step": 216
    },
    {
      "epoch": 2.2,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 0.3142,
      "step": 217
    },
    {
      "epoch": 2.21,
      "learning_rate": 1.4829931972789115e-05,
      "loss": 0.3226,
      "step": 218
    },
    {
      "epoch": 2.22,
      "learning_rate": 1.4897959183673472e-05,
      "loss": 0.3986,
      "step": 219
    },
    {
      "epoch": 2.23,
      "learning_rate": 1.4965986394557824e-05,
      "loss": 0.3934,
      "step": 220
    },
    {
      "epoch": 2.24,
      "learning_rate": 1.5034013605442177e-05,
      "loss": 0.4629,
      "step": 221
    },
    {
      "epoch": 2.25,
      "learning_rate": 1.5102040816326532e-05,
      "loss": 0.2548,
      "step": 222
    },
    {
      "epoch": 2.26,
      "learning_rate": 1.5170068027210884e-05,
      "loss": 0.248,
      "step": 223
    },
    {
      "epoch": 2.27,
      "learning_rate": 1.5238095238095241e-05,
      "loss": 0.2867,
      "step": 224
    },
    {
      "epoch": 2.28,
      "learning_rate": 1.5306122448979594e-05,
      "loss": 0.2621,
      "step": 225
    },
    {
      "epoch": 2.29,
      "learning_rate": 1.5374149659863945e-05,
      "loss": 0.2443,
      "step": 226
    },
    {
      "epoch": 2.3,
      "learning_rate": 1.54421768707483e-05,
      "loss": 0.2123,
      "step": 227
    },
    {
      "epoch": 2.31,
      "learning_rate": 1.5510204081632655e-05,
      "loss": 0.2862,
      "step": 228
    },
    {
      "epoch": 2.32,
      "learning_rate": 1.5578231292517005e-05,
      "loss": 0.2308,
      "step": 229
    },
    {
      "epoch": 2.34,
      "learning_rate": 1.5646258503401362e-05,
      "loss": 0.3561,
      "step": 230
    },
    {
      "epoch": 2.35,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.243,
      "step": 231
    },
    {
      "epoch": 2.36,
      "learning_rate": 1.578231292517007e-05,
      "loss": 0.3465,
      "step": 232
    },
    {
      "epoch": 2.37,
      "learning_rate": 1.5850340136054422e-05,
      "loss": 0.2623,
      "step": 233
    },
    {
      "epoch": 2.38,
      "learning_rate": 1.5918367346938776e-05,
      "loss": 0.2997,
      "step": 234
    },
    {
      "epoch": 2.39,
      "learning_rate": 1.5986394557823133e-05,
      "loss": 0.2989,
      "step": 235
    },
    {
      "epoch": 2.4,
      "learning_rate": 1.6054421768707483e-05,
      "loss": 0.3025,
      "step": 236
    },
    {
      "epoch": 2.41,
      "learning_rate": 1.6122448979591836e-05,
      "loss": 0.3103,
      "step": 237
    },
    {
      "epoch": 2.42,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 0.3038,
      "step": 238
    },
    {
      "epoch": 2.43,
      "learning_rate": 1.6258503401360543e-05,
      "loss": 0.2242,
      "step": 239
    },
    {
      "epoch": 2.44,
      "learning_rate": 1.6326530612244897e-05,
      "loss": 0.2926,
      "step": 240
    },
    {
      "epoch": 2.45,
      "learning_rate": 1.6394557823129254e-05,
      "loss": 0.356,
      "step": 241
    },
    {
      "epoch": 2.46,
      "learning_rate": 1.6462585034013607e-05,
      "loss": 0.4097,
      "step": 242
    },
    {
      "epoch": 2.47,
      "learning_rate": 1.653061224489796e-05,
      "loss": 0.319,
      "step": 243
    },
    {
      "epoch": 2.48,
      "learning_rate": 1.6598639455782314e-05,
      "loss": 0.4302,
      "step": 244
    },
    {
      "epoch": 2.49,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.442,
      "step": 245
    },
    {
      "epoch": 2.5,
      "learning_rate": 1.673469387755102e-05,
      "loss": 0.1695,
      "step": 246
    },
    {
      "epoch": 2.51,
      "learning_rate": 1.6802721088435374e-05,
      "loss": 0.2192,
      "step": 247
    },
    {
      "epoch": 2.52,
      "learning_rate": 1.6870748299319728e-05,
      "loss": 0.2466,
      "step": 248
    },
    {
      "epoch": 2.53,
      "learning_rate": 1.693877551020408e-05,
      "loss": 0.1692,
      "step": 249
    },
    {
      "epoch": 2.54,
      "learning_rate": 1.7006802721088435e-05,
      "loss": 0.2556,
      "step": 250
    },
    {
      "epoch": 2.55,
      "learning_rate": 1.7074829931972792e-05,
      "loss": 0.2519,
      "step": 251
    },
    {
      "epoch": 2.56,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.2111,
      "step": 252
    },
    {
      "epoch": 2.57,
      "learning_rate": 1.7210884353741495e-05,
      "loss": 0.182,
      "step": 253
    },
    {
      "epoch": 2.58,
      "learning_rate": 1.7278911564625852e-05,
      "loss": 0.2414,
      "step": 254
    },
    {
      "epoch": 2.59,
      "learning_rate": 1.7346938775510206e-05,
      "loss": 0.2423,
      "step": 255
    },
    {
      "epoch": 2.6,
      "learning_rate": 1.7414965986394556e-05,
      "loss": 0.2336,
      "step": 256
    },
    {
      "epoch": 2.61,
      "learning_rate": 1.7482993197278913e-05,
      "loss": 0.264,
      "step": 257
    },
    {
      "epoch": 2.62,
      "learning_rate": 1.7551020408163266e-05,
      "loss": 0.2917,
      "step": 258
    },
    {
      "epoch": 2.63,
      "learning_rate": 1.761904761904762e-05,
      "loss": 0.2402,
      "step": 259
    },
    {
      "epoch": 2.64,
      "learning_rate": 1.7687074829931973e-05,
      "loss": 0.3409,
      "step": 260
    },
    {
      "epoch": 2.65,
      "learning_rate": 1.7755102040816327e-05,
      "loss": 0.2434,
      "step": 261
    },
    {
      "epoch": 2.66,
      "learning_rate": 1.7823129251700683e-05,
      "loss": 0.3376,
      "step": 262
    },
    {
      "epoch": 2.67,
      "learning_rate": 1.7891156462585034e-05,
      "loss": 0.2931,
      "step": 263
    },
    {
      "epoch": 2.68,
      "learning_rate": 1.7959183673469387e-05,
      "loss": 0.2652,
      "step": 264
    },
    {
      "epoch": 2.69,
      "learning_rate": 1.8027210884353744e-05,
      "loss": 0.2521,
      "step": 265
    },
    {
      "epoch": 2.7,
      "learning_rate": 1.8095238095238094e-05,
      "loss": 0.3421,
      "step": 266
    },
    {
      "epoch": 2.71,
      "learning_rate": 1.816326530612245e-05,
      "loss": 0.3367,
      "step": 267
    },
    {
      "epoch": 2.72,
      "learning_rate": 1.8231292517006804e-05,
      "loss": 0.314,
      "step": 268
    },
    {
      "epoch": 2.73,
      "learning_rate": 1.8299319727891158e-05,
      "loss": 0.5105,
      "step": 269
    },
    {
      "epoch": 2.74,
      "learning_rate": 1.836734693877551e-05,
      "loss": 0.1812,
      "step": 270
    },
    {
      "epoch": 2.75,
      "learning_rate": 1.8435374149659865e-05,
      "loss": 0.2035,
      "step": 271
    },
    {
      "epoch": 2.76,
      "learning_rate": 1.8503401360544218e-05,
      "loss": 0.171,
      "step": 272
    },
    {
      "epoch": 2.77,
      "learning_rate": 1.8571428571428572e-05,
      "loss": 0.2004,
      "step": 273
    },
    {
      "epoch": 2.78,
      "learning_rate": 1.8639455782312925e-05,
      "loss": 0.1736,
      "step": 274
    },
    {
      "epoch": 2.79,
      "learning_rate": 1.8707482993197282e-05,
      "loss": 0.2657,
      "step": 275
    },
    {
      "epoch": 2.8,
      "learning_rate": 1.8775510204081632e-05,
      "loss": 0.2473,
      "step": 276
    },
    {
      "epoch": 2.81,
      "learning_rate": 1.8843537414965986e-05,
      "loss": 0.2561,
      "step": 277
    },
    {
      "epoch": 2.82,
      "learning_rate": 1.8911564625850343e-05,
      "loss": 0.2601,
      "step": 278
    },
    {
      "epoch": 2.83,
      "learning_rate": 1.8979591836734696e-05,
      "loss": 0.3008,
      "step": 279
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 0.1957,
      "step": 280
    },
    {
      "epoch": 2.85,
      "learning_rate": 1.9115646258503403e-05,
      "loss": 0.2353,
      "step": 281
    },
    {
      "epoch": 2.86,
      "learning_rate": 1.9183673469387756e-05,
      "loss": 0.1929,
      "step": 282
    },
    {
      "epoch": 2.87,
      "learning_rate": 1.925170068027211e-05,
      "loss": 0.3047,
      "step": 283
    },
    {
      "epoch": 2.88,
      "learning_rate": 1.9319727891156463e-05,
      "loss": 0.2353,
      "step": 284
    },
    {
      "epoch": 2.89,
      "learning_rate": 1.9387755102040817e-05,
      "loss": 0.2464,
      "step": 285
    },
    {
      "epoch": 2.9,
      "learning_rate": 1.945578231292517e-05,
      "loss": 0.2589,
      "step": 286
    },
    {
      "epoch": 2.91,
      "learning_rate": 1.9523809523809524e-05,
      "loss": 0.2696,
      "step": 287
    },
    {
      "epoch": 2.92,
      "learning_rate": 1.9591836734693877e-05,
      "loss": 0.2561,
      "step": 288
    },
    {
      "epoch": 2.93,
      "learning_rate": 1.9659863945578234e-05,
      "loss": 0.3034,
      "step": 289
    },
    {
      "epoch": 2.94,
      "learning_rate": 1.9727891156462584e-05,
      "loss": 0.2717,
      "step": 290
    },
    {
      "epoch": 2.95,
      "learning_rate": 1.9795918367346938e-05,
      "loss": 0.3464,
      "step": 291
    },
    {
      "epoch": 2.96,
      "learning_rate": 1.9863945578231295e-05,
      "loss": 0.329,
      "step": 292
    },
    {
      "epoch": 2.97,
      "learning_rate": 1.9931972789115648e-05,
      "loss": 0.535,
      "step": 293
    },
    {
      "epoch": 2.98,
      "learning_rate": 2e-05,
      "loss": 0.1819,
      "step": 294
    },
    {
      "epoch": 2.99,
      "learning_rate": 2.0068027210884355e-05,
      "loss": 0.2072,
      "step": 295
    },
    {
      "epoch": 2.99,
      "eval_loss": 0.15714825689792633,
      "eval_runtime": 31.4806,
      "eval_samples_per_second": 100.062,
      "eval_steps_per_second": 6.258,
      "eval_wer": 0.06574903969270167,
      "step": 295
    },
    {
      "epoch": 3.01,
      "learning_rate": 2.013605442176871e-05,
      "loss": 0.3143,
      "step": 296
    },
    {
      "epoch": 3.02,
      "learning_rate": 2.0204081632653062e-05,
      "loss": 0.1637,
      "step": 297
    },
    {
      "epoch": 3.03,
      "learning_rate": 2.0272108843537416e-05,
      "loss": 0.1674,
      "step": 298
    },
    {
      "epoch": 3.04,
      "learning_rate": 2.034013605442177e-05,
      "loss": 0.1906,
      "step": 299
    },
    {
      "epoch": 3.05,
      "learning_rate": 2.0408163265306123e-05,
      "loss": 0.211,
      "step": 300
    },
    {
      "epoch": 3.06,
      "learning_rate": 2.0476190476190476e-05,
      "loss": 0.1703,
      "step": 301
    },
    {
      "epoch": 3.07,
      "learning_rate": 2.0544217687074833e-05,
      "loss": 0.1958,
      "step": 302
    },
    {
      "epoch": 3.08,
      "learning_rate": 2.0612244897959186e-05,
      "loss": 0.1976,
      "step": 303
    },
    {
      "epoch": 3.09,
      "learning_rate": 2.0680272108843536e-05,
      "loss": 0.1596,
      "step": 304
    },
    {
      "epoch": 3.1,
      "learning_rate": 2.0748299319727893e-05,
      "loss": 0.1806,
      "step": 305
    },
    {
      "epoch": 3.11,
      "learning_rate": 2.0816326530612247e-05,
      "loss": 0.2093,
      "step": 306
    },
    {
      "epoch": 3.12,
      "learning_rate": 2.0884353741496597e-05,
      "loss": 0.1783,
      "step": 307
    },
    {
      "epoch": 3.13,
      "learning_rate": 2.0952380952380954e-05,
      "loss": 0.1741,
      "step": 308
    },
    {
      "epoch": 3.14,
      "learning_rate": 2.1020408163265307e-05,
      "loss": 0.1658,
      "step": 309
    },
    {
      "epoch": 3.15,
      "learning_rate": 2.108843537414966e-05,
      "loss": 0.2326,
      "step": 310
    },
    {
      "epoch": 3.16,
      "learning_rate": 2.1156462585034014e-05,
      "loss": 0.1732,
      "step": 311
    },
    {
      "epoch": 3.17,
      "learning_rate": 2.1224489795918368e-05,
      "loss": 0.2839,
      "step": 312
    },
    {
      "epoch": 3.18,
      "learning_rate": 2.1292517006802725e-05,
      "loss": 0.1973,
      "step": 313
    },
    {
      "epoch": 3.19,
      "learning_rate": 2.1360544217687075e-05,
      "loss": 0.2269,
      "step": 314
    },
    {
      "epoch": 3.2,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 0.1816,
      "step": 315
    },
    {
      "epoch": 3.21,
      "learning_rate": 2.1496598639455785e-05,
      "loss": 0.2438,
      "step": 316
    },
    {
      "epoch": 3.22,
      "learning_rate": 2.1564625850340135e-05,
      "loss": 0.3223,
      "step": 317
    },
    {
      "epoch": 3.23,
      "learning_rate": 2.1632653061224492e-05,
      "loss": 0.2685,
      "step": 318
    },
    {
      "epoch": 3.24,
      "learning_rate": 2.1700680272108845e-05,
      "loss": 0.2664,
      "step": 319
    },
    {
      "epoch": 3.25,
      "learning_rate": 2.17687074829932e-05,
      "loss": 0.254,
      "step": 320
    },
    {
      "epoch": 3.26,
      "learning_rate": 2.1836734693877552e-05,
      "loss": 0.1152,
      "step": 321
    },
    {
      "epoch": 3.27,
      "learning_rate": 2.1904761904761906e-05,
      "loss": 0.1806,
      "step": 322
    },
    {
      "epoch": 3.28,
      "learning_rate": 2.197278911564626e-05,
      "loss": 0.1773,
      "step": 323
    },
    {
      "epoch": 3.29,
      "learning_rate": 2.2040816326530613e-05,
      "loss": 0.1483,
      "step": 324
    },
    {
      "epoch": 3.3,
      "learning_rate": 2.2108843537414966e-05,
      "loss": 0.2395,
      "step": 325
    },
    {
      "epoch": 3.31,
      "learning_rate": 2.2176870748299323e-05,
      "loss": 0.2224,
      "step": 326
    },
    {
      "epoch": 3.32,
      "learning_rate": 2.2244897959183673e-05,
      "loss": 0.1715,
      "step": 327
    },
    {
      "epoch": 3.33,
      "learning_rate": 2.2312925170068027e-05,
      "loss": 0.1913,
      "step": 328
    },
    {
      "epoch": 3.34,
      "learning_rate": 2.2380952380952384e-05,
      "loss": 0.1794,
      "step": 329
    },
    {
      "epoch": 3.35,
      "learning_rate": 2.2448979591836737e-05,
      "loss": 0.1959,
      "step": 330
    },
    {
      "epoch": 3.36,
      "learning_rate": 2.2517006802721087e-05,
      "loss": 0.1594,
      "step": 331
    },
    {
      "epoch": 3.37,
      "learning_rate": 2.2585034013605444e-05,
      "loss": 0.128,
      "step": 332
    },
    {
      "epoch": 3.38,
      "learning_rate": 2.2653061224489798e-05,
      "loss": 0.1242,
      "step": 333
    },
    {
      "epoch": 3.39,
      "learning_rate": 2.272108843537415e-05,
      "loss": 0.1628,
      "step": 334
    },
    {
      "epoch": 3.4,
      "learning_rate": 2.2789115646258505e-05,
      "loss": 0.2432,
      "step": 335
    },
    {
      "epoch": 3.41,
      "learning_rate": 2.2857142857142858e-05,
      "loss": 0.1848,
      "step": 336
    },
    {
      "epoch": 3.42,
      "learning_rate": 2.292517006802721e-05,
      "loss": 0.2724,
      "step": 337
    },
    {
      "epoch": 3.43,
      "learning_rate": 2.2993197278911565e-05,
      "loss": 0.2131,
      "step": 338
    },
    {
      "epoch": 3.44,
      "learning_rate": 2.306122448979592e-05,
      "loss": 0.2156,
      "step": 339
    },
    {
      "epoch": 3.45,
      "learning_rate": 2.3129251700680275e-05,
      "loss": 0.1869,
      "step": 340
    },
    {
      "epoch": 3.46,
      "learning_rate": 2.3197278911564625e-05,
      "loss": 0.1537,
      "step": 341
    },
    {
      "epoch": 3.47,
      "learning_rate": 2.326530612244898e-05,
      "loss": 0.2091,
      "step": 342
    },
    {
      "epoch": 3.48,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.3383,
      "step": 343
    },
    {
      "epoch": 3.49,
      "learning_rate": 2.3401360544217686e-05,
      "loss": 0.3369,
      "step": 344
    },
    {
      "epoch": 3.5,
      "learning_rate": 2.3469387755102043e-05,
      "loss": 0.118,
      "step": 345
    },
    {
      "epoch": 3.51,
      "learning_rate": 2.3537414965986396e-05,
      "loss": 0.1761,
      "step": 346
    },
    {
      "epoch": 3.52,
      "learning_rate": 2.360544217687075e-05,
      "loss": 0.1424,
      "step": 347
    },
    {
      "epoch": 3.53,
      "learning_rate": 2.3673469387755103e-05,
      "loss": 0.1662,
      "step": 348
    },
    {
      "epoch": 3.54,
      "learning_rate": 2.3741496598639457e-05,
      "loss": 0.1114,
      "step": 349
    },
    {
      "epoch": 3.55,
      "learning_rate": 2.380952380952381e-05,
      "loss": 0.1963,
      "step": 350
    },
    {
      "epoch": 3.56,
      "learning_rate": 2.3877551020408164e-05,
      "loss": 0.1725,
      "step": 351
    },
    {
      "epoch": 3.57,
      "learning_rate": 2.3945578231292517e-05,
      "loss": 0.199,
      "step": 352
    },
    {
      "epoch": 3.58,
      "learning_rate": 2.4013605442176874e-05,
      "loss": 0.2376,
      "step": 353
    },
    {
      "epoch": 3.59,
      "learning_rate": 2.4081632653061224e-05,
      "loss": 0.2389,
      "step": 354
    },
    {
      "epoch": 3.6,
      "learning_rate": 2.4149659863945578e-05,
      "loss": 0.2219,
      "step": 355
    },
    {
      "epoch": 3.61,
      "learning_rate": 2.4217687074829934e-05,
      "loss": 0.1997,
      "step": 356
    },
    {
      "epoch": 3.62,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 0.1632,
      "step": 357
    },
    {
      "epoch": 3.63,
      "learning_rate": 2.4353741496598638e-05,
      "loss": 0.1732,
      "step": 358
    },
    {
      "epoch": 3.64,
      "learning_rate": 2.4421768707482995e-05,
      "loss": 0.1733,
      "step": 359
    },
    {
      "epoch": 3.65,
      "learning_rate": 2.448979591836735e-05,
      "loss": 0.2188,
      "step": 360
    },
    {
      "epoch": 3.66,
      "learning_rate": 2.4557823129251702e-05,
      "loss": 0.2047,
      "step": 361
    },
    {
      "epoch": 3.68,
      "learning_rate": 2.4625850340136055e-05,
      "loss": 0.2505,
      "step": 362
    },
    {
      "epoch": 3.69,
      "learning_rate": 2.469387755102041e-05,
      "loss": 0.1408,
      "step": 363
    },
    {
      "epoch": 3.7,
      "learning_rate": 2.4761904761904762e-05,
      "loss": 0.2559,
      "step": 364
    },
    {
      "epoch": 3.71,
      "learning_rate": 2.4829931972789116e-05,
      "loss": 0.2245,
      "step": 365
    },
    {
      "epoch": 3.72,
      "learning_rate": 2.489795918367347e-05,
      "loss": 0.2256,
      "step": 366
    },
    {
      "epoch": 3.73,
      "learning_rate": 2.4965986394557826e-05,
      "loss": 0.2151,
      "step": 367
    },
    {
      "epoch": 3.74,
      "learning_rate": 2.503401360544218e-05,
      "loss": 0.2544,
      "step": 368
    },
    {
      "epoch": 3.75,
      "learning_rate": 2.5102040816326533e-05,
      "loss": 0.1246,
      "step": 369
    },
    {
      "epoch": 3.76,
      "learning_rate": 2.5170068027210887e-05,
      "loss": 0.1691,
      "step": 370
    },
    {
      "epoch": 3.77,
      "learning_rate": 2.523809523809524e-05,
      "loss": 0.091,
      "step": 371
    },
    {
      "epoch": 3.78,
      "learning_rate": 2.530612244897959e-05,
      "loss": 0.1573,
      "step": 372
    },
    {
      "epoch": 3.79,
      "learning_rate": 2.537414965986395e-05,
      "loss": 0.1407,
      "step": 373
    },
    {
      "epoch": 3.8,
      "learning_rate": 2.54421768707483e-05,
      "loss": 0.1748,
      "step": 374
    },
    {
      "epoch": 3.81,
      "learning_rate": 2.5510204081632654e-05,
      "loss": 0.1591,
      "step": 375
    },
    {
      "epoch": 3.82,
      "learning_rate": 2.5578231292517007e-05,
      "loss": 0.1412,
      "step": 376
    },
    {
      "epoch": 3.83,
      "learning_rate": 2.564625850340136e-05,
      "loss": 0.1584,
      "step": 377
    },
    {
      "epoch": 3.84,
      "learning_rate": 2.5714285714285714e-05,
      "loss": 0.1279,
      "step": 378
    },
    {
      "epoch": 3.85,
      "learning_rate": 2.578231292517007e-05,
      "loss": 0.1042,
      "step": 379
    },
    {
      "epoch": 3.86,
      "learning_rate": 2.5850340136054425e-05,
      "loss": 0.229,
      "step": 380
    },
    {
      "epoch": 3.87,
      "learning_rate": 2.5918367346938778e-05,
      "loss": 0.1726,
      "step": 381
    },
    {
      "epoch": 3.88,
      "learning_rate": 2.598639455782313e-05,
      "loss": 0.191,
      "step": 382
    },
    {
      "epoch": 3.89,
      "learning_rate": 2.6054421768707482e-05,
      "loss": 0.1927,
      "step": 383
    },
    {
      "epoch": 3.9,
      "learning_rate": 2.612244897959184e-05,
      "loss": 0.2021,
      "step": 384
    },
    {
      "epoch": 3.91,
      "learning_rate": 2.6190476190476192e-05,
      "loss": 0.2452,
      "step": 385
    },
    {
      "epoch": 3.92,
      "learning_rate": 2.6258503401360546e-05,
      "loss": 0.1778,
      "step": 386
    },
    {
      "epoch": 3.93,
      "learning_rate": 2.63265306122449e-05,
      "loss": 0.2071,
      "step": 387
    },
    {
      "epoch": 3.94,
      "learning_rate": 2.6394557823129253e-05,
      "loss": 0.1853,
      "step": 388
    },
    {
      "epoch": 3.95,
      "learning_rate": 2.646258503401361e-05,
      "loss": 0.1439,
      "step": 389
    },
    {
      "epoch": 3.96,
      "learning_rate": 2.6530612244897963e-05,
      "loss": 0.2626,
      "step": 390
    },
    {
      "epoch": 3.97,
      "learning_rate": 2.6598639455782316e-05,
      "loss": 0.2008,
      "step": 391
    },
    {
      "epoch": 3.98,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.2825,
      "step": 392
    },
    {
      "epoch": 3.99,
      "learning_rate": 2.673469387755102e-05,
      "loss": 0.1395,
      "step": 393
    },
    {
      "epoch": 4.0,
      "learning_rate": 2.6802721088435374e-05,
      "loss": 0.1841,
      "step": 394
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.10878162086009979,
      "eval_runtime": 31.4054,
      "eval_samples_per_second": 100.301,
      "eval_steps_per_second": 6.273,
      "eval_wer": 0.04788732394366197,
      "step": 394
    },
    {
      "epoch": 4.01,
      "learning_rate": 2.687074829931973e-05,
      "loss": 0.0956,
      "step": 395
    },
    {
      "epoch": 4.02,
      "learning_rate": 2.6938775510204084e-05,
      "loss": 0.1022,
      "step": 396
    },
    {
      "epoch": 4.03,
      "learning_rate": 2.7006802721088437e-05,
      "loss": 0.1471,
      "step": 397
    },
    {
      "epoch": 4.04,
      "learning_rate": 2.707482993197279e-05,
      "loss": 0.117,
      "step": 398
    },
    {
      "epoch": 4.05,
      "learning_rate": 2.714285714285714e-05,
      "loss": 0.1295,
      "step": 399
    },
    {
      "epoch": 4.06,
      "learning_rate": 2.72108843537415e-05,
      "loss": 0.1536,
      "step": 400
    },
    {
      "epoch": 4.07,
      "learning_rate": 2.7278911564625855e-05,
      "loss": 0.1728,
      "step": 401
    },
    {
      "epoch": 4.08,
      "learning_rate": 2.7346938775510205e-05,
      "loss": 0.2341,
      "step": 402
    },
    {
      "epoch": 4.09,
      "learning_rate": 2.7414965986394558e-05,
      "loss": 0.1842,
      "step": 403
    },
    {
      "epoch": 4.1,
      "learning_rate": 2.7482993197278912e-05,
      "loss": 0.2115,
      "step": 404
    },
    {
      "epoch": 4.11,
      "learning_rate": 2.7551020408163265e-05,
      "loss": 0.1799,
      "step": 405
    },
    {
      "epoch": 4.12,
      "learning_rate": 2.7619047619047622e-05,
      "loss": 0.1752,
      "step": 406
    },
    {
      "epoch": 4.13,
      "learning_rate": 2.7687074829931976e-05,
      "loss": 0.1706,
      "step": 407
    },
    {
      "epoch": 4.14,
      "learning_rate": 2.775510204081633e-05,
      "loss": 0.1728,
      "step": 408
    },
    {
      "epoch": 4.15,
      "learning_rate": 2.782312925170068e-05,
      "loss": 0.1484,
      "step": 409
    },
    {
      "epoch": 4.16,
      "learning_rate": 2.7891156462585033e-05,
      "loss": 0.1254,
      "step": 410
    },
    {
      "epoch": 4.17,
      "learning_rate": 2.7959183673469393e-05,
      "loss": 0.1636,
      "step": 411
    },
    {
      "epoch": 4.18,
      "learning_rate": 2.8027210884353743e-05,
      "loss": 0.1479,
      "step": 412
    },
    {
      "epoch": 4.19,
      "learning_rate": 2.8095238095238096e-05,
      "loss": 0.163,
      "step": 413
    },
    {
      "epoch": 4.2,
      "learning_rate": 2.816326530612245e-05,
      "loss": 0.1593,
      "step": 414
    },
    {
      "epoch": 4.21,
      "learning_rate": 2.8231292517006803e-05,
      "loss": 0.193,
      "step": 415
    },
    {
      "epoch": 4.22,
      "learning_rate": 2.829931972789116e-05,
      "loss": 0.2104,
      "step": 416
    },
    {
      "epoch": 4.23,
      "learning_rate": 2.8367346938775514e-05,
      "loss": 0.2347,
      "step": 417
    },
    {
      "epoch": 4.24,
      "learning_rate": 2.8435374149659867e-05,
      "loss": 0.2409,
      "step": 418
    },
    {
      "epoch": 4.25,
      "learning_rate": 2.8503401360544217e-05,
      "loss": 0.1107,
      "step": 419
    },
    {
      "epoch": 4.26,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.1398,
      "step": 420
    },
    {
      "epoch": 4.27,
      "learning_rate": 2.8639455782312924e-05,
      "loss": 0.1214,
      "step": 421
    },
    {
      "epoch": 4.28,
      "learning_rate": 2.870748299319728e-05,
      "loss": 0.1079,
      "step": 422
    },
    {
      "epoch": 4.29,
      "learning_rate": 2.8775510204081635e-05,
      "loss": 0.1695,
      "step": 423
    },
    {
      "epoch": 4.3,
      "learning_rate": 2.8843537414965988e-05,
      "loss": 0.1517,
      "step": 424
    },
    {
      "epoch": 4.31,
      "learning_rate": 2.891156462585034e-05,
      "loss": 0.1509,
      "step": 425
    },
    {
      "epoch": 4.32,
      "learning_rate": 2.8979591836734692e-05,
      "loss": 0.1484,
      "step": 426
    },
    {
      "epoch": 4.34,
      "learning_rate": 2.9047619047619052e-05,
      "loss": 0.081,
      "step": 427
    },
    {
      "epoch": 4.35,
      "learning_rate": 2.9115646258503405e-05,
      "loss": 0.0774,
      "step": 428
    },
    {
      "epoch": 4.36,
      "learning_rate": 2.9183673469387756e-05,
      "loss": 0.1436,
      "step": 429
    },
    {
      "epoch": 4.37,
      "learning_rate": 2.925170068027211e-05,
      "loss": 0.129,
      "step": 430
    },
    {
      "epoch": 4.38,
      "learning_rate": 2.9319727891156463e-05,
      "loss": 0.1738,
      "step": 431
    },
    {
      "epoch": 4.39,
      "learning_rate": 2.938775510204082e-05,
      "loss": 0.1319,
      "step": 432
    },
    {
      "epoch": 4.4,
      "learning_rate": 2.9455782312925173e-05,
      "loss": 0.1362,
      "step": 433
    },
    {
      "epoch": 4.41,
      "learning_rate": 2.9523809523809526e-05,
      "loss": 0.0954,
      "step": 434
    },
    {
      "epoch": 4.42,
      "learning_rate": 2.959183673469388e-05,
      "loss": 0.1916,
      "step": 435
    },
    {
      "epoch": 4.43,
      "learning_rate": 2.965986394557823e-05,
      "loss": 0.1626,
      "step": 436
    },
    {
      "epoch": 4.44,
      "learning_rate": 2.9727891156462583e-05,
      "loss": 0.1296,
      "step": 437
    },
    {
      "epoch": 4.45,
      "learning_rate": 2.9795918367346944e-05,
      "loss": 0.0892,
      "step": 438
    },
    {
      "epoch": 4.46,
      "learning_rate": 2.9863945578231294e-05,
      "loss": 0.1843,
      "step": 439
    },
    {
      "epoch": 4.47,
      "learning_rate": 2.9931972789115647e-05,
      "loss": 0.1669,
      "step": 440
    },
    {
      "epoch": 4.48,
      "learning_rate": 3e-05,
      "loss": 0.2298,
      "step": 441
    },
    {
      "epoch": 4.49,
      "learning_rate": 3.0068027210884354e-05,
      "loss": 0.2124,
      "step": 442
    },
    {
      "epoch": 4.5,
      "learning_rate": 3.013605442176871e-05,
      "loss": 0.1468,
      "step": 443
    },
    {
      "epoch": 4.51,
      "learning_rate": 3.0204081632653065e-05,
      "loss": 0.1171,
      "step": 444
    },
    {
      "epoch": 4.52,
      "learning_rate": 3.0272108843537418e-05,
      "loss": 0.1096,
      "step": 445
    },
    {
      "epoch": 4.53,
      "learning_rate": 3.0340136054421768e-05,
      "loss": 0.1161,
      "step": 446
    },
    {
      "epoch": 4.54,
      "learning_rate": 3.040816326530612e-05,
      "loss": 0.0846,
      "step": 447
    },
    {
      "epoch": 4.55,
      "learning_rate": 3.0476190476190482e-05,
      "loss": 0.1597,
      "step": 448
    },
    {
      "epoch": 4.56,
      "learning_rate": 3.054421768707483e-05,
      "loss": 0.1168,
      "step": 449
    },
    {
      "epoch": 4.57,
      "learning_rate": 3.061224489795919e-05,
      "loss": 0.0966,
      "step": 450
    },
    {
      "epoch": 4.58,
      "learning_rate": 3.068027210884354e-05,
      "loss": 0.1149,
      "step": 451
    },
    {
      "epoch": 4.59,
      "learning_rate": 3.074829931972789e-05,
      "loss": 0.0958,
      "step": 452
    },
    {
      "epoch": 4.6,
      "learning_rate": 3.0816326530612246e-05,
      "loss": 0.0745,
      "step": 453
    },
    {
      "epoch": 4.61,
      "learning_rate": 3.08843537414966e-05,
      "loss": 0.1856,
      "step": 454
    },
    {
      "epoch": 4.62,
      "learning_rate": 3.095238095238095e-05,
      "loss": 0.1511,
      "step": 455
    },
    {
      "epoch": 4.63,
      "learning_rate": 3.102040816326531e-05,
      "loss": 0.1284,
      "step": 456
    },
    {
      "epoch": 4.64,
      "learning_rate": 3.108843537414966e-05,
      "loss": 0.1577,
      "step": 457
    },
    {
      "epoch": 4.65,
      "learning_rate": 3.115646258503401e-05,
      "loss": 0.1641,
      "step": 458
    },
    {
      "epoch": 4.66,
      "learning_rate": 3.1224489795918374e-05,
      "loss": 0.1655,
      "step": 459
    },
    {
      "epoch": 4.67,
      "learning_rate": 3.1292517006802724e-05,
      "loss": 0.162,
      "step": 460
    },
    {
      "epoch": 4.68,
      "learning_rate": 3.1360544217687074e-05,
      "loss": 0.1642,
      "step": 461
    },
    {
      "epoch": 4.69,
      "learning_rate": 3.142857142857143e-05,
      "loss": 0.1281,
      "step": 462
    },
    {
      "epoch": 4.7,
      "learning_rate": 3.149659863945578e-05,
      "loss": 0.1284,
      "step": 463
    },
    {
      "epoch": 4.71,
      "learning_rate": 3.156462585034014e-05,
      "loss": 0.1679,
      "step": 464
    },
    {
      "epoch": 4.72,
      "learning_rate": 3.1632653061224494e-05,
      "loss": 0.207,
      "step": 465
    },
    {
      "epoch": 4.73,
      "learning_rate": 3.1700680272108845e-05,
      "loss": 0.295,
      "step": 466
    },
    {
      "epoch": 4.74,
      "learning_rate": 3.17687074829932e-05,
      "loss": 0.1389,
      "step": 467
    },
    {
      "epoch": 4.75,
      "learning_rate": 3.183673469387755e-05,
      "loss": 0.115,
      "step": 468
    },
    {
      "epoch": 4.76,
      "learning_rate": 3.19047619047619e-05,
      "loss": 0.1027,
      "step": 469
    },
    {
      "epoch": 4.77,
      "learning_rate": 3.1972789115646265e-05,
      "loss": 0.1071,
      "step": 470
    },
    {
      "epoch": 4.78,
      "learning_rate": 3.2040816326530615e-05,
      "loss": 0.1549,
      "step": 471
    },
    {
      "epoch": 4.79,
      "learning_rate": 3.2108843537414965e-05,
      "loss": 0.1289,
      "step": 472
    },
    {
      "epoch": 4.8,
      "learning_rate": 3.217687074829932e-05,
      "loss": 0.1138,
      "step": 473
    },
    {
      "epoch": 4.81,
      "learning_rate": 3.224489795918367e-05,
      "loss": 0.1486,
      "step": 474
    },
    {
      "epoch": 4.82,
      "learning_rate": 3.231292517006803e-05,
      "loss": 0.1549,
      "step": 475
    },
    {
      "epoch": 4.83,
      "learning_rate": 3.2380952380952386e-05,
      "loss": 0.1598,
      "step": 476
    },
    {
      "epoch": 4.84,
      "learning_rate": 3.2448979591836736e-05,
      "loss": 0.1068,
      "step": 477
    },
    {
      "epoch": 4.85,
      "learning_rate": 3.2517006802721086e-05,
      "loss": 0.1511,
      "step": 478
    },
    {
      "epoch": 4.86,
      "learning_rate": 3.258503401360544e-05,
      "loss": 0.0925,
      "step": 479
    },
    {
      "epoch": 4.87,
      "learning_rate": 3.265306122448979e-05,
      "loss": 0.1299,
      "step": 480
    },
    {
      "epoch": 4.88,
      "learning_rate": 3.272108843537415e-05,
      "loss": 0.065,
      "step": 481
    },
    {
      "epoch": 4.89,
      "learning_rate": 3.278911564625851e-05,
      "loss": 0.1263,
      "step": 482
    },
    {
      "epoch": 4.9,
      "learning_rate": 3.285714285714286e-05,
      "loss": 0.1523,
      "step": 483
    },
    {
      "epoch": 4.91,
      "learning_rate": 3.2925170068027214e-05,
      "loss": 0.1653,
      "step": 484
    },
    {
      "epoch": 4.92,
      "learning_rate": 3.2993197278911564e-05,
      "loss": 0.1376,
      "step": 485
    },
    {
      "epoch": 4.93,
      "learning_rate": 3.306122448979592e-05,
      "loss": 0.1371,
      "step": 486
    },
    {
      "epoch": 4.94,
      "learning_rate": 3.312925170068028e-05,
      "loss": 0.1365,
      "step": 487
    },
    {
      "epoch": 4.95,
      "learning_rate": 3.319727891156463e-05,
      "loss": 0.1324,
      "step": 488
    },
    {
      "epoch": 4.96,
      "learning_rate": 3.326530612244898e-05,
      "loss": 0.1529,
      "step": 489
    },
    {
      "epoch": 4.97,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.2147,
      "step": 490
    },
    {
      "epoch": 4.98,
      "learning_rate": 3.340136054421769e-05,
      "loss": 0.0987,
      "step": 491
    },
    {
      "epoch": 4.99,
      "learning_rate": 3.346938775510204e-05,
      "loss": 0.0988,
      "step": 492
    },
    {
      "epoch": 4.99,
      "eval_loss": 0.07133904099464417,
      "eval_runtime": 31.6749,
      "eval_samples_per_second": 99.448,
      "eval_steps_per_second": 6.219,
      "eval_wer": 0.033898847631242,
      "step": 492
    },
    {
      "epoch": 5.01,
      "learning_rate": 3.35374149659864e-05,
      "loss": 0.1753,
      "step": 493
    },
    {
      "epoch": 5.02,
      "learning_rate": 3.360544217687075e-05,
      "loss": 0.1051,
      "step": 494
    },
    {
      "epoch": 5.03,
      "learning_rate": 3.36734693877551e-05,
      "loss": 0.1019,
      "step": 495
    },
    {
      "epoch": 5.04,
      "learning_rate": 3.3741496598639456e-05,
      "loss": 0.1136,
      "step": 496
    },
    {
      "epoch": 5.05,
      "learning_rate": 3.380952380952381e-05,
      "loss": 0.0612,
      "step": 497
    },
    {
      "epoch": 5.06,
      "learning_rate": 3.387755102040816e-05,
      "loss": 0.1444,
      "step": 498
    },
    {
      "epoch": 5.07,
      "learning_rate": 3.394557823129252e-05,
      "loss": 0.0726,
      "step": 499
    },
    {
      "epoch": 5.08,
      "learning_rate": 3.401360544217687e-05,
      "loss": 0.0807,
      "step": 500
    },
    {
      "epoch": 5.09,
      "learning_rate": 3.408163265306123e-05,
      "loss": 0.0876,
      "step": 501
    },
    {
      "epoch": 5.1,
      "learning_rate": 3.4149659863945583e-05,
      "loss": 0.115,
      "step": 502
    },
    {
      "epoch": 5.11,
      "learning_rate": 3.4217687074829934e-05,
      "loss": 0.1083,
      "step": 503
    },
    {
      "epoch": 5.12,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.1227,
      "step": 504
    },
    {
      "epoch": 5.13,
      "learning_rate": 3.435374149659864e-05,
      "loss": 0.1343,
      "step": 505
    },
    {
      "epoch": 5.14,
      "learning_rate": 3.442176870748299e-05,
      "loss": 0.1022,
      "step": 506
    },
    {
      "epoch": 5.15,
      "learning_rate": 3.4489795918367354e-05,
      "loss": 0.126,
      "step": 507
    },
    {
      "epoch": 5.16,
      "learning_rate": 3.4557823129251704e-05,
      "loss": 0.1367,
      "step": 508
    },
    {
      "epoch": 5.17,
      "learning_rate": 3.4625850340136054e-05,
      "loss": 0.108,
      "step": 509
    },
    {
      "epoch": 5.18,
      "learning_rate": 3.469387755102041e-05,
      "loss": 0.1275,
      "step": 510
    },
    {
      "epoch": 5.19,
      "learning_rate": 3.476190476190476e-05,
      "loss": 0.127,
      "step": 511
    },
    {
      "epoch": 5.2,
      "learning_rate": 3.482993197278911e-05,
      "loss": 0.1489,
      "step": 512
    },
    {
      "epoch": 5.21,
      "learning_rate": 3.4897959183673475e-05,
      "loss": 0.1624,
      "step": 513
    },
    {
      "epoch": 5.22,
      "learning_rate": 3.4965986394557825e-05,
      "loss": 0.1553,
      "step": 514
    },
    {
      "epoch": 5.23,
      "learning_rate": 3.5034013605442175e-05,
      "loss": 0.163,
      "step": 515
    },
    {
      "epoch": 5.24,
      "learning_rate": 3.510204081632653e-05,
      "loss": 0.1561,
      "step": 516
    },
    {
      "epoch": 5.25,
      "learning_rate": 3.517006802721088e-05,
      "loss": 0.1594,
      "step": 517
    },
    {
      "epoch": 5.26,
      "learning_rate": 3.523809523809524e-05,
      "loss": 0.0609,
      "step": 518
    },
    {
      "epoch": 5.27,
      "learning_rate": 3.5306122448979596e-05,
      "loss": 0.0887,
      "step": 519
    },
    {
      "epoch": 5.28,
      "learning_rate": 3.5374149659863946e-05,
      "loss": 0.1072,
      "step": 520
    },
    {
      "epoch": 5.29,
      "learning_rate": 3.54421768707483e-05,
      "loss": 0.1066,
      "step": 521
    },
    {
      "epoch": 5.3,
      "learning_rate": 3.551020408163265e-05,
      "loss": 0.1036,
      "step": 522
    },
    {
      "epoch": 5.31,
      "learning_rate": 3.5578231292517e-05,
      "loss": 0.129,
      "step": 523
    },
    {
      "epoch": 5.32,
      "learning_rate": 3.564625850340137e-05,
      "loss": 0.0732,
      "step": 524
    },
    {
      "epoch": 5.33,
      "learning_rate": 3.571428571428572e-05,
      "loss": 0.064,
      "step": 525
    },
    {
      "epoch": 5.34,
      "learning_rate": 3.578231292517007e-05,
      "loss": 0.1092,
      "step": 526
    },
    {
      "epoch": 5.35,
      "learning_rate": 3.5850340136054424e-05,
      "loss": 0.0969,
      "step": 527
    },
    {
      "epoch": 5.36,
      "learning_rate": 3.5918367346938774e-05,
      "loss": 0.1115,
      "step": 528
    },
    {
      "epoch": 5.37,
      "learning_rate": 3.598639455782313e-05,
      "loss": 0.0846,
      "step": 529
    },
    {
      "epoch": 5.38,
      "learning_rate": 3.605442176870749e-05,
      "loss": 0.1143,
      "step": 530
    },
    {
      "epoch": 5.39,
      "learning_rate": 3.612244897959184e-05,
      "loss": 0.0785,
      "step": 531
    },
    {
      "epoch": 5.4,
      "learning_rate": 3.619047619047619e-05,
      "loss": 0.1018,
      "step": 532
    },
    {
      "epoch": 5.41,
      "learning_rate": 3.6258503401360545e-05,
      "loss": 0.1027,
      "step": 533
    },
    {
      "epoch": 5.42,
      "learning_rate": 3.63265306122449e-05,
      "loss": 0.0896,
      "step": 534
    },
    {
      "epoch": 5.43,
      "learning_rate": 3.639455782312925e-05,
      "loss": 0.0931,
      "step": 535
    },
    {
      "epoch": 5.44,
      "learning_rate": 3.646258503401361e-05,
      "loss": 0.0919,
      "step": 536
    },
    {
      "epoch": 5.45,
      "learning_rate": 3.653061224489796e-05,
      "loss": 0.1592,
      "step": 537
    },
    {
      "epoch": 5.46,
      "learning_rate": 3.6598639455782316e-05,
      "loss": 0.069,
      "step": 538
    },
    {
      "epoch": 5.47,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.1207,
      "step": 539
    },
    {
      "epoch": 5.48,
      "learning_rate": 3.673469387755102e-05,
      "loss": 0.1151,
      "step": 540
    },
    {
      "epoch": 5.49,
      "learning_rate": 3.680272108843538e-05,
      "loss": 0.2094,
      "step": 541
    },
    {
      "epoch": 5.5,
      "learning_rate": 3.687074829931973e-05,
      "loss": 0.0561,
      "step": 542
    },
    {
      "epoch": 5.51,
      "learning_rate": 3.693877551020408e-05,
      "loss": 0.0373,
      "step": 543
    },
    {
      "epoch": 5.52,
      "learning_rate": 3.7006802721088437e-05,
      "loss": 0.0966,
      "step": 544
    },
    {
      "epoch": 5.53,
      "learning_rate": 3.707482993197279e-05,
      "loss": 0.129,
      "step": 545
    },
    {
      "epoch": 5.54,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 0.0529,
      "step": 546
    },
    {
      "epoch": 5.55,
      "learning_rate": 3.72108843537415e-05,
      "loss": 0.0409,
      "step": 547
    },
    {
      "epoch": 5.56,
      "learning_rate": 3.727891156462585e-05,
      "loss": 0.0764,
      "step": 548
    },
    {
      "epoch": 5.57,
      "learning_rate": 3.734693877551021e-05,
      "loss": 0.0927,
      "step": 549
    },
    {
      "epoch": 5.58,
      "learning_rate": 3.7414965986394564e-05,
      "loss": 0.0888,
      "step": 550
    },
    {
      "epoch": 5.59,
      "learning_rate": 3.7482993197278914e-05,
      "loss": 0.0895,
      "step": 551
    },
    {
      "epoch": 5.6,
      "learning_rate": 3.7551020408163264e-05,
      "loss": 0.13,
      "step": 552
    },
    {
      "epoch": 5.61,
      "learning_rate": 3.761904761904762e-05,
      "loss": 0.0881,
      "step": 553
    },
    {
      "epoch": 5.62,
      "learning_rate": 3.768707482993197e-05,
      "loss": 0.119,
      "step": 554
    },
    {
      "epoch": 5.63,
      "learning_rate": 3.775510204081633e-05,
      "loss": 0.0811,
      "step": 555
    },
    {
      "epoch": 5.64,
      "learning_rate": 3.7823129251700685e-05,
      "loss": 0.1,
      "step": 556
    },
    {
      "epoch": 5.65,
      "learning_rate": 3.7891156462585035e-05,
      "loss": 0.0906,
      "step": 557
    },
    {
      "epoch": 5.66,
      "learning_rate": 3.795918367346939e-05,
      "loss": 0.1295,
      "step": 558
    },
    {
      "epoch": 5.68,
      "learning_rate": 3.802721088435374e-05,
      "loss": 0.063,
      "step": 559
    },
    {
      "epoch": 5.69,
      "learning_rate": 3.809523809523809e-05,
      "loss": 0.121,
      "step": 560
    },
    {
      "epoch": 5.7,
      "learning_rate": 3.8163265306122456e-05,
      "loss": 0.1095,
      "step": 561
    },
    {
      "epoch": 5.71,
      "learning_rate": 3.8231292517006806e-05,
      "loss": 0.1401,
      "step": 562
    },
    {
      "epoch": 5.72,
      "learning_rate": 3.8299319727891156e-05,
      "loss": 0.1227,
      "step": 563
    },
    {
      "epoch": 5.73,
      "learning_rate": 3.836734693877551e-05,
      "loss": 0.14,
      "step": 564
    },
    {
      "epoch": 5.74,
      "learning_rate": 3.843537414965986e-05,
      "loss": 0.1716,
      "step": 565
    },
    {
      "epoch": 5.75,
      "learning_rate": 3.850340136054422e-05,
      "loss": 0.0786,
      "step": 566
    },
    {
      "epoch": 5.76,
      "learning_rate": 3.857142857142858e-05,
      "loss": 0.0956,
      "step": 567
    },
    {
      "epoch": 5.77,
      "learning_rate": 3.863945578231293e-05,
      "loss": 0.0408,
      "step": 568
    },
    {
      "epoch": 5.78,
      "learning_rate": 3.8707482993197284e-05,
      "loss": 0.094,
      "step": 569
    },
    {
      "epoch": 5.79,
      "learning_rate": 3.8775510204081634e-05,
      "loss": 0.0889,
      "step": 570
    },
    {
      "epoch": 5.8,
      "learning_rate": 3.8843537414965984e-05,
      "loss": 0.0673,
      "step": 571
    },
    {
      "epoch": 5.81,
      "learning_rate": 3.891156462585034e-05,
      "loss": 0.0785,
      "step": 572
    },
    {
      "epoch": 5.82,
      "learning_rate": 3.89795918367347e-05,
      "loss": 0.0696,
      "step": 573
    },
    {
      "epoch": 5.83,
      "learning_rate": 3.904761904761905e-05,
      "loss": 0.1045,
      "step": 574
    },
    {
      "epoch": 5.84,
      "learning_rate": 3.9115646258503405e-05,
      "loss": 0.0759,
      "step": 575
    },
    {
      "epoch": 5.85,
      "learning_rate": 3.9183673469387755e-05,
      "loss": 0.0667,
      "step": 576
    },
    {
      "epoch": 5.86,
      "learning_rate": 3.925170068027211e-05,
      "loss": 0.0995,
      "step": 577
    },
    {
      "epoch": 5.87,
      "learning_rate": 3.931972789115647e-05,
      "loss": 0.081,
      "step": 578
    },
    {
      "epoch": 5.88,
      "learning_rate": 3.938775510204082e-05,
      "loss": 0.0894,
      "step": 579
    },
    {
      "epoch": 5.89,
      "learning_rate": 3.945578231292517e-05,
      "loss": 0.0673,
      "step": 580
    },
    {
      "epoch": 5.9,
      "learning_rate": 3.9523809523809526e-05,
      "loss": 0.1022,
      "step": 581
    },
    {
      "epoch": 5.91,
      "learning_rate": 3.9591836734693876e-05,
      "loss": 0.1006,
      "step": 582
    },
    {
      "epoch": 5.92,
      "learning_rate": 3.965986394557823e-05,
      "loss": 0.0873,
      "step": 583
    },
    {
      "epoch": 5.93,
      "learning_rate": 3.972789115646259e-05,
      "loss": 0.1126,
      "step": 584
    },
    {
      "epoch": 5.94,
      "learning_rate": 3.979591836734694e-05,
      "loss": 0.0966,
      "step": 585
    },
    {
      "epoch": 5.95,
      "learning_rate": 3.9863945578231296e-05,
      "loss": 0.0973,
      "step": 586
    },
    {
      "epoch": 5.96,
      "learning_rate": 3.9931972789115646e-05,
      "loss": 0.1687,
      "step": 587
    },
    {
      "epoch": 5.97,
      "learning_rate": 4e-05,
      "loss": 0.1244,
      "step": 588
    },
    {
      "epoch": 5.98,
      "learning_rate": 4.006802721088436e-05,
      "loss": 0.1073,
      "step": 589
    },
    {
      "epoch": 5.99,
      "learning_rate": 4.013605442176871e-05,
      "loss": 0.141,
      "step": 590
    },
    {
      "epoch": 6.0,
      "learning_rate": 4.020408163265306e-05,
      "loss": 0.1156,
      "step": 591
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.05040908232331276,
      "eval_runtime": 31.871,
      "eval_samples_per_second": 98.836,
      "eval_steps_per_second": 6.181,
      "eval_wer": 0.024199743918053778,
      "step": 591
    },
    {
      "epoch": 6.01,
      "learning_rate": 4.027210884353742e-05,
      "loss": 0.0802,
      "step": 592
    },
    {
      "epoch": 6.02,
      "learning_rate": 4.0340136054421774e-05,
      "loss": 0.0785,
      "step": 593
    },
    {
      "epoch": 6.03,
      "learning_rate": 4.0408163265306124e-05,
      "loss": 0.0826,
      "step": 594
    },
    {
      "epoch": 6.04,
      "learning_rate": 4.047619047619048e-05,
      "loss": 0.0675,
      "step": 595
    },
    {
      "epoch": 6.05,
      "learning_rate": 4.054421768707483e-05,
      "loss": 0.0769,
      "step": 596
    },
    {
      "epoch": 6.06,
      "learning_rate": 4.061224489795918e-05,
      "loss": 0.1017,
      "step": 597
    },
    {
      "epoch": 6.07,
      "learning_rate": 4.068027210884354e-05,
      "loss": 0.0719,
      "step": 598
    },
    {
      "epoch": 6.08,
      "learning_rate": 4.0748299319727895e-05,
      "loss": 0.0607,
      "step": 599
    },
    {
      "epoch": 6.09,
      "learning_rate": 4.0816326530612245e-05,
      "loss": 0.0782,
      "step": 600
    },
    {
      "epoch": 6.1,
      "learning_rate": 4.08843537414966e-05,
      "loss": 0.084,
      "step": 601
    },
    {
      "epoch": 6.11,
      "learning_rate": 4.095238095238095e-05,
      "loss": 0.1028,
      "step": 602
    },
    {
      "epoch": 6.12,
      "learning_rate": 4.102040816326531e-05,
      "loss": 0.0934,
      "step": 603
    },
    {
      "epoch": 6.13,
      "learning_rate": 4.1088435374149666e-05,
      "loss": 0.0942,
      "step": 604
    },
    {
      "epoch": 6.14,
      "learning_rate": 4.1156462585034016e-05,
      "loss": 0.0671,
      "step": 605
    },
    {
      "epoch": 6.15,
      "learning_rate": 4.122448979591837e-05,
      "loss": 0.0794,
      "step": 606
    },
    {
      "epoch": 6.16,
      "learning_rate": 4.129251700680272e-05,
      "loss": 0.0666,
      "step": 607
    },
    {
      "epoch": 6.17,
      "learning_rate": 4.136054421768707e-05,
      "loss": 0.0703,
      "step": 608
    },
    {
      "epoch": 6.18,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 0.0911,
      "step": 609
    },
    {
      "epoch": 6.19,
      "learning_rate": 4.149659863945579e-05,
      "loss": 0.0985,
      "step": 610
    },
    {
      "epoch": 6.2,
      "learning_rate": 4.156462585034014e-05,
      "loss": 0.096,
      "step": 611
    },
    {
      "epoch": 6.21,
      "learning_rate": 4.1632653061224494e-05,
      "loss": 0.0737,
      "step": 612
    },
    {
      "epoch": 6.22,
      "learning_rate": 4.1700680272108844e-05,
      "loss": 0.1241,
      "step": 613
    },
    {
      "epoch": 6.23,
      "learning_rate": 4.1768707482993194e-05,
      "loss": 0.1688,
      "step": 614
    },
    {
      "epoch": 6.24,
      "learning_rate": 4.183673469387756e-05,
      "loss": 0.185,
      "step": 615
    },
    {
      "epoch": 6.25,
      "learning_rate": 4.190476190476191e-05,
      "loss": 0.0627,
      "step": 616
    },
    {
      "epoch": 6.26,
      "learning_rate": 4.197278911564626e-05,
      "loss": 0.0957,
      "step": 617
    },
    {
      "epoch": 6.27,
      "learning_rate": 4.2040816326530615e-05,
      "loss": 0.0554,
      "step": 618
    },
    {
      "epoch": 6.28,
      "learning_rate": 4.2108843537414965e-05,
      "loss": 0.105,
      "step": 619
    },
    {
      "epoch": 6.29,
      "learning_rate": 4.217687074829932e-05,
      "loss": 0.0673,
      "step": 620
    },
    {
      "epoch": 6.3,
      "learning_rate": 4.224489795918368e-05,
      "loss": 0.0769,
      "step": 621
    },
    {
      "epoch": 6.31,
      "learning_rate": 4.231292517006803e-05,
      "loss": 0.106,
      "step": 622
    },
    {
      "epoch": 6.32,
      "learning_rate": 4.2380952380952385e-05,
      "loss": 0.0716,
      "step": 623
    },
    {
      "epoch": 6.34,
      "learning_rate": 4.2448979591836735e-05,
      "loss": 0.0932,
      "step": 624
    },
    {
      "epoch": 6.35,
      "learning_rate": 4.2517006802721085e-05,
      "loss": 0.0628,
      "step": 625
    },
    {
      "epoch": 6.36,
      "learning_rate": 4.258503401360545e-05,
      "loss": 0.0455,
      "step": 626
    },
    {
      "epoch": 6.37,
      "learning_rate": 4.26530612244898e-05,
      "loss": 0.06,
      "step": 627
    },
    {
      "epoch": 6.38,
      "learning_rate": 4.272108843537415e-05,
      "loss": 0.0506,
      "step": 628
    },
    {
      "epoch": 6.39,
      "learning_rate": 4.2789115646258506e-05,
      "loss": 0.0838,
      "step": 629
    },
    {
      "epoch": 6.4,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 0.0664,
      "step": 630
    },
    {
      "epoch": 6.41,
      "learning_rate": 4.292517006802721e-05,
      "loss": 0.0617,
      "step": 631
    },
    {
      "epoch": 6.42,
      "learning_rate": 4.299319727891157e-05,
      "loss": 0.1026,
      "step": 632
    },
    {
      "epoch": 6.43,
      "learning_rate": 4.306122448979592e-05,
      "loss": 0.08,
      "step": 633
    },
    {
      "epoch": 6.44,
      "learning_rate": 4.312925170068027e-05,
      "loss": 0.0825,
      "step": 634
    },
    {
      "epoch": 6.45,
      "learning_rate": 4.319727891156463e-05,
      "loss": 0.0727,
      "step": 635
    },
    {
      "epoch": 6.46,
      "learning_rate": 4.3265306122448984e-05,
      "loss": 0.0388,
      "step": 636
    },
    {
      "epoch": 6.47,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.0902,
      "step": 637
    },
    {
      "epoch": 6.48,
      "learning_rate": 4.340136054421769e-05,
      "loss": 0.1302,
      "step": 638
    },
    {
      "epoch": 6.49,
      "learning_rate": 4.346938775510204e-05,
      "loss": 0.1319,
      "step": 639
    },
    {
      "epoch": 6.5,
      "learning_rate": 4.35374149659864e-05,
      "loss": 0.033,
      "step": 640
    },
    {
      "epoch": 6.51,
      "learning_rate": 4.360544217687075e-05,
      "loss": 0.0758,
      "step": 641
    },
    {
      "epoch": 6.52,
      "learning_rate": 4.3673469387755105e-05,
      "loss": 0.0967,
      "step": 642
    },
    {
      "epoch": 6.53,
      "learning_rate": 4.374149659863946e-05,
      "loss": 0.0448,
      "step": 643
    },
    {
      "epoch": 6.54,
      "learning_rate": 4.380952380952381e-05,
      "loss": 0.0583,
      "step": 644
    },
    {
      "epoch": 6.55,
      "learning_rate": 4.387755102040816e-05,
      "loss": 0.0991,
      "step": 645
    },
    {
      "epoch": 6.56,
      "learning_rate": 4.394557823129252e-05,
      "loss": 0.0853,
      "step": 646
    },
    {
      "epoch": 6.57,
      "learning_rate": 4.4013605442176876e-05,
      "loss": 0.0939,
      "step": 647
    },
    {
      "epoch": 6.58,
      "learning_rate": 4.4081632653061226e-05,
      "loss": 0.0779,
      "step": 648
    },
    {
      "epoch": 6.59,
      "learning_rate": 4.414965986394558e-05,
      "loss": 0.0733,
      "step": 649
    },
    {
      "epoch": 6.6,
      "learning_rate": 4.421768707482993e-05,
      "loss": 0.0863,
      "step": 650
    },
    {
      "epoch": 6.61,
      "learning_rate": 4.428571428571428e-05,
      "loss": 0.0821,
      "step": 651
    },
    {
      "epoch": 6.62,
      "learning_rate": 4.4353741496598646e-05,
      "loss": 0.0812,
      "step": 652
    },
    {
      "epoch": 6.63,
      "learning_rate": 4.4421768707482997e-05,
      "loss": 0.1195,
      "step": 653
    },
    {
      "epoch": 6.64,
      "learning_rate": 4.448979591836735e-05,
      "loss": 0.1179,
      "step": 654
    },
    {
      "epoch": 6.65,
      "learning_rate": 4.4557823129251704e-05,
      "loss": 0.0644,
      "step": 655
    },
    {
      "epoch": 6.66,
      "learning_rate": 4.4625850340136054e-05,
      "loss": 0.0759,
      "step": 656
    },
    {
      "epoch": 6.67,
      "learning_rate": 4.469387755102041e-05,
      "loss": 0.1104,
      "step": 657
    },
    {
      "epoch": 6.68,
      "learning_rate": 4.476190476190477e-05,
      "loss": 0.0615,
      "step": 658
    },
    {
      "epoch": 6.69,
      "learning_rate": 4.482993197278912e-05,
      "loss": 0.071,
      "step": 659
    },
    {
      "epoch": 6.7,
      "learning_rate": 4.4897959183673474e-05,
      "loss": 0.0904,
      "step": 660
    },
    {
      "epoch": 6.71,
      "learning_rate": 4.4965986394557824e-05,
      "loss": 0.0814,
      "step": 661
    },
    {
      "epoch": 6.72,
      "learning_rate": 4.5034013605442174e-05,
      "loss": 0.0785,
      "step": 662
    },
    {
      "epoch": 6.73,
      "learning_rate": 4.510204081632654e-05,
      "loss": 0.2131,
      "step": 663
    },
    {
      "epoch": 6.74,
      "learning_rate": 4.517006802721089e-05,
      "loss": 0.0726,
      "step": 664
    },
    {
      "epoch": 6.75,
      "learning_rate": 4.523809523809524e-05,
      "loss": 0.049,
      "step": 665
    },
    {
      "epoch": 6.76,
      "learning_rate": 4.5306122448979595e-05,
      "loss": 0.0808,
      "step": 666
    },
    {
      "epoch": 6.77,
      "learning_rate": 4.5374149659863945e-05,
      "loss": 0.055,
      "step": 667
    },
    {
      "epoch": 6.78,
      "learning_rate": 4.54421768707483e-05,
      "loss": 0.0525,
      "step": 668
    },
    {
      "epoch": 6.79,
      "learning_rate": 4.551020408163266e-05,
      "loss": 0.1063,
      "step": 669
    },
    {
      "epoch": 6.8,
      "learning_rate": 4.557823129251701e-05,
      "loss": 0.0705,
      "step": 670
    },
    {
      "epoch": 6.81,
      "learning_rate": 4.564625850340136e-05,
      "loss": 0.0912,
      "step": 671
    },
    {
      "epoch": 6.82,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.1163,
      "step": 672
    },
    {
      "epoch": 6.83,
      "learning_rate": 4.5782312925170066e-05,
      "loss": 0.1227,
      "step": 673
    },
    {
      "epoch": 6.84,
      "learning_rate": 4.585034013605442e-05,
      "loss": 0.0863,
      "step": 674
    },
    {
      "epoch": 6.85,
      "learning_rate": 4.591836734693878e-05,
      "loss": 0.073,
      "step": 675
    },
    {
      "epoch": 6.86,
      "learning_rate": 4.598639455782313e-05,
      "loss": 0.075,
      "step": 676
    },
    {
      "epoch": 6.87,
      "learning_rate": 4.605442176870749e-05,
      "loss": 0.0554,
      "step": 677
    },
    {
      "epoch": 6.88,
      "learning_rate": 4.612244897959184e-05,
      "loss": 0.098,
      "step": 678
    },
    {
      "epoch": 6.89,
      "learning_rate": 4.6190476190476194e-05,
      "loss": 0.0554,
      "step": 679
    },
    {
      "epoch": 6.9,
      "learning_rate": 4.625850340136055e-05,
      "loss": 0.0615,
      "step": 680
    },
    {
      "epoch": 6.91,
      "learning_rate": 4.63265306122449e-05,
      "loss": 0.0706,
      "step": 681
    },
    {
      "epoch": 6.92,
      "learning_rate": 4.639455782312925e-05,
      "loss": 0.0519,
      "step": 682
    },
    {
      "epoch": 6.93,
      "learning_rate": 4.646258503401361e-05,
      "loss": 0.072,
      "step": 683
    },
    {
      "epoch": 6.94,
      "learning_rate": 4.653061224489796e-05,
      "loss": 0.0664,
      "step": 684
    },
    {
      "epoch": 6.95,
      "learning_rate": 4.6598639455782315e-05,
      "loss": 0.0751,
      "step": 685
    },
    {
      "epoch": 6.96,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0986,
      "step": 686
    },
    {
      "epoch": 6.97,
      "learning_rate": 4.673469387755102e-05,
      "loss": 0.0744,
      "step": 687
    },
    {
      "epoch": 6.98,
      "learning_rate": 4.680272108843537e-05,
      "loss": 0.0844,
      "step": 688
    },
    {
      "epoch": 6.99,
      "learning_rate": 4.687074829931973e-05,
      "loss": 0.1129,
      "step": 689
    },
    {
      "epoch": 6.99,
      "eval_loss": 0.04437623172998428,
      "eval_runtime": 31.552,
      "eval_samples_per_second": 99.835,
      "eval_steps_per_second": 6.244,
      "eval_wer": 0.02112676056338028,
      "step": 689
    },
    {
      "epoch": 7.01,
      "learning_rate": 4.6938775510204086e-05,
      "loss": 0.0895,
      "step": 690
    },
    {
      "epoch": 7.02,
      "learning_rate": 4.7006802721088436e-05,
      "loss": 0.0557,
      "step": 691
    },
    {
      "epoch": 7.03,
      "learning_rate": 4.707482993197279e-05,
      "loss": 0.0908,
      "step": 692
    },
    {
      "epoch": 7.04,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.076,
      "step": 693
    },
    {
      "epoch": 7.05,
      "learning_rate": 4.72108843537415e-05,
      "loss": 0.0696,
      "step": 694
    },
    {
      "epoch": 7.06,
      "learning_rate": 4.7278911564625856e-05,
      "loss": 0.0575,
      "step": 695
    },
    {
      "epoch": 7.07,
      "learning_rate": 4.7346938775510206e-05,
      "loss": 0.0396,
      "step": 696
    },
    {
      "epoch": 7.08,
      "learning_rate": 4.741496598639456e-05,
      "loss": 0.0681,
      "step": 697
    },
    {
      "epoch": 7.09,
      "learning_rate": 4.7482993197278913e-05,
      "loss": 0.0394,
      "step": 698
    },
    {
      "epoch": 7.1,
      "learning_rate": 4.7551020408163263e-05,
      "loss": 0.0707,
      "step": 699
    },
    {
      "epoch": 7.11,
      "learning_rate": 4.761904761904762e-05,
      "loss": 0.0901,
      "step": 700
    },
    {
      "epoch": 7.12,
      "learning_rate": 4.768707482993198e-05,
      "loss": 0.0629,
      "step": 701
    },
    {
      "epoch": 7.13,
      "learning_rate": 4.775510204081633e-05,
      "loss": 0.035,
      "step": 702
    },
    {
      "epoch": 7.14,
      "learning_rate": 4.7823129251700684e-05,
      "loss": 0.0507,
      "step": 703
    },
    {
      "epoch": 7.15,
      "learning_rate": 4.7891156462585034e-05,
      "loss": 0.0564,
      "step": 704
    },
    {
      "epoch": 7.16,
      "learning_rate": 4.795918367346939e-05,
      "loss": 0.0815,
      "step": 705
    },
    {
      "epoch": 7.17,
      "learning_rate": 4.802721088435375e-05,
      "loss": 0.0769,
      "step": 706
    },
    {
      "epoch": 7.18,
      "learning_rate": 4.80952380952381e-05,
      "loss": 0.0823,
      "step": 707
    },
    {
      "epoch": 7.19,
      "learning_rate": 4.816326530612245e-05,
      "loss": 0.0629,
      "step": 708
    },
    {
      "epoch": 7.2,
      "learning_rate": 4.8231292517006805e-05,
      "loss": 0.0842,
      "step": 709
    },
    {
      "epoch": 7.21,
      "learning_rate": 4.8299319727891155e-05,
      "loss": 0.0667,
      "step": 710
    },
    {
      "epoch": 7.22,
      "learning_rate": 4.836734693877551e-05,
      "loss": 0.1243,
      "step": 711
    },
    {
      "epoch": 7.23,
      "learning_rate": 4.843537414965987e-05,
      "loss": 0.046,
      "step": 712
    },
    {
      "epoch": 7.24,
      "learning_rate": 4.850340136054422e-05,
      "loss": 0.0864,
      "step": 713
    },
    {
      "epoch": 7.25,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.1021,
      "step": 714
    },
    {
      "epoch": 7.26,
      "learning_rate": 4.8639455782312926e-05,
      "loss": 0.053,
      "step": 715
    },
    {
      "epoch": 7.27,
      "learning_rate": 4.8707482993197276e-05,
      "loss": 0.1095,
      "step": 716
    },
    {
      "epoch": 7.28,
      "learning_rate": 4.877551020408164e-05,
      "loss": 0.1065,
      "step": 717
    },
    {
      "epoch": 7.29,
      "learning_rate": 4.884353741496599e-05,
      "loss": 0.0424,
      "step": 718
    },
    {
      "epoch": 7.3,
      "learning_rate": 4.891156462585034e-05,
      "loss": 0.0634,
      "step": 719
    },
    {
      "epoch": 7.31,
      "learning_rate": 4.89795918367347e-05,
      "loss": 0.056,
      "step": 720
    },
    {
      "epoch": 7.32,
      "learning_rate": 4.904761904761905e-05,
      "loss": 0.034,
      "step": 721
    },
    {
      "epoch": 7.33,
      "learning_rate": 4.9115646258503404e-05,
      "loss": 0.0444,
      "step": 722
    },
    {
      "epoch": 7.34,
      "learning_rate": 4.918367346938776e-05,
      "loss": 0.0785,
      "step": 723
    },
    {
      "epoch": 7.35,
      "learning_rate": 4.925170068027211e-05,
      "loss": 0.0618,
      "step": 724
    },
    {
      "epoch": 7.36,
      "learning_rate": 4.931972789115647e-05,
      "loss": 0.1025,
      "step": 725
    },
    {
      "epoch": 7.37,
      "learning_rate": 4.938775510204082e-05,
      "loss": 0.0537,
      "step": 726
    },
    {
      "epoch": 7.38,
      "learning_rate": 4.9455782312925175e-05,
      "loss": 0.0685,
      "step": 727
    },
    {
      "epoch": 7.39,
      "learning_rate": 4.9523809523809525e-05,
      "loss": 0.0518,
      "step": 728
    },
    {
      "epoch": 7.4,
      "learning_rate": 4.959183673469388e-05,
      "loss": 0.0568,
      "step": 729
    },
    {
      "epoch": 7.41,
      "learning_rate": 4.965986394557823e-05,
      "loss": 0.0708,
      "step": 730
    },
    {
      "epoch": 7.42,
      "learning_rate": 4.972789115646259e-05,
      "loss": 0.0858,
      "step": 731
    },
    {
      "epoch": 7.43,
      "learning_rate": 4.979591836734694e-05,
      "loss": 0.0579,
      "step": 732
    },
    {
      "epoch": 7.44,
      "learning_rate": 4.9863945578231295e-05,
      "loss": 0.0469,
      "step": 733
    },
    {
      "epoch": 7.45,
      "learning_rate": 4.993197278911565e-05,
      "loss": 0.0451,
      "step": 734
    },
    {
      "epoch": 7.46,
      "learning_rate": 5e-05,
      "loss": 0.0756,
      "step": 735
    },
    {
      "epoch": 7.47,
      "learning_rate": 5.006802721088436e-05,
      "loss": 0.0857,
      "step": 736
    },
    {
      "epoch": 7.48,
      "learning_rate": 5.013605442176871e-05,
      "loss": 0.0948,
      "step": 737
    },
    {
      "epoch": 7.49,
      "learning_rate": 5.0204081632653066e-05,
      "loss": 0.0697,
      "step": 738
    },
    {
      "epoch": 7.5,
      "learning_rate": 5.0272108843537416e-05,
      "loss": 0.0149,
      "step": 739
    },
    {
      "epoch": 7.51,
      "learning_rate": 5.034013605442177e-05,
      "loss": 0.0684,
      "step": 740
    },
    {
      "epoch": 7.52,
      "learning_rate": 5.040816326530613e-05,
      "loss": 0.0432,
      "step": 741
    },
    {
      "epoch": 7.53,
      "learning_rate": 5.047619047619048e-05,
      "loss": 0.0564,
      "step": 742
    },
    {
      "epoch": 7.54,
      "learning_rate": 5.054421768707484e-05,
      "loss": 0.1029,
      "step": 743
    },
    {
      "epoch": 7.55,
      "learning_rate": 5.061224489795918e-05,
      "loss": 0.076,
      "step": 744
    },
    {
      "epoch": 7.56,
      "learning_rate": 5.068027210884354e-05,
      "loss": 0.1185,
      "step": 745
    },
    {
      "epoch": 7.57,
      "learning_rate": 5.07482993197279e-05,
      "loss": 0.0462,
      "step": 746
    },
    {
      "epoch": 7.58,
      "learning_rate": 5.0816326530612244e-05,
      "loss": 0.093,
      "step": 747
    },
    {
      "epoch": 7.59,
      "learning_rate": 5.08843537414966e-05,
      "loss": 0.0292,
      "step": 748
    },
    {
      "epoch": 7.6,
      "learning_rate": 5.095238095238095e-05,
      "loss": 0.0495,
      "step": 749
    },
    {
      "epoch": 7.61,
      "learning_rate": 5.102040816326531e-05,
      "loss": 0.0646,
      "step": 750
    },
    {
      "epoch": 7.62,
      "learning_rate": 5.108843537414966e-05,
      "loss": 0.0545,
      "step": 751
    },
    {
      "epoch": 7.63,
      "learning_rate": 5.1156462585034015e-05,
      "loss": 0.0685,
      "step": 752
    },
    {
      "epoch": 7.64,
      "learning_rate": 5.122448979591837e-05,
      "loss": 0.0492,
      "step": 753
    },
    {
      "epoch": 7.65,
      "learning_rate": 5.129251700680272e-05,
      "loss": 0.0406,
      "step": 754
    },
    {
      "epoch": 7.66,
      "learning_rate": 5.136054421768708e-05,
      "loss": 0.0758,
      "step": 755
    },
    {
      "epoch": 7.68,
      "learning_rate": 5.142857142857143e-05,
      "loss": 0.0934,
      "step": 756
    },
    {
      "epoch": 7.69,
      "learning_rate": 5.1496598639455786e-05,
      "loss": 0.1227,
      "step": 757
    },
    {
      "epoch": 7.7,
      "learning_rate": 5.156462585034014e-05,
      "loss": 0.086,
      "step": 758
    },
    {
      "epoch": 7.71,
      "learning_rate": 5.163265306122449e-05,
      "loss": 0.0841,
      "step": 759
    },
    {
      "epoch": 7.72,
      "learning_rate": 5.170068027210885e-05,
      "loss": 0.0461,
      "step": 760
    },
    {
      "epoch": 7.73,
      "learning_rate": 5.176870748299319e-05,
      "loss": 0.1439,
      "step": 761
    },
    {
      "epoch": 7.74,
      "learning_rate": 5.1836734693877557e-05,
      "loss": 0.0853,
      "step": 762
    },
    {
      "epoch": 7.75,
      "learning_rate": 5.1904761904761913e-05,
      "loss": 0.0465,
      "step": 763
    },
    {
      "epoch": 7.76,
      "learning_rate": 5.197278911564626e-05,
      "loss": 0.0363,
      "step": 764
    },
    {
      "epoch": 7.77,
      "learning_rate": 5.2040816326530614e-05,
      "loss": 0.0439,
      "step": 765
    },
    {
      "epoch": 7.78,
      "learning_rate": 5.2108843537414964e-05,
      "loss": 0.0217,
      "step": 766
    },
    {
      "epoch": 7.79,
      "learning_rate": 5.217687074829932e-05,
      "loss": 0.0537,
      "step": 767
    },
    {
      "epoch": 7.8,
      "learning_rate": 5.224489795918368e-05,
      "loss": 0.0363,
      "step": 768
    },
    {
      "epoch": 7.81,
      "learning_rate": 5.231292517006803e-05,
      "loss": 0.0576,
      "step": 769
    },
    {
      "epoch": 7.82,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 0.054,
      "step": 770
    },
    {
      "epoch": 7.83,
      "learning_rate": 5.2448979591836735e-05,
      "loss": 0.0645,
      "step": 771
    },
    {
      "epoch": 7.84,
      "learning_rate": 5.251700680272109e-05,
      "loss": 0.0947,
      "step": 772
    },
    {
      "epoch": 7.85,
      "learning_rate": 5.258503401360545e-05,
      "loss": 0.0605,
      "step": 773
    },
    {
      "epoch": 7.86,
      "learning_rate": 5.26530612244898e-05,
      "loss": 0.0568,
      "step": 774
    },
    {
      "epoch": 7.87,
      "learning_rate": 5.2721088435374155e-05,
      "loss": 0.0732,
      "step": 775
    },
    {
      "epoch": 7.88,
      "learning_rate": 5.2789115646258505e-05,
      "loss": 0.0635,
      "step": 776
    },
    {
      "epoch": 7.89,
      "learning_rate": 5.285714285714286e-05,
      "loss": 0.0278,
      "step": 777
    },
    {
      "epoch": 7.9,
      "learning_rate": 5.292517006802722e-05,
      "loss": 0.0591,
      "step": 778
    },
    {
      "epoch": 7.91,
      "learning_rate": 5.299319727891157e-05,
      "loss": 0.037,
      "step": 779
    },
    {
      "epoch": 7.92,
      "learning_rate": 5.3061224489795926e-05,
      "loss": 0.0518,
      "step": 780
    },
    {
      "epoch": 7.93,
      "learning_rate": 5.312925170068027e-05,
      "loss": 0.0706,
      "step": 781
    },
    {
      "epoch": 7.94,
      "learning_rate": 5.319727891156463e-05,
      "loss": 0.0985,
      "step": 782
    },
    {
      "epoch": 7.95,
      "learning_rate": 5.3265306122448976e-05,
      "loss": 0.0526,
      "step": 783
    },
    {
      "epoch": 7.96,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.0877,
      "step": 784
    },
    {
      "epoch": 7.97,
      "learning_rate": 5.340136054421769e-05,
      "loss": 0.1279,
      "step": 785
    },
    {
      "epoch": 7.98,
      "learning_rate": 5.346938775510204e-05,
      "loss": 0.1198,
      "step": 786
    },
    {
      "epoch": 7.99,
      "learning_rate": 5.35374149659864e-05,
      "loss": 0.0358,
      "step": 787
    },
    {
      "epoch": 8.0,
      "learning_rate": 5.360544217687075e-05,
      "loss": 0.1291,
      "step": 788
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.03692350536584854,
      "eval_runtime": 32.6586,
      "eval_samples_per_second": 96.452,
      "eval_steps_per_second": 6.032,
      "eval_wer": 0.02029449423815621,
      "step": 788
    },
    {
      "epoch": 8.01,
      "learning_rate": 5.3673469387755104e-05,
      "loss": 0.044,
      "step": 789
    },
    {
      "epoch": 8.02,
      "learning_rate": 5.374149659863946e-05,
      "loss": 0.0413,
      "step": 790
    },
    {
      "epoch": 8.03,
      "learning_rate": 5.380952380952381e-05,
      "loss": 0.0443,
      "step": 791
    },
    {
      "epoch": 8.04,
      "learning_rate": 5.387755102040817e-05,
      "loss": 0.0351,
      "step": 792
    },
    {
      "epoch": 8.05,
      "learning_rate": 5.394557823129252e-05,
      "loss": 0.042,
      "step": 793
    },
    {
      "epoch": 8.06,
      "learning_rate": 5.4013605442176875e-05,
      "loss": 0.0842,
      "step": 794
    },
    {
      "epoch": 8.07,
      "learning_rate": 5.408163265306123e-05,
      "loss": 0.052,
      "step": 795
    },
    {
      "epoch": 8.08,
      "learning_rate": 5.414965986394558e-05,
      "loss": 0.0834,
      "step": 796
    },
    {
      "epoch": 8.09,
      "learning_rate": 5.421768707482994e-05,
      "loss": 0.0262,
      "step": 797
    },
    {
      "epoch": 8.1,
      "learning_rate": 5.428571428571428e-05,
      "loss": 0.0513,
      "step": 798
    },
    {
      "epoch": 8.11,
      "learning_rate": 5.4353741496598646e-05,
      "loss": 0.0359,
      "step": 799
    },
    {
      "epoch": 8.12,
      "learning_rate": 5.4421768707483e-05,
      "loss": 0.0736,
      "step": 800
    },
    {
      "epoch": 8.13,
      "learning_rate": 5.4489795918367346e-05,
      "loss": 0.0726,
      "step": 801
    },
    {
      "epoch": 8.14,
      "learning_rate": 5.455782312925171e-05,
      "loss": 0.0697,
      "step": 802
    },
    {
      "epoch": 8.15,
      "learning_rate": 5.462585034013605e-05,
      "loss": 0.0419,
      "step": 803
    },
    {
      "epoch": 8.16,
      "learning_rate": 5.469387755102041e-05,
      "loss": 0.05,
      "step": 804
    },
    {
      "epoch": 8.17,
      "learning_rate": 5.4761904761904766e-05,
      "loss": 0.0824,
      "step": 805
    },
    {
      "epoch": 8.18,
      "learning_rate": 5.4829931972789117e-05,
      "loss": 0.0507,
      "step": 806
    },
    {
      "epoch": 8.19,
      "learning_rate": 5.4897959183673473e-05,
      "loss": 0.0632,
      "step": 807
    },
    {
      "epoch": 8.2,
      "learning_rate": 5.4965986394557824e-05,
      "loss": 0.0616,
      "step": 808
    },
    {
      "epoch": 8.21,
      "learning_rate": 5.503401360544218e-05,
      "loss": 0.0823,
      "step": 809
    },
    {
      "epoch": 8.22,
      "learning_rate": 5.510204081632653e-05,
      "loss": 0.0858,
      "step": 810
    },
    {
      "epoch": 8.23,
      "learning_rate": 5.517006802721089e-05,
      "loss": 0.0692,
      "step": 811
    },
    {
      "epoch": 8.24,
      "learning_rate": 5.5238095238095244e-05,
      "loss": 0.1393,
      "step": 812
    },
    {
      "epoch": 8.25,
      "learning_rate": 5.5306122448979594e-05,
      "loss": 0.0546,
      "step": 813
    },
    {
      "epoch": 8.26,
      "learning_rate": 5.537414965986395e-05,
      "loss": 0.0602,
      "step": 814
    },
    {
      "epoch": 8.27,
      "learning_rate": 5.5442176870748295e-05,
      "loss": 0.0449,
      "step": 815
    },
    {
      "epoch": 8.28,
      "learning_rate": 5.551020408163266e-05,
      "loss": 0.0266,
      "step": 816
    },
    {
      "epoch": 8.29,
      "learning_rate": 5.5578231292517015e-05,
      "loss": 0.0304,
      "step": 817
    },
    {
      "epoch": 8.3,
      "learning_rate": 5.564625850340136e-05,
      "loss": 0.0406,
      "step": 818
    },
    {
      "epoch": 8.31,
      "learning_rate": 5.571428571428572e-05,
      "loss": 0.0305,
      "step": 819
    },
    {
      "epoch": 8.32,
      "learning_rate": 5.5782312925170065e-05,
      "loss": 0.0757,
      "step": 820
    },
    {
      "epoch": 8.34,
      "learning_rate": 5.585034013605442e-05,
      "loss": 0.0382,
      "step": 821
    },
    {
      "epoch": 8.35,
      "learning_rate": 5.5918367346938786e-05,
      "loss": 0.0316,
      "step": 822
    },
    {
      "epoch": 8.36,
      "learning_rate": 5.598639455782313e-05,
      "loss": 0.0362,
      "step": 823
    },
    {
      "epoch": 8.37,
      "learning_rate": 5.6054421768707486e-05,
      "loss": 0.0273,
      "step": 824
    },
    {
      "epoch": 8.38,
      "learning_rate": 5.6122448979591836e-05,
      "loss": 0.0305,
      "step": 825
    },
    {
      "epoch": 8.39,
      "learning_rate": 5.619047619047619e-05,
      "loss": 0.0731,
      "step": 826
    },
    {
      "epoch": 8.4,
      "learning_rate": 5.625850340136055e-05,
      "loss": 0.0474,
      "step": 827
    },
    {
      "epoch": 8.41,
      "learning_rate": 5.63265306122449e-05,
      "loss": 0.0411,
      "step": 828
    },
    {
      "epoch": 8.42,
      "learning_rate": 5.639455782312926e-05,
      "loss": 0.0707,
      "step": 829
    },
    {
      "epoch": 8.43,
      "learning_rate": 5.646258503401361e-05,
      "loss": 0.08,
      "step": 830
    },
    {
      "epoch": 8.44,
      "learning_rate": 5.6530612244897964e-05,
      "loss": 0.0133,
      "step": 831
    },
    {
      "epoch": 8.45,
      "learning_rate": 5.659863945578232e-05,
      "loss": 0.0587,
      "step": 832
    },
    {
      "epoch": 8.46,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.0234,
      "step": 833
    },
    {
      "epoch": 8.47,
      "learning_rate": 5.673469387755103e-05,
      "loss": 0.0586,
      "step": 834
    },
    {
      "epoch": 8.48,
      "learning_rate": 5.680272108843537e-05,
      "loss": 0.0618,
      "step": 835
    },
    {
      "epoch": 8.49,
      "learning_rate": 5.6870748299319735e-05,
      "loss": 0.0787,
      "step": 836
    },
    {
      "epoch": 8.5,
      "learning_rate": 5.693877551020409e-05,
      "loss": 0.0628,
      "step": 837
    },
    {
      "epoch": 8.51,
      "learning_rate": 5.7006802721088435e-05,
      "loss": 0.0332,
      "step": 838
    },
    {
      "epoch": 8.52,
      "learning_rate": 5.70748299319728e-05,
      "loss": 0.0503,
      "step": 839
    },
    {
      "epoch": 8.53,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.0359,
      "step": 840
    },
    {
      "epoch": 8.54,
      "learning_rate": 5.72108843537415e-05,
      "loss": 0.0263,
      "step": 841
    },
    {
      "epoch": 8.55,
      "learning_rate": 5.727891156462585e-05,
      "loss": 0.0369,
      "step": 842
    },
    {
      "epoch": 8.56,
      "learning_rate": 5.7346938775510206e-05,
      "loss": 0.0457,
      "step": 843
    },
    {
      "epoch": 8.57,
      "learning_rate": 5.741496598639456e-05,
      "loss": 0.0202,
      "step": 844
    },
    {
      "epoch": 8.58,
      "learning_rate": 5.748299319727891e-05,
      "loss": 0.0427,
      "step": 845
    },
    {
      "epoch": 8.59,
      "learning_rate": 5.755102040816327e-05,
      "loss": 0.0742,
      "step": 846
    },
    {
      "epoch": 8.6,
      "learning_rate": 5.761904761904762e-05,
      "loss": 0.0378,
      "step": 847
    },
    {
      "epoch": 8.61,
      "learning_rate": 5.7687074829931976e-05,
      "loss": 0.0778,
      "step": 848
    },
    {
      "epoch": 8.62,
      "learning_rate": 5.775510204081633e-05,
      "loss": 0.0518,
      "step": 849
    },
    {
      "epoch": 8.63,
      "learning_rate": 5.782312925170068e-05,
      "loss": 0.0465,
      "step": 850
    },
    {
      "epoch": 8.64,
      "learning_rate": 5.789115646258504e-05,
      "loss": 0.027,
      "step": 851
    },
    {
      "epoch": 8.65,
      "learning_rate": 5.7959183673469384e-05,
      "loss": 0.0576,
      "step": 852
    },
    {
      "epoch": 8.66,
      "learning_rate": 5.802721088435375e-05,
      "loss": 0.0636,
      "step": 853
    },
    {
      "epoch": 8.67,
      "learning_rate": 5.8095238095238104e-05,
      "loss": 0.0548,
      "step": 854
    },
    {
      "epoch": 8.68,
      "learning_rate": 5.816326530612245e-05,
      "loss": 0.0741,
      "step": 855
    },
    {
      "epoch": 8.69,
      "learning_rate": 5.823129251700681e-05,
      "loss": 0.0786,
      "step": 856
    },
    {
      "epoch": 8.7,
      "learning_rate": 5.8299319727891154e-05,
      "loss": 0.0516,
      "step": 857
    },
    {
      "epoch": 8.71,
      "learning_rate": 5.836734693877551e-05,
      "loss": 0.0845,
      "step": 858
    },
    {
      "epoch": 8.72,
      "learning_rate": 5.8435374149659875e-05,
      "loss": 0.0646,
      "step": 859
    },
    {
      "epoch": 8.73,
      "learning_rate": 5.850340136054422e-05,
      "loss": 0.1427,
      "step": 860
    },
    {
      "epoch": 8.74,
      "learning_rate": 5.8571428571428575e-05,
      "loss": 0.0465,
      "step": 861
    },
    {
      "epoch": 8.75,
      "learning_rate": 5.8639455782312925e-05,
      "loss": 0.0319,
      "step": 862
    },
    {
      "epoch": 8.76,
      "learning_rate": 5.870748299319728e-05,
      "loss": 0.0195,
      "step": 863
    },
    {
      "epoch": 8.77,
      "learning_rate": 5.877551020408164e-05,
      "loss": 0.047,
      "step": 864
    },
    {
      "epoch": 8.78,
      "learning_rate": 5.884353741496599e-05,
      "loss": 0.0255,
      "step": 865
    },
    {
      "epoch": 8.79,
      "learning_rate": 5.8911564625850346e-05,
      "loss": 0.0574,
      "step": 866
    },
    {
      "epoch": 8.8,
      "learning_rate": 5.8979591836734696e-05,
      "loss": 0.0943,
      "step": 867
    },
    {
      "epoch": 8.81,
      "learning_rate": 5.904761904761905e-05,
      "loss": 0.0882,
      "step": 868
    },
    {
      "epoch": 8.82,
      "learning_rate": 5.9115646258503396e-05,
      "loss": 0.0387,
      "step": 869
    },
    {
      "epoch": 8.83,
      "learning_rate": 5.918367346938776e-05,
      "loss": 0.0525,
      "step": 870
    },
    {
      "epoch": 8.84,
      "learning_rate": 5.9251700680272117e-05,
      "loss": 0.0626,
      "step": 871
    },
    {
      "epoch": 8.85,
      "learning_rate": 5.931972789115646e-05,
      "loss": 0.0462,
      "step": 872
    },
    {
      "epoch": 8.86,
      "learning_rate": 5.9387755102040824e-05,
      "loss": 0.0249,
      "step": 873
    },
    {
      "epoch": 8.87,
      "learning_rate": 5.945578231292517e-05,
      "loss": 0.0457,
      "step": 874
    },
    {
      "epoch": 8.88,
      "learning_rate": 5.9523809523809524e-05,
      "loss": 0.0265,
      "step": 875
    },
    {
      "epoch": 8.89,
      "learning_rate": 5.959183673469389e-05,
      "loss": 0.0574,
      "step": 876
    },
    {
      "epoch": 8.9,
      "learning_rate": 5.965986394557823e-05,
      "loss": 0.0858,
      "step": 877
    },
    {
      "epoch": 8.91,
      "learning_rate": 5.972789115646259e-05,
      "loss": 0.0607,
      "step": 878
    },
    {
      "epoch": 8.92,
      "learning_rate": 5.979591836734694e-05,
      "loss": 0.0869,
      "step": 879
    },
    {
      "epoch": 8.93,
      "learning_rate": 5.9863945578231295e-05,
      "loss": 0.0294,
      "step": 880
    },
    {
      "epoch": 8.94,
      "learning_rate": 5.993197278911565e-05,
      "loss": 0.0604,
      "step": 881
    },
    {
      "epoch": 8.95,
      "learning_rate": 6e-05,
      "loss": 0.0418,
      "step": 882
    },
    {
      "epoch": 8.96,
      "learning_rate": 6.006802721088436e-05,
      "loss": 0.0356,
      "step": 883
    },
    {
      "epoch": 8.97,
      "learning_rate": 6.013605442176871e-05,
      "loss": 0.1019,
      "step": 884
    },
    {
      "epoch": 8.98,
      "learning_rate": 6.0204081632653065e-05,
      "loss": 0.028,
      "step": 885
    },
    {
      "epoch": 8.99,
      "learning_rate": 6.027210884353742e-05,
      "loss": 0.0405,
      "step": 886
    },
    {
      "epoch": 8.99,
      "eval_loss": 0.0335860438644886,
      "eval_runtime": 31.8889,
      "eval_samples_per_second": 98.781,
      "eval_steps_per_second": 6.178,
      "eval_wer": 0.017765685019206147,
      "step": 886
    },
    {
      "epoch": 9.01,
      "learning_rate": 6.034013605442177e-05,
      "loss": 0.0834,
      "step": 887
    },
    {
      "epoch": 9.02,
      "learning_rate": 6.040816326530613e-05,
      "loss": 0.0399,
      "step": 888
    },
    {
      "epoch": 9.03,
      "learning_rate": 6.047619047619047e-05,
      "loss": 0.0563,
      "step": 889
    },
    {
      "epoch": 9.04,
      "learning_rate": 6.0544217687074836e-05,
      "loss": 0.0478,
      "step": 890
    },
    {
      "epoch": 9.05,
      "learning_rate": 6.061224489795919e-05,
      "loss": 0.0543,
      "step": 891
    },
    {
      "epoch": 9.06,
      "learning_rate": 6.0680272108843536e-05,
      "loss": 0.0352,
      "step": 892
    },
    {
      "epoch": 9.07,
      "learning_rate": 6.07482993197279e-05,
      "loss": 0.0418,
      "step": 893
    },
    {
      "epoch": 9.08,
      "learning_rate": 6.081632653061224e-05,
      "loss": 0.0325,
      "step": 894
    },
    {
      "epoch": 9.09,
      "learning_rate": 6.08843537414966e-05,
      "loss": 0.0461,
      "step": 895
    },
    {
      "epoch": 9.1,
      "learning_rate": 6.0952380952380964e-05,
      "loss": 0.0773,
      "step": 896
    },
    {
      "epoch": 9.11,
      "learning_rate": 6.102040816326531e-05,
      "loss": 0.0275,
      "step": 897
    },
    {
      "epoch": 9.12,
      "learning_rate": 6.108843537414966e-05,
      "loss": 0.0278,
      "step": 898
    },
    {
      "epoch": 9.13,
      "learning_rate": 6.115646258503401e-05,
      "loss": 0.0486,
      "step": 899
    },
    {
      "epoch": 9.14,
      "learning_rate": 6.122448979591838e-05,
      "loss": 0.0278,
      "step": 900
    },
    {
      "epoch": 9.15,
      "learning_rate": 6.129251700680272e-05,
      "loss": 0.0347,
      "step": 901
    },
    {
      "epoch": 9.16,
      "learning_rate": 6.136054421768708e-05,
      "loss": 0.0554,
      "step": 902
    },
    {
      "epoch": 9.17,
      "learning_rate": 6.142857142857143e-05,
      "loss": 0.0453,
      "step": 903
    },
    {
      "epoch": 9.18,
      "learning_rate": 6.149659863945578e-05,
      "loss": 0.0231,
      "step": 904
    },
    {
      "epoch": 9.19,
      "learning_rate": 6.156462585034013e-05,
      "loss": 0.0392,
      "step": 905
    },
    {
      "epoch": 9.2,
      "learning_rate": 6.163265306122449e-05,
      "loss": 0.0495,
      "step": 906
    },
    {
      "epoch": 9.21,
      "learning_rate": 6.170068027210885e-05,
      "loss": 0.035,
      "step": 907
    },
    {
      "epoch": 9.22,
      "learning_rate": 6.17687074829932e-05,
      "loss": 0.0863,
      "step": 908
    },
    {
      "epoch": 9.23,
      "learning_rate": 6.183673469387755e-05,
      "loss": 0.0778,
      "step": 909
    },
    {
      "epoch": 9.24,
      "learning_rate": 6.19047619047619e-05,
      "loss": 0.0289,
      "step": 910
    },
    {
      "epoch": 9.25,
      "learning_rate": 6.197278911564626e-05,
      "loss": 0.0788,
      "step": 911
    },
    {
      "epoch": 9.26,
      "learning_rate": 6.204081632653062e-05,
      "loss": 0.0469,
      "step": 912
    },
    {
      "epoch": 9.27,
      "learning_rate": 6.210884353741498e-05,
      "loss": 0.0295,
      "step": 913
    },
    {
      "epoch": 9.28,
      "learning_rate": 6.217687074829932e-05,
      "loss": 0.0573,
      "step": 914
    },
    {
      "epoch": 9.29,
      "learning_rate": 6.224489795918368e-05,
      "loss": 0.0231,
      "step": 915
    },
    {
      "epoch": 9.3,
      "learning_rate": 6.231292517006802e-05,
      "loss": 0.0319,
      "step": 916
    },
    {
      "epoch": 9.31,
      "learning_rate": 6.238095238095239e-05,
      "loss": 0.0337,
      "step": 917
    },
    {
      "epoch": 9.32,
      "learning_rate": 6.244897959183675e-05,
      "loss": 0.0619,
      "step": 918
    },
    {
      "epoch": 9.33,
      "learning_rate": 6.251700680272109e-05,
      "loss": 0.0519,
      "step": 919
    },
    {
      "epoch": 9.34,
      "learning_rate": 6.258503401360545e-05,
      "loss": 0.0373,
      "step": 920
    },
    {
      "epoch": 9.35,
      "learning_rate": 6.265306122448979e-05,
      "loss": 0.0237,
      "step": 921
    },
    {
      "epoch": 9.36,
      "learning_rate": 6.272108843537415e-05,
      "loss": 0.043,
      "step": 922
    },
    {
      "epoch": 9.37,
      "learning_rate": 6.278911564625852e-05,
      "loss": 0.0741,
      "step": 923
    },
    {
      "epoch": 9.38,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.0701,
      "step": 924
    },
    {
      "epoch": 9.39,
      "learning_rate": 6.292517006802722e-05,
      "loss": 0.0347,
      "step": 925
    },
    {
      "epoch": 9.4,
      "learning_rate": 6.299319727891156e-05,
      "loss": 0.0422,
      "step": 926
    },
    {
      "epoch": 9.41,
      "learning_rate": 6.306122448979592e-05,
      "loss": 0.0345,
      "step": 927
    },
    {
      "epoch": 9.42,
      "learning_rate": 6.312925170068028e-05,
      "loss": 0.0801,
      "step": 928
    },
    {
      "epoch": 9.43,
      "learning_rate": 6.319727891156463e-05,
      "loss": 0.0613,
      "step": 929
    },
    {
      "epoch": 9.44,
      "learning_rate": 6.326530612244899e-05,
      "loss": 0.0436,
      "step": 930
    },
    {
      "epoch": 9.45,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.0714,
      "step": 931
    },
    {
      "epoch": 9.46,
      "learning_rate": 6.340136054421769e-05,
      "loss": 0.0502,
      "step": 932
    },
    {
      "epoch": 9.47,
      "learning_rate": 6.346938775510203e-05,
      "loss": 0.0756,
      "step": 933
    },
    {
      "epoch": 9.48,
      "learning_rate": 6.35374149659864e-05,
      "loss": 0.0849,
      "step": 934
    },
    {
      "epoch": 9.49,
      "learning_rate": 6.360544217687076e-05,
      "loss": 0.0535,
      "step": 935
    },
    {
      "epoch": 9.5,
      "learning_rate": 6.36734693877551e-05,
      "loss": 0.0401,
      "step": 936
    },
    {
      "epoch": 9.51,
      "learning_rate": 6.374149659863946e-05,
      "loss": 0.024,
      "step": 937
    },
    {
      "epoch": 9.52,
      "learning_rate": 6.38095238095238e-05,
      "loss": 0.037,
      "step": 938
    },
    {
      "epoch": 9.53,
      "learning_rate": 6.387755102040816e-05,
      "loss": 0.0284,
      "step": 939
    },
    {
      "epoch": 9.54,
      "learning_rate": 6.394557823129253e-05,
      "loss": 0.0166,
      "step": 940
    },
    {
      "epoch": 9.55,
      "learning_rate": 6.401360544217687e-05,
      "loss": 0.0215,
      "step": 941
    },
    {
      "epoch": 9.56,
      "learning_rate": 6.408163265306123e-05,
      "loss": 0.0683,
      "step": 942
    },
    {
      "epoch": 9.57,
      "learning_rate": 6.414965986394557e-05,
      "loss": 0.044,
      "step": 943
    },
    {
      "epoch": 9.58,
      "learning_rate": 6.421768707482993e-05,
      "loss": 0.0401,
      "step": 944
    },
    {
      "epoch": 9.59,
      "learning_rate": 6.428571428571429e-05,
      "loss": 0.0424,
      "step": 945
    },
    {
      "epoch": 9.6,
      "learning_rate": 6.435374149659864e-05,
      "loss": 0.072,
      "step": 946
    },
    {
      "epoch": 9.61,
      "learning_rate": 6.4421768707483e-05,
      "loss": 0.0174,
      "step": 947
    },
    {
      "epoch": 9.62,
      "learning_rate": 6.448979591836734e-05,
      "loss": 0.0392,
      "step": 948
    },
    {
      "epoch": 9.63,
      "learning_rate": 6.45578231292517e-05,
      "loss": 0.0576,
      "step": 949
    },
    {
      "epoch": 9.64,
      "learning_rate": 6.462585034013606e-05,
      "loss": 0.0509,
      "step": 950
    },
    {
      "epoch": 9.65,
      "learning_rate": 6.469387755102042e-05,
      "loss": 0.0884,
      "step": 951
    },
    {
      "epoch": 9.66,
      "learning_rate": 6.476190476190477e-05,
      "loss": 0.0251,
      "step": 952
    },
    {
      "epoch": 9.68,
      "learning_rate": 6.482993197278912e-05,
      "loss": 0.0182,
      "step": 953
    },
    {
      "epoch": 9.69,
      "learning_rate": 6.489795918367347e-05,
      "loss": 0.0637,
      "step": 954
    },
    {
      "epoch": 9.7,
      "learning_rate": 6.496598639455783e-05,
      "loss": 0.0371,
      "step": 955
    },
    {
      "epoch": 9.71,
      "learning_rate": 6.503401360544217e-05,
      "loss": 0.0465,
      "step": 956
    },
    {
      "epoch": 9.72,
      "learning_rate": 6.510204081632654e-05,
      "loss": 0.0731,
      "step": 957
    },
    {
      "epoch": 9.73,
      "learning_rate": 6.517006802721089e-05,
      "loss": 0.1176,
      "step": 958
    },
    {
      "epoch": 9.74,
      "learning_rate": 6.523809523809524e-05,
      "loss": 0.0835,
      "step": 959
    },
    {
      "epoch": 9.75,
      "learning_rate": 6.530612244897959e-05,
      "loss": 0.051,
      "step": 960
    },
    {
      "epoch": 9.76,
      "learning_rate": 6.537414965986394e-05,
      "loss": 0.0211,
      "step": 961
    },
    {
      "epoch": 9.77,
      "learning_rate": 6.54421768707483e-05,
      "loss": 0.05,
      "step": 962
    },
    {
      "epoch": 9.78,
      "learning_rate": 6.551020408163266e-05,
      "loss": 0.0595,
      "step": 963
    },
    {
      "epoch": 9.79,
      "learning_rate": 6.557823129251701e-05,
      "loss": 0.0729,
      "step": 964
    },
    {
      "epoch": 9.8,
      "learning_rate": 6.564625850340136e-05,
      "loss": 0.0329,
      "step": 965
    },
    {
      "epoch": 9.81,
      "learning_rate": 6.571428571428571e-05,
      "loss": 0.068,
      "step": 966
    },
    {
      "epoch": 9.82,
      "learning_rate": 6.578231292517007e-05,
      "loss": 0.0325,
      "step": 967
    },
    {
      "epoch": 9.83,
      "learning_rate": 6.585034013605443e-05,
      "loss": 0.0298,
      "step": 968
    },
    {
      "epoch": 9.84,
      "learning_rate": 6.591836734693878e-05,
      "loss": 0.0729,
      "step": 969
    },
    {
      "epoch": 9.85,
      "learning_rate": 6.598639455782313e-05,
      "loss": 0.0473,
      "step": 970
    },
    {
      "epoch": 9.86,
      "learning_rate": 6.605442176870749e-05,
      "loss": 0.0143,
      "step": 971
    },
    {
      "epoch": 9.87,
      "learning_rate": 6.612244897959184e-05,
      "loss": 0.0459,
      "step": 972
    },
    {
      "epoch": 9.88,
      "learning_rate": 6.619047619047619e-05,
      "loss": 0.0294,
      "step": 973
    },
    {
      "epoch": 9.89,
      "learning_rate": 6.625850340136056e-05,
      "loss": 0.0317,
      "step": 974
    },
    {
      "epoch": 9.9,
      "learning_rate": 6.63265306122449e-05,
      "loss": 0.061,
      "step": 975
    },
    {
      "epoch": 9.91,
      "learning_rate": 6.639455782312926e-05,
      "loss": 0.0526,
      "step": 976
    },
    {
      "epoch": 9.92,
      "learning_rate": 6.646258503401361e-05,
      "loss": 0.0287,
      "step": 977
    },
    {
      "epoch": 9.93,
      "learning_rate": 6.653061224489796e-05,
      "loss": 0.0564,
      "step": 978
    },
    {
      "epoch": 9.94,
      "learning_rate": 6.659863945578231e-05,
      "loss": 0.0391,
      "step": 979
    },
    {
      "epoch": 9.95,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0569,
      "step": 980
    },
    {
      "epoch": 9.96,
      "learning_rate": 6.673469387755103e-05,
      "loss": 0.0666,
      "step": 981
    },
    {
      "epoch": 9.97,
      "learning_rate": 6.680272108843538e-05,
      "loss": 0.088,
      "step": 982
    },
    {
      "epoch": 9.98,
      "learning_rate": 6.687074829931973e-05,
      "loss": 0.0817,
      "step": 983
    },
    {
      "epoch": 9.99,
      "learning_rate": 6.693877551020408e-05,
      "loss": 0.0452,
      "step": 984
    },
    {
      "epoch": 10.0,
      "learning_rate": 6.700680272108844e-05,
      "loss": 0.0325,
      "step": 985
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.027066553011536598,
      "eval_runtime": 33.4008,
      "eval_samples_per_second": 94.309,
      "eval_steps_per_second": 5.898,
      "eval_wer": 0.01411651728553137,
      "step": 985
    },
    {
      "epoch": 10.01,
      "learning_rate": 6.70748299319728e-05,
      "loss": 0.0608,
      "step": 986
    },
    {
      "epoch": 10.02,
      "learning_rate": 6.714285714285714e-05,
      "loss": 0.0484,
      "step": 987
    },
    {
      "epoch": 10.03,
      "learning_rate": 6.72108843537415e-05,
      "loss": 0.0638,
      "step": 988
    },
    {
      "epoch": 10.04,
      "learning_rate": 6.727891156462585e-05,
      "loss": 0.0232,
      "step": 989
    },
    {
      "epoch": 10.05,
      "learning_rate": 6.73469387755102e-05,
      "loss": 0.0175,
      "step": 990
    },
    {
      "epoch": 10.06,
      "learning_rate": 6.741496598639457e-05,
      "loss": 0.0458,
      "step": 991
    },
    {
      "epoch": 10.07,
      "learning_rate": 6.748299319727891e-05,
      "loss": 0.0638,
      "step": 992
    },
    {
      "epoch": 10.08,
      "learning_rate": 6.755102040816327e-05,
      "loss": 0.0408,
      "step": 993
    },
    {
      "epoch": 10.09,
      "learning_rate": 6.761904761904763e-05,
      "loss": 0.0205,
      "step": 994
    },
    {
      "epoch": 10.1,
      "learning_rate": 6.768707482993197e-05,
      "loss": 0.0316,
      "step": 995
    },
    {
      "epoch": 10.11,
      "learning_rate": 6.775510204081633e-05,
      "loss": 0.0742,
      "step": 996
    },
    {
      "epoch": 10.12,
      "learning_rate": 6.782312925170068e-05,
      "loss": 0.0655,
      "step": 997
    },
    {
      "epoch": 10.13,
      "learning_rate": 6.789115646258504e-05,
      "loss": 0.0295,
      "step": 998
    },
    {
      "epoch": 10.14,
      "learning_rate": 6.79591836734694e-05,
      "loss": 0.0213,
      "step": 999
    },
    {
      "epoch": 10.15,
      "learning_rate": 6.802721088435374e-05,
      "loss": 0.0508,
      "step": 1000
    },
    {
      "epoch": 10.16,
      "learning_rate": 6.80952380952381e-05,
      "loss": 0.0103,
      "step": 1001
    },
    {
      "epoch": 10.17,
      "learning_rate": 6.816326530612245e-05,
      "loss": 0.0577,
      "step": 1002
    },
    {
      "epoch": 10.18,
      "learning_rate": 6.823129251700681e-05,
      "loss": 0.0272,
      "step": 1003
    },
    {
      "epoch": 10.19,
      "learning_rate": 6.829931972789117e-05,
      "loss": 0.0768,
      "step": 1004
    },
    {
      "epoch": 10.2,
      "learning_rate": 6.836734693877551e-05,
      "loss": 0.0629,
      "step": 1005
    },
    {
      "epoch": 10.21,
      "learning_rate": 6.843537414965987e-05,
      "loss": 0.0394,
      "step": 1006
    },
    {
      "epoch": 10.22,
      "learning_rate": 6.850340136054421e-05,
      "loss": 0.0799,
      "step": 1007
    },
    {
      "epoch": 10.23,
      "learning_rate": 6.857142857142858e-05,
      "loss": 0.086,
      "step": 1008
    },
    {
      "epoch": 10.24,
      "learning_rate": 6.863945578231294e-05,
      "loss": 0.0584,
      "step": 1009
    },
    {
      "epoch": 10.25,
      "learning_rate": 6.870748299319728e-05,
      "loss": 0.0519,
      "step": 1010
    },
    {
      "epoch": 10.26,
      "learning_rate": 6.877551020408164e-05,
      "loss": 0.0451,
      "step": 1011
    },
    {
      "epoch": 10.27,
      "learning_rate": 6.884353741496598e-05,
      "loss": 0.0249,
      "step": 1012
    },
    {
      "epoch": 10.28,
      "learning_rate": 6.891156462585034e-05,
      "loss": 0.0258,
      "step": 1013
    },
    {
      "epoch": 10.29,
      "learning_rate": 6.897959183673471e-05,
      "loss": 0.0261,
      "step": 1014
    },
    {
      "epoch": 10.3,
      "learning_rate": 6.904761904761905e-05,
      "loss": 0.0205,
      "step": 1015
    },
    {
      "epoch": 10.31,
      "learning_rate": 6.911564625850341e-05,
      "loss": 0.0438,
      "step": 1016
    },
    {
      "epoch": 10.32,
      "learning_rate": 6.918367346938775e-05,
      "loss": 0.0224,
      "step": 1017
    },
    {
      "epoch": 10.34,
      "learning_rate": 6.925170068027211e-05,
      "loss": 0.0582,
      "step": 1018
    },
    {
      "epoch": 10.35,
      "learning_rate": 6.931972789115647e-05,
      "loss": 0.064,
      "step": 1019
    },
    {
      "epoch": 10.36,
      "learning_rate": 6.938775510204082e-05,
      "loss": 0.0208,
      "step": 1020
    },
    {
      "epoch": 10.37,
      "learning_rate": 6.945578231292518e-05,
      "loss": 0.0631,
      "step": 1021
    },
    {
      "epoch": 10.38,
      "learning_rate": 6.952380952380952e-05,
      "loss": 0.0173,
      "step": 1022
    },
    {
      "epoch": 10.39,
      "learning_rate": 6.959183673469388e-05,
      "loss": 0.0691,
      "step": 1023
    },
    {
      "epoch": 10.4,
      "learning_rate": 6.965986394557822e-05,
      "loss": 0.0554,
      "step": 1024
    },
    {
      "epoch": 10.41,
      "learning_rate": 6.97278911564626e-05,
      "loss": 0.0274,
      "step": 1025
    },
    {
      "epoch": 10.42,
      "learning_rate": 6.979591836734695e-05,
      "loss": 0.0245,
      "step": 1026
    },
    {
      "epoch": 10.43,
      "learning_rate": 6.98639455782313e-05,
      "loss": 0.0415,
      "step": 1027
    },
    {
      "epoch": 10.44,
      "learning_rate": 6.993197278911565e-05,
      "loss": 0.0618,
      "step": 1028
    },
    {
      "epoch": 10.45,
      "learning_rate": 7e-05,
      "loss": 0.0239,
      "step": 1029
    },
    {
      "epoch": 10.46,
      "learning_rate": 7.006802721088435e-05,
      "loss": 0.0513,
      "step": 1030
    },
    {
      "epoch": 10.47,
      "learning_rate": 7.013605442176872e-05,
      "loss": 0.0423,
      "step": 1031
    },
    {
      "epoch": 10.48,
      "learning_rate": 7.020408163265306e-05,
      "loss": 0.0532,
      "step": 1032
    },
    {
      "epoch": 10.49,
      "learning_rate": 7.027210884353742e-05,
      "loss": 0.0953,
      "step": 1033
    },
    {
      "epoch": 10.5,
      "learning_rate": 7.034013605442176e-05,
      "loss": 0.0209,
      "step": 1034
    },
    {
      "epoch": 10.51,
      "learning_rate": 7.040816326530612e-05,
      "loss": 0.0584,
      "step": 1035
    },
    {
      "epoch": 10.52,
      "learning_rate": 7.047619047619048e-05,
      "loss": 0.0415,
      "step": 1036
    },
    {
      "epoch": 10.53,
      "learning_rate": 7.054421768707484e-05,
      "loss": 0.029,
      "step": 1037
    },
    {
      "epoch": 10.54,
      "learning_rate": 7.061224489795919e-05,
      "loss": 0.0515,
      "step": 1038
    },
    {
      "epoch": 10.55,
      "learning_rate": 7.068027210884354e-05,
      "loss": 0.0454,
      "step": 1039
    },
    {
      "epoch": 10.56,
      "learning_rate": 7.074829931972789e-05,
      "loss": 0.0143,
      "step": 1040
    },
    {
      "epoch": 10.57,
      "learning_rate": 7.081632653061225e-05,
      "loss": 0.0351,
      "step": 1041
    },
    {
      "epoch": 10.58,
      "learning_rate": 7.08843537414966e-05,
      "loss": 0.027,
      "step": 1042
    },
    {
      "epoch": 10.59,
      "learning_rate": 7.095238095238096e-05,
      "loss": 0.0347,
      "step": 1043
    },
    {
      "epoch": 10.6,
      "learning_rate": 7.10204081632653e-05,
      "loss": 0.0209,
      "step": 1044
    },
    {
      "epoch": 10.61,
      "learning_rate": 7.108843537414966e-05,
      "loss": 0.0564,
      "step": 1045
    },
    {
      "epoch": 10.62,
      "learning_rate": 7.1156462585034e-05,
      "loss": 0.0486,
      "step": 1046
    },
    {
      "epoch": 10.63,
      "learning_rate": 7.122448979591836e-05,
      "loss": 0.0744,
      "step": 1047
    },
    {
      "epoch": 10.64,
      "learning_rate": 7.129251700680273e-05,
      "loss": 0.0469,
      "step": 1048
    },
    {
      "epoch": 10.65,
      "learning_rate": 7.136054421768708e-05,
      "loss": 0.0217,
      "step": 1049
    },
    {
      "epoch": 10.66,
      "learning_rate": 7.142857142857143e-05,
      "loss": 0.0267,
      "step": 1050
    },
    {
      "epoch": 10.67,
      "learning_rate": 7.149659863945578e-05,
      "loss": 0.0467,
      "step": 1051
    },
    {
      "epoch": 10.68,
      "learning_rate": 7.156462585034013e-05,
      "loss": 0.0357,
      "step": 1052
    },
    {
      "epoch": 10.69,
      "learning_rate": 7.163265306122449e-05,
      "loss": 0.0981,
      "step": 1053
    },
    {
      "epoch": 10.7,
      "learning_rate": 7.170068027210885e-05,
      "loss": 0.0222,
      "step": 1054
    },
    {
      "epoch": 10.71,
      "learning_rate": 7.17687074829932e-05,
      "loss": 0.0822,
      "step": 1055
    },
    {
      "epoch": 10.72,
      "learning_rate": 7.183673469387755e-05,
      "loss": 0.0661,
      "step": 1056
    },
    {
      "epoch": 10.73,
      "learning_rate": 7.19047619047619e-05,
      "loss": 0.0543,
      "step": 1057
    },
    {
      "epoch": 10.74,
      "learning_rate": 7.197278911564626e-05,
      "loss": 0.0318,
      "step": 1058
    },
    {
      "epoch": 10.75,
      "learning_rate": 7.204081632653062e-05,
      "loss": 0.0347,
      "step": 1059
    },
    {
      "epoch": 10.76,
      "learning_rate": 7.210884353741498e-05,
      "loss": 0.0193,
      "step": 1060
    },
    {
      "epoch": 10.77,
      "learning_rate": 7.217687074829932e-05,
      "loss": 0.0476,
      "step": 1061
    },
    {
      "epoch": 10.78,
      "learning_rate": 7.224489795918368e-05,
      "loss": 0.0923,
      "step": 1062
    },
    {
      "epoch": 10.79,
      "learning_rate": 7.231292517006803e-05,
      "loss": 0.0104,
      "step": 1063
    },
    {
      "epoch": 10.8,
      "learning_rate": 7.238095238095238e-05,
      "loss": 0.0293,
      "step": 1064
    },
    {
      "epoch": 10.81,
      "learning_rate": 7.244897959183675e-05,
      "loss": 0.0799,
      "step": 1065
    },
    {
      "epoch": 10.82,
      "learning_rate": 7.251700680272109e-05,
      "loss": 0.0271,
      "step": 1066
    },
    {
      "epoch": 10.83,
      "learning_rate": 7.258503401360545e-05,
      "loss": 0.0373,
      "step": 1067
    },
    {
      "epoch": 10.84,
      "learning_rate": 7.26530612244898e-05,
      "loss": 0.0379,
      "step": 1068
    },
    {
      "epoch": 10.85,
      "learning_rate": 7.272108843537415e-05,
      "loss": 0.0389,
      "step": 1069
    },
    {
      "epoch": 10.86,
      "learning_rate": 7.27891156462585e-05,
      "loss": 0.0627,
      "step": 1070
    },
    {
      "epoch": 10.87,
      "learning_rate": 7.285714285714286e-05,
      "loss": 0.0227,
      "step": 1071
    },
    {
      "epoch": 10.88,
      "learning_rate": 7.292517006802722e-05,
      "loss": 0.0475,
      "step": 1072
    },
    {
      "epoch": 10.89,
      "learning_rate": 7.299319727891157e-05,
      "loss": 0.0341,
      "step": 1073
    },
    {
      "epoch": 10.9,
      "learning_rate": 7.306122448979592e-05,
      "loss": 0.0439,
      "step": 1074
    },
    {
      "epoch": 10.91,
      "learning_rate": 7.312925170068027e-05,
      "loss": 0.0496,
      "step": 1075
    },
    {
      "epoch": 10.92,
      "learning_rate": 7.319727891156463e-05,
      "loss": 0.0604,
      "step": 1076
    },
    {
      "epoch": 10.93,
      "learning_rate": 7.326530612244899e-05,
      "loss": 0.0174,
      "step": 1077
    },
    {
      "epoch": 10.94,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.0317,
      "step": 1078
    },
    {
      "epoch": 10.95,
      "learning_rate": 7.340136054421769e-05,
      "loss": 0.038,
      "step": 1079
    },
    {
      "epoch": 10.96,
      "learning_rate": 7.346938775510205e-05,
      "loss": 0.0231,
      "step": 1080
    },
    {
      "epoch": 10.97,
      "learning_rate": 7.35374149659864e-05,
      "loss": 0.0509,
      "step": 1081
    },
    {
      "epoch": 10.98,
      "learning_rate": 7.360544217687076e-05,
      "loss": 0.0765,
      "step": 1082
    },
    {
      "epoch": 10.99,
      "learning_rate": 7.36734693877551e-05,
      "loss": 0.0236,
      "step": 1083
    },
    {
      "epoch": 10.99,
      "eval_loss": 0.028024207800626755,
      "eval_runtime": 33.0086,
      "eval_samples_per_second": 95.43,
      "eval_steps_per_second": 5.968,
      "eval_wer": 0.016005121638924456,
      "step": 1083
    },
    {
      "epoch": 11.01,
      "learning_rate": 7.374149659863946e-05,
      "loss": 0.036,
      "step": 1084
    },
    {
      "epoch": 11.02,
      "learning_rate": 7.380952380952382e-05,
      "loss": 0.0325,
      "step": 1085
    },
    {
      "epoch": 11.03,
      "learning_rate": 7.387755102040816e-05,
      "loss": 0.0342,
      "step": 1086
    },
    {
      "epoch": 11.04,
      "learning_rate": 7.394557823129252e-05,
      "loss": 0.0229,
      "step": 1087
    },
    {
      "epoch": 11.05,
      "learning_rate": 7.401360544217687e-05,
      "loss": 0.0265,
      "step": 1088
    },
    {
      "epoch": 11.06,
      "learning_rate": 7.408163265306123e-05,
      "loss": 0.0355,
      "step": 1089
    },
    {
      "epoch": 11.07,
      "learning_rate": 7.414965986394559e-05,
      "loss": 0.0156,
      "step": 1090
    },
    {
      "epoch": 11.08,
      "learning_rate": 7.421768707482993e-05,
      "loss": 0.0363,
      "step": 1091
    },
    {
      "epoch": 11.09,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.0164,
      "step": 1092
    },
    {
      "epoch": 11.1,
      "learning_rate": 7.435374149659864e-05,
      "loss": 0.0443,
      "step": 1093
    },
    {
      "epoch": 11.11,
      "learning_rate": 7.4421768707483e-05,
      "loss": 0.0579,
      "step": 1094
    },
    {
      "epoch": 11.12,
      "learning_rate": 7.448979591836736e-05,
      "loss": 0.0516,
      "step": 1095
    },
    {
      "epoch": 11.13,
      "learning_rate": 7.45578231292517e-05,
      "loss": 0.0516,
      "step": 1096
    },
    {
      "epoch": 11.14,
      "learning_rate": 7.462585034013606e-05,
      "loss": 0.0171,
      "step": 1097
    },
    {
      "epoch": 11.15,
      "learning_rate": 7.469387755102041e-05,
      "loss": 0.0349,
      "step": 1098
    },
    {
      "epoch": 11.16,
      "learning_rate": 7.476190476190477e-05,
      "loss": 0.0174,
      "step": 1099
    },
    {
      "epoch": 11.17,
      "learning_rate": 7.482993197278913e-05,
      "loss": 0.0389,
      "step": 1100
    },
    {
      "epoch": 11.18,
      "learning_rate": 7.489795918367347e-05,
      "loss": 0.0391,
      "step": 1101
    },
    {
      "epoch": 11.19,
      "learning_rate": 7.496598639455783e-05,
      "loss": 0.0336,
      "step": 1102
    },
    {
      "epoch": 11.2,
      "learning_rate": 7.503401360544217e-05,
      "loss": 0.0276,
      "step": 1103
    },
    {
      "epoch": 11.21,
      "learning_rate": 7.510204081632653e-05,
      "loss": 0.0442,
      "step": 1104
    },
    {
      "epoch": 11.22,
      "learning_rate": 7.517006802721089e-05,
      "loss": 0.0378,
      "step": 1105
    },
    {
      "epoch": 11.23,
      "learning_rate": 7.523809523809524e-05,
      "loss": 0.0257,
      "step": 1106
    },
    {
      "epoch": 11.24,
      "learning_rate": 7.53061224489796e-05,
      "loss": 0.1051,
      "step": 1107
    },
    {
      "epoch": 11.25,
      "learning_rate": 7.537414965986394e-05,
      "loss": 0.0322,
      "step": 1108
    },
    {
      "epoch": 11.26,
      "learning_rate": 7.54421768707483e-05,
      "loss": 0.0526,
      "step": 1109
    },
    {
      "epoch": 11.27,
      "learning_rate": 7.551020408163266e-05,
      "loss": 0.0147,
      "step": 1110
    },
    {
      "epoch": 11.28,
      "learning_rate": 7.557823129251701e-05,
      "loss": 0.0124,
      "step": 1111
    },
    {
      "epoch": 11.29,
      "learning_rate": 7.564625850340137e-05,
      "loss": 0.0338,
      "step": 1112
    },
    {
      "epoch": 11.3,
      "learning_rate": 7.571428571428571e-05,
      "loss": 0.0088,
      "step": 1113
    },
    {
      "epoch": 11.31,
      "learning_rate": 7.578231292517007e-05,
      "loss": 0.0318,
      "step": 1114
    },
    {
      "epoch": 11.32,
      "learning_rate": 7.585034013605443e-05,
      "loss": 0.0326,
      "step": 1115
    },
    {
      "epoch": 11.33,
      "learning_rate": 7.591836734693878e-05,
      "loss": 0.0364,
      "step": 1116
    },
    {
      "epoch": 11.34,
      "learning_rate": 7.598639455782314e-05,
      "loss": 0.0307,
      "step": 1117
    },
    {
      "epoch": 11.35,
      "learning_rate": 7.605442176870748e-05,
      "loss": 0.0458,
      "step": 1118
    },
    {
      "epoch": 11.36,
      "learning_rate": 7.612244897959184e-05,
      "loss": 0.0186,
      "step": 1119
    },
    {
      "epoch": 11.37,
      "learning_rate": 7.619047619047618e-05,
      "loss": 0.0476,
      "step": 1120
    },
    {
      "epoch": 11.38,
      "learning_rate": 7.625850340136055e-05,
      "loss": 0.0631,
      "step": 1121
    },
    {
      "epoch": 11.39,
      "learning_rate": 7.632653061224491e-05,
      "loss": 0.0255,
      "step": 1122
    },
    {
      "epoch": 11.4,
      "learning_rate": 7.639455782312926e-05,
      "loss": 0.0048,
      "step": 1123
    },
    {
      "epoch": 11.41,
      "learning_rate": 7.646258503401361e-05,
      "loss": 0.0257,
      "step": 1124
    },
    {
      "epoch": 11.42,
      "learning_rate": 7.653061224489796e-05,
      "loss": 0.068,
      "step": 1125
    },
    {
      "epoch": 11.43,
      "learning_rate": 7.659863945578231e-05,
      "loss": 0.0552,
      "step": 1126
    },
    {
      "epoch": 11.44,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.0497,
      "step": 1127
    },
    {
      "epoch": 11.45,
      "learning_rate": 7.673469387755103e-05,
      "loss": 0.0383,
      "step": 1128
    },
    {
      "epoch": 11.46,
      "learning_rate": 7.680272108843538e-05,
      "loss": 0.0662,
      "step": 1129
    },
    {
      "epoch": 11.47,
      "learning_rate": 7.687074829931973e-05,
      "loss": 0.0355,
      "step": 1130
    },
    {
      "epoch": 11.48,
      "learning_rate": 7.693877551020408e-05,
      "loss": 0.0267,
      "step": 1131
    },
    {
      "epoch": 11.49,
      "learning_rate": 7.700680272108844e-05,
      "loss": 0.0428,
      "step": 1132
    },
    {
      "epoch": 11.5,
      "learning_rate": 7.70748299319728e-05,
      "loss": 0.0315,
      "step": 1133
    },
    {
      "epoch": 11.51,
      "learning_rate": 7.714285714285715e-05,
      "loss": 0.0487,
      "step": 1134
    },
    {
      "epoch": 11.52,
      "learning_rate": 7.72108843537415e-05,
      "loss": 0.0175,
      "step": 1135
    },
    {
      "epoch": 11.53,
      "learning_rate": 7.727891156462585e-05,
      "loss": 0.0266,
      "step": 1136
    },
    {
      "epoch": 11.54,
      "learning_rate": 7.73469387755102e-05,
      "loss": 0.0342,
      "step": 1137
    },
    {
      "epoch": 11.55,
      "learning_rate": 7.741496598639457e-05,
      "loss": 0.0496,
      "step": 1138
    },
    {
      "epoch": 11.56,
      "learning_rate": 7.748299319727892e-05,
      "loss": 0.0197,
      "step": 1139
    },
    {
      "epoch": 11.57,
      "learning_rate": 7.755102040816327e-05,
      "loss": 0.0836,
      "step": 1140
    },
    {
      "epoch": 11.58,
      "learning_rate": 7.761904761904762e-05,
      "loss": 0.0301,
      "step": 1141
    },
    {
      "epoch": 11.59,
      "learning_rate": 7.768707482993197e-05,
      "loss": 0.0179,
      "step": 1142
    },
    {
      "epoch": 11.6,
      "learning_rate": 7.775510204081632e-05,
      "loss": 0.0512,
      "step": 1143
    },
    {
      "epoch": 11.61,
      "learning_rate": 7.782312925170068e-05,
      "loss": 0.0565,
      "step": 1144
    },
    {
      "epoch": 11.62,
      "learning_rate": 7.789115646258504e-05,
      "loss": 0.0434,
      "step": 1145
    },
    {
      "epoch": 11.63,
      "learning_rate": 7.79591836734694e-05,
      "loss": 0.0265,
      "step": 1146
    },
    {
      "epoch": 11.64,
      "learning_rate": 7.802721088435374e-05,
      "loss": 0.0326,
      "step": 1147
    },
    {
      "epoch": 11.65,
      "learning_rate": 7.80952380952381e-05,
      "loss": 0.0476,
      "step": 1148
    },
    {
      "epoch": 11.66,
      "learning_rate": 7.816326530612245e-05,
      "loss": 0.034,
      "step": 1149
    },
    {
      "epoch": 11.68,
      "learning_rate": 7.823129251700681e-05,
      "loss": 0.0905,
      "step": 1150
    },
    {
      "epoch": 11.69,
      "learning_rate": 7.829931972789117e-05,
      "loss": 0.0258,
      "step": 1151
    },
    {
      "epoch": 11.7,
      "learning_rate": 7.836734693877551e-05,
      "loss": 0.0686,
      "step": 1152
    },
    {
      "epoch": 11.71,
      "learning_rate": 7.843537414965987e-05,
      "loss": 0.0569,
      "step": 1153
    },
    {
      "epoch": 11.72,
      "learning_rate": 7.850340136054422e-05,
      "loss": 0.0278,
      "step": 1154
    },
    {
      "epoch": 11.73,
      "learning_rate": 7.857142857142858e-05,
      "loss": 0.0286,
      "step": 1155
    },
    {
      "epoch": 11.74,
      "learning_rate": 7.863945578231294e-05,
      "loss": 0.0488,
      "step": 1156
    },
    {
      "epoch": 11.75,
      "learning_rate": 7.870748299319728e-05,
      "loss": 0.0212,
      "step": 1157
    },
    {
      "epoch": 11.76,
      "learning_rate": 7.877551020408164e-05,
      "loss": 0.0261,
      "step": 1158
    },
    {
      "epoch": 11.77,
      "learning_rate": 7.8843537414966e-05,
      "loss": 0.0127,
      "step": 1159
    },
    {
      "epoch": 11.78,
      "learning_rate": 7.891156462585034e-05,
      "loss": 0.0497,
      "step": 1160
    },
    {
      "epoch": 11.79,
      "learning_rate": 7.897959183673471e-05,
      "loss": 0.0252,
      "step": 1161
    },
    {
      "epoch": 11.8,
      "learning_rate": 7.904761904761905e-05,
      "loss": 0.0514,
      "step": 1162
    },
    {
      "epoch": 11.81,
      "learning_rate": 7.911564625850341e-05,
      "loss": 0.0339,
      "step": 1163
    },
    {
      "epoch": 11.82,
      "learning_rate": 7.918367346938775e-05,
      "loss": 0.05,
      "step": 1164
    },
    {
      "epoch": 11.83,
      "learning_rate": 7.925170068027211e-05,
      "loss": 0.0336,
      "step": 1165
    },
    {
      "epoch": 11.84,
      "learning_rate": 7.931972789115646e-05,
      "loss": 0.0245,
      "step": 1166
    },
    {
      "epoch": 11.85,
      "learning_rate": 7.938775510204082e-05,
      "loss": 0.0222,
      "step": 1167
    },
    {
      "epoch": 11.86,
      "learning_rate": 7.945578231292518e-05,
      "loss": 0.0758,
      "step": 1168
    },
    {
      "epoch": 11.87,
      "learning_rate": 7.952380952380952e-05,
      "loss": 0.0184,
      "step": 1169
    },
    {
      "epoch": 11.88,
      "learning_rate": 7.959183673469388e-05,
      "loss": 0.0187,
      "step": 1170
    },
    {
      "epoch": 11.89,
      "learning_rate": 7.965986394557824e-05,
      "loss": 0.0558,
      "step": 1171
    },
    {
      "epoch": 11.9,
      "learning_rate": 7.972789115646259e-05,
      "loss": 0.0556,
      "step": 1172
    },
    {
      "epoch": 11.91,
      "learning_rate": 7.979591836734695e-05,
      "loss": 0.0148,
      "step": 1173
    },
    {
      "epoch": 11.92,
      "learning_rate": 7.986394557823129e-05,
      "loss": 0.0382,
      "step": 1174
    },
    {
      "epoch": 11.93,
      "learning_rate": 7.993197278911565e-05,
      "loss": 0.0271,
      "step": 1175
    },
    {
      "epoch": 11.94,
      "learning_rate": 8e-05,
      "loss": 0.0348,
      "step": 1176
    },
    {
      "epoch": 11.95,
      "learning_rate": 8.006802721088435e-05,
      "loss": 0.0445,
      "step": 1177
    },
    {
      "epoch": 11.96,
      "learning_rate": 8.013605442176872e-05,
      "loss": 0.0386,
      "step": 1178
    },
    {
      "epoch": 11.97,
      "learning_rate": 8.020408163265306e-05,
      "loss": 0.051,
      "step": 1179
    },
    {
      "epoch": 11.98,
      "learning_rate": 8.027210884353742e-05,
      "loss": 0.0897,
      "step": 1180
    },
    {
      "epoch": 11.99,
      "learning_rate": 8.034013605442178e-05,
      "loss": 0.0137,
      "step": 1181
    },
    {
      "epoch": 12.0,
      "learning_rate": 8.040816326530612e-05,
      "loss": 0.06,
      "step": 1182
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.023940404877066612,
      "eval_runtime": 33.1716,
      "eval_samples_per_second": 94.961,
      "eval_steps_per_second": 5.939,
      "eval_wer": 0.012740076824583868,
      "step": 1182
    },
    {
      "epoch": 12.01,
      "learning_rate": 8.047619047619048e-05,
      "loss": 0.0261,
      "step": 1183
    },
    {
      "epoch": 12.02,
      "learning_rate": 8.054421768707483e-05,
      "loss": 0.011,
      "step": 1184
    },
    {
      "epoch": 12.03,
      "learning_rate": 8.061224489795919e-05,
      "loss": 0.0315,
      "step": 1185
    },
    {
      "epoch": 12.04,
      "learning_rate": 8.068027210884355e-05,
      "loss": 0.0255,
      "step": 1186
    },
    {
      "epoch": 12.05,
      "learning_rate": 8.074829931972789e-05,
      "loss": 0.0175,
      "step": 1187
    },
    {
      "epoch": 12.06,
      "learning_rate": 8.081632653061225e-05,
      "loss": 0.035,
      "step": 1188
    },
    {
      "epoch": 12.07,
      "learning_rate": 8.08843537414966e-05,
      "loss": 0.0103,
      "step": 1189
    },
    {
      "epoch": 12.08,
      "learning_rate": 8.095238095238096e-05,
      "loss": 0.0413,
      "step": 1190
    },
    {
      "epoch": 12.09,
      "learning_rate": 8.10204081632653e-05,
      "loss": 0.0183,
      "step": 1191
    },
    {
      "epoch": 12.1,
      "learning_rate": 8.108843537414966e-05,
      "loss": 0.0245,
      "step": 1192
    },
    {
      "epoch": 12.11,
      "learning_rate": 8.115646258503402e-05,
      "loss": 0.0395,
      "step": 1193
    },
    {
      "epoch": 12.12,
      "learning_rate": 8.122448979591836e-05,
      "loss": 0.0309,
      "step": 1194
    },
    {
      "epoch": 12.13,
      "learning_rate": 8.129251700680273e-05,
      "loss": 0.0289,
      "step": 1195
    },
    {
      "epoch": 12.14,
      "learning_rate": 8.136054421768708e-05,
      "loss": 0.0239,
      "step": 1196
    },
    {
      "epoch": 12.15,
      "learning_rate": 8.142857142857143e-05,
      "loss": 0.0306,
      "step": 1197
    },
    {
      "epoch": 12.16,
      "learning_rate": 8.149659863945579e-05,
      "loss": 0.0471,
      "step": 1198
    },
    {
      "epoch": 12.17,
      "learning_rate": 8.156462585034013e-05,
      "loss": 0.0253,
      "step": 1199
    },
    {
      "epoch": 12.18,
      "learning_rate": 8.163265306122449e-05,
      "loss": 0.0061,
      "step": 1200
    },
    {
      "epoch": 12.19,
      "learning_rate": 8.170068027210885e-05,
      "loss": 0.0301,
      "step": 1201
    },
    {
      "epoch": 12.2,
      "learning_rate": 8.17687074829932e-05,
      "loss": 0.0659,
      "step": 1202
    },
    {
      "epoch": 12.21,
      "learning_rate": 8.183673469387756e-05,
      "loss": 0.0319,
      "step": 1203
    },
    {
      "epoch": 12.22,
      "learning_rate": 8.19047619047619e-05,
      "loss": 0.0337,
      "step": 1204
    },
    {
      "epoch": 12.23,
      "learning_rate": 8.197278911564626e-05,
      "loss": 0.0496,
      "step": 1205
    },
    {
      "epoch": 12.24,
      "learning_rate": 8.204081632653062e-05,
      "loss": 0.0618,
      "step": 1206
    },
    {
      "epoch": 12.25,
      "learning_rate": 8.210884353741497e-05,
      "loss": 0.0225,
      "step": 1207
    },
    {
      "epoch": 12.26,
      "learning_rate": 8.217687074829933e-05,
      "loss": 0.0318,
      "step": 1208
    },
    {
      "epoch": 12.27,
      "learning_rate": 8.224489795918367e-05,
      "loss": 0.038,
      "step": 1209
    },
    {
      "epoch": 12.28,
      "learning_rate": 8.231292517006803e-05,
      "loss": 0.0122,
      "step": 1210
    },
    {
      "epoch": 12.29,
      "learning_rate": 8.238095238095238e-05,
      "loss": 0.0653,
      "step": 1211
    },
    {
      "epoch": 12.3,
      "learning_rate": 8.244897959183675e-05,
      "loss": 0.0428,
      "step": 1212
    },
    {
      "epoch": 12.31,
      "learning_rate": 8.25170068027211e-05,
      "loss": 0.0226,
      "step": 1213
    },
    {
      "epoch": 12.32,
      "learning_rate": 8.258503401360545e-05,
      "loss": 0.0276,
      "step": 1214
    },
    {
      "epoch": 12.34,
      "learning_rate": 8.26530612244898e-05,
      "loss": 0.0608,
      "step": 1215
    },
    {
      "epoch": 12.35,
      "learning_rate": 8.272108843537415e-05,
      "loss": 0.0265,
      "step": 1216
    },
    {
      "epoch": 12.36,
      "learning_rate": 8.27891156462585e-05,
      "loss": 0.035,
      "step": 1217
    },
    {
      "epoch": 12.37,
      "learning_rate": 8.285714285714287e-05,
      "loss": 0.029,
      "step": 1218
    },
    {
      "epoch": 12.38,
      "learning_rate": 8.292517006802722e-05,
      "loss": 0.0206,
      "step": 1219
    },
    {
      "epoch": 12.39,
      "learning_rate": 8.299319727891157e-05,
      "loss": 0.0154,
      "step": 1220
    },
    {
      "epoch": 12.4,
      "learning_rate": 8.306122448979592e-05,
      "loss": 0.0588,
      "step": 1221
    },
    {
      "epoch": 12.41,
      "learning_rate": 8.312925170068027e-05,
      "loss": 0.0272,
      "step": 1222
    },
    {
      "epoch": 12.42,
      "learning_rate": 8.319727891156463e-05,
      "loss": 0.0387,
      "step": 1223
    },
    {
      "epoch": 12.43,
      "learning_rate": 8.326530612244899e-05,
      "loss": 0.035,
      "step": 1224
    },
    {
      "epoch": 12.44,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.0574,
      "step": 1225
    },
    {
      "epoch": 12.45,
      "learning_rate": 8.340136054421769e-05,
      "loss": 0.0133,
      "step": 1226
    },
    {
      "epoch": 12.46,
      "learning_rate": 8.346938775510204e-05,
      "loss": 0.0285,
      "step": 1227
    },
    {
      "epoch": 12.47,
      "learning_rate": 8.353741496598639e-05,
      "loss": 0.0273,
      "step": 1228
    },
    {
      "epoch": 12.48,
      "learning_rate": 8.360544217687076e-05,
      "loss": 0.0709,
      "step": 1229
    },
    {
      "epoch": 12.49,
      "learning_rate": 8.367346938775511e-05,
      "loss": 0.0664,
      "step": 1230
    },
    {
      "epoch": 12.5,
      "learning_rate": 8.374149659863946e-05,
      "loss": 0.0235,
      "step": 1231
    },
    {
      "epoch": 12.51,
      "learning_rate": 8.380952380952382e-05,
      "loss": 0.0271,
      "step": 1232
    },
    {
      "epoch": 12.52,
      "learning_rate": 8.387755102040816e-05,
      "loss": 0.0074,
      "step": 1233
    },
    {
      "epoch": 12.53,
      "learning_rate": 8.394557823129252e-05,
      "loss": 0.0322,
      "step": 1234
    },
    {
      "epoch": 12.54,
      "learning_rate": 8.401360544217689e-05,
      "loss": 0.0416,
      "step": 1235
    },
    {
      "epoch": 12.55,
      "learning_rate": 8.408163265306123e-05,
      "loss": 0.0287,
      "step": 1236
    },
    {
      "epoch": 12.56,
      "learning_rate": 8.414965986394559e-05,
      "loss": 0.0365,
      "step": 1237
    },
    {
      "epoch": 12.57,
      "learning_rate": 8.421768707482993e-05,
      "loss": 0.0245,
      "step": 1238
    },
    {
      "epoch": 12.58,
      "learning_rate": 8.428571428571429e-05,
      "loss": 0.0411,
      "step": 1239
    },
    {
      "epoch": 12.59,
      "learning_rate": 8.435374149659864e-05,
      "loss": 0.0254,
      "step": 1240
    },
    {
      "epoch": 12.6,
      "learning_rate": 8.4421768707483e-05,
      "loss": 0.0689,
      "step": 1241
    },
    {
      "epoch": 12.61,
      "learning_rate": 8.448979591836736e-05,
      "loss": 0.0259,
      "step": 1242
    },
    {
      "epoch": 12.62,
      "learning_rate": 8.45578231292517e-05,
      "loss": 0.0376,
      "step": 1243
    },
    {
      "epoch": 12.63,
      "learning_rate": 8.462585034013606e-05,
      "loss": 0.0478,
      "step": 1244
    },
    {
      "epoch": 12.64,
      "learning_rate": 8.469387755102041e-05,
      "loss": 0.0303,
      "step": 1245
    },
    {
      "epoch": 12.65,
      "learning_rate": 8.476190476190477e-05,
      "loss": 0.0206,
      "step": 1246
    },
    {
      "epoch": 12.66,
      "learning_rate": 8.482993197278913e-05,
      "loss": 0.0312,
      "step": 1247
    },
    {
      "epoch": 12.67,
      "learning_rate": 8.489795918367347e-05,
      "loss": 0.0327,
      "step": 1248
    },
    {
      "epoch": 12.68,
      "learning_rate": 8.496598639455783e-05,
      "loss": 0.0168,
      "step": 1249
    },
    {
      "epoch": 12.69,
      "learning_rate": 8.503401360544217e-05,
      "loss": 0.0192,
      "step": 1250
    },
    {
      "epoch": 12.7,
      "learning_rate": 8.510204081632653e-05,
      "loss": 0.0723,
      "step": 1251
    },
    {
      "epoch": 12.71,
      "learning_rate": 8.51700680272109e-05,
      "loss": 0.0564,
      "step": 1252
    },
    {
      "epoch": 12.72,
      "learning_rate": 8.523809523809524e-05,
      "loss": 0.0249,
      "step": 1253
    },
    {
      "epoch": 12.73,
      "learning_rate": 8.53061224489796e-05,
      "loss": 0.0823,
      "step": 1254
    },
    {
      "epoch": 12.74,
      "learning_rate": 8.537414965986394e-05,
      "loss": 0.0096,
      "step": 1255
    },
    {
      "epoch": 12.75,
      "learning_rate": 8.54421768707483e-05,
      "loss": 0.0389,
      "step": 1256
    },
    {
      "epoch": 12.76,
      "learning_rate": 8.551020408163266e-05,
      "loss": 0.0299,
      "step": 1257
    },
    {
      "epoch": 12.77,
      "learning_rate": 8.557823129251701e-05,
      "loss": 0.0507,
      "step": 1258
    },
    {
      "epoch": 12.78,
      "learning_rate": 8.564625850340137e-05,
      "loss": 0.0277,
      "step": 1259
    },
    {
      "epoch": 12.79,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.0277,
      "step": 1260
    },
    {
      "epoch": 12.8,
      "learning_rate": 8.578231292517007e-05,
      "loss": 0.0099,
      "step": 1261
    },
    {
      "epoch": 12.81,
      "learning_rate": 8.585034013605443e-05,
      "loss": 0.0408,
      "step": 1262
    },
    {
      "epoch": 12.82,
      "learning_rate": 8.591836734693878e-05,
      "loss": 0.0272,
      "step": 1263
    },
    {
      "epoch": 12.83,
      "learning_rate": 8.598639455782314e-05,
      "loss": 0.0253,
      "step": 1264
    },
    {
      "epoch": 12.84,
      "learning_rate": 8.605442176870748e-05,
      "loss": 0.0186,
      "step": 1265
    },
    {
      "epoch": 12.85,
      "learning_rate": 8.612244897959184e-05,
      "loss": 0.0209,
      "step": 1266
    },
    {
      "epoch": 12.86,
      "learning_rate": 8.61904761904762e-05,
      "loss": 0.0239,
      "step": 1267
    },
    {
      "epoch": 12.87,
      "learning_rate": 8.625850340136054e-05,
      "loss": 0.0463,
      "step": 1268
    },
    {
      "epoch": 12.88,
      "learning_rate": 8.632653061224491e-05,
      "loss": 0.0274,
      "step": 1269
    },
    {
      "epoch": 12.89,
      "learning_rate": 8.639455782312925e-05,
      "loss": 0.0258,
      "step": 1270
    },
    {
      "epoch": 12.9,
      "learning_rate": 8.646258503401361e-05,
      "loss": 0.0273,
      "step": 1271
    },
    {
      "epoch": 12.91,
      "learning_rate": 8.653061224489797e-05,
      "loss": 0.0383,
      "step": 1272
    },
    {
      "epoch": 12.92,
      "learning_rate": 8.659863945578231e-05,
      "loss": 0.0746,
      "step": 1273
    },
    {
      "epoch": 12.93,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.0351,
      "step": 1274
    },
    {
      "epoch": 12.94,
      "learning_rate": 8.673469387755102e-05,
      "loss": 0.0138,
      "step": 1275
    },
    {
      "epoch": 12.95,
      "learning_rate": 8.680272108843538e-05,
      "loss": 0.0227,
      "step": 1276
    },
    {
      "epoch": 12.96,
      "learning_rate": 8.687074829931974e-05,
      "loss": 0.0226,
      "step": 1277
    },
    {
      "epoch": 12.97,
      "learning_rate": 8.693877551020408e-05,
      "loss": 0.05,
      "step": 1278
    },
    {
      "epoch": 12.98,
      "learning_rate": 8.700680272108844e-05,
      "loss": 0.0351,
      "step": 1279
    },
    {
      "epoch": 12.99,
      "learning_rate": 8.70748299319728e-05,
      "loss": 0.0431,
      "step": 1280
    },
    {
      "epoch": 12.99,
      "eval_loss": 0.02205580472946167,
      "eval_runtime": 31.63,
      "eval_samples_per_second": 99.589,
      "eval_steps_per_second": 6.228,
      "eval_wer": 0.015813060179257363,
      "step": 1280
    },
    {
      "epoch": 13.01,
      "learning_rate": 8.714285714285715e-05,
      "loss": 0.016,
      "step": 1281
    },
    {
      "epoch": 13.02,
      "learning_rate": 8.72108843537415e-05,
      "loss": 0.0315,
      "step": 1282
    },
    {
      "epoch": 13.03,
      "learning_rate": 8.727891156462585e-05,
      "loss": 0.035,
      "step": 1283
    },
    {
      "epoch": 13.04,
      "learning_rate": 8.734693877551021e-05,
      "loss": 0.0066,
      "step": 1284
    },
    {
      "epoch": 13.05,
      "learning_rate": 8.741496598639455e-05,
      "loss": 0.0239,
      "step": 1285
    },
    {
      "epoch": 13.06,
      "learning_rate": 8.748299319727892e-05,
      "loss": 0.0333,
      "step": 1286
    },
    {
      "epoch": 13.07,
      "learning_rate": 8.755102040816327e-05,
      "loss": 0.0358,
      "step": 1287
    },
    {
      "epoch": 13.08,
      "learning_rate": 8.761904761904762e-05,
      "loss": 0.0192,
      "step": 1288
    },
    {
      "epoch": 13.09,
      "learning_rate": 8.768707482993198e-05,
      "loss": 0.0217,
      "step": 1289
    },
    {
      "epoch": 13.1,
      "learning_rate": 8.775510204081632e-05,
      "loss": 0.0351,
      "step": 1290
    },
    {
      "epoch": 13.11,
      "learning_rate": 8.782312925170068e-05,
      "loss": 0.0152,
      "step": 1291
    },
    {
      "epoch": 13.12,
      "learning_rate": 8.789115646258504e-05,
      "loss": 0.0414,
      "step": 1292
    },
    {
      "epoch": 13.13,
      "learning_rate": 8.79591836734694e-05,
      "loss": 0.0149,
      "step": 1293
    },
    {
      "epoch": 13.14,
      "learning_rate": 8.802721088435375e-05,
      "loss": 0.0266,
      "step": 1294
    },
    {
      "epoch": 13.15,
      "learning_rate": 8.80952380952381e-05,
      "loss": 0.0414,
      "step": 1295
    },
    {
      "epoch": 13.16,
      "learning_rate": 8.816326530612245e-05,
      "loss": 0.0623,
      "step": 1296
    },
    {
      "epoch": 13.17,
      "learning_rate": 8.823129251700681e-05,
      "loss": 0.0201,
      "step": 1297
    },
    {
      "epoch": 13.18,
      "learning_rate": 8.829931972789117e-05,
      "loss": 0.0156,
      "step": 1298
    },
    {
      "epoch": 13.19,
      "learning_rate": 8.836734693877552e-05,
      "loss": 0.03,
      "step": 1299
    },
    {
      "epoch": 13.2,
      "learning_rate": 8.843537414965987e-05,
      "loss": 0.0185,
      "step": 1300
    },
    {
      "epoch": 13.21,
      "learning_rate": 8.850340136054422e-05,
      "loss": 0.028,
      "step": 1301
    },
    {
      "epoch": 13.22,
      "learning_rate": 8.857142857142857e-05,
      "loss": 0.0285,
      "step": 1302
    },
    {
      "epoch": 13.23,
      "learning_rate": 8.863945578231294e-05,
      "loss": 0.0187,
      "step": 1303
    },
    {
      "epoch": 13.24,
      "learning_rate": 8.870748299319729e-05,
      "loss": 0.0356,
      "step": 1304
    },
    {
      "epoch": 13.25,
      "learning_rate": 8.877551020408164e-05,
      "loss": 0.0562,
      "step": 1305
    },
    {
      "epoch": 13.26,
      "learning_rate": 8.884353741496599e-05,
      "loss": 0.0468,
      "step": 1306
    },
    {
      "epoch": 13.27,
      "learning_rate": 8.891156462585034e-05,
      "loss": 0.0231,
      "step": 1307
    },
    {
      "epoch": 13.28,
      "learning_rate": 8.89795918367347e-05,
      "loss": 0.0057,
      "step": 1308
    },
    {
      "epoch": 13.29,
      "learning_rate": 8.904761904761905e-05,
      "loss": 0.0469,
      "step": 1309
    },
    {
      "epoch": 13.3,
      "learning_rate": 8.911564625850341e-05,
      "loss": 0.0447,
      "step": 1310
    },
    {
      "epoch": 13.31,
      "learning_rate": 8.918367346938776e-05,
      "loss": 0.0234,
      "step": 1311
    },
    {
      "epoch": 13.32,
      "learning_rate": 8.925170068027211e-05,
      "loss": 0.051,
      "step": 1312
    },
    {
      "epoch": 13.33,
      "learning_rate": 8.931972789115646e-05,
      "loss": 0.0075,
      "step": 1313
    },
    {
      "epoch": 13.34,
      "learning_rate": 8.938775510204082e-05,
      "loss": 0.0456,
      "step": 1314
    },
    {
      "epoch": 13.35,
      "learning_rate": 8.945578231292518e-05,
      "loss": 0.019,
      "step": 1315
    },
    {
      "epoch": 13.36,
      "learning_rate": 8.952380952380953e-05,
      "loss": 0.0271,
      "step": 1316
    },
    {
      "epoch": 13.37,
      "learning_rate": 8.959183673469388e-05,
      "loss": 0.0147,
      "step": 1317
    },
    {
      "epoch": 13.38,
      "learning_rate": 8.965986394557823e-05,
      "loss": 0.0251,
      "step": 1318
    },
    {
      "epoch": 13.39,
      "learning_rate": 8.972789115646258e-05,
      "loss": 0.0305,
      "step": 1319
    },
    {
      "epoch": 13.4,
      "learning_rate": 8.979591836734695e-05,
      "loss": 0.0258,
      "step": 1320
    },
    {
      "epoch": 13.41,
      "learning_rate": 8.98639455782313e-05,
      "loss": 0.0293,
      "step": 1321
    },
    {
      "epoch": 13.42,
      "learning_rate": 8.993197278911565e-05,
      "loss": 0.0429,
      "step": 1322
    },
    {
      "epoch": 13.43,
      "learning_rate": 9e-05,
      "loss": 0.1008,
      "step": 1323
    },
    {
      "epoch": 13.44,
      "learning_rate": 9.006802721088435e-05,
      "loss": 0.0208,
      "step": 1324
    },
    {
      "epoch": 13.45,
      "learning_rate": 9.01360544217687e-05,
      "loss": 0.0327,
      "step": 1325
    },
    {
      "epoch": 13.46,
      "learning_rate": 9.020408163265308e-05,
      "loss": 0.0271,
      "step": 1326
    },
    {
      "epoch": 13.47,
      "learning_rate": 9.027210884353742e-05,
      "loss": 0.0734,
      "step": 1327
    },
    {
      "epoch": 13.48,
      "learning_rate": 9.034013605442178e-05,
      "loss": 0.088,
      "step": 1328
    },
    {
      "epoch": 13.49,
      "learning_rate": 9.040816326530612e-05,
      "loss": 0.0582,
      "step": 1329
    },
    {
      "epoch": 13.5,
      "learning_rate": 9.047619047619048e-05,
      "loss": 0.0347,
      "step": 1330
    },
    {
      "epoch": 13.51,
      "learning_rate": 9.054421768707483e-05,
      "loss": 0.0482,
      "step": 1331
    },
    {
      "epoch": 13.52,
      "learning_rate": 9.061224489795919e-05,
      "loss": 0.0556,
      "step": 1332
    },
    {
      "epoch": 13.53,
      "learning_rate": 9.068027210884355e-05,
      "loss": 0.0062,
      "step": 1333
    },
    {
      "epoch": 13.54,
      "learning_rate": 9.074829931972789e-05,
      "loss": 0.0224,
      "step": 1334
    },
    {
      "epoch": 13.55,
      "learning_rate": 9.081632653061225e-05,
      "loss": 0.0104,
      "step": 1335
    },
    {
      "epoch": 13.56,
      "learning_rate": 9.08843537414966e-05,
      "loss": 0.0344,
      "step": 1336
    },
    {
      "epoch": 13.57,
      "learning_rate": 9.095238095238096e-05,
      "loss": 0.014,
      "step": 1337
    },
    {
      "epoch": 13.58,
      "learning_rate": 9.102040816326532e-05,
      "loss": 0.0286,
      "step": 1338
    },
    {
      "epoch": 13.59,
      "learning_rate": 9.108843537414966e-05,
      "loss": 0.0258,
      "step": 1339
    },
    {
      "epoch": 13.6,
      "learning_rate": 9.115646258503402e-05,
      "loss": 0.0497,
      "step": 1340
    },
    {
      "epoch": 13.61,
      "learning_rate": 9.122448979591836e-05,
      "loss": 0.0264,
      "step": 1341
    },
    {
      "epoch": 13.62,
      "learning_rate": 9.129251700680272e-05,
      "loss": 0.0424,
      "step": 1342
    },
    {
      "epoch": 13.63,
      "learning_rate": 9.136054421768709e-05,
      "loss": 0.0191,
      "step": 1343
    },
    {
      "epoch": 13.64,
      "learning_rate": 9.142857142857143e-05,
      "loss": 0.0475,
      "step": 1344
    },
    {
      "epoch": 13.65,
      "learning_rate": 9.149659863945579e-05,
      "loss": 0.0366,
      "step": 1345
    },
    {
      "epoch": 13.66,
      "learning_rate": 9.156462585034013e-05,
      "loss": 0.0247,
      "step": 1346
    },
    {
      "epoch": 13.68,
      "learning_rate": 9.163265306122449e-05,
      "loss": 0.0204,
      "step": 1347
    },
    {
      "epoch": 13.69,
      "learning_rate": 9.170068027210885e-05,
      "loss": 0.048,
      "step": 1348
    },
    {
      "epoch": 13.7,
      "learning_rate": 9.17687074829932e-05,
      "loss": 0.0408,
      "step": 1349
    },
    {
      "epoch": 13.71,
      "learning_rate": 9.183673469387756e-05,
      "loss": 0.0519,
      "step": 1350
    },
    {
      "epoch": 13.72,
      "learning_rate": 9.19047619047619e-05,
      "loss": 0.0162,
      "step": 1351
    },
    {
      "epoch": 13.73,
      "learning_rate": 9.197278911564626e-05,
      "loss": 0.0235,
      "step": 1352
    },
    {
      "epoch": 13.74,
      "learning_rate": 9.204081632653062e-05,
      "loss": 0.0627,
      "step": 1353
    },
    {
      "epoch": 13.75,
      "learning_rate": 9.210884353741497e-05,
      "loss": 0.0258,
      "step": 1354
    },
    {
      "epoch": 13.76,
      "learning_rate": 9.217687074829933e-05,
      "loss": 0.0233,
      "step": 1355
    },
    {
      "epoch": 13.77,
      "learning_rate": 9.224489795918367e-05,
      "loss": 0.035,
      "step": 1356
    },
    {
      "epoch": 13.78,
      "learning_rate": 9.231292517006803e-05,
      "loss": 0.0249,
      "step": 1357
    },
    {
      "epoch": 13.79,
      "learning_rate": 9.238095238095239e-05,
      "loss": 0.0334,
      "step": 1358
    },
    {
      "epoch": 13.8,
      "learning_rate": 9.244897959183673e-05,
      "loss": 0.0348,
      "step": 1359
    },
    {
      "epoch": 13.81,
      "learning_rate": 9.25170068027211e-05,
      "loss": 0.0161,
      "step": 1360
    },
    {
      "epoch": 13.82,
      "learning_rate": 9.258503401360544e-05,
      "loss": 0.0303,
      "step": 1361
    },
    {
      "epoch": 13.83,
      "learning_rate": 9.26530612244898e-05,
      "loss": 0.0144,
      "step": 1362
    },
    {
      "epoch": 13.84,
      "learning_rate": 9.272108843537416e-05,
      "loss": 0.0402,
      "step": 1363
    },
    {
      "epoch": 13.85,
      "learning_rate": 9.27891156462585e-05,
      "loss": 0.044,
      "step": 1364
    },
    {
      "epoch": 13.86,
      "learning_rate": 9.285714285714286e-05,
      "loss": 0.0294,
      "step": 1365
    },
    {
      "epoch": 13.87,
      "learning_rate": 9.292517006802722e-05,
      "loss": 0.0211,
      "step": 1366
    },
    {
      "epoch": 13.88,
      "learning_rate": 9.299319727891157e-05,
      "loss": 0.0477,
      "step": 1367
    },
    {
      "epoch": 13.89,
      "learning_rate": 9.306122448979592e-05,
      "loss": 0.0285,
      "step": 1368
    },
    {
      "epoch": 13.9,
      "learning_rate": 9.312925170068027e-05,
      "loss": 0.0305,
      "step": 1369
    },
    {
      "epoch": 13.91,
      "learning_rate": 9.319727891156463e-05,
      "loss": 0.032,
      "step": 1370
    },
    {
      "epoch": 13.92,
      "learning_rate": 9.326530612244899e-05,
      "loss": 0.0763,
      "step": 1371
    },
    {
      "epoch": 13.93,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.0146,
      "step": 1372
    },
    {
      "epoch": 13.94,
      "learning_rate": 9.340136054421769e-05,
      "loss": 0.0291,
      "step": 1373
    },
    {
      "epoch": 13.95,
      "learning_rate": 9.346938775510204e-05,
      "loss": 0.0346,
      "step": 1374
    },
    {
      "epoch": 13.96,
      "learning_rate": 9.35374149659864e-05,
      "loss": 0.0526,
      "step": 1375
    },
    {
      "epoch": 13.97,
      "learning_rate": 9.360544217687074e-05,
      "loss": 0.0286,
      "step": 1376
    },
    {
      "epoch": 13.98,
      "learning_rate": 9.367346938775511e-05,
      "loss": 0.0278,
      "step": 1377
    },
    {
      "epoch": 13.99,
      "learning_rate": 9.374149659863946e-05,
      "loss": 0.0695,
      "step": 1378
    },
    {
      "epoch": 14.0,
      "learning_rate": 9.380952380952381e-05,
      "loss": 0.0378,
      "step": 1379
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.023425433784723282,
      "eval_runtime": 31.8612,
      "eval_samples_per_second": 98.866,
      "eval_steps_per_second": 6.183,
      "eval_wer": 0.01293213828425096,
      "step": 1379
    },
    {
      "epoch": 14.01,
      "learning_rate": 9.387755102040817e-05,
      "loss": 0.0029,
      "step": 1380
    },
    {
      "epoch": 14.02,
      "learning_rate": 9.394557823129251e-05,
      "loss": 0.032,
      "step": 1381
    },
    {
      "epoch": 14.03,
      "learning_rate": 9.401360544217687e-05,
      "loss": 0.0088,
      "step": 1382
    },
    {
      "epoch": 14.04,
      "learning_rate": 9.408163265306123e-05,
      "loss": 0.0142,
      "step": 1383
    },
    {
      "epoch": 14.05,
      "learning_rate": 9.414965986394559e-05,
      "loss": 0.0194,
      "step": 1384
    },
    {
      "epoch": 14.06,
      "learning_rate": 9.421768707482994e-05,
      "loss": 0.01,
      "step": 1385
    },
    {
      "epoch": 14.07,
      "learning_rate": 9.428571428571429e-05,
      "loss": 0.0357,
      "step": 1386
    },
    {
      "epoch": 14.08,
      "learning_rate": 9.435374149659864e-05,
      "loss": 0.0153,
      "step": 1387
    },
    {
      "epoch": 14.09,
      "learning_rate": 9.4421768707483e-05,
      "loss": 0.0059,
      "step": 1388
    },
    {
      "epoch": 14.1,
      "learning_rate": 9.448979591836736e-05,
      "loss": 0.0272,
      "step": 1389
    },
    {
      "epoch": 14.11,
      "learning_rate": 9.455782312925171e-05,
      "loss": 0.009,
      "step": 1390
    },
    {
      "epoch": 14.12,
      "learning_rate": 9.462585034013606e-05,
      "loss": 0.0114,
      "step": 1391
    },
    {
      "epoch": 14.13,
      "learning_rate": 9.469387755102041e-05,
      "loss": 0.0245,
      "step": 1392
    },
    {
      "epoch": 14.14,
      "learning_rate": 9.476190476190476e-05,
      "loss": 0.0388,
      "step": 1393
    },
    {
      "epoch": 14.15,
      "learning_rate": 9.482993197278913e-05,
      "loss": 0.0096,
      "step": 1394
    },
    {
      "epoch": 14.16,
      "learning_rate": 9.489795918367348e-05,
      "loss": 0.0357,
      "step": 1395
    },
    {
      "epoch": 14.17,
      "learning_rate": 9.496598639455783e-05,
      "loss": 0.0444,
      "step": 1396
    },
    {
      "epoch": 14.18,
      "learning_rate": 9.503401360544218e-05,
      "loss": 0.0252,
      "step": 1397
    },
    {
      "epoch": 14.19,
      "learning_rate": 9.510204081632653e-05,
      "loss": 0.0116,
      "step": 1398
    },
    {
      "epoch": 14.2,
      "learning_rate": 9.517006802721088e-05,
      "loss": 0.0482,
      "step": 1399
    },
    {
      "epoch": 14.21,
      "learning_rate": 9.523809523809524e-05,
      "loss": 0.0409,
      "step": 1400
    },
    {
      "epoch": 14.22,
      "learning_rate": 9.53061224489796e-05,
      "loss": 0.0246,
      "step": 1401
    },
    {
      "epoch": 14.23,
      "learning_rate": 9.537414965986395e-05,
      "loss": 0.0308,
      "step": 1402
    },
    {
      "epoch": 14.24,
      "learning_rate": 9.54421768707483e-05,
      "loss": 0.0298,
      "step": 1403
    },
    {
      "epoch": 14.25,
      "learning_rate": 9.551020408163265e-05,
      "loss": 0.0161,
      "step": 1404
    },
    {
      "epoch": 14.26,
      "learning_rate": 9.557823129251701e-05,
      "loss": 0.0243,
      "step": 1405
    },
    {
      "epoch": 14.27,
      "learning_rate": 9.564625850340137e-05,
      "loss": 0.0145,
      "step": 1406
    },
    {
      "epoch": 14.28,
      "learning_rate": 9.571428571428573e-05,
      "loss": 0.0264,
      "step": 1407
    },
    {
      "epoch": 14.29,
      "learning_rate": 9.578231292517007e-05,
      "loss": 0.0039,
      "step": 1408
    },
    {
      "epoch": 14.3,
      "learning_rate": 9.585034013605443e-05,
      "loss": 0.0176,
      "step": 1409
    },
    {
      "epoch": 14.31,
      "learning_rate": 9.591836734693878e-05,
      "loss": 0.0143,
      "step": 1410
    },
    {
      "epoch": 14.32,
      "learning_rate": 9.598639455782314e-05,
      "loss": 0.0146,
      "step": 1411
    },
    {
      "epoch": 14.34,
      "learning_rate": 9.60544217687075e-05,
      "loss": 0.0399,
      "step": 1412
    },
    {
      "epoch": 14.35,
      "learning_rate": 9.612244897959184e-05,
      "loss": 0.0396,
      "step": 1413
    },
    {
      "epoch": 14.36,
      "learning_rate": 9.61904761904762e-05,
      "loss": 0.0325,
      "step": 1414
    },
    {
      "epoch": 14.37,
      "learning_rate": 9.625850340136054e-05,
      "loss": 0.0362,
      "step": 1415
    },
    {
      "epoch": 14.38,
      "learning_rate": 9.63265306122449e-05,
      "loss": 0.0177,
      "step": 1416
    },
    {
      "epoch": 14.39,
      "learning_rate": 9.639455782312927e-05,
      "loss": 0.0379,
      "step": 1417
    },
    {
      "epoch": 14.4,
      "learning_rate": 9.646258503401361e-05,
      "loss": 0.0161,
      "step": 1418
    },
    {
      "epoch": 14.41,
      "learning_rate": 9.653061224489797e-05,
      "loss": 0.0252,
      "step": 1419
    },
    {
      "epoch": 14.42,
      "learning_rate": 9.659863945578231e-05,
      "loss": 0.0325,
      "step": 1420
    },
    {
      "epoch": 14.43,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.0448,
      "step": 1421
    },
    {
      "epoch": 14.44,
      "learning_rate": 9.673469387755102e-05,
      "loss": 0.0176,
      "step": 1422
    },
    {
      "epoch": 14.45,
      "learning_rate": 9.680272108843538e-05,
      "loss": 0.0329,
      "step": 1423
    },
    {
      "epoch": 14.46,
      "learning_rate": 9.687074829931974e-05,
      "loss": 0.0262,
      "step": 1424
    },
    {
      "epoch": 14.47,
      "learning_rate": 9.693877551020408e-05,
      "loss": 0.0292,
      "step": 1425
    },
    {
      "epoch": 14.48,
      "learning_rate": 9.700680272108844e-05,
      "loss": 0.0629,
      "step": 1426
    },
    {
      "epoch": 14.49,
      "learning_rate": 9.70748299319728e-05,
      "loss": 0.0456,
      "step": 1427
    },
    {
      "epoch": 14.5,
      "learning_rate": 9.714285714285715e-05,
      "loss": 0.0341,
      "step": 1428
    },
    {
      "epoch": 14.51,
      "learning_rate": 9.721088435374151e-05,
      "loss": 0.0183,
      "step": 1429
    },
    {
      "epoch": 14.52,
      "learning_rate": 9.727891156462585e-05,
      "loss": 0.0132,
      "step": 1430
    },
    {
      "epoch": 14.53,
      "learning_rate": 9.734693877551021e-05,
      "loss": 0.0465,
      "step": 1431
    },
    {
      "epoch": 14.54,
      "learning_rate": 9.741496598639455e-05,
      "loss": 0.0145,
      "step": 1432
    },
    {
      "epoch": 14.55,
      "learning_rate": 9.748299319727891e-05,
      "loss": 0.027,
      "step": 1433
    },
    {
      "epoch": 14.56,
      "learning_rate": 9.755102040816328e-05,
      "loss": 0.0192,
      "step": 1434
    },
    {
      "epoch": 14.57,
      "learning_rate": 9.761904761904762e-05,
      "loss": 0.0348,
      "step": 1435
    },
    {
      "epoch": 14.58,
      "learning_rate": 9.768707482993198e-05,
      "loss": 0.0301,
      "step": 1436
    },
    {
      "epoch": 14.59,
      "learning_rate": 9.775510204081632e-05,
      "loss": 0.0207,
      "step": 1437
    },
    {
      "epoch": 14.6,
      "learning_rate": 9.782312925170068e-05,
      "loss": 0.0175,
      "step": 1438
    },
    {
      "epoch": 14.61,
      "learning_rate": 9.789115646258504e-05,
      "loss": 0.0351,
      "step": 1439
    },
    {
      "epoch": 14.62,
      "learning_rate": 9.79591836734694e-05,
      "loss": 0.0179,
      "step": 1440
    },
    {
      "epoch": 14.63,
      "learning_rate": 9.802721088435375e-05,
      "loss": 0.0187,
      "step": 1441
    },
    {
      "epoch": 14.64,
      "learning_rate": 9.80952380952381e-05,
      "loss": 0.0253,
      "step": 1442
    },
    {
      "epoch": 14.65,
      "learning_rate": 9.816326530612245e-05,
      "loss": 0.0175,
      "step": 1443
    },
    {
      "epoch": 14.66,
      "learning_rate": 9.823129251700681e-05,
      "loss": 0.0144,
      "step": 1444
    },
    {
      "epoch": 14.67,
      "learning_rate": 9.829931972789116e-05,
      "loss": 0.0212,
      "step": 1445
    },
    {
      "epoch": 14.68,
      "learning_rate": 9.836734693877552e-05,
      "loss": 0.0208,
      "step": 1446
    },
    {
      "epoch": 14.69,
      "learning_rate": 9.843537414965986e-05,
      "loss": 0.0151,
      "step": 1447
    },
    {
      "epoch": 14.7,
      "learning_rate": 9.850340136054422e-05,
      "loss": 0.0318,
      "step": 1448
    },
    {
      "epoch": 14.71,
      "learning_rate": 9.857142857142858e-05,
      "loss": 0.0215,
      "step": 1449
    },
    {
      "epoch": 14.72,
      "learning_rate": 9.863945578231294e-05,
      "loss": 0.0356,
      "step": 1450
    },
    {
      "epoch": 14.73,
      "learning_rate": 9.870748299319729e-05,
      "loss": 0.0306,
      "step": 1451
    },
    {
      "epoch": 14.74,
      "learning_rate": 9.877551020408164e-05,
      "loss": 0.031,
      "step": 1452
    },
    {
      "epoch": 14.75,
      "learning_rate": 9.884353741496599e-05,
      "loss": 0.0457,
      "step": 1453
    },
    {
      "epoch": 14.76,
      "learning_rate": 9.891156462585035e-05,
      "loss": 0.0381,
      "step": 1454
    },
    {
      "epoch": 14.77,
      "learning_rate": 9.897959183673469e-05,
      "loss": 0.0066,
      "step": 1455
    },
    {
      "epoch": 14.78,
      "learning_rate": 9.904761904761905e-05,
      "loss": 0.0287,
      "step": 1456
    },
    {
      "epoch": 14.79,
      "learning_rate": 9.91156462585034e-05,
      "loss": 0.0217,
      "step": 1457
    },
    {
      "epoch": 14.8,
      "learning_rate": 9.918367346938776e-05,
      "loss": 0.0343,
      "step": 1458
    },
    {
      "epoch": 14.81,
      "learning_rate": 9.92517006802721e-05,
      "loss": 0.0527,
      "step": 1459
    },
    {
      "epoch": 14.82,
      "learning_rate": 9.931972789115646e-05,
      "loss": 0.0132,
      "step": 1460
    },
    {
      "epoch": 14.83,
      "learning_rate": 9.938775510204082e-05,
      "loss": 0.0085,
      "step": 1461
    },
    {
      "epoch": 14.84,
      "learning_rate": 9.945578231292518e-05,
      "loss": 0.0109,
      "step": 1462
    },
    {
      "epoch": 14.85,
      "learning_rate": 9.952380952380953e-05,
      "loss": 0.0302,
      "step": 1463
    },
    {
      "epoch": 14.86,
      "learning_rate": 9.959183673469388e-05,
      "loss": 0.0432,
      "step": 1464
    },
    {
      "epoch": 14.87,
      "learning_rate": 9.965986394557823e-05,
      "loss": 0.0291,
      "step": 1465
    },
    {
      "epoch": 14.88,
      "learning_rate": 9.972789115646259e-05,
      "loss": 0.0132,
      "step": 1466
    },
    {
      "epoch": 14.89,
      "learning_rate": 9.979591836734695e-05,
      "loss": 0.0416,
      "step": 1467
    },
    {
      "epoch": 14.9,
      "learning_rate": 9.98639455782313e-05,
      "loss": 0.0674,
      "step": 1468
    },
    {
      "epoch": 14.91,
      "learning_rate": 9.993197278911565e-05,
      "loss": 0.0101,
      "step": 1469
    },
    {
      "epoch": 14.92,
      "learning_rate": 0.0001,
      "loss": 0.0202,
      "step": 1470
    },
    {
      "epoch": 14.93,
      "learning_rate": 9.999999859032155e-05,
      "loss": 0.0223,
      "step": 1471
    },
    {
      "epoch": 14.94,
      "learning_rate": 9.999999436128624e-05,
      "loss": 0.0135,
      "step": 1472
    },
    {
      "epoch": 14.95,
      "learning_rate": 9.999998731289435e-05,
      "loss": 0.0484,
      "step": 1473
    },
    {
      "epoch": 14.96,
      "learning_rate": 9.999997744514624e-05,
      "loss": 0.0351,
      "step": 1474
    },
    {
      "epoch": 14.97,
      "learning_rate": 9.999996475804249e-05,
      "loss": 0.0722,
      "step": 1475
    },
    {
      "epoch": 14.98,
      "learning_rate": 9.999994925158381e-05,
      "loss": 0.0463,
      "step": 1476
    },
    {
      "epoch": 14.99,
      "learning_rate": 9.999993092577106e-05,
      "loss": 0.0371,
      "step": 1477
    },
    {
      "epoch": 14.99,
      "eval_loss": 0.029168928042054176,
      "eval_runtime": 31.7043,
      "eval_samples_per_second": 99.356,
      "eval_steps_per_second": 6.214,
      "eval_wer": 0.015460947503201025,
      "step": 1477
    },
    {
      "epoch": 15.01,
      "learning_rate": 9.999990978060529e-05,
      "loss": 0.0144,
      "step": 1478
    },
    {
      "epoch": 15.02,
      "learning_rate": 9.999988581608769e-05,
      "loss": 0.0276,
      "step": 1479
    },
    {
      "epoch": 15.03,
      "learning_rate": 9.999985903221961e-05,
      "loss": 0.0405,
      "step": 1480
    },
    {
      "epoch": 15.04,
      "learning_rate": 9.999982942900256e-05,
      "loss": 0.0074,
      "step": 1481
    },
    {
      "epoch": 15.05,
      "learning_rate": 9.999979700643821e-05,
      "loss": 0.0117,
      "step": 1482
    },
    {
      "epoch": 15.06,
      "learning_rate": 9.999976176452838e-05,
      "loss": 0.0449,
      "step": 1483
    },
    {
      "epoch": 15.07,
      "learning_rate": 9.999972370327507e-05,
      "loss": 0.0564,
      "step": 1484
    },
    {
      "epoch": 15.08,
      "learning_rate": 9.999968282268041e-05,
      "loss": 0.0167,
      "step": 1485
    },
    {
      "epoch": 15.09,
      "learning_rate": 9.999963912274674e-05,
      "loss": 0.0184,
      "step": 1486
    },
    {
      "epoch": 15.1,
      "learning_rate": 9.999959260347648e-05,
      "loss": 0.0386,
      "step": 1487
    },
    {
      "epoch": 15.11,
      "learning_rate": 9.999954326487227e-05,
      "loss": 0.0237,
      "step": 1488
    },
    {
      "epoch": 15.12,
      "learning_rate": 9.99994911069369e-05,
      "loss": 0.01,
      "step": 1489
    },
    {
      "epoch": 15.13,
      "learning_rate": 9.999943612967331e-05,
      "loss": 0.0223,
      "step": 1490
    },
    {
      "epoch": 15.14,
      "learning_rate": 9.999937833308459e-05,
      "loss": 0.0253,
      "step": 1491
    },
    {
      "epoch": 15.15,
      "learning_rate": 9.999931771717401e-05,
      "loss": 0.0337,
      "step": 1492
    },
    {
      "epoch": 15.16,
      "learning_rate": 9.999925428194499e-05,
      "loss": 0.0276,
      "step": 1493
    },
    {
      "epoch": 15.17,
      "learning_rate": 9.999918802740108e-05,
      "loss": 0.0381,
      "step": 1494
    },
    {
      "epoch": 15.18,
      "learning_rate": 9.999911895354604e-05,
      "loss": 0.0256,
      "step": 1495
    },
    {
      "epoch": 15.19,
      "learning_rate": 9.999904706038376e-05,
      "loss": 0.0356,
      "step": 1496
    },
    {
      "epoch": 15.2,
      "learning_rate": 9.99989723479183e-05,
      "loss": 0.0447,
      "step": 1497
    },
    {
      "epoch": 15.21,
      "learning_rate": 9.999889481615387e-05,
      "loss": 0.0543,
      "step": 1498
    },
    {
      "epoch": 15.22,
      "learning_rate": 9.999881446509484e-05,
      "loss": 0.0209,
      "step": 1499
    },
    {
      "epoch": 15.23,
      "learning_rate": 9.999873129474573e-05,
      "loss": 0.02,
      "step": 1500
    },
    {
      "epoch": 15.24,
      "learning_rate": 9.999864530511125e-05,
      "loss": 0.0496,
      "step": 1501
    },
    {
      "epoch": 15.25,
      "learning_rate": 9.999855649619623e-05,
      "loss": 0.069,
      "step": 1502
    },
    {
      "epoch": 15.26,
      "learning_rate": 9.999846486800568e-05,
      "loss": 0.0363,
      "step": 1503
    },
    {
      "epoch": 15.27,
      "learning_rate": 9.999837042054478e-05,
      "loss": 0.0182,
      "step": 1504
    },
    {
      "epoch": 15.28,
      "learning_rate": 9.999827315381885e-05,
      "loss": 0.0224,
      "step": 1505
    },
    {
      "epoch": 15.29,
      "learning_rate": 9.999817306783337e-05,
      "loss": 0.0274,
      "step": 1506
    },
    {
      "epoch": 15.3,
      "learning_rate": 9.999807016259398e-05,
      "loss": 0.0735,
      "step": 1507
    },
    {
      "epoch": 15.31,
      "learning_rate": 9.99979644381065e-05,
      "loss": 0.0314,
      "step": 1508
    },
    {
      "epoch": 15.32,
      "learning_rate": 9.999785589437687e-05,
      "loss": 0.0378,
      "step": 1509
    },
    {
      "epoch": 15.33,
      "learning_rate": 9.999774453141123e-05,
      "loss": 0.0409,
      "step": 1510
    },
    {
      "epoch": 15.34,
      "learning_rate": 9.999763034921584e-05,
      "loss": 0.0124,
      "step": 1511
    },
    {
      "epoch": 15.35,
      "learning_rate": 9.999751334779716e-05,
      "loss": 0.0247,
      "step": 1512
    },
    {
      "epoch": 15.36,
      "learning_rate": 9.999739352716177e-05,
      "loss": 0.0094,
      "step": 1513
    },
    {
      "epoch": 15.37,
      "learning_rate": 9.999727088731643e-05,
      "loss": 0.0274,
      "step": 1514
    },
    {
      "epoch": 15.38,
      "learning_rate": 9.999714542826806e-05,
      "loss": 0.0241,
      "step": 1515
    },
    {
      "epoch": 15.39,
      "learning_rate": 9.999701715002372e-05,
      "loss": 0.042,
      "step": 1516
    },
    {
      "epoch": 15.4,
      "learning_rate": 9.999688605259068e-05,
      "loss": 0.0166,
      "step": 1517
    },
    {
      "epoch": 15.41,
      "learning_rate": 9.999675213597629e-05,
      "loss": 0.0135,
      "step": 1518
    },
    {
      "epoch": 15.42,
      "learning_rate": 9.999661540018812e-05,
      "loss": 0.051,
      "step": 1519
    },
    {
      "epoch": 15.43,
      "learning_rate": 9.999647584523389e-05,
      "loss": 0.0147,
      "step": 1520
    },
    {
      "epoch": 15.44,
      "learning_rate": 9.999633347112143e-05,
      "loss": 0.0217,
      "step": 1521
    },
    {
      "epoch": 15.45,
      "learning_rate": 9.999618827785882e-05,
      "loss": 0.0296,
      "step": 1522
    },
    {
      "epoch": 15.46,
      "learning_rate": 9.999604026545422e-05,
      "loss": 0.0197,
      "step": 1523
    },
    {
      "epoch": 15.47,
      "learning_rate": 9.999588943391597e-05,
      "loss": 0.0544,
      "step": 1524
    },
    {
      "epoch": 15.48,
      "learning_rate": 9.999573578325258e-05,
      "loss": 0.0306,
      "step": 1525
    },
    {
      "epoch": 15.49,
      "learning_rate": 9.999557931347273e-05,
      "loss": 0.0463,
      "step": 1526
    },
    {
      "epoch": 15.5,
      "learning_rate": 9.999542002458523e-05,
      "loss": 0.017,
      "step": 1527
    },
    {
      "epoch": 15.51,
      "learning_rate": 9.999525791659906e-05,
      "loss": 0.0072,
      "step": 1528
    },
    {
      "epoch": 15.52,
      "learning_rate": 9.999509298952337e-05,
      "loss": 0.0277,
      "step": 1529
    },
    {
      "epoch": 15.53,
      "learning_rate": 9.999492524336743e-05,
      "loss": 0.0204,
      "step": 1530
    },
    {
      "epoch": 15.54,
      "learning_rate": 9.999475467814074e-05,
      "loss": 0.0239,
      "step": 1531
    },
    {
      "epoch": 15.55,
      "learning_rate": 9.99945812938529e-05,
      "loss": 0.0266,
      "step": 1532
    },
    {
      "epoch": 15.56,
      "learning_rate": 9.999440509051368e-05,
      "loss": 0.0273,
      "step": 1533
    },
    {
      "epoch": 15.57,
      "learning_rate": 9.999422606813302e-05,
      "loss": 0.0395,
      "step": 1534
    },
    {
      "epoch": 15.58,
      "learning_rate": 9.999404422672102e-05,
      "loss": 0.0238,
      "step": 1535
    },
    {
      "epoch": 15.59,
      "learning_rate": 9.999385956628793e-05,
      "loss": 0.0149,
      "step": 1536
    },
    {
      "epoch": 15.6,
      "learning_rate": 9.999367208684416e-05,
      "loss": 0.0302,
      "step": 1537
    },
    {
      "epoch": 15.61,
      "learning_rate": 9.999348178840028e-05,
      "loss": 0.0236,
      "step": 1538
    },
    {
      "epoch": 15.62,
      "learning_rate": 9.999328867096702e-05,
      "loss": 0.0244,
      "step": 1539
    },
    {
      "epoch": 15.63,
      "learning_rate": 9.999309273455528e-05,
      "loss": 0.0356,
      "step": 1540
    },
    {
      "epoch": 15.64,
      "learning_rate": 9.99928939791761e-05,
      "loss": 0.0114,
      "step": 1541
    },
    {
      "epoch": 15.65,
      "learning_rate": 9.99926924048407e-05,
      "loss": 0.052,
      "step": 1542
    },
    {
      "epoch": 15.66,
      "learning_rate": 9.999248801156043e-05,
      "loss": 0.0488,
      "step": 1543
    },
    {
      "epoch": 15.68,
      "learning_rate": 9.999228079934682e-05,
      "loss": 0.0078,
      "step": 1544
    },
    {
      "epoch": 15.69,
      "learning_rate": 9.999207076821155e-05,
      "loss": 0.022,
      "step": 1545
    },
    {
      "epoch": 15.7,
      "learning_rate": 9.999185791816648e-05,
      "loss": 0.0186,
      "step": 1546
    },
    {
      "epoch": 15.71,
      "learning_rate": 9.999164224922357e-05,
      "loss": 0.0133,
      "step": 1547
    },
    {
      "epoch": 15.72,
      "learning_rate": 9.999142376139503e-05,
      "loss": 0.0368,
      "step": 1548
    },
    {
      "epoch": 15.73,
      "learning_rate": 9.999120245469316e-05,
      "loss": 0.0352,
      "step": 1549
    },
    {
      "epoch": 15.74,
      "learning_rate": 9.999097832913045e-05,
      "loss": 0.0243,
      "step": 1550
    },
    {
      "epoch": 15.75,
      "learning_rate": 9.999075138471951e-05,
      "loss": 0.0294,
      "step": 1551
    },
    {
      "epoch": 15.76,
      "learning_rate": 9.999052162147316e-05,
      "loss": 0.0322,
      "step": 1552
    },
    {
      "epoch": 15.77,
      "learning_rate": 9.999028903940435e-05,
      "loss": 0.0029,
      "step": 1553
    },
    {
      "epoch": 15.78,
      "learning_rate": 9.999005363852618e-05,
      "loss": 0.0232,
      "step": 1554
    },
    {
      "epoch": 15.79,
      "learning_rate": 9.998981541885196e-05,
      "loss": 0.0426,
      "step": 1555
    },
    {
      "epoch": 15.8,
      "learning_rate": 9.998957438039507e-05,
      "loss": 0.0283,
      "step": 1556
    },
    {
      "epoch": 15.81,
      "learning_rate": 9.998933052316916e-05,
      "loss": 0.0162,
      "step": 1557
    },
    {
      "epoch": 15.82,
      "learning_rate": 9.998908384718794e-05,
      "loss": 0.0138,
      "step": 1558
    },
    {
      "epoch": 15.83,
      "learning_rate": 9.998883435246534e-05,
      "loss": 0.0185,
      "step": 1559
    },
    {
      "epoch": 15.84,
      "learning_rate": 9.99885820390154e-05,
      "loss": 0.0288,
      "step": 1560
    },
    {
      "epoch": 15.85,
      "learning_rate": 9.998832690685238e-05,
      "loss": 0.0077,
      "step": 1561
    },
    {
      "epoch": 15.86,
      "learning_rate": 9.998806895599065e-05,
      "loss": 0.0337,
      "step": 1562
    },
    {
      "epoch": 15.87,
      "learning_rate": 9.998780818644476e-05,
      "loss": 0.0097,
      "step": 1563
    },
    {
      "epoch": 15.88,
      "learning_rate": 9.99875445982294e-05,
      "loss": 0.0376,
      "step": 1564
    },
    {
      "epoch": 15.89,
      "learning_rate": 9.998727819135946e-05,
      "loss": 0.0248,
      "step": 1565
    },
    {
      "epoch": 15.9,
      "learning_rate": 9.998700896584996e-05,
      "loss": 0.0031,
      "step": 1566
    },
    {
      "epoch": 15.91,
      "learning_rate": 9.998673692171605e-05,
      "loss": 0.0182,
      "step": 1567
    },
    {
      "epoch": 15.92,
      "learning_rate": 9.998646205897309e-05,
      "loss": 0.0235,
      "step": 1568
    },
    {
      "epoch": 15.93,
      "learning_rate": 9.998618437763659e-05,
      "loss": 0.0434,
      "step": 1569
    },
    {
      "epoch": 15.94,
      "learning_rate": 9.998590387772217e-05,
      "loss": 0.0215,
      "step": 1570
    },
    {
      "epoch": 15.95,
      "learning_rate": 9.998562055924567e-05,
      "loss": 0.0163,
      "step": 1571
    },
    {
      "epoch": 15.96,
      "learning_rate": 9.998533442222308e-05,
      "loss": 0.0125,
      "step": 1572
    },
    {
      "epoch": 15.97,
      "learning_rate": 9.998504546667051e-05,
      "loss": 0.0259,
      "step": 1573
    },
    {
      "epoch": 15.98,
      "learning_rate": 9.998475369260428e-05,
      "loss": 0.0233,
      "step": 1574
    },
    {
      "epoch": 15.99,
      "learning_rate": 9.998445910004082e-05,
      "loss": 0.0205,
      "step": 1575
    },
    {
      "epoch": 16.0,
      "learning_rate": 9.998416168899674e-05,
      "loss": 0.0145,
      "step": 1576
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.024804692715406418,
      "eval_runtime": 31.8818,
      "eval_samples_per_second": 98.803,
      "eval_steps_per_second": 6.179,
      "eval_wer": 0.012548015364916773,
      "step": 1576
    },
    {
      "epoch": 16.01,
      "learning_rate": 9.998386145948882e-05,
      "loss": 0.0139,
      "step": 1577
    },
    {
      "epoch": 16.02,
      "learning_rate": 9.9983558411534e-05,
      "loss": 0.0083,
      "step": 1578
    },
    {
      "epoch": 16.03,
      "learning_rate": 9.998325254514934e-05,
      "loss": 0.035,
      "step": 1579
    },
    {
      "epoch": 16.04,
      "learning_rate": 9.99829438603521e-05,
      "loss": 0.0176,
      "step": 1580
    },
    {
      "epoch": 16.05,
      "learning_rate": 9.99826323571597e-05,
      "loss": 0.0296,
      "step": 1581
    },
    {
      "epoch": 16.06,
      "learning_rate": 9.998231803558968e-05,
      "loss": 0.0118,
      "step": 1582
    },
    {
      "epoch": 16.07,
      "learning_rate": 9.998200089565979e-05,
      "loss": 0.0225,
      "step": 1583
    },
    {
      "epoch": 16.08,
      "learning_rate": 9.998168093738789e-05,
      "loss": 0.0358,
      "step": 1584
    },
    {
      "epoch": 16.09,
      "learning_rate": 9.998135816079203e-05,
      "loss": 0.0261,
      "step": 1585
    },
    {
      "epoch": 16.1,
      "learning_rate": 9.99810325658904e-05,
      "loss": 0.0048,
      "step": 1586
    },
    {
      "epoch": 16.11,
      "learning_rate": 9.998070415270139e-05,
      "loss": 0.0347,
      "step": 1587
    },
    {
      "epoch": 16.12,
      "learning_rate": 9.998037292124349e-05,
      "loss": 0.0252,
      "step": 1588
    },
    {
      "epoch": 16.13,
      "learning_rate": 9.998003887153537e-05,
      "loss": 0.0085,
      "step": 1589
    },
    {
      "epoch": 16.14,
      "learning_rate": 9.99797020035959e-05,
      "loss": 0.0113,
      "step": 1590
    },
    {
      "epoch": 16.15,
      "learning_rate": 9.997936231744407e-05,
      "loss": 0.0622,
      "step": 1591
    },
    {
      "epoch": 16.16,
      "learning_rate": 9.9979019813099e-05,
      "loss": 0.0182,
      "step": 1592
    },
    {
      "epoch": 16.17,
      "learning_rate": 9.997867449058003e-05,
      "loss": 0.0347,
      "step": 1593
    },
    {
      "epoch": 16.18,
      "learning_rate": 9.997832634990661e-05,
      "loss": 0.0452,
      "step": 1594
    },
    {
      "epoch": 16.19,
      "learning_rate": 9.99779753910984e-05,
      "loss": 0.0234,
      "step": 1595
    },
    {
      "epoch": 16.2,
      "learning_rate": 9.997762161417517e-05,
      "loss": 0.0395,
      "step": 1596
    },
    {
      "epoch": 16.21,
      "learning_rate": 9.997726501915687e-05,
      "loss": 0.0087,
      "step": 1597
    },
    {
      "epoch": 16.22,
      "learning_rate": 9.997690560606363e-05,
      "loss": 0.021,
      "step": 1598
    },
    {
      "epoch": 16.23,
      "learning_rate": 9.99765433749157e-05,
      "loss": 0.0315,
      "step": 1599
    },
    {
      "epoch": 16.24,
      "learning_rate": 9.997617832573347e-05,
      "loss": 0.0562,
      "step": 1600
    },
    {
      "epoch": 16.25,
      "learning_rate": 9.997581045853757e-05,
      "loss": 0.0146,
      "step": 1601
    },
    {
      "epoch": 16.26,
      "learning_rate": 9.997543977334874e-05,
      "loss": 0.0074,
      "step": 1602
    },
    {
      "epoch": 16.27,
      "learning_rate": 9.997506627018787e-05,
      "loss": 0.0054,
      "step": 1603
    },
    {
      "epoch": 16.28,
      "learning_rate": 9.997468994907602e-05,
      "loss": 0.0246,
      "step": 1604
    },
    {
      "epoch": 16.29,
      "learning_rate": 9.99743108100344e-05,
      "loss": 0.0091,
      "step": 1605
    },
    {
      "epoch": 16.3,
      "learning_rate": 9.997392885308441e-05,
      "loss": 0.0014,
      "step": 1606
    },
    {
      "epoch": 16.31,
      "learning_rate": 9.997354407824757e-05,
      "loss": 0.0056,
      "step": 1607
    },
    {
      "epoch": 16.32,
      "learning_rate": 9.997315648554559e-05,
      "loss": 0.0291,
      "step": 1608
    },
    {
      "epoch": 16.34,
      "learning_rate": 9.997276607500032e-05,
      "loss": 0.0383,
      "step": 1609
    },
    {
      "epoch": 16.35,
      "learning_rate": 9.997237284663379e-05,
      "loss": 0.0062,
      "step": 1610
    },
    {
      "epoch": 16.36,
      "learning_rate": 9.997197680046814e-05,
      "loss": 0.0203,
      "step": 1611
    },
    {
      "epoch": 16.37,
      "learning_rate": 9.997157793652571e-05,
      "loss": 0.014,
      "step": 1612
    },
    {
      "epoch": 16.38,
      "learning_rate": 9.997117625482902e-05,
      "loss": 0.0218,
      "step": 1613
    },
    {
      "epoch": 16.39,
      "learning_rate": 9.997077175540068e-05,
      "loss": 0.0264,
      "step": 1614
    },
    {
      "epoch": 16.4,
      "learning_rate": 9.997036443826354e-05,
      "loss": 0.0325,
      "step": 1615
    },
    {
      "epoch": 16.41,
      "learning_rate": 9.996995430344053e-05,
      "loss": 0.008,
      "step": 1616
    },
    {
      "epoch": 16.42,
      "learning_rate": 9.99695413509548e-05,
      "loss": 0.0266,
      "step": 1617
    },
    {
      "epoch": 16.43,
      "learning_rate": 9.996912558082961e-05,
      "loss": 0.0426,
      "step": 1618
    },
    {
      "epoch": 16.44,
      "learning_rate": 9.996870699308844e-05,
      "loss": 0.0078,
      "step": 1619
    },
    {
      "epoch": 16.45,
      "learning_rate": 9.996828558775486e-05,
      "loss": 0.0223,
      "step": 1620
    },
    {
      "epoch": 16.46,
      "learning_rate": 9.996786136485265e-05,
      "loss": 0.0187,
      "step": 1621
    },
    {
      "epoch": 16.47,
      "learning_rate": 9.996743432440572e-05,
      "loss": 0.0645,
      "step": 1622
    },
    {
      "epoch": 16.48,
      "learning_rate": 9.996700446643817e-05,
      "loss": 0.0105,
      "step": 1623
    },
    {
      "epoch": 16.49,
      "learning_rate": 9.996657179097421e-05,
      "loss": 0.0606,
      "step": 1624
    },
    {
      "epoch": 16.5,
      "learning_rate": 9.996613629803826e-05,
      "loss": 0.0081,
      "step": 1625
    },
    {
      "epoch": 16.51,
      "learning_rate": 9.996569798765487e-05,
      "loss": 0.0193,
      "step": 1626
    },
    {
      "epoch": 16.52,
      "learning_rate": 9.996525685984875e-05,
      "loss": 0.0108,
      "step": 1627
    },
    {
      "epoch": 16.53,
      "learning_rate": 9.996481291464477e-05,
      "loss": 0.0086,
      "step": 1628
    },
    {
      "epoch": 16.54,
      "learning_rate": 9.996436615206798e-05,
      "loss": 0.0278,
      "step": 1629
    },
    {
      "epoch": 16.55,
      "learning_rate": 9.996391657214356e-05,
      "loss": 0.0097,
      "step": 1630
    },
    {
      "epoch": 16.56,
      "learning_rate": 9.996346417489686e-05,
      "loss": 0.0507,
      "step": 1631
    },
    {
      "epoch": 16.57,
      "learning_rate": 9.996300896035339e-05,
      "loss": 0.0202,
      "step": 1632
    },
    {
      "epoch": 16.58,
      "learning_rate": 9.996255092853881e-05,
      "loss": 0.0108,
      "step": 1633
    },
    {
      "epoch": 16.59,
      "learning_rate": 9.996209007947897e-05,
      "loss": 0.0161,
      "step": 1634
    },
    {
      "epoch": 16.6,
      "learning_rate": 9.996162641319984e-05,
      "loss": 0.0059,
      "step": 1635
    },
    {
      "epoch": 16.61,
      "learning_rate": 9.996115992972757e-05,
      "loss": 0.0062,
      "step": 1636
    },
    {
      "epoch": 16.62,
      "learning_rate": 9.996069062908846e-05,
      "loss": 0.0212,
      "step": 1637
    },
    {
      "epoch": 16.63,
      "learning_rate": 9.996021851130897e-05,
      "loss": 0.0251,
      "step": 1638
    },
    {
      "epoch": 16.64,
      "learning_rate": 9.995974357641571e-05,
      "loss": 0.0294,
      "step": 1639
    },
    {
      "epoch": 16.65,
      "learning_rate": 9.995926582443551e-05,
      "loss": 0.0254,
      "step": 1640
    },
    {
      "epoch": 16.66,
      "learning_rate": 9.995878525539525e-05,
      "loss": 0.031,
      "step": 1641
    },
    {
      "epoch": 16.67,
      "learning_rate": 9.995830186932205e-05,
      "loss": 0.0117,
      "step": 1642
    },
    {
      "epoch": 16.68,
      "learning_rate": 9.995781566624319e-05,
      "loss": 0.0435,
      "step": 1643
    },
    {
      "epoch": 16.69,
      "learning_rate": 9.995732664618604e-05,
      "loss": 0.0365,
      "step": 1644
    },
    {
      "epoch": 16.7,
      "learning_rate": 9.995683480917821e-05,
      "loss": 0.0534,
      "step": 1645
    },
    {
      "epoch": 16.71,
      "learning_rate": 9.995634015524742e-05,
      "loss": 0.0269,
      "step": 1646
    },
    {
      "epoch": 16.72,
      "learning_rate": 9.995584268442158e-05,
      "loss": 0.0367,
      "step": 1647
    },
    {
      "epoch": 16.73,
      "learning_rate": 9.99553423967287e-05,
      "loss": 0.041,
      "step": 1648
    },
    {
      "epoch": 16.74,
      "learning_rate": 9.995483929219702e-05,
      "loss": 0.0102,
      "step": 1649
    },
    {
      "epoch": 16.75,
      "learning_rate": 9.995433337085491e-05,
      "loss": 0.0126,
      "step": 1650
    },
    {
      "epoch": 16.76,
      "learning_rate": 9.99538246327309e-05,
      "loss": 0.0455,
      "step": 1651
    },
    {
      "epoch": 16.77,
      "learning_rate": 9.995331307785365e-05,
      "loss": 0.0113,
      "step": 1652
    },
    {
      "epoch": 16.78,
      "learning_rate": 9.995279870625204e-05,
      "loss": 0.0323,
      "step": 1653
    },
    {
      "epoch": 16.79,
      "learning_rate": 9.995228151795503e-05,
      "loss": 0.0135,
      "step": 1654
    },
    {
      "epoch": 16.8,
      "learning_rate": 9.995176151299183e-05,
      "loss": 0.0494,
      "step": 1655
    },
    {
      "epoch": 16.81,
      "learning_rate": 9.995123869139176e-05,
      "loss": 0.0142,
      "step": 1656
    },
    {
      "epoch": 16.82,
      "learning_rate": 9.995071305318424e-05,
      "loss": 0.0379,
      "step": 1657
    },
    {
      "epoch": 16.83,
      "learning_rate": 9.995018459839898e-05,
      "loss": 0.0285,
      "step": 1658
    },
    {
      "epoch": 16.84,
      "learning_rate": 9.994965332706573e-05,
      "loss": 0.0192,
      "step": 1659
    },
    {
      "epoch": 16.85,
      "learning_rate": 9.994911923921448e-05,
      "loss": 0.0136,
      "step": 1660
    },
    {
      "epoch": 16.86,
      "learning_rate": 9.994858233487532e-05,
      "loss": 0.019,
      "step": 1661
    },
    {
      "epoch": 16.87,
      "learning_rate": 9.994804261407855e-05,
      "loss": 0.0446,
      "step": 1662
    },
    {
      "epoch": 16.88,
      "learning_rate": 9.994750007685457e-05,
      "loss": 0.0041,
      "step": 1663
    },
    {
      "epoch": 16.89,
      "learning_rate": 9.9946954723234e-05,
      "loss": 0.037,
      "step": 1664
    },
    {
      "epoch": 16.9,
      "learning_rate": 9.994640655324758e-05,
      "loss": 0.0228,
      "step": 1665
    },
    {
      "epoch": 16.91,
      "learning_rate": 9.994585556692624e-05,
      "loss": 0.0172,
      "step": 1666
    },
    {
      "epoch": 16.92,
      "learning_rate": 9.9945301764301e-05,
      "loss": 0.0106,
      "step": 1667
    },
    {
      "epoch": 16.93,
      "learning_rate": 9.994474514540313e-05,
      "loss": 0.0421,
      "step": 1668
    },
    {
      "epoch": 16.94,
      "learning_rate": 9.994418571026401e-05,
      "loss": 0.037,
      "step": 1669
    },
    {
      "epoch": 16.95,
      "learning_rate": 9.994362345891517e-05,
      "loss": 0.0419,
      "step": 1670
    },
    {
      "epoch": 16.96,
      "learning_rate": 9.994305839138834e-05,
      "loss": 0.0464,
      "step": 1671
    },
    {
      "epoch": 16.97,
      "learning_rate": 9.994249050771535e-05,
      "loss": 0.0176,
      "step": 1672
    },
    {
      "epoch": 16.98,
      "learning_rate": 9.994191980792823e-05,
      "loss": 0.0272,
      "step": 1673
    },
    {
      "epoch": 16.99,
      "learning_rate": 9.994134629205918e-05,
      "loss": 0.0386,
      "step": 1674
    },
    {
      "epoch": 16.99,
      "eval_loss": 0.01999177411198616,
      "eval_runtime": 32.0961,
      "eval_samples_per_second": 98.143,
      "eval_steps_per_second": 6.138,
      "eval_wer": 0.01232394366197183,
      "step": 1674
    },
    {
      "epoch": 17.01,
      "learning_rate": 9.994076996014052e-05,
      "loss": 0.0154,
      "step": 1675
    },
    {
      "epoch": 17.02,
      "learning_rate": 9.994019081220475e-05,
      "loss": 0.0263,
      "step": 1676
    },
    {
      "epoch": 17.03,
      "learning_rate": 9.993960884828453e-05,
      "loss": 0.0233,
      "step": 1677
    },
    {
      "epoch": 17.04,
      "learning_rate": 9.993902406841267e-05,
      "loss": 0.0084,
      "step": 1678
    },
    {
      "epoch": 17.05,
      "learning_rate": 9.993843647262217e-05,
      "loss": 0.0245,
      "step": 1679
    },
    {
      "epoch": 17.06,
      "learning_rate": 9.993784606094612e-05,
      "loss": 0.0107,
      "step": 1680
    },
    {
      "epoch": 17.07,
      "learning_rate": 9.993725283341783e-05,
      "loss": 0.0289,
      "step": 1681
    },
    {
      "epoch": 17.08,
      "learning_rate": 9.993665679007078e-05,
      "loss": 0.0092,
      "step": 1682
    },
    {
      "epoch": 17.09,
      "learning_rate": 9.993605793093854e-05,
      "loss": 0.0185,
      "step": 1683
    },
    {
      "epoch": 17.1,
      "learning_rate": 9.99354562560549e-05,
      "loss": 0.0028,
      "step": 1684
    },
    {
      "epoch": 17.11,
      "learning_rate": 9.993485176545375e-05,
      "loss": 0.0339,
      "step": 1685
    },
    {
      "epoch": 17.12,
      "learning_rate": 9.993424445916923e-05,
      "loss": 0.0092,
      "step": 1686
    },
    {
      "epoch": 17.13,
      "learning_rate": 9.993363433723554e-05,
      "loss": 0.0109,
      "step": 1687
    },
    {
      "epoch": 17.14,
      "learning_rate": 9.99330213996871e-05,
      "loss": 0.0049,
      "step": 1688
    },
    {
      "epoch": 17.15,
      "learning_rate": 9.993240564655848e-05,
      "loss": 0.0401,
      "step": 1689
    },
    {
      "epoch": 17.16,
      "learning_rate": 9.99317870778844e-05,
      "loss": 0.0324,
      "step": 1690
    },
    {
      "epoch": 17.17,
      "learning_rate": 9.993116569369973e-05,
      "loss": 0.0208,
      "step": 1691
    },
    {
      "epoch": 17.18,
      "learning_rate": 9.99305414940395e-05,
      "loss": 0.014,
      "step": 1692
    },
    {
      "epoch": 17.19,
      "learning_rate": 9.992991447893892e-05,
      "loss": 0.0217,
      "step": 1693
    },
    {
      "epoch": 17.2,
      "learning_rate": 9.992928464843334e-05,
      "loss": 0.0272,
      "step": 1694
    },
    {
      "epoch": 17.21,
      "learning_rate": 9.992865200255829e-05,
      "loss": 0.0357,
      "step": 1695
    },
    {
      "epoch": 17.22,
      "learning_rate": 9.992801654134942e-05,
      "loss": 0.0221,
      "step": 1696
    },
    {
      "epoch": 17.23,
      "learning_rate": 9.992737826484258e-05,
      "loss": 0.0391,
      "step": 1697
    },
    {
      "epoch": 17.24,
      "learning_rate": 9.992673717307374e-05,
      "loss": 0.0316,
      "step": 1698
    },
    {
      "epoch": 17.25,
      "learning_rate": 9.992609326607907e-05,
      "loss": 0.0185,
      "step": 1699
    },
    {
      "epoch": 17.26,
      "learning_rate": 9.992544654389487e-05,
      "loss": 0.0101,
      "step": 1700
    },
    {
      "epoch": 17.27,
      "learning_rate": 9.99247970065576e-05,
      "loss": 0.0136,
      "step": 1701
    },
    {
      "epoch": 17.28,
      "learning_rate": 9.99241446541039e-05,
      "loss": 0.0237,
      "step": 1702
    },
    {
      "epoch": 17.29,
      "learning_rate": 9.992348948657054e-05,
      "loss": 0.0172,
      "step": 1703
    },
    {
      "epoch": 17.3,
      "learning_rate": 9.992283150399447e-05,
      "loss": 0.0225,
      "step": 1704
    },
    {
      "epoch": 17.31,
      "learning_rate": 9.992217070641279e-05,
      "loss": 0.0228,
      "step": 1705
    },
    {
      "epoch": 17.32,
      "learning_rate": 9.992150709386277e-05,
      "loss": 0.028,
      "step": 1706
    },
    {
      "epoch": 17.33,
      "learning_rate": 9.992084066638181e-05,
      "loss": 0.0237,
      "step": 1707
    },
    {
      "epoch": 17.34,
      "learning_rate": 9.992017142400751e-05,
      "loss": 0.0199,
      "step": 1708
    },
    {
      "epoch": 17.35,
      "learning_rate": 9.991949936677757e-05,
      "loss": 0.0073,
      "step": 1709
    },
    {
      "epoch": 17.36,
      "learning_rate": 9.991882449472995e-05,
      "loss": 0.0132,
      "step": 1710
    },
    {
      "epoch": 17.37,
      "learning_rate": 9.991814680790264e-05,
      "loss": 0.0219,
      "step": 1711
    },
    {
      "epoch": 17.38,
      "learning_rate": 9.991746630633389e-05,
      "loss": 0.0315,
      "step": 1712
    },
    {
      "epoch": 17.39,
      "learning_rate": 9.991678299006205e-05,
      "loss": 0.0253,
      "step": 1713
    },
    {
      "epoch": 17.4,
      "learning_rate": 9.991609685912566e-05,
      "loss": 0.0353,
      "step": 1714
    },
    {
      "epoch": 17.41,
      "learning_rate": 9.991540791356342e-05,
      "loss": 0.0235,
      "step": 1715
    },
    {
      "epoch": 17.42,
      "learning_rate": 9.991471615341415e-05,
      "loss": 0.0388,
      "step": 1716
    },
    {
      "epoch": 17.43,
      "learning_rate": 9.991402157871687e-05,
      "loss": 0.0193,
      "step": 1717
    },
    {
      "epoch": 17.44,
      "learning_rate": 9.991332418951077e-05,
      "loss": 0.0297,
      "step": 1718
    },
    {
      "epoch": 17.45,
      "learning_rate": 9.991262398583514e-05,
      "loss": 0.0177,
      "step": 1719
    },
    {
      "epoch": 17.46,
      "learning_rate": 9.991192096772947e-05,
      "loss": 0.0123,
      "step": 1720
    },
    {
      "epoch": 17.47,
      "learning_rate": 9.991121513523341e-05,
      "loss": 0.0314,
      "step": 1721
    },
    {
      "epoch": 17.48,
      "learning_rate": 9.991050648838675e-05,
      "loss": 0.0159,
      "step": 1722
    },
    {
      "epoch": 17.49,
      "learning_rate": 9.990979502722947e-05,
      "loss": 0.0302,
      "step": 1723
    },
    {
      "epoch": 17.5,
      "learning_rate": 9.990908075180166e-05,
      "loss": 0.0199,
      "step": 1724
    },
    {
      "epoch": 17.51,
      "learning_rate": 9.99083636621436e-05,
      "loss": 0.0231,
      "step": 1725
    },
    {
      "epoch": 17.52,
      "learning_rate": 9.990764375829574e-05,
      "loss": 0.0204,
      "step": 1726
    },
    {
      "epoch": 17.53,
      "learning_rate": 9.990692104029866e-05,
      "loss": 0.0422,
      "step": 1727
    },
    {
      "epoch": 17.54,
      "learning_rate": 9.990619550819312e-05,
      "loss": 0.0094,
      "step": 1728
    },
    {
      "epoch": 17.55,
      "learning_rate": 9.990546716202003e-05,
      "loss": 0.0266,
      "step": 1729
    },
    {
      "epoch": 17.56,
      "learning_rate": 9.990473600182045e-05,
      "loss": 0.0021,
      "step": 1730
    },
    {
      "epoch": 17.57,
      "learning_rate": 9.990400202763563e-05,
      "loss": 0.0102,
      "step": 1731
    },
    {
      "epoch": 17.58,
      "learning_rate": 9.990326523950692e-05,
      "loss": 0.0472,
      "step": 1732
    },
    {
      "epoch": 17.59,
      "learning_rate": 9.99025256374759e-05,
      "loss": 0.0387,
      "step": 1733
    },
    {
      "epoch": 17.6,
      "learning_rate": 9.990178322158426e-05,
      "loss": 0.0386,
      "step": 1734
    },
    {
      "epoch": 17.61,
      "learning_rate": 9.990103799187385e-05,
      "loss": 0.0072,
      "step": 1735
    },
    {
      "epoch": 17.62,
      "learning_rate": 9.990028994838673e-05,
      "loss": 0.0319,
      "step": 1736
    },
    {
      "epoch": 17.63,
      "learning_rate": 9.989953909116503e-05,
      "loss": 0.0195,
      "step": 1737
    },
    {
      "epoch": 17.64,
      "learning_rate": 9.989878542025113e-05,
      "loss": 0.0234,
      "step": 1738
    },
    {
      "epoch": 17.65,
      "learning_rate": 9.989802893568752e-05,
      "loss": 0.0263,
      "step": 1739
    },
    {
      "epoch": 17.66,
      "learning_rate": 9.989726963751682e-05,
      "loss": 0.02,
      "step": 1740
    },
    {
      "epoch": 17.68,
      "learning_rate": 9.989650752578188e-05,
      "loss": 0.0224,
      "step": 1741
    },
    {
      "epoch": 17.69,
      "learning_rate": 9.989574260052567e-05,
      "loss": 0.0644,
      "step": 1742
    },
    {
      "epoch": 17.7,
      "learning_rate": 9.989497486179132e-05,
      "loss": 0.006,
      "step": 1743
    },
    {
      "epoch": 17.71,
      "learning_rate": 9.989420430962212e-05,
      "loss": 0.0217,
      "step": 1744
    },
    {
      "epoch": 17.72,
      "learning_rate": 9.989343094406152e-05,
      "loss": 0.0355,
      "step": 1745
    },
    {
      "epoch": 17.73,
      "learning_rate": 9.98926547651531e-05,
      "loss": 0.0446,
      "step": 1746
    },
    {
      "epoch": 17.74,
      "learning_rate": 9.989187577294068e-05,
      "loss": 0.0193,
      "step": 1747
    },
    {
      "epoch": 17.75,
      "learning_rate": 9.989109396746815e-05,
      "loss": 0.0039,
      "step": 1748
    },
    {
      "epoch": 17.76,
      "learning_rate": 9.989030934877959e-05,
      "loss": 0.0142,
      "step": 1749
    },
    {
      "epoch": 17.77,
      "learning_rate": 9.988952191691925e-05,
      "loss": 0.0048,
      "step": 1750
    },
    {
      "epoch": 17.78,
      "learning_rate": 9.988873167193154e-05,
      "loss": 0.0031,
      "step": 1751
    },
    {
      "epoch": 17.79,
      "learning_rate": 9.9887938613861e-05,
      "loss": 0.014,
      "step": 1752
    },
    {
      "epoch": 17.8,
      "learning_rate": 9.988714274275239e-05,
      "loss": 0.0263,
      "step": 1753
    },
    {
      "epoch": 17.81,
      "learning_rate": 9.988634405865053e-05,
      "loss": 0.0087,
      "step": 1754
    },
    {
      "epoch": 17.82,
      "learning_rate": 9.988554256160052e-05,
      "loss": 0.0167,
      "step": 1755
    },
    {
      "epoch": 17.83,
      "learning_rate": 9.988473825164748e-05,
      "loss": 0.0248,
      "step": 1756
    },
    {
      "epoch": 17.84,
      "learning_rate": 9.988393112883683e-05,
      "loss": 0.0159,
      "step": 1757
    },
    {
      "epoch": 17.85,
      "learning_rate": 9.988312119321404e-05,
      "loss": 0.0591,
      "step": 1758
    },
    {
      "epoch": 17.86,
      "learning_rate": 9.988230844482478e-05,
      "loss": 0.0147,
      "step": 1759
    },
    {
      "epoch": 17.87,
      "learning_rate": 9.988149288371491e-05,
      "loss": 0.0217,
      "step": 1760
    },
    {
      "epoch": 17.88,
      "learning_rate": 9.988067450993038e-05,
      "loss": 0.04,
      "step": 1761
    },
    {
      "epoch": 17.89,
      "learning_rate": 9.987985332351737e-05,
      "loss": 0.0077,
      "step": 1762
    },
    {
      "epoch": 17.9,
      "learning_rate": 9.987902932452215e-05,
      "loss": 0.0312,
      "step": 1763
    },
    {
      "epoch": 17.91,
      "learning_rate": 9.987820251299122e-05,
      "loss": 0.0211,
      "step": 1764
    },
    {
      "epoch": 17.92,
      "learning_rate": 9.987737288897117e-05,
      "loss": 0.0251,
      "step": 1765
    },
    {
      "epoch": 17.93,
      "learning_rate": 9.98765404525088e-05,
      "loss": 0.0158,
      "step": 1766
    },
    {
      "epoch": 17.94,
      "learning_rate": 9.987570520365104e-05,
      "loss": 0.031,
      "step": 1767
    },
    {
      "epoch": 17.95,
      "learning_rate": 9.987486714244498e-05,
      "loss": 0.012,
      "step": 1768
    },
    {
      "epoch": 17.96,
      "learning_rate": 9.98740262689379e-05,
      "loss": 0.0276,
      "step": 1769
    },
    {
      "epoch": 17.97,
      "learning_rate": 9.987318258317717e-05,
      "loss": 0.0355,
      "step": 1770
    },
    {
      "epoch": 17.98,
      "learning_rate": 9.987233608521042e-05,
      "loss": 0.0725,
      "step": 1771
    },
    {
      "epoch": 17.99,
      "learning_rate": 9.987148677508535e-05,
      "loss": 0.0197,
      "step": 1772
    },
    {
      "epoch": 18.0,
      "learning_rate": 9.987063465284985e-05,
      "loss": 0.0193,
      "step": 1773
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.02175280638039112,
      "eval_runtime": 31.8165,
      "eval_samples_per_second": 99.005,
      "eval_steps_per_second": 6.192,
      "eval_wer": 0.009795134443021767,
      "step": 1773
    },
    {
      "epoch": 18.01,
      "learning_rate": 9.986977971855196e-05,
      "loss": 0.0147,
      "step": 1774
    },
    {
      "epoch": 18.02,
      "learning_rate": 9.986892197223991e-05,
      "loss": 0.0061,
      "step": 1775
    },
    {
      "epoch": 18.03,
      "learning_rate": 9.986806141396205e-05,
      "loss": 0.0228,
      "step": 1776
    },
    {
      "epoch": 18.04,
      "learning_rate": 9.986719804376692e-05,
      "loss": 0.0338,
      "step": 1777
    },
    {
      "epoch": 18.05,
      "learning_rate": 9.986633186170319e-05,
      "loss": 0.0076,
      "step": 1778
    },
    {
      "epoch": 18.06,
      "learning_rate": 9.986546286781971e-05,
      "loss": 0.0281,
      "step": 1779
    },
    {
      "epoch": 18.07,
      "learning_rate": 9.986459106216546e-05,
      "loss": 0.0256,
      "step": 1780
    },
    {
      "epoch": 18.08,
      "learning_rate": 9.986371644478962e-05,
      "loss": 0.0084,
      "step": 1781
    },
    {
      "epoch": 18.09,
      "learning_rate": 9.98628390157415e-05,
      "loss": 0.0444,
      "step": 1782
    },
    {
      "epoch": 18.1,
      "learning_rate": 9.986195877507058e-05,
      "loss": 0.0378,
      "step": 1783
    },
    {
      "epoch": 18.11,
      "learning_rate": 9.986107572282649e-05,
      "loss": 0.0104,
      "step": 1784
    },
    {
      "epoch": 18.12,
      "learning_rate": 9.986018985905901e-05,
      "loss": 0.0272,
      "step": 1785
    },
    {
      "epoch": 18.13,
      "learning_rate": 9.985930118381813e-05,
      "loss": 0.0312,
      "step": 1786
    },
    {
      "epoch": 18.14,
      "learning_rate": 9.985840969715389e-05,
      "loss": 0.0544,
      "step": 1787
    },
    {
      "epoch": 18.15,
      "learning_rate": 9.985751539911666e-05,
      "loss": 0.0067,
      "step": 1788
    },
    {
      "epoch": 18.16,
      "learning_rate": 9.985661828975677e-05,
      "loss": 0.0214,
      "step": 1789
    },
    {
      "epoch": 18.17,
      "learning_rate": 9.985571836912485e-05,
      "loss": 0.0165,
      "step": 1790
    },
    {
      "epoch": 18.18,
      "learning_rate": 9.985481563727165e-05,
      "loss": 0.0187,
      "step": 1791
    },
    {
      "epoch": 18.19,
      "learning_rate": 9.985391009424805e-05,
      "loss": 0.0443,
      "step": 1792
    },
    {
      "epoch": 18.2,
      "learning_rate": 9.985300174010512e-05,
      "loss": 0.0228,
      "step": 1793
    },
    {
      "epoch": 18.21,
      "learning_rate": 9.98520905748941e-05,
      "loss": 0.013,
      "step": 1794
    },
    {
      "epoch": 18.22,
      "learning_rate": 9.985117659866634e-05,
      "loss": 0.0251,
      "step": 1795
    },
    {
      "epoch": 18.23,
      "learning_rate": 9.985025981147338e-05,
      "loss": 0.0271,
      "step": 1796
    },
    {
      "epoch": 18.24,
      "learning_rate": 9.984934021336693e-05,
      "loss": 0.0177,
      "step": 1797
    },
    {
      "epoch": 18.25,
      "learning_rate": 9.984841780439884e-05,
      "loss": 0.0175,
      "step": 1798
    },
    {
      "epoch": 18.26,
      "learning_rate": 9.98474925846211e-05,
      "loss": 0.0272,
      "step": 1799
    },
    {
      "epoch": 18.27,
      "learning_rate": 9.984656455408591e-05,
      "loss": 0.035,
      "step": 1800
    },
    {
      "epoch": 18.28,
      "learning_rate": 9.984563371284559e-05,
      "loss": 0.017,
      "step": 1801
    },
    {
      "epoch": 18.29,
      "learning_rate": 9.984470006095261e-05,
      "loss": 0.0386,
      "step": 1802
    },
    {
      "epoch": 18.3,
      "learning_rate": 9.984376359845964e-05,
      "loss": 0.0087,
      "step": 1803
    },
    {
      "epoch": 18.31,
      "learning_rate": 9.984282432541947e-05,
      "loss": 0.0124,
      "step": 1804
    },
    {
      "epoch": 18.32,
      "learning_rate": 9.984188224188507e-05,
      "loss": 0.0253,
      "step": 1805
    },
    {
      "epoch": 18.34,
      "learning_rate": 9.984093734790956e-05,
      "loss": 0.0083,
      "step": 1806
    },
    {
      "epoch": 18.35,
      "learning_rate": 9.983998964354621e-05,
      "loss": 0.0595,
      "step": 1807
    },
    {
      "epoch": 18.36,
      "learning_rate": 9.983903912884847e-05,
      "loss": 0.0328,
      "step": 1808
    },
    {
      "epoch": 18.37,
      "learning_rate": 9.983808580386992e-05,
      "loss": 0.0129,
      "step": 1809
    },
    {
      "epoch": 18.38,
      "learning_rate": 9.983712966866436e-05,
      "loss": 0.0343,
      "step": 1810
    },
    {
      "epoch": 18.39,
      "learning_rate": 9.983617072328564e-05,
      "loss": 0.0026,
      "step": 1811
    },
    {
      "epoch": 18.4,
      "learning_rate": 9.983520896778788e-05,
      "loss": 0.0613,
      "step": 1812
    },
    {
      "epoch": 18.41,
      "learning_rate": 9.983424440222531e-05,
      "loss": 0.026,
      "step": 1813
    },
    {
      "epoch": 18.42,
      "learning_rate": 9.983327702665229e-05,
      "loss": 0.0572,
      "step": 1814
    },
    {
      "epoch": 18.43,
      "learning_rate": 9.983230684112338e-05,
      "loss": 0.0797,
      "step": 1815
    },
    {
      "epoch": 18.44,
      "learning_rate": 9.983133384569329e-05,
      "loss": 0.0417,
      "step": 1816
    },
    {
      "epoch": 18.45,
      "learning_rate": 9.983035804041688e-05,
      "loss": 0.0247,
      "step": 1817
    },
    {
      "epoch": 18.46,
      "learning_rate": 9.982937942534918e-05,
      "loss": 0.021,
      "step": 1818
    },
    {
      "epoch": 18.47,
      "learning_rate": 9.982839800054537e-05,
      "loss": 0.061,
      "step": 1819
    },
    {
      "epoch": 18.48,
      "learning_rate": 9.982741376606078e-05,
      "loss": 0.0245,
      "step": 1820
    },
    {
      "epoch": 18.49,
      "learning_rate": 9.982642672195092e-05,
      "loss": 0.0387,
      "step": 1821
    },
    {
      "epoch": 18.5,
      "learning_rate": 9.982543686827144e-05,
      "loss": 0.0135,
      "step": 1822
    },
    {
      "epoch": 18.51,
      "learning_rate": 9.982444420507816e-05,
      "loss": 0.005,
      "step": 1823
    },
    {
      "epoch": 18.52,
      "learning_rate": 9.982344873242703e-05,
      "loss": 0.0547,
      "step": 1824
    },
    {
      "epoch": 18.53,
      "learning_rate": 9.982245045037422e-05,
      "loss": 0.0102,
      "step": 1825
    },
    {
      "epoch": 18.54,
      "learning_rate": 9.982144935897599e-05,
      "loss": 0.0056,
      "step": 1826
    },
    {
      "epoch": 18.55,
      "learning_rate": 9.98204454582888e-05,
      "loss": 0.0118,
      "step": 1827
    },
    {
      "epoch": 18.56,
      "learning_rate": 9.981943874836926e-05,
      "loss": 0.01,
      "step": 1828
    },
    {
      "epoch": 18.57,
      "learning_rate": 9.981842922927414e-05,
      "loss": 0.0115,
      "step": 1829
    },
    {
      "epoch": 18.58,
      "learning_rate": 9.981741690106034e-05,
      "loss": 0.0253,
      "step": 1830
    },
    {
      "epoch": 18.59,
      "learning_rate": 9.981640176378498e-05,
      "loss": 0.0166,
      "step": 1831
    },
    {
      "epoch": 18.6,
      "learning_rate": 9.981538381750528e-05,
      "loss": 0.0355,
      "step": 1832
    },
    {
      "epoch": 18.61,
      "learning_rate": 9.981436306227862e-05,
      "loss": 0.0313,
      "step": 1833
    },
    {
      "epoch": 18.62,
      "learning_rate": 9.981333949816259e-05,
      "loss": 0.0245,
      "step": 1834
    },
    {
      "epoch": 18.63,
      "learning_rate": 9.981231312521488e-05,
      "loss": 0.0067,
      "step": 1835
    },
    {
      "epoch": 18.64,
      "learning_rate": 9.981128394349339e-05,
      "loss": 0.0098,
      "step": 1836
    },
    {
      "epoch": 18.65,
      "learning_rate": 9.981025195305614e-05,
      "loss": 0.0068,
      "step": 1837
    },
    {
      "epoch": 18.66,
      "learning_rate": 9.980921715396132e-05,
      "loss": 0.0159,
      "step": 1838
    },
    {
      "epoch": 18.67,
      "learning_rate": 9.980817954626726e-05,
      "loss": 0.0251,
      "step": 1839
    },
    {
      "epoch": 18.68,
      "learning_rate": 9.980713913003252e-05,
      "loss": 0.0511,
      "step": 1840
    },
    {
      "epoch": 18.69,
      "learning_rate": 9.980609590531571e-05,
      "loss": 0.011,
      "step": 1841
    },
    {
      "epoch": 18.7,
      "learning_rate": 9.980504987217567e-05,
      "loss": 0.0203,
      "step": 1842
    },
    {
      "epoch": 18.71,
      "learning_rate": 9.98040010306714e-05,
      "loss": 0.0193,
      "step": 1843
    },
    {
      "epoch": 18.72,
      "learning_rate": 9.980294938086204e-05,
      "loss": 0.0233,
      "step": 1844
    },
    {
      "epoch": 18.73,
      "learning_rate": 9.980189492280687e-05,
      "loss": 0.056,
      "step": 1845
    },
    {
      "epoch": 18.74,
      "learning_rate": 9.980083765656537e-05,
      "loss": 0.0095,
      "step": 1846
    },
    {
      "epoch": 18.75,
      "learning_rate": 9.979977758219714e-05,
      "loss": 0.025,
      "step": 1847
    },
    {
      "epoch": 18.76,
      "learning_rate": 9.979871469976196e-05,
      "loss": 0.015,
      "step": 1848
    },
    {
      "epoch": 18.77,
      "learning_rate": 9.979764900931976e-05,
      "loss": 0.0057,
      "step": 1849
    },
    {
      "epoch": 18.78,
      "learning_rate": 9.979658051093063e-05,
      "loss": 0.0128,
      "step": 1850
    },
    {
      "epoch": 18.79,
      "learning_rate": 9.979550920465483e-05,
      "loss": 0.0191,
      "step": 1851
    },
    {
      "epoch": 18.8,
      "learning_rate": 9.979443509055277e-05,
      "loss": 0.0165,
      "step": 1852
    },
    {
      "epoch": 18.81,
      "learning_rate": 9.979335816868499e-05,
      "loss": 0.0117,
      "step": 1853
    },
    {
      "epoch": 18.82,
      "learning_rate": 9.979227843911224e-05,
      "loss": 0.0211,
      "step": 1854
    },
    {
      "epoch": 18.83,
      "learning_rate": 9.97911959018954e-05,
      "loss": 0.0192,
      "step": 1855
    },
    {
      "epoch": 18.84,
      "learning_rate": 9.979011055709549e-05,
      "loss": 0.0139,
      "step": 1856
    },
    {
      "epoch": 18.85,
      "learning_rate": 9.978902240477375e-05,
      "loss": 0.0039,
      "step": 1857
    },
    {
      "epoch": 18.86,
      "learning_rate": 9.97879314449915e-05,
      "loss": 0.0179,
      "step": 1858
    },
    {
      "epoch": 18.87,
      "learning_rate": 9.978683767781026e-05,
      "loss": 0.0191,
      "step": 1859
    },
    {
      "epoch": 18.88,
      "learning_rate": 9.978574110329173e-05,
      "loss": 0.03,
      "step": 1860
    },
    {
      "epoch": 18.89,
      "learning_rate": 9.978464172149772e-05,
      "loss": 0.0482,
      "step": 1861
    },
    {
      "epoch": 18.9,
      "learning_rate": 9.978353953249022e-05,
      "loss": 0.0361,
      "step": 1862
    },
    {
      "epoch": 18.91,
      "learning_rate": 9.97824345363314e-05,
      "loss": 0.0082,
      "step": 1863
    },
    {
      "epoch": 18.92,
      "learning_rate": 9.978132673308355e-05,
      "loss": 0.0132,
      "step": 1864
    },
    {
      "epoch": 18.93,
      "learning_rate": 9.978021612280914e-05,
      "loss": 0.0085,
      "step": 1865
    },
    {
      "epoch": 18.94,
      "learning_rate": 9.97791027055708e-05,
      "loss": 0.0063,
      "step": 1866
    },
    {
      "epoch": 18.95,
      "learning_rate": 9.97779864814313e-05,
      "loss": 0.0221,
      "step": 1867
    },
    {
      "epoch": 18.96,
      "learning_rate": 9.977686745045358e-05,
      "loss": 0.0331,
      "step": 1868
    },
    {
      "epoch": 18.97,
      "learning_rate": 9.977574561270076e-05,
      "loss": 0.0158,
      "step": 1869
    },
    {
      "epoch": 18.98,
      "learning_rate": 9.977462096823608e-05,
      "loss": 0.0213,
      "step": 1870
    },
    {
      "epoch": 18.99,
      "learning_rate": 9.977349351712296e-05,
      "loss": 0.0215,
      "step": 1871
    },
    {
      "epoch": 18.99,
      "eval_loss": 0.020280009135603905,
      "eval_runtime": 31.7681,
      "eval_samples_per_second": 99.156,
      "eval_steps_per_second": 6.201,
      "eval_wer": 0.010915492957746478,
      "step": 1871
    },
    {
      "epoch": 19.01,
      "learning_rate": 9.977236325942497e-05,
      "loss": 0.0317,
      "step": 1872
    },
    {
      "epoch": 19.02,
      "learning_rate": 9.977123019520585e-05,
      "loss": 0.0239,
      "step": 1873
    },
    {
      "epoch": 19.03,
      "learning_rate": 9.977009432452949e-05,
      "loss": 0.0266,
      "step": 1874
    },
    {
      "epoch": 19.04,
      "learning_rate": 9.976895564745991e-05,
      "loss": 0.008,
      "step": 1875
    },
    {
      "epoch": 19.05,
      "learning_rate": 9.976781416406136e-05,
      "loss": 0.01,
      "step": 1876
    },
    {
      "epoch": 19.06,
      "learning_rate": 9.976666987439817e-05,
      "loss": 0.0059,
      "step": 1877
    },
    {
      "epoch": 19.07,
      "learning_rate": 9.97655227785349e-05,
      "loss": 0.01,
      "step": 1878
    },
    {
      "epoch": 19.08,
      "learning_rate": 9.976437287653621e-05,
      "loss": 0.0081,
      "step": 1879
    },
    {
      "epoch": 19.09,
      "learning_rate": 9.976322016846693e-05,
      "loss": 0.008,
      "step": 1880
    },
    {
      "epoch": 19.1,
      "learning_rate": 9.976206465439207e-05,
      "loss": 0.0081,
      "step": 1881
    },
    {
      "epoch": 19.11,
      "learning_rate": 9.976090633437678e-05,
      "loss": 0.0301,
      "step": 1882
    },
    {
      "epoch": 19.12,
      "learning_rate": 9.975974520848637e-05,
      "loss": 0.0193,
      "step": 1883
    },
    {
      "epoch": 19.13,
      "learning_rate": 9.975858127678634e-05,
      "loss": 0.013,
      "step": 1884
    },
    {
      "epoch": 19.14,
      "learning_rate": 9.975741453934229e-05,
      "loss": 0.0186,
      "step": 1885
    },
    {
      "epoch": 19.15,
      "learning_rate": 9.975624499622003e-05,
      "loss": 0.0079,
      "step": 1886
    },
    {
      "epoch": 19.16,
      "learning_rate": 9.975507264748548e-05,
      "loss": 0.0164,
      "step": 1887
    },
    {
      "epoch": 19.17,
      "learning_rate": 9.975389749320477e-05,
      "loss": 0.0353,
      "step": 1888
    },
    {
      "epoch": 19.18,
      "learning_rate": 9.975271953344416e-05,
      "loss": 0.0657,
      "step": 1889
    },
    {
      "epoch": 19.19,
      "learning_rate": 9.975153876827008e-05,
      "loss": 0.0259,
      "step": 1890
    },
    {
      "epoch": 19.2,
      "learning_rate": 9.975035519774909e-05,
      "loss": 0.0231,
      "step": 1891
    },
    {
      "epoch": 19.21,
      "learning_rate": 9.974916882194793e-05,
      "loss": 0.008,
      "step": 1892
    },
    {
      "epoch": 19.22,
      "learning_rate": 9.97479796409335e-05,
      "loss": 0.0323,
      "step": 1893
    },
    {
      "epoch": 19.23,
      "learning_rate": 9.974678765477287e-05,
      "loss": 0.0197,
      "step": 1894
    },
    {
      "epoch": 19.24,
      "learning_rate": 9.974559286353324e-05,
      "loss": 0.0369,
      "step": 1895
    },
    {
      "epoch": 19.25,
      "learning_rate": 9.974439526728197e-05,
      "loss": 0.0063,
      "step": 1896
    },
    {
      "epoch": 19.26,
      "learning_rate": 9.974319486608662e-05,
      "loss": 0.0042,
      "step": 1897
    },
    {
      "epoch": 19.27,
      "learning_rate": 9.974199166001484e-05,
      "loss": 0.0023,
      "step": 1898
    },
    {
      "epoch": 19.28,
      "learning_rate": 9.974078564913448e-05,
      "loss": 0.0132,
      "step": 1899
    },
    {
      "epoch": 19.29,
      "learning_rate": 9.973957683351359e-05,
      "loss": 0.0041,
      "step": 1900
    },
    {
      "epoch": 19.3,
      "learning_rate": 9.973836521322026e-05,
      "loss": 0.0023,
      "step": 1901
    },
    {
      "epoch": 19.31,
      "learning_rate": 9.973715078832288e-05,
      "loss": 0.0201,
      "step": 1902
    },
    {
      "epoch": 19.32,
      "learning_rate": 9.973593355888988e-05,
      "loss": 0.0199,
      "step": 1903
    },
    {
      "epoch": 19.33,
      "learning_rate": 9.973471352498991e-05,
      "loss": 0.01,
      "step": 1904
    },
    {
      "epoch": 19.34,
      "learning_rate": 9.973349068669177e-05,
      "loss": 0.0312,
      "step": 1905
    },
    {
      "epoch": 19.35,
      "learning_rate": 9.973226504406441e-05,
      "loss": 0.0344,
      "step": 1906
    },
    {
      "epoch": 19.36,
      "learning_rate": 9.973103659717693e-05,
      "loss": 0.0226,
      "step": 1907
    },
    {
      "epoch": 19.37,
      "learning_rate": 9.972980534609861e-05,
      "loss": 0.0222,
      "step": 1908
    },
    {
      "epoch": 19.38,
      "learning_rate": 9.972857129089888e-05,
      "loss": 0.0216,
      "step": 1909
    },
    {
      "epoch": 19.39,
      "learning_rate": 9.972733443164732e-05,
      "loss": 0.0219,
      "step": 1910
    },
    {
      "epoch": 19.4,
      "learning_rate": 9.972609476841367e-05,
      "loss": 0.0051,
      "step": 1911
    },
    {
      "epoch": 19.41,
      "learning_rate": 9.972485230126783e-05,
      "loss": 0.0186,
      "step": 1912
    },
    {
      "epoch": 19.42,
      "learning_rate": 9.972360703027986e-05,
      "loss": 0.0212,
      "step": 1913
    },
    {
      "epoch": 19.43,
      "learning_rate": 9.972235895551999e-05,
      "loss": 0.0241,
      "step": 1914
    },
    {
      "epoch": 19.44,
      "learning_rate": 9.972110807705858e-05,
      "loss": 0.0091,
      "step": 1915
    },
    {
      "epoch": 19.45,
      "learning_rate": 9.971985439496617e-05,
      "loss": 0.0442,
      "step": 1916
    },
    {
      "epoch": 19.46,
      "learning_rate": 9.971859790931343e-05,
      "loss": 0.0223,
      "step": 1917
    },
    {
      "epoch": 19.47,
      "learning_rate": 9.971733862017126e-05,
      "loss": 0.0061,
      "step": 1918
    },
    {
      "epoch": 19.48,
      "learning_rate": 9.971607652761062e-05,
      "loss": 0.0523,
      "step": 1919
    },
    {
      "epoch": 19.49,
      "learning_rate": 9.971481163170268e-05,
      "loss": 0.028,
      "step": 1920
    },
    {
      "epoch": 19.5,
      "learning_rate": 9.971354393251879e-05,
      "loss": 0.006,
      "step": 1921
    },
    {
      "epoch": 19.51,
      "learning_rate": 9.971227343013042e-05,
      "loss": 0.0464,
      "step": 1922
    },
    {
      "epoch": 19.52,
      "learning_rate": 9.971100012460921e-05,
      "loss": 0.0153,
      "step": 1923
    },
    {
      "epoch": 19.53,
      "learning_rate": 9.970972401602696e-05,
      "loss": 0.005,
      "step": 1924
    },
    {
      "epoch": 19.54,
      "learning_rate": 9.97084451044556e-05,
      "loss": 0.0146,
      "step": 1925
    },
    {
      "epoch": 19.55,
      "learning_rate": 9.97071633899673e-05,
      "loss": 0.0266,
      "step": 1926
    },
    {
      "epoch": 19.56,
      "learning_rate": 9.970587887263428e-05,
      "loss": 0.0153,
      "step": 1927
    },
    {
      "epoch": 19.57,
      "learning_rate": 9.970459155252899e-05,
      "loss": 0.0063,
      "step": 1928
    },
    {
      "epoch": 19.58,
      "learning_rate": 9.970330142972401e-05,
      "loss": 0.0037,
      "step": 1929
    },
    {
      "epoch": 19.59,
      "learning_rate": 9.970200850429211e-05,
      "loss": 0.0031,
      "step": 1930
    },
    {
      "epoch": 19.6,
      "learning_rate": 9.970071277630617e-05,
      "loss": 0.0032,
      "step": 1931
    },
    {
      "epoch": 19.61,
      "learning_rate": 9.969941424583926e-05,
      "loss": 0.0125,
      "step": 1932
    },
    {
      "epoch": 19.62,
      "learning_rate": 9.96981129129646e-05,
      "loss": 0.0155,
      "step": 1933
    },
    {
      "epoch": 19.63,
      "learning_rate": 9.969680877775559e-05,
      "loss": 0.0415,
      "step": 1934
    },
    {
      "epoch": 19.64,
      "learning_rate": 9.969550184028572e-05,
      "loss": 0.0215,
      "step": 1935
    },
    {
      "epoch": 19.65,
      "learning_rate": 9.969419210062871e-05,
      "loss": 0.0239,
      "step": 1936
    },
    {
      "epoch": 19.66,
      "learning_rate": 9.969287955885844e-05,
      "loss": 0.0059,
      "step": 1937
    },
    {
      "epoch": 19.68,
      "learning_rate": 9.969156421504887e-05,
      "loss": 0.0281,
      "step": 1938
    },
    {
      "epoch": 19.69,
      "learning_rate": 9.96902460692742e-05,
      "loss": 0.0239,
      "step": 1939
    },
    {
      "epoch": 19.7,
      "learning_rate": 9.968892512160874e-05,
      "loss": 0.0096,
      "step": 1940
    },
    {
      "epoch": 19.71,
      "learning_rate": 9.968760137212699e-05,
      "loss": 0.0035,
      "step": 1941
    },
    {
      "epoch": 19.72,
      "learning_rate": 9.968627482090358e-05,
      "loss": 0.0367,
      "step": 1942
    },
    {
      "epoch": 19.73,
      "learning_rate": 9.968494546801332e-05,
      "loss": 0.0297,
      "step": 1943
    },
    {
      "epoch": 19.74,
      "learning_rate": 9.968361331353117e-05,
      "loss": 0.0107,
      "step": 1944
    },
    {
      "epoch": 19.75,
      "learning_rate": 9.968227835753223e-05,
      "loss": 0.0024,
      "step": 1945
    },
    {
      "epoch": 19.76,
      "learning_rate": 9.96809406000918e-05,
      "loss": 0.0197,
      "step": 1946
    },
    {
      "epoch": 19.77,
      "learning_rate": 9.967960004128529e-05,
      "loss": 0.0373,
      "step": 1947
    },
    {
      "epoch": 19.78,
      "learning_rate": 9.967825668118828e-05,
      "loss": 0.0062,
      "step": 1948
    },
    {
      "epoch": 19.79,
      "learning_rate": 9.967691051987655e-05,
      "loss": 0.0291,
      "step": 1949
    },
    {
      "epoch": 19.8,
      "learning_rate": 9.9675561557426e-05,
      "loss": 0.0176,
      "step": 1950
    },
    {
      "epoch": 19.81,
      "learning_rate": 9.967420979391268e-05,
      "loss": 0.0211,
      "step": 1951
    },
    {
      "epoch": 19.82,
      "learning_rate": 9.96728552294128e-05,
      "loss": 0.0083,
      "step": 1952
    },
    {
      "epoch": 19.83,
      "learning_rate": 9.967149786400278e-05,
      "loss": 0.017,
      "step": 1953
    },
    {
      "epoch": 19.84,
      "learning_rate": 9.967013769775913e-05,
      "loss": 0.0096,
      "step": 1954
    },
    {
      "epoch": 19.85,
      "learning_rate": 9.966877473075856e-05,
      "loss": 0.0186,
      "step": 1955
    },
    {
      "epoch": 19.86,
      "learning_rate": 9.966740896307791e-05,
      "loss": 0.0057,
      "step": 1956
    },
    {
      "epoch": 19.87,
      "learning_rate": 9.966604039479419e-05,
      "loss": 0.0046,
      "step": 1957
    },
    {
      "epoch": 19.88,
      "learning_rate": 9.966466902598458e-05,
      "loss": 0.0369,
      "step": 1958
    },
    {
      "epoch": 19.89,
      "learning_rate": 9.966329485672641e-05,
      "loss": 0.018,
      "step": 1959
    },
    {
      "epoch": 19.9,
      "learning_rate": 9.966191788709716e-05,
      "loss": 0.0111,
      "step": 1960
    },
    {
      "epoch": 19.91,
      "learning_rate": 9.966053811717447e-05,
      "loss": 0.0095,
      "step": 1961
    },
    {
      "epoch": 19.92,
      "learning_rate": 9.965915554703614e-05,
      "loss": 0.0198,
      "step": 1962
    },
    {
      "epoch": 19.93,
      "learning_rate": 9.965777017676015e-05,
      "loss": 0.0129,
      "step": 1963
    },
    {
      "epoch": 19.94,
      "learning_rate": 9.965638200642458e-05,
      "loss": 0.018,
      "step": 1964
    },
    {
      "epoch": 19.95,
      "learning_rate": 9.965499103610774e-05,
      "loss": 0.0186,
      "step": 1965
    },
    {
      "epoch": 19.96,
      "learning_rate": 9.965359726588804e-05,
      "loss": 0.0104,
      "step": 1966
    },
    {
      "epoch": 19.97,
      "learning_rate": 9.965220069584409e-05,
      "loss": 0.0153,
      "step": 1967
    },
    {
      "epoch": 19.98,
      "learning_rate": 9.965080132605462e-05,
      "loss": 0.0091,
      "step": 1968
    },
    {
      "epoch": 19.99,
      "learning_rate": 9.964939915659854e-05,
      "loss": 0.0194,
      "step": 1969
    },
    {
      "epoch": 20.0,
      "learning_rate": 9.964799418755493e-05,
      "loss": 0.0222,
      "step": 1970
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.016809895634651184,
      "eval_runtime": 32.7203,
      "eval_samples_per_second": 96.271,
      "eval_steps_per_second": 6.021,
      "eval_wer": 0.008962868117797696,
      "step": 1970
    },
    {
      "epoch": 20.01,
      "learning_rate": 9.9646586419003e-05,
      "loss": 0.0078,
      "step": 1971
    },
    {
      "epoch": 20.02,
      "learning_rate": 9.964517585102212e-05,
      "loss": 0.0021,
      "step": 1972
    },
    {
      "epoch": 20.03,
      "learning_rate": 9.964376248369185e-05,
      "loss": 0.0148,
      "step": 1973
    },
    {
      "epoch": 20.04,
      "learning_rate": 9.964234631709187e-05,
      "loss": 0.0121,
      "step": 1974
    },
    {
      "epoch": 20.05,
      "learning_rate": 9.964092735130203e-05,
      "loss": 0.0132,
      "step": 1975
    },
    {
      "epoch": 20.06,
      "learning_rate": 9.963950558640237e-05,
      "loss": 0.0134,
      "step": 1976
    },
    {
      "epoch": 20.07,
      "learning_rate": 9.963808102247303e-05,
      "loss": 0.0242,
      "step": 1977
    },
    {
      "epoch": 20.08,
      "learning_rate": 9.963665365959434e-05,
      "loss": 0.0399,
      "step": 1978
    },
    {
      "epoch": 20.09,
      "learning_rate": 9.96352234978468e-05,
      "loss": 0.0103,
      "step": 1979
    },
    {
      "epoch": 20.1,
      "learning_rate": 9.963379053731103e-05,
      "loss": 0.0045,
      "step": 1980
    },
    {
      "epoch": 20.11,
      "learning_rate": 9.963235477806786e-05,
      "loss": 0.0219,
      "step": 1981
    },
    {
      "epoch": 20.12,
      "learning_rate": 9.963091622019823e-05,
      "loss": 0.0083,
      "step": 1982
    },
    {
      "epoch": 20.13,
      "learning_rate": 9.962947486378326e-05,
      "loss": 0.015,
      "step": 1983
    },
    {
      "epoch": 20.14,
      "learning_rate": 9.962803070890421e-05,
      "loss": 0.0292,
      "step": 1984
    },
    {
      "epoch": 20.15,
      "learning_rate": 9.962658375564254e-05,
      "loss": 0.0265,
      "step": 1985
    },
    {
      "epoch": 20.16,
      "learning_rate": 9.962513400407981e-05,
      "loss": 0.0064,
      "step": 1986
    },
    {
      "epoch": 20.17,
      "learning_rate": 9.96236814542978e-05,
      "loss": 0.0035,
      "step": 1987
    },
    {
      "epoch": 20.18,
      "learning_rate": 9.962222610637837e-05,
      "loss": 0.0141,
      "step": 1988
    },
    {
      "epoch": 20.19,
      "learning_rate": 9.962076796040363e-05,
      "loss": 0.0325,
      "step": 1989
    },
    {
      "epoch": 20.2,
      "learning_rate": 9.961930701645577e-05,
      "loss": 0.0281,
      "step": 1990
    },
    {
      "epoch": 20.21,
      "learning_rate": 9.961784327461719e-05,
      "loss": 0.0226,
      "step": 1991
    },
    {
      "epoch": 20.22,
      "learning_rate": 9.96163767349704e-05,
      "loss": 0.0038,
      "step": 1992
    },
    {
      "epoch": 20.23,
      "learning_rate": 9.961490739759811e-05,
      "loss": 0.0113,
      "step": 1993
    },
    {
      "epoch": 20.24,
      "learning_rate": 9.961343526258317e-05,
      "loss": 0.0858,
      "step": 1994
    },
    {
      "epoch": 20.25,
      "learning_rate": 9.961196033000861e-05,
      "loss": 0.009,
      "step": 1995
    },
    {
      "epoch": 20.26,
      "learning_rate": 9.961048259995756e-05,
      "loss": 0.0082,
      "step": 1996
    },
    {
      "epoch": 20.27,
      "learning_rate": 9.960900207251337e-05,
      "loss": 0.0231,
      "step": 1997
    },
    {
      "epoch": 20.28,
      "learning_rate": 9.960751874775951e-05,
      "loss": 0.0058,
      "step": 1998
    },
    {
      "epoch": 20.29,
      "learning_rate": 9.960603262577964e-05,
      "loss": 0.0294,
      "step": 1999
    },
    {
      "epoch": 20.3,
      "learning_rate": 9.960454370665751e-05,
      "loss": 0.0367,
      "step": 2000
    },
    {
      "epoch": 20.31,
      "learning_rate": 9.960305199047712e-05,
      "loss": 0.0196,
      "step": 2001
    },
    {
      "epoch": 20.32,
      "learning_rate": 9.960155747732259e-05,
      "loss": 0.0368,
      "step": 2002
    },
    {
      "epoch": 20.34,
      "learning_rate": 9.960006016727816e-05,
      "loss": 0.0105,
      "step": 2003
    },
    {
      "epoch": 20.35,
      "learning_rate": 9.95985600604283e-05,
      "loss": 0.0156,
      "step": 2004
    },
    {
      "epoch": 20.36,
      "learning_rate": 9.959705715685754e-05,
      "loss": 0.0208,
      "step": 2005
    },
    {
      "epoch": 20.37,
      "learning_rate": 9.959555145665067e-05,
      "loss": 0.007,
      "step": 2006
    },
    {
      "epoch": 20.38,
      "learning_rate": 9.959404295989257e-05,
      "loss": 0.0043,
      "step": 2007
    },
    {
      "epoch": 20.39,
      "learning_rate": 9.95925316666683e-05,
      "loss": 0.0336,
      "step": 2008
    },
    {
      "epoch": 20.4,
      "learning_rate": 9.959101757706308e-05,
      "loss": 0.0038,
      "step": 2009
    },
    {
      "epoch": 20.41,
      "learning_rate": 9.95895006911623e-05,
      "loss": 0.021,
      "step": 2010
    },
    {
      "epoch": 20.42,
      "learning_rate": 9.958798100905149e-05,
      "loss": 0.0167,
      "step": 2011
    },
    {
      "epoch": 20.43,
      "learning_rate": 9.958645853081634e-05,
      "loss": 0.0079,
      "step": 2012
    },
    {
      "epoch": 20.44,
      "learning_rate": 9.958493325654266e-05,
      "loss": 0.0281,
      "step": 2013
    },
    {
      "epoch": 20.45,
      "learning_rate": 9.95834051863165e-05,
      "loss": 0.0054,
      "step": 2014
    },
    {
      "epoch": 20.46,
      "learning_rate": 9.958187432022402e-05,
      "loss": 0.0164,
      "step": 2015
    },
    {
      "epoch": 20.47,
      "learning_rate": 9.958034065835151e-05,
      "loss": 0.0201,
      "step": 2016
    },
    {
      "epoch": 20.48,
      "learning_rate": 9.957880420078549e-05,
      "loss": 0.0183,
      "step": 2017
    },
    {
      "epoch": 20.49,
      "learning_rate": 9.957726494761257e-05,
      "loss": 0.0193,
      "step": 2018
    },
    {
      "epoch": 20.5,
      "learning_rate": 9.957572289891954e-05,
      "loss": 0.0047,
      "step": 2019
    },
    {
      "epoch": 20.51,
      "learning_rate": 9.957417805479338e-05,
      "loss": 0.0478,
      "step": 2020
    },
    {
      "epoch": 20.52,
      "learning_rate": 9.957263041532117e-05,
      "loss": 0.0164,
      "step": 2021
    },
    {
      "epoch": 20.53,
      "learning_rate": 9.957107998059018e-05,
      "loss": 0.0176,
      "step": 2022
    },
    {
      "epoch": 20.54,
      "learning_rate": 9.956952675068786e-05,
      "loss": 0.0182,
      "step": 2023
    },
    {
      "epoch": 20.55,
      "learning_rate": 9.956797072570178e-05,
      "loss": 0.0073,
      "step": 2024
    },
    {
      "epoch": 20.56,
      "learning_rate": 9.956641190571967e-05,
      "loss": 0.0127,
      "step": 2025
    },
    {
      "epoch": 20.57,
      "learning_rate": 9.956485029082943e-05,
      "loss": 0.0315,
      "step": 2026
    },
    {
      "epoch": 20.58,
      "learning_rate": 9.95632858811191e-05,
      "loss": 0.0085,
      "step": 2027
    },
    {
      "epoch": 20.59,
      "learning_rate": 9.956171867667694e-05,
      "loss": 0.0059,
      "step": 2028
    },
    {
      "epoch": 20.6,
      "learning_rate": 9.956014867759126e-05,
      "loss": 0.0094,
      "step": 2029
    },
    {
      "epoch": 20.61,
      "learning_rate": 9.955857588395065e-05,
      "loss": 0.0403,
      "step": 2030
    },
    {
      "epoch": 20.62,
      "learning_rate": 9.955700029584374e-05,
      "loss": 0.0179,
      "step": 2031
    },
    {
      "epoch": 20.63,
      "learning_rate": 9.95554219133594e-05,
      "loss": 0.0087,
      "step": 2032
    },
    {
      "epoch": 20.64,
      "learning_rate": 9.955384073658663e-05,
      "loss": 0.0097,
      "step": 2033
    },
    {
      "epoch": 20.65,
      "learning_rate": 9.955225676561459e-05,
      "loss": 0.0187,
      "step": 2034
    },
    {
      "epoch": 20.66,
      "learning_rate": 9.955067000053257e-05,
      "loss": 0.0339,
      "step": 2035
    },
    {
      "epoch": 20.67,
      "learning_rate": 9.954908044143009e-05,
      "loss": 0.0162,
      "step": 2036
    },
    {
      "epoch": 20.68,
      "learning_rate": 9.954748808839674e-05,
      "loss": 0.0169,
      "step": 2037
    },
    {
      "epoch": 20.69,
      "learning_rate": 9.954589294152233e-05,
      "loss": 0.0176,
      "step": 2038
    },
    {
      "epoch": 20.7,
      "learning_rate": 9.954429500089679e-05,
      "loss": 0.02,
      "step": 2039
    },
    {
      "epoch": 20.71,
      "learning_rate": 9.954269426661024e-05,
      "loss": 0.0139,
      "step": 2040
    },
    {
      "epoch": 20.72,
      "learning_rate": 9.954109073875292e-05,
      "loss": 0.0079,
      "step": 2041
    },
    {
      "epoch": 20.73,
      "learning_rate": 9.953948441741528e-05,
      "loss": 0.0894,
      "step": 2042
    },
    {
      "epoch": 20.74,
      "learning_rate": 9.953787530268785e-05,
      "loss": 0.0285,
      "step": 2043
    },
    {
      "epoch": 20.75,
      "learning_rate": 9.95362633946614e-05,
      "loss": 0.0236,
      "step": 2044
    },
    {
      "epoch": 20.76,
      "learning_rate": 9.953464869342683e-05,
      "loss": 0.0263,
      "step": 2045
    },
    {
      "epoch": 20.77,
      "learning_rate": 9.953303119907514e-05,
      "loss": 0.0056,
      "step": 2046
    },
    {
      "epoch": 20.78,
      "learning_rate": 9.953141091169759e-05,
      "loss": 0.0114,
      "step": 2047
    },
    {
      "epoch": 20.79,
      "learning_rate": 9.95297878313855e-05,
      "loss": 0.0148,
      "step": 2048
    },
    {
      "epoch": 20.8,
      "learning_rate": 9.952816195823042e-05,
      "loss": 0.0088,
      "step": 2049
    },
    {
      "epoch": 20.81,
      "learning_rate": 9.952653329232402e-05,
      "loss": 0.0475,
      "step": 2050
    },
    {
      "epoch": 20.82,
      "learning_rate": 9.952490183375812e-05,
      "loss": 0.0257,
      "step": 2051
    },
    {
      "epoch": 20.83,
      "learning_rate": 9.952326758262473e-05,
      "loss": 0.0124,
      "step": 2052
    },
    {
      "epoch": 20.84,
      "learning_rate": 9.9521630539016e-05,
      "loss": 0.0194,
      "step": 2053
    },
    {
      "epoch": 20.85,
      "learning_rate": 9.951999070302425e-05,
      "loss": 0.0228,
      "step": 2054
    },
    {
      "epoch": 20.86,
      "learning_rate": 9.951834807474191e-05,
      "loss": 0.0405,
      "step": 2055
    },
    {
      "epoch": 20.87,
      "learning_rate": 9.951670265426163e-05,
      "loss": 0.0245,
      "step": 2056
    },
    {
      "epoch": 20.88,
      "learning_rate": 9.95150544416762e-05,
      "loss": 0.0356,
      "step": 2057
    },
    {
      "epoch": 20.89,
      "learning_rate": 9.951340343707852e-05,
      "loss": 0.0103,
      "step": 2058
    },
    {
      "epoch": 20.9,
      "learning_rate": 9.951174964056172e-05,
      "loss": 0.0199,
      "step": 2059
    },
    {
      "epoch": 20.91,
      "learning_rate": 9.951009305221903e-05,
      "loss": 0.0179,
      "step": 2060
    },
    {
      "epoch": 20.92,
      "learning_rate": 9.950843367214389e-05,
      "loss": 0.0233,
      "step": 2061
    },
    {
      "epoch": 20.93,
      "learning_rate": 9.950677150042984e-05,
      "loss": 0.0253,
      "step": 2062
    },
    {
      "epoch": 20.94,
      "learning_rate": 9.950510653717062e-05,
      "loss": 0.0144,
      "step": 2063
    },
    {
      "epoch": 20.95,
      "learning_rate": 9.95034387824601e-05,
      "loss": 0.0276,
      "step": 2064
    },
    {
      "epoch": 20.96,
      "learning_rate": 9.950176823639233e-05,
      "loss": 0.0401,
      "step": 2065
    },
    {
      "epoch": 20.97,
      "learning_rate": 9.950009489906149e-05,
      "loss": 0.027,
      "step": 2066
    },
    {
      "epoch": 20.98,
      "learning_rate": 9.949841877056196e-05,
      "loss": 0.0469,
      "step": 2067
    },
    {
      "epoch": 20.99,
      "learning_rate": 9.949673985098825e-05,
      "loss": 0.0309,
      "step": 2068
    },
    {
      "epoch": 20.99,
      "eval_loss": 0.014789811335504055,
      "eval_runtime": 32.1785,
      "eval_samples_per_second": 97.892,
      "eval_steps_per_second": 6.122,
      "eval_wer": 0.008258642765685019,
      "step": 2068
    },
    {
      "epoch": 21.01,
      "learning_rate": 9.949505814043502e-05,
      "loss": 0.0212,
      "step": 2069
    },
    {
      "epoch": 21.02,
      "learning_rate": 9.949337363899709e-05,
      "loss": 0.0044,
      "step": 2070
    },
    {
      "epoch": 21.03,
      "learning_rate": 9.949168634676944e-05,
      "loss": 0.0332,
      "step": 2071
    },
    {
      "epoch": 21.04,
      "learning_rate": 9.948999626384724e-05,
      "loss": 0.0185,
      "step": 2072
    },
    {
      "epoch": 21.05,
      "learning_rate": 9.948830339032577e-05,
      "loss": 0.0095,
      "step": 2073
    },
    {
      "epoch": 21.06,
      "learning_rate": 9.948660772630048e-05,
      "loss": 0.0044,
      "step": 2074
    },
    {
      "epoch": 21.07,
      "learning_rate": 9.9484909271867e-05,
      "loss": 0.011,
      "step": 2075
    },
    {
      "epoch": 21.08,
      "learning_rate": 9.948320802712108e-05,
      "loss": 0.0317,
      "step": 2076
    },
    {
      "epoch": 21.09,
      "learning_rate": 9.948150399215868e-05,
      "loss": 0.0308,
      "step": 2077
    },
    {
      "epoch": 21.1,
      "learning_rate": 9.947979716707585e-05,
      "loss": 0.0129,
      "step": 2078
    },
    {
      "epoch": 21.11,
      "learning_rate": 9.947808755196886e-05,
      "loss": 0.0213,
      "step": 2079
    },
    {
      "epoch": 21.12,
      "learning_rate": 9.947637514693409e-05,
      "loss": 0.0214,
      "step": 2080
    },
    {
      "epoch": 21.13,
      "learning_rate": 9.947465995206811e-05,
      "loss": 0.0357,
      "step": 2081
    },
    {
      "epoch": 21.14,
      "learning_rate": 9.947294196746764e-05,
      "loss": 0.0081,
      "step": 2082
    },
    {
      "epoch": 21.15,
      "learning_rate": 9.947122119322954e-05,
      "loss": 0.0191,
      "step": 2083
    },
    {
      "epoch": 21.16,
      "learning_rate": 9.946949762945084e-05,
      "loss": 0.024,
      "step": 2084
    },
    {
      "epoch": 21.17,
      "learning_rate": 9.946777127622874e-05,
      "loss": 0.008,
      "step": 2085
    },
    {
      "epoch": 21.18,
      "learning_rate": 9.946604213366057e-05,
      "loss": 0.0282,
      "step": 2086
    },
    {
      "epoch": 21.19,
      "learning_rate": 9.946431020184383e-05,
      "loss": 0.0156,
      "step": 2087
    },
    {
      "epoch": 21.2,
      "learning_rate": 9.946257548087621e-05,
      "loss": 0.0041,
      "step": 2088
    },
    {
      "epoch": 21.21,
      "learning_rate": 9.946083797085548e-05,
      "loss": 0.0243,
      "step": 2089
    },
    {
      "epoch": 21.22,
      "learning_rate": 9.945909767187964e-05,
      "loss": 0.0339,
      "step": 2090
    },
    {
      "epoch": 21.23,
      "learning_rate": 9.945735458404681e-05,
      "loss": 0.0209,
      "step": 2091
    },
    {
      "epoch": 21.24,
      "learning_rate": 9.945560870745529e-05,
      "loss": 0.0322,
      "step": 2092
    },
    {
      "epoch": 21.25,
      "learning_rate": 9.945386004220352e-05,
      "loss": 0.0295,
      "step": 2093
    },
    {
      "epoch": 21.26,
      "learning_rate": 9.945210858839009e-05,
      "loss": 0.0039,
      "step": 2094
    },
    {
      "epoch": 21.27,
      "learning_rate": 9.945035434611379e-05,
      "loss": 0.0093,
      "step": 2095
    },
    {
      "epoch": 21.28,
      "learning_rate": 9.944859731547349e-05,
      "loss": 0.0019,
      "step": 2096
    },
    {
      "epoch": 21.29,
      "learning_rate": 9.944683749656831e-05,
      "loss": 0.0049,
      "step": 2097
    },
    {
      "epoch": 21.3,
      "learning_rate": 9.944507488949743e-05,
      "loss": 0.007,
      "step": 2098
    },
    {
      "epoch": 21.31,
      "learning_rate": 9.94433094943603e-05,
      "loss": 0.0036,
      "step": 2099
    },
    {
      "epoch": 21.32,
      "learning_rate": 9.944154131125642e-05,
      "loss": 0.0261,
      "step": 2100
    },
    {
      "epoch": 21.33,
      "learning_rate": 9.943977034028553e-05,
      "loss": 0.0102,
      "step": 2101
    },
    {
      "epoch": 21.34,
      "learning_rate": 9.943799658154745e-05,
      "loss": 0.0044,
      "step": 2102
    },
    {
      "epoch": 21.35,
      "learning_rate": 9.943622003514221e-05,
      "loss": 0.0132,
      "step": 2103
    },
    {
      "epoch": 21.36,
      "learning_rate": 9.943444070117001e-05,
      "loss": 0.0035,
      "step": 2104
    },
    {
      "epoch": 21.37,
      "learning_rate": 9.943265857973115e-05,
      "loss": 0.0052,
      "step": 2105
    },
    {
      "epoch": 21.38,
      "learning_rate": 9.943087367092612e-05,
      "loss": 0.0174,
      "step": 2106
    },
    {
      "epoch": 21.39,
      "learning_rate": 9.942908597485558e-05,
      "loss": 0.0048,
      "step": 2107
    },
    {
      "epoch": 21.4,
      "learning_rate": 9.942729549162034e-05,
      "loss": 0.0057,
      "step": 2108
    },
    {
      "epoch": 21.41,
      "learning_rate": 9.942550222132134e-05,
      "loss": 0.0136,
      "step": 2109
    },
    {
      "epoch": 21.42,
      "learning_rate": 9.942370616405972e-05,
      "loss": 0.0241,
      "step": 2110
    },
    {
      "epoch": 21.43,
      "learning_rate": 9.942190731993672e-05,
      "loss": 0.0125,
      "step": 2111
    },
    {
      "epoch": 21.44,
      "learning_rate": 9.94201056890538e-05,
      "loss": 0.0223,
      "step": 2112
    },
    {
      "epoch": 21.45,
      "learning_rate": 9.941830127151255e-05,
      "loss": 0.0255,
      "step": 2113
    },
    {
      "epoch": 21.46,
      "learning_rate": 9.941649406741469e-05,
      "loss": 0.017,
      "step": 2114
    },
    {
      "epoch": 21.47,
      "learning_rate": 9.941468407686217e-05,
      "loss": 0.0219,
      "step": 2115
    },
    {
      "epoch": 21.48,
      "learning_rate": 9.941287129995699e-05,
      "loss": 0.032,
      "step": 2116
    },
    {
      "epoch": 21.49,
      "learning_rate": 9.94110557368014e-05,
      "loss": 0.0245,
      "step": 2117
    },
    {
      "epoch": 21.5,
      "learning_rate": 9.940923738749778e-05,
      "loss": 0.009,
      "step": 2118
    },
    {
      "epoch": 21.51,
      "learning_rate": 9.940741625214867e-05,
      "loss": 0.0126,
      "step": 2119
    },
    {
      "epoch": 21.52,
      "learning_rate": 9.940559233085673e-05,
      "loss": 0.0099,
      "step": 2120
    },
    {
      "epoch": 21.53,
      "learning_rate": 9.940376562372482e-05,
      "loss": 0.0083,
      "step": 2121
    },
    {
      "epoch": 21.54,
      "learning_rate": 9.940193613085593e-05,
      "loss": 0.0348,
      "step": 2122
    },
    {
      "epoch": 21.55,
      "learning_rate": 9.940010385235323e-05,
      "loss": 0.0306,
      "step": 2123
    },
    {
      "epoch": 21.56,
      "learning_rate": 9.939826878832005e-05,
      "loss": 0.009,
      "step": 2124
    },
    {
      "epoch": 21.57,
      "learning_rate": 9.939643093885984e-05,
      "loss": 0.0118,
      "step": 2125
    },
    {
      "epoch": 21.58,
      "learning_rate": 9.939459030407625e-05,
      "loss": 0.0221,
      "step": 2126
    },
    {
      "epoch": 21.59,
      "learning_rate": 9.939274688407308e-05,
      "loss": 0.0114,
      "step": 2127
    },
    {
      "epoch": 21.6,
      "learning_rate": 9.939090067895422e-05,
      "loss": 0.0078,
      "step": 2128
    },
    {
      "epoch": 21.61,
      "learning_rate": 9.938905168882383e-05,
      "loss": 0.0104,
      "step": 2129
    },
    {
      "epoch": 21.62,
      "learning_rate": 9.938719991378614e-05,
      "loss": 0.0056,
      "step": 2130
    },
    {
      "epoch": 21.63,
      "learning_rate": 9.938534535394558e-05,
      "loss": 0.014,
      "step": 2131
    },
    {
      "epoch": 21.64,
      "learning_rate": 9.938348800940671e-05,
      "loss": 0.0274,
      "step": 2132
    },
    {
      "epoch": 21.65,
      "learning_rate": 9.938162788027428e-05,
      "loss": 0.0234,
      "step": 2133
    },
    {
      "epoch": 21.66,
      "learning_rate": 9.937976496665316e-05,
      "loss": 0.026,
      "step": 2134
    },
    {
      "epoch": 21.68,
      "learning_rate": 9.937789926864838e-05,
      "loss": 0.0181,
      "step": 2135
    },
    {
      "epoch": 21.69,
      "learning_rate": 9.937603078636518e-05,
      "loss": 0.0099,
      "step": 2136
    },
    {
      "epoch": 21.7,
      "learning_rate": 9.93741595199089e-05,
      "loss": 0.0166,
      "step": 2137
    },
    {
      "epoch": 21.71,
      "learning_rate": 9.937228546938504e-05,
      "loss": 0.0214,
      "step": 2138
    },
    {
      "epoch": 21.72,
      "learning_rate": 9.937040863489931e-05,
      "loss": 0.0143,
      "step": 2139
    },
    {
      "epoch": 21.73,
      "learning_rate": 9.936852901655749e-05,
      "loss": 0.0323,
      "step": 2140
    },
    {
      "epoch": 21.74,
      "learning_rate": 9.936664661446561e-05,
      "loss": 0.003,
      "step": 2141
    },
    {
      "epoch": 21.75,
      "learning_rate": 9.936476142872979e-05,
      "loss": 0.0072,
      "step": 2142
    },
    {
      "epoch": 21.76,
      "learning_rate": 9.936287345945634e-05,
      "loss": 0.0027,
      "step": 2143
    },
    {
      "epoch": 21.77,
      "learning_rate": 9.93609827067517e-05,
      "loss": 0.0047,
      "step": 2144
    },
    {
      "epoch": 21.78,
      "learning_rate": 9.935908917072252e-05,
      "loss": 0.0124,
      "step": 2145
    },
    {
      "epoch": 21.79,
      "learning_rate": 9.935719285147553e-05,
      "loss": 0.0433,
      "step": 2146
    },
    {
      "epoch": 21.8,
      "learning_rate": 9.935529374911767e-05,
      "loss": 0.0105,
      "step": 2147
    },
    {
      "epoch": 21.81,
      "learning_rate": 9.935339186375605e-05,
      "loss": 0.0166,
      "step": 2148
    },
    {
      "epoch": 21.82,
      "learning_rate": 9.935148719549788e-05,
      "loss": 0.0197,
      "step": 2149
    },
    {
      "epoch": 21.83,
      "learning_rate": 9.934957974445058e-05,
      "loss": 0.0353,
      "step": 2150
    },
    {
      "epoch": 21.84,
      "learning_rate": 9.934766951072169e-05,
      "loss": 0.02,
      "step": 2151
    },
    {
      "epoch": 21.85,
      "learning_rate": 9.934575649441894e-05,
      "loss": 0.0128,
      "step": 2152
    },
    {
      "epoch": 21.86,
      "learning_rate": 9.93438406956502e-05,
      "loss": 0.0095,
      "step": 2153
    },
    {
      "epoch": 21.87,
      "learning_rate": 9.934192211452346e-05,
      "loss": 0.0228,
      "step": 2154
    },
    {
      "epoch": 21.88,
      "learning_rate": 9.934000075114693e-05,
      "loss": 0.0216,
      "step": 2155
    },
    {
      "epoch": 21.89,
      "learning_rate": 9.933807660562898e-05,
      "loss": 0.0216,
      "step": 2156
    },
    {
      "epoch": 21.9,
      "learning_rate": 9.933614967807804e-05,
      "loss": 0.0183,
      "step": 2157
    },
    {
      "epoch": 21.91,
      "learning_rate": 9.933421996860282e-05,
      "loss": 0.0148,
      "step": 2158
    },
    {
      "epoch": 21.92,
      "learning_rate": 9.93322874773121e-05,
      "loss": 0.0245,
      "step": 2159
    },
    {
      "epoch": 21.93,
      "learning_rate": 9.933035220431488e-05,
      "loss": 0.0036,
      "step": 2160
    },
    {
      "epoch": 21.94,
      "learning_rate": 9.932841414972025e-05,
      "loss": 0.0209,
      "step": 2161
    },
    {
      "epoch": 21.95,
      "learning_rate": 9.932647331363749e-05,
      "loss": 0.0037,
      "step": 2162
    },
    {
      "epoch": 21.96,
      "learning_rate": 9.932452969617607e-05,
      "loss": 0.0275,
      "step": 2163
    },
    {
      "epoch": 21.97,
      "learning_rate": 9.932258329744556e-05,
      "loss": 0.015,
      "step": 2164
    },
    {
      "epoch": 21.98,
      "learning_rate": 9.932063411755575e-05,
      "loss": 0.0075,
      "step": 2165
    },
    {
      "epoch": 21.99,
      "learning_rate": 9.931868215661649e-05,
      "loss": 0.0072,
      "step": 2166
    },
    {
      "epoch": 22.0,
      "learning_rate": 9.931672741473787e-05,
      "loss": 0.0061,
      "step": 2167
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.01791045442223549,
      "eval_runtime": 32.0634,
      "eval_samples_per_second": 98.243,
      "eval_steps_per_second": 6.144,
      "eval_wer": 0.009795134443021767,
      "step": 2167
    },
    {
      "epoch": 22.01,
      "learning_rate": 9.931476989203012e-05,
      "loss": 0.0023,
      "step": 2168
    },
    {
      "epoch": 22.02,
      "learning_rate": 9.931280958860362e-05,
      "loss": 0.0104,
      "step": 2169
    },
    {
      "epoch": 22.03,
      "learning_rate": 9.931084650456892e-05,
      "loss": 0.0195,
      "step": 2170
    },
    {
      "epoch": 22.04,
      "learning_rate": 9.930888064003667e-05,
      "loss": 0.0125,
      "step": 2171
    },
    {
      "epoch": 22.05,
      "learning_rate": 9.930691199511775e-05,
      "loss": 0.022,
      "step": 2172
    },
    {
      "epoch": 22.06,
      "learning_rate": 9.930494056992317e-05,
      "loss": 0.0028,
      "step": 2173
    },
    {
      "epoch": 22.07,
      "learning_rate": 9.930296636456406e-05,
      "loss": 0.0146,
      "step": 2174
    },
    {
      "epoch": 22.08,
      "learning_rate": 9.930098937915178e-05,
      "loss": 0.0304,
      "step": 2175
    },
    {
      "epoch": 22.09,
      "learning_rate": 9.92990096137978e-05,
      "loss": 0.0254,
      "step": 2176
    },
    {
      "epoch": 22.1,
      "learning_rate": 9.929702706861373e-05,
      "loss": 0.0263,
      "step": 2177
    },
    {
      "epoch": 22.11,
      "learning_rate": 9.929504174371136e-05,
      "loss": 0.0306,
      "step": 2178
    },
    {
      "epoch": 22.12,
      "learning_rate": 9.929305363920264e-05,
      "loss": 0.0133,
      "step": 2179
    },
    {
      "epoch": 22.13,
      "learning_rate": 9.929106275519973e-05,
      "loss": 0.0053,
      "step": 2180
    },
    {
      "epoch": 22.14,
      "learning_rate": 9.928906909181481e-05,
      "loss": 0.0226,
      "step": 2181
    },
    {
      "epoch": 22.15,
      "learning_rate": 9.928707264916033e-05,
      "loss": 0.0183,
      "step": 2182
    },
    {
      "epoch": 22.16,
      "learning_rate": 9.928507342734887e-05,
      "loss": 0.0429,
      "step": 2183
    },
    {
      "epoch": 22.17,
      "learning_rate": 9.928307142649316e-05,
      "loss": 0.0078,
      "step": 2184
    },
    {
      "epoch": 22.18,
      "learning_rate": 9.928106664670607e-05,
      "loss": 0.0128,
      "step": 2185
    },
    {
      "epoch": 22.19,
      "learning_rate": 9.927905908810067e-05,
      "loss": 0.0216,
      "step": 2186
    },
    {
      "epoch": 22.2,
      "learning_rate": 9.927704875079013e-05,
      "loss": 0.0164,
      "step": 2187
    },
    {
      "epoch": 22.21,
      "learning_rate": 9.927503563488782e-05,
      "loss": 0.0247,
      "step": 2188
    },
    {
      "epoch": 22.22,
      "learning_rate": 9.927301974050727e-05,
      "loss": 0.0396,
      "step": 2189
    },
    {
      "epoch": 22.23,
      "learning_rate": 9.927100106776212e-05,
      "loss": 0.0324,
      "step": 2190
    },
    {
      "epoch": 22.24,
      "learning_rate": 9.926897961676624e-05,
      "loss": 0.0115,
      "step": 2191
    },
    {
      "epoch": 22.25,
      "learning_rate": 9.926695538763357e-05,
      "loss": 0.0259,
      "step": 2192
    },
    {
      "epoch": 22.26,
      "learning_rate": 9.926492838047828e-05,
      "loss": 0.0072,
      "step": 2193
    },
    {
      "epoch": 22.27,
      "learning_rate": 9.926289859541464e-05,
      "loss": 0.0084,
      "step": 2194
    },
    {
      "epoch": 22.28,
      "learning_rate": 9.926086603255713e-05,
      "loss": 0.0114,
      "step": 2195
    },
    {
      "epoch": 22.29,
      "learning_rate": 9.925883069202036e-05,
      "loss": 0.017,
      "step": 2196
    },
    {
      "epoch": 22.3,
      "learning_rate": 9.925679257391907e-05,
      "loss": 0.0024,
      "step": 2197
    },
    {
      "epoch": 22.31,
      "learning_rate": 9.925475167836821e-05,
      "loss": 0.0069,
      "step": 2198
    },
    {
      "epoch": 22.32,
      "learning_rate": 9.925270800548285e-05,
      "loss": 0.0591,
      "step": 2199
    },
    {
      "epoch": 22.34,
      "learning_rate": 9.925066155537821e-05,
      "loss": 0.0242,
      "step": 2200
    },
    {
      "epoch": 22.35,
      "learning_rate": 9.924861232816972e-05,
      "loss": 0.0148,
      "step": 2201
    },
    {
      "epoch": 22.36,
      "learning_rate": 9.924656032397291e-05,
      "loss": 0.0115,
      "step": 2202
    },
    {
      "epoch": 22.37,
      "learning_rate": 9.924450554290348e-05,
      "loss": 0.0045,
      "step": 2203
    },
    {
      "epoch": 22.38,
      "learning_rate": 9.924244798507731e-05,
      "loss": 0.0338,
      "step": 2204
    },
    {
      "epoch": 22.39,
      "learning_rate": 9.924038765061042e-05,
      "loss": 0.024,
      "step": 2205
    },
    {
      "epoch": 22.4,
      "learning_rate": 9.923832453961895e-05,
      "loss": 0.0101,
      "step": 2206
    },
    {
      "epoch": 22.41,
      "learning_rate": 9.923625865221928e-05,
      "loss": 0.0096,
      "step": 2207
    },
    {
      "epoch": 22.42,
      "learning_rate": 9.923418998852787e-05,
      "loss": 0.0362,
      "step": 2208
    },
    {
      "epoch": 22.43,
      "learning_rate": 9.923211854866138e-05,
      "loss": 0.0059,
      "step": 2209
    },
    {
      "epoch": 22.44,
      "learning_rate": 9.923004433273662e-05,
      "loss": 0.0061,
      "step": 2210
    },
    {
      "epoch": 22.45,
      "learning_rate": 9.922796734087052e-05,
      "loss": 0.0171,
      "step": 2211
    },
    {
      "epoch": 22.46,
      "learning_rate": 9.922588757318021e-05,
      "loss": 0.0066,
      "step": 2212
    },
    {
      "epoch": 22.47,
      "learning_rate": 9.922380502978298e-05,
      "loss": 0.0403,
      "step": 2213
    },
    {
      "epoch": 22.48,
      "learning_rate": 9.922171971079624e-05,
      "loss": 0.0243,
      "step": 2214
    },
    {
      "epoch": 22.49,
      "learning_rate": 9.921963161633757e-05,
      "loss": 0.0503,
      "step": 2215
    },
    {
      "epoch": 22.5,
      "learning_rate": 9.921754074652473e-05,
      "loss": 0.0243,
      "step": 2216
    },
    {
      "epoch": 22.51,
      "learning_rate": 9.921544710147561e-05,
      "loss": 0.0217,
      "step": 2217
    },
    {
      "epoch": 22.52,
      "learning_rate": 9.921335068130827e-05,
      "loss": 0.0505,
      "step": 2218
    },
    {
      "epoch": 22.53,
      "learning_rate": 9.921125148614088e-05,
      "loss": 0.0058,
      "step": 2219
    },
    {
      "epoch": 22.54,
      "learning_rate": 9.920914951609188e-05,
      "loss": 0.0058,
      "step": 2220
    },
    {
      "epoch": 22.55,
      "learning_rate": 9.920704477127973e-05,
      "loss": 0.0151,
      "step": 2221
    },
    {
      "epoch": 22.56,
      "learning_rate": 9.920493725182316e-05,
      "loss": 0.0271,
      "step": 2222
    },
    {
      "epoch": 22.57,
      "learning_rate": 9.920282695784097e-05,
      "loss": 0.0033,
      "step": 2223
    },
    {
      "epoch": 22.58,
      "learning_rate": 9.920071388945216e-05,
      "loss": 0.0338,
      "step": 2224
    },
    {
      "epoch": 22.59,
      "learning_rate": 9.919859804677591e-05,
      "loss": 0.0037,
      "step": 2225
    },
    {
      "epoch": 22.6,
      "learning_rate": 9.919647942993148e-05,
      "loss": 0.0239,
      "step": 2226
    },
    {
      "epoch": 22.61,
      "learning_rate": 9.919435803903839e-05,
      "loss": 0.0043,
      "step": 2227
    },
    {
      "epoch": 22.62,
      "learning_rate": 9.919223387421619e-05,
      "loss": 0.0131,
      "step": 2228
    },
    {
      "epoch": 22.63,
      "learning_rate": 9.91901069355847e-05,
      "loss": 0.013,
      "step": 2229
    },
    {
      "epoch": 22.64,
      "learning_rate": 9.918797722326385e-05,
      "loss": 0.0139,
      "step": 2230
    },
    {
      "epoch": 22.65,
      "learning_rate": 9.918584473737371e-05,
      "loss": 0.0048,
      "step": 2231
    },
    {
      "epoch": 22.66,
      "learning_rate": 9.918370947803455e-05,
      "loss": 0.0124,
      "step": 2232
    },
    {
      "epoch": 22.67,
      "learning_rate": 9.918157144536675e-05,
      "loss": 0.0204,
      "step": 2233
    },
    {
      "epoch": 22.68,
      "learning_rate": 9.917943063949088e-05,
      "loss": 0.0017,
      "step": 2234
    },
    {
      "epoch": 22.69,
      "learning_rate": 9.917728706052764e-05,
      "loss": 0.0213,
      "step": 2235
    },
    {
      "epoch": 22.7,
      "learning_rate": 9.917514070859792e-05,
      "loss": 0.0056,
      "step": 2236
    },
    {
      "epoch": 22.71,
      "learning_rate": 9.917299158382272e-05,
      "loss": 0.0224,
      "step": 2237
    },
    {
      "epoch": 22.72,
      "learning_rate": 9.917083968632325e-05,
      "loss": 0.0554,
      "step": 2238
    },
    {
      "epoch": 22.73,
      "learning_rate": 9.916868501622083e-05,
      "loss": 0.0467,
      "step": 2239
    },
    {
      "epoch": 22.74,
      "learning_rate": 9.916652757363698e-05,
      "loss": 0.022,
      "step": 2240
    },
    {
      "epoch": 22.75,
      "learning_rate": 9.916436735869333e-05,
      "loss": 0.0204,
      "step": 2241
    },
    {
      "epoch": 22.76,
      "learning_rate": 9.916220437151168e-05,
      "loss": 0.0078,
      "step": 2242
    },
    {
      "epoch": 22.77,
      "learning_rate": 9.916003861221402e-05,
      "loss": 0.0455,
      "step": 2243
    },
    {
      "epoch": 22.78,
      "learning_rate": 9.915787008092246e-05,
      "loss": 0.0129,
      "step": 2244
    },
    {
      "epoch": 22.79,
      "learning_rate": 9.915569877775927e-05,
      "loss": 0.0087,
      "step": 2245
    },
    {
      "epoch": 22.8,
      "learning_rate": 9.915352470284689e-05,
      "loss": 0.0067,
      "step": 2246
    },
    {
      "epoch": 22.81,
      "learning_rate": 9.915134785630791e-05,
      "loss": 0.004,
      "step": 2247
    },
    {
      "epoch": 22.82,
      "learning_rate": 9.914916823826508e-05,
      "loss": 0.0185,
      "step": 2248
    },
    {
      "epoch": 22.83,
      "learning_rate": 9.914698584884131e-05,
      "loss": 0.031,
      "step": 2249
    },
    {
      "epoch": 22.84,
      "learning_rate": 9.914480068815964e-05,
      "loss": 0.0017,
      "step": 2250
    },
    {
      "epoch": 22.85,
      "learning_rate": 9.914261275634329e-05,
      "loss": 0.0232,
      "step": 2251
    },
    {
      "epoch": 22.86,
      "learning_rate": 9.914042205351563e-05,
      "loss": 0.0089,
      "step": 2252
    },
    {
      "epoch": 22.87,
      "learning_rate": 9.91382285798002e-05,
      "loss": 0.0203,
      "step": 2253
    },
    {
      "epoch": 22.88,
      "learning_rate": 9.913603233532067e-05,
      "loss": 0.0055,
      "step": 2254
    },
    {
      "epoch": 22.89,
      "learning_rate": 9.913383332020089e-05,
      "loss": 0.0158,
      "step": 2255
    },
    {
      "epoch": 22.9,
      "learning_rate": 9.913163153456483e-05,
      "loss": 0.0138,
      "step": 2256
    },
    {
      "epoch": 22.91,
      "learning_rate": 9.91294269785367e-05,
      "loss": 0.0295,
      "step": 2257
    },
    {
      "epoch": 22.92,
      "learning_rate": 9.912721965224075e-05,
      "loss": 0.0032,
      "step": 2258
    },
    {
      "epoch": 22.93,
      "learning_rate": 9.912500955580146e-05,
      "loss": 0.0045,
      "step": 2259
    },
    {
      "epoch": 22.94,
      "learning_rate": 9.912279668934346e-05,
      "loss": 0.0156,
      "step": 2260
    },
    {
      "epoch": 22.95,
      "learning_rate": 9.912058105299153e-05,
      "loss": 0.0298,
      "step": 2261
    },
    {
      "epoch": 22.96,
      "learning_rate": 9.91183626468706e-05,
      "loss": 0.0452,
      "step": 2262
    },
    {
      "epoch": 22.97,
      "learning_rate": 9.911614147110578e-05,
      "loss": 0.0105,
      "step": 2263
    },
    {
      "epoch": 22.98,
      "learning_rate": 9.911391752582226e-05,
      "loss": 0.0015,
      "step": 2264
    },
    {
      "epoch": 22.99,
      "learning_rate": 9.911169081114549e-05,
      "loss": 0.0276,
      "step": 2265
    },
    {
      "epoch": 22.99,
      "eval_loss": 0.01702396757900715,
      "eval_runtime": 31.7661,
      "eval_samples_per_second": 99.162,
      "eval_steps_per_second": 6.202,
      "eval_wer": 0.0067541613316261205,
      "step": 2265
    },
    {
      "epoch": 23.01,
      "learning_rate": 9.9109461327201e-05,
      "loss": 0.0059,
      "step": 2266
    },
    {
      "epoch": 23.02,
      "learning_rate": 9.910722907411453e-05,
      "loss": 0.0046,
      "step": 2267
    },
    {
      "epoch": 23.03,
      "learning_rate": 9.910499405201195e-05,
      "loss": 0.0018,
      "step": 2268
    },
    {
      "epoch": 23.04,
      "learning_rate": 9.910275626101926e-05,
      "loss": 0.0205,
      "step": 2269
    },
    {
      "epoch": 23.05,
      "learning_rate": 9.910051570126267e-05,
      "loss": 0.0212,
      "step": 2270
    },
    {
      "epoch": 23.06,
      "learning_rate": 9.909827237286849e-05,
      "loss": 0.014,
      "step": 2271
    },
    {
      "epoch": 23.07,
      "learning_rate": 9.909602627596325e-05,
      "loss": 0.01,
      "step": 2272
    },
    {
      "epoch": 23.08,
      "learning_rate": 9.909377741067356e-05,
      "loss": 0.0017,
      "step": 2273
    },
    {
      "epoch": 23.09,
      "learning_rate": 9.909152577712625e-05,
      "loss": 0.0236,
      "step": 2274
    },
    {
      "epoch": 23.1,
      "learning_rate": 9.90892713754483e-05,
      "loss": 0.0124,
      "step": 2275
    },
    {
      "epoch": 23.11,
      "learning_rate": 9.908701420576681e-05,
      "loss": 0.0195,
      "step": 2276
    },
    {
      "epoch": 23.12,
      "learning_rate": 9.908475426820904e-05,
      "loss": 0.0161,
      "step": 2277
    },
    {
      "epoch": 23.13,
      "learning_rate": 9.908249156290244e-05,
      "loss": 0.0225,
      "step": 2278
    },
    {
      "epoch": 23.14,
      "learning_rate": 9.90802260899746e-05,
      "loss": 0.0054,
      "step": 2279
    },
    {
      "epoch": 23.15,
      "learning_rate": 9.907795784955327e-05,
      "loss": 0.0091,
      "step": 2280
    },
    {
      "epoch": 23.16,
      "learning_rate": 9.907568684176633e-05,
      "loss": 0.0127,
      "step": 2281
    },
    {
      "epoch": 23.17,
      "learning_rate": 9.907341306674185e-05,
      "loss": 0.0291,
      "step": 2282
    },
    {
      "epoch": 23.18,
      "learning_rate": 9.907113652460804e-05,
      "loss": 0.0318,
      "step": 2283
    },
    {
      "epoch": 23.19,
      "learning_rate": 9.906885721549324e-05,
      "loss": 0.0446,
      "step": 2284
    },
    {
      "epoch": 23.2,
      "learning_rate": 9.906657513952601e-05,
      "loss": 0.0277,
      "step": 2285
    },
    {
      "epoch": 23.21,
      "learning_rate": 9.906429029683504e-05,
      "loss": 0.0065,
      "step": 2286
    },
    {
      "epoch": 23.22,
      "learning_rate": 9.906200268754913e-05,
      "loss": 0.0036,
      "step": 2287
    },
    {
      "epoch": 23.23,
      "learning_rate": 9.905971231179728e-05,
      "loss": 0.0028,
      "step": 2288
    },
    {
      "epoch": 23.24,
      "learning_rate": 9.905741916970864e-05,
      "loss": 0.0182,
      "step": 2289
    },
    {
      "epoch": 23.25,
      "learning_rate": 9.90551232614125e-05,
      "loss": 0.0198,
      "step": 2290
    },
    {
      "epoch": 23.26,
      "learning_rate": 9.905282458703837e-05,
      "loss": 0.0061,
      "step": 2291
    },
    {
      "epoch": 23.27,
      "learning_rate": 9.905052314671582e-05,
      "loss": 0.0037,
      "step": 2292
    },
    {
      "epoch": 23.28,
      "learning_rate": 9.904821894057463e-05,
      "loss": 0.0028,
      "step": 2293
    },
    {
      "epoch": 23.29,
      "learning_rate": 9.904591196874473e-05,
      "loss": 0.0098,
      "step": 2294
    },
    {
      "epoch": 23.3,
      "learning_rate": 9.904360223135621e-05,
      "loss": 0.0083,
      "step": 2295
    },
    {
      "epoch": 23.31,
      "learning_rate": 9.90412897285393e-05,
      "loss": 0.0221,
      "step": 2296
    },
    {
      "epoch": 23.32,
      "learning_rate": 9.903897446042439e-05,
      "loss": 0.0181,
      "step": 2297
    },
    {
      "epoch": 23.33,
      "learning_rate": 9.903665642714205e-05,
      "loss": 0.0289,
      "step": 2298
    },
    {
      "epoch": 23.34,
      "learning_rate": 9.903433562882298e-05,
      "loss": 0.0173,
      "step": 2299
    },
    {
      "epoch": 23.35,
      "learning_rate": 9.903201206559803e-05,
      "loss": 0.0094,
      "step": 2300
    },
    {
      "epoch": 23.36,
      "learning_rate": 9.902968573759825e-05,
      "loss": 0.0082,
      "step": 2301
    },
    {
      "epoch": 23.37,
      "learning_rate": 9.902735664495477e-05,
      "loss": 0.0051,
      "step": 2302
    },
    {
      "epoch": 23.38,
      "learning_rate": 9.902502478779896e-05,
      "loss": 0.0347,
      "step": 2303
    },
    {
      "epoch": 23.39,
      "learning_rate": 9.902269016626232e-05,
      "loss": 0.003,
      "step": 2304
    },
    {
      "epoch": 23.4,
      "learning_rate": 9.902035278047642e-05,
      "loss": 0.0181,
      "step": 2305
    },
    {
      "epoch": 23.41,
      "learning_rate": 9.901801263057313e-05,
      "loss": 0.0134,
      "step": 2306
    },
    {
      "epoch": 23.42,
      "learning_rate": 9.901566971668437e-05,
      "loss": 0.0047,
      "step": 2307
    },
    {
      "epoch": 23.43,
      "learning_rate": 9.901332403894225e-05,
      "loss": 0.023,
      "step": 2308
    },
    {
      "epoch": 23.44,
      "learning_rate": 9.901097559747905e-05,
      "loss": 0.0167,
      "step": 2309
    },
    {
      "epoch": 23.45,
      "learning_rate": 9.900862439242719e-05,
      "loss": 0.0058,
      "step": 2310
    },
    {
      "epoch": 23.46,
      "learning_rate": 9.900627042391925e-05,
      "loss": 0.018,
      "step": 2311
    },
    {
      "epoch": 23.47,
      "learning_rate": 9.900391369208795e-05,
      "loss": 0.0201,
      "step": 2312
    },
    {
      "epoch": 23.48,
      "learning_rate": 9.900155419706619e-05,
      "loss": 0.0158,
      "step": 2313
    },
    {
      "epoch": 23.49,
      "learning_rate": 9.899919193898701e-05,
      "loss": 0.0066,
      "step": 2314
    },
    {
      "epoch": 23.5,
      "learning_rate": 9.899682691798362e-05,
      "loss": 0.0025,
      "step": 2315
    },
    {
      "epoch": 23.51,
      "learning_rate": 9.899445913418936e-05,
      "loss": 0.0026,
      "step": 2316
    },
    {
      "epoch": 23.52,
      "learning_rate": 9.899208858773776e-05,
      "loss": 0.0014,
      "step": 2317
    },
    {
      "epoch": 23.53,
      "learning_rate": 9.898971527876249e-05,
      "loss": 0.0186,
      "step": 2318
    },
    {
      "epoch": 23.54,
      "learning_rate": 9.898733920739734e-05,
      "loss": 0.0166,
      "step": 2319
    },
    {
      "epoch": 23.55,
      "learning_rate": 9.898496037377634e-05,
      "loss": 0.0246,
      "step": 2320
    },
    {
      "epoch": 23.56,
      "learning_rate": 9.898257877803359e-05,
      "loss": 0.0149,
      "step": 2321
    },
    {
      "epoch": 23.57,
      "learning_rate": 9.898019442030337e-05,
      "loss": 0.0016,
      "step": 2322
    },
    {
      "epoch": 23.58,
      "learning_rate": 9.897780730072017e-05,
      "loss": 0.0233,
      "step": 2323
    },
    {
      "epoch": 23.59,
      "learning_rate": 9.897541741941858e-05,
      "loss": 0.0121,
      "step": 2324
    },
    {
      "epoch": 23.6,
      "learning_rate": 9.897302477653334e-05,
      "loss": 0.0052,
      "step": 2325
    },
    {
      "epoch": 23.61,
      "learning_rate": 9.897062937219937e-05,
      "loss": 0.0184,
      "step": 2326
    },
    {
      "epoch": 23.62,
      "learning_rate": 9.896823120655177e-05,
      "loss": 0.0036,
      "step": 2327
    },
    {
      "epoch": 23.63,
      "learning_rate": 9.896583027972571e-05,
      "loss": 0.0452,
      "step": 2328
    },
    {
      "epoch": 23.64,
      "learning_rate": 9.896342659185661e-05,
      "loss": 0.0074,
      "step": 2329
    },
    {
      "epoch": 23.65,
      "learning_rate": 9.896102014308e-05,
      "loss": 0.0012,
      "step": 2330
    },
    {
      "epoch": 23.66,
      "learning_rate": 9.895861093353158e-05,
      "loss": 0.0264,
      "step": 2331
    },
    {
      "epoch": 23.68,
      "learning_rate": 9.895619896334717e-05,
      "loss": 0.0017,
      "step": 2332
    },
    {
      "epoch": 23.69,
      "learning_rate": 9.895378423266282e-05,
      "loss": 0.0157,
      "step": 2333
    },
    {
      "epoch": 23.7,
      "learning_rate": 9.895136674161465e-05,
      "loss": 0.0038,
      "step": 2334
    },
    {
      "epoch": 23.71,
      "learning_rate": 9.894894649033899e-05,
      "loss": 0.0274,
      "step": 2335
    },
    {
      "epoch": 23.72,
      "learning_rate": 9.894652347897231e-05,
      "loss": 0.0217,
      "step": 2336
    },
    {
      "epoch": 23.73,
      "learning_rate": 9.894409770765123e-05,
      "loss": 0.0167,
      "step": 2337
    },
    {
      "epoch": 23.74,
      "learning_rate": 9.894166917651256e-05,
      "loss": 0.0191,
      "step": 2338
    },
    {
      "epoch": 23.75,
      "learning_rate": 9.893923788569321e-05,
      "loss": 0.0022,
      "step": 2339
    },
    {
      "epoch": 23.76,
      "learning_rate": 9.893680383533026e-05,
      "loss": 0.0138,
      "step": 2340
    },
    {
      "epoch": 23.77,
      "learning_rate": 9.8934367025561e-05,
      "loss": 0.0093,
      "step": 2341
    },
    {
      "epoch": 23.78,
      "learning_rate": 9.893192745652281e-05,
      "loss": 0.0016,
      "step": 2342
    },
    {
      "epoch": 23.79,
      "learning_rate": 9.892948512835325e-05,
      "loss": 0.0117,
      "step": 2343
    },
    {
      "epoch": 23.8,
      "learning_rate": 9.892704004119005e-05,
      "loss": 0.0019,
      "step": 2344
    },
    {
      "epoch": 23.81,
      "learning_rate": 9.892459219517108e-05,
      "loss": 0.0062,
      "step": 2345
    },
    {
      "epoch": 23.82,
      "learning_rate": 9.892214159043434e-05,
      "loss": 0.0156,
      "step": 2346
    },
    {
      "epoch": 23.83,
      "learning_rate": 9.891968822711803e-05,
      "loss": 0.0039,
      "step": 2347
    },
    {
      "epoch": 23.84,
      "learning_rate": 9.89172321053605e-05,
      "loss": 0.0156,
      "step": 2348
    },
    {
      "epoch": 23.85,
      "learning_rate": 9.891477322530024e-05,
      "loss": 0.0264,
      "step": 2349
    },
    {
      "epoch": 23.86,
      "learning_rate": 9.891231158707587e-05,
      "loss": 0.0282,
      "step": 2350
    },
    {
      "epoch": 23.87,
      "learning_rate": 9.890984719082624e-05,
      "loss": 0.0149,
      "step": 2351
    },
    {
      "epoch": 23.88,
      "learning_rate": 9.890738003669029e-05,
      "loss": 0.0149,
      "step": 2352
    },
    {
      "epoch": 23.89,
      "learning_rate": 9.890491012480712e-05,
      "loss": 0.0106,
      "step": 2353
    },
    {
      "epoch": 23.9,
      "learning_rate": 9.890243745531603e-05,
      "loss": 0.0106,
      "step": 2354
    },
    {
      "epoch": 23.91,
      "learning_rate": 9.889996202835641e-05,
      "loss": 0.0365,
      "step": 2355
    },
    {
      "epoch": 23.92,
      "learning_rate": 9.889748384406788e-05,
      "loss": 0.0246,
      "step": 2356
    },
    {
      "epoch": 23.93,
      "learning_rate": 9.889500290259015e-05,
      "loss": 0.0069,
      "step": 2357
    },
    {
      "epoch": 23.94,
      "learning_rate": 9.889251920406314e-05,
      "loss": 0.0425,
      "step": 2358
    },
    {
      "epoch": 23.95,
      "learning_rate": 9.889003274862687e-05,
      "loss": 0.0105,
      "step": 2359
    },
    {
      "epoch": 23.96,
      "learning_rate": 9.888754353642156e-05,
      "loss": 0.0082,
      "step": 2360
    },
    {
      "epoch": 23.97,
      "learning_rate": 9.888505156758759e-05,
      "loss": 0.0206,
      "step": 2361
    },
    {
      "epoch": 23.98,
      "learning_rate": 9.888255684226542e-05,
      "loss": 0.0143,
      "step": 2362
    },
    {
      "epoch": 23.99,
      "learning_rate": 9.888005936059577e-05,
      "loss": 0.0102,
      "step": 2363
    },
    {
      "epoch": 24.0,
      "learning_rate": 9.887755912271943e-05,
      "loss": 0.0362,
      "step": 2364
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.01742827706038952,
      "eval_runtime": 32.5932,
      "eval_samples_per_second": 96.646,
      "eval_steps_per_second": 6.044,
      "eval_wer": 0.009667093469910371,
      "step": 2364
    },
    {
      "epoch": 24.01,
      "learning_rate": 9.887505612877743e-05,
      "loss": 0.0128,
      "step": 2365
    },
    {
      "epoch": 24.02,
      "learning_rate": 9.887255037891086e-05,
      "loss": 0.0016,
      "step": 2366
    },
    {
      "epoch": 24.03,
      "learning_rate": 9.887004187326102e-05,
      "loss": 0.0035,
      "step": 2367
    },
    {
      "epoch": 24.04,
      "learning_rate": 9.886753061196938e-05,
      "loss": 0.0196,
      "step": 2368
    },
    {
      "epoch": 24.05,
      "learning_rate": 9.886501659517751e-05,
      "loss": 0.0056,
      "step": 2369
    },
    {
      "epoch": 24.06,
      "learning_rate": 9.88624998230272e-05,
      "loss": 0.0088,
      "step": 2370
    },
    {
      "epoch": 24.07,
      "learning_rate": 9.885998029566034e-05,
      "loss": 0.004,
      "step": 2371
    },
    {
      "epoch": 24.08,
      "learning_rate": 9.885745801321905e-05,
      "loss": 0.0051,
      "step": 2372
    },
    {
      "epoch": 24.09,
      "learning_rate": 9.885493297584548e-05,
      "loss": 0.0112,
      "step": 2373
    },
    {
      "epoch": 24.1,
      "learning_rate": 9.885240518368204e-05,
      "loss": 0.0329,
      "step": 2374
    },
    {
      "epoch": 24.11,
      "learning_rate": 9.884987463687127e-05,
      "loss": 0.0086,
      "step": 2375
    },
    {
      "epoch": 24.12,
      "learning_rate": 9.884734133555586e-05,
      "loss": 0.0316,
      "step": 2376
    },
    {
      "epoch": 24.13,
      "learning_rate": 9.884480527987866e-05,
      "loss": 0.0147,
      "step": 2377
    },
    {
      "epoch": 24.14,
      "learning_rate": 9.884226646998268e-05,
      "loss": 0.0244,
      "step": 2378
    },
    {
      "epoch": 24.15,
      "learning_rate": 9.883972490601104e-05,
      "loss": 0.0163,
      "step": 2379
    },
    {
      "epoch": 24.16,
      "learning_rate": 9.883718058810707e-05,
      "loss": 0.0022,
      "step": 2380
    },
    {
      "epoch": 24.17,
      "learning_rate": 9.883463351641424e-05,
      "loss": 0.0243,
      "step": 2381
    },
    {
      "epoch": 24.18,
      "learning_rate": 9.883208369107618e-05,
      "loss": 0.0178,
      "step": 2382
    },
    {
      "epoch": 24.19,
      "learning_rate": 9.882953111223667e-05,
      "loss": 0.0033,
      "step": 2383
    },
    {
      "epoch": 24.2,
      "learning_rate": 9.88269757800396e-05,
      "loss": 0.0093,
      "step": 2384
    },
    {
      "epoch": 24.21,
      "learning_rate": 9.882441769462912e-05,
      "loss": 0.0275,
      "step": 2385
    },
    {
      "epoch": 24.22,
      "learning_rate": 9.882185685614944e-05,
      "loss": 0.0052,
      "step": 2386
    },
    {
      "epoch": 24.23,
      "learning_rate": 9.881929326474494e-05,
      "loss": 0.019,
      "step": 2387
    },
    {
      "epoch": 24.24,
      "learning_rate": 9.881672692056021e-05,
      "loss": 0.0097,
      "step": 2388
    },
    {
      "epoch": 24.25,
      "learning_rate": 9.881415782373995e-05,
      "loss": 0.009,
      "step": 2389
    },
    {
      "epoch": 24.26,
      "learning_rate": 9.881158597442901e-05,
      "loss": 0.0162,
      "step": 2390
    },
    {
      "epoch": 24.27,
      "learning_rate": 9.88090113727724e-05,
      "loss": 0.0099,
      "step": 2391
    },
    {
      "epoch": 24.28,
      "learning_rate": 9.880643401891533e-05,
      "loss": 0.0149,
      "step": 2392
    },
    {
      "epoch": 24.29,
      "learning_rate": 9.880385391300311e-05,
      "loss": 0.0065,
      "step": 2393
    },
    {
      "epoch": 24.3,
      "learning_rate": 9.880127105518122e-05,
      "loss": 0.0142,
      "step": 2394
    },
    {
      "epoch": 24.31,
      "learning_rate": 9.879868544559531e-05,
      "loss": 0.0193,
      "step": 2395
    },
    {
      "epoch": 24.32,
      "learning_rate": 9.879609708439117e-05,
      "loss": 0.0091,
      "step": 2396
    },
    {
      "epoch": 24.34,
      "learning_rate": 9.879350597171475e-05,
      "loss": 0.0302,
      "step": 2397
    },
    {
      "epoch": 24.35,
      "learning_rate": 9.879091210771216e-05,
      "loss": 0.023,
      "step": 2398
    },
    {
      "epoch": 24.36,
      "learning_rate": 9.878831549252965e-05,
      "loss": 0.0064,
      "step": 2399
    },
    {
      "epoch": 24.37,
      "learning_rate": 9.878571612631364e-05,
      "loss": 0.0023,
      "step": 2400
    },
    {
      "epoch": 24.38,
      "learning_rate": 9.878311400921072e-05,
      "loss": 0.0026,
      "step": 2401
    },
    {
      "epoch": 24.39,
      "learning_rate": 9.878050914136759e-05,
      "loss": 0.03,
      "step": 2402
    },
    {
      "epoch": 24.4,
      "learning_rate": 9.877790152293114e-05,
      "loss": 0.0056,
      "step": 2403
    },
    {
      "epoch": 24.41,
      "learning_rate": 9.87752911540484e-05,
      "loss": 0.0252,
      "step": 2404
    },
    {
      "epoch": 24.42,
      "learning_rate": 9.877267803486658e-05,
      "loss": 0.0158,
      "step": 2405
    },
    {
      "epoch": 24.43,
      "learning_rate": 9.877006216553301e-05,
      "loss": 0.0122,
      "step": 2406
    },
    {
      "epoch": 24.44,
      "learning_rate": 9.876744354619519e-05,
      "loss": 0.0058,
      "step": 2407
    },
    {
      "epoch": 24.45,
      "learning_rate": 9.876482217700078e-05,
      "loss": 0.0335,
      "step": 2408
    },
    {
      "epoch": 24.46,
      "learning_rate": 9.87621980580976e-05,
      "loss": 0.0327,
      "step": 2409
    },
    {
      "epoch": 24.47,
      "learning_rate": 9.875957118963362e-05,
      "loss": 0.0222,
      "step": 2410
    },
    {
      "epoch": 24.48,
      "learning_rate": 9.875694157175692e-05,
      "loss": 0.0143,
      "step": 2411
    },
    {
      "epoch": 24.49,
      "learning_rate": 9.875430920461583e-05,
      "loss": 0.0136,
      "step": 2412
    },
    {
      "epoch": 24.5,
      "learning_rate": 9.875167408835877e-05,
      "loss": 0.0141,
      "step": 2413
    },
    {
      "epoch": 24.51,
      "learning_rate": 9.87490362231343e-05,
      "loss": 0.006,
      "step": 2414
    },
    {
      "epoch": 24.52,
      "learning_rate": 9.874639560909117e-05,
      "loss": 0.0149,
      "step": 2415
    },
    {
      "epoch": 24.53,
      "learning_rate": 9.87437522463783e-05,
      "loss": 0.0034,
      "step": 2416
    },
    {
      "epoch": 24.54,
      "learning_rate": 9.874110613514474e-05,
      "loss": 0.0015,
      "step": 2417
    },
    {
      "epoch": 24.55,
      "learning_rate": 9.873845727553966e-05,
      "loss": 0.0075,
      "step": 2418
    },
    {
      "epoch": 24.56,
      "learning_rate": 9.873580566771246e-05,
      "loss": 0.0063,
      "step": 2419
    },
    {
      "epoch": 24.57,
      "learning_rate": 9.873315131181264e-05,
      "loss": 0.0278,
      "step": 2420
    },
    {
      "epoch": 24.58,
      "learning_rate": 9.873049420798985e-05,
      "loss": 0.0371,
      "step": 2421
    },
    {
      "epoch": 24.59,
      "learning_rate": 9.872783435639397e-05,
      "loss": 0.0055,
      "step": 2422
    },
    {
      "epoch": 24.6,
      "learning_rate": 9.872517175717493e-05,
      "loss": 0.0049,
      "step": 2423
    },
    {
      "epoch": 24.61,
      "learning_rate": 9.872250641048289e-05,
      "loss": 0.0098,
      "step": 2424
    },
    {
      "epoch": 24.62,
      "learning_rate": 9.871983831646815e-05,
      "loss": 0.0139,
      "step": 2425
    },
    {
      "epoch": 24.63,
      "learning_rate": 9.871716747528113e-05,
      "loss": 0.022,
      "step": 2426
    },
    {
      "epoch": 24.64,
      "learning_rate": 9.871449388707245e-05,
      "loss": 0.0093,
      "step": 2427
    },
    {
      "epoch": 24.65,
      "learning_rate": 9.871181755199288e-05,
      "loss": 0.023,
      "step": 2428
    },
    {
      "epoch": 24.66,
      "learning_rate": 9.87091384701933e-05,
      "loss": 0.0075,
      "step": 2429
    },
    {
      "epoch": 24.67,
      "learning_rate": 9.870645664182478e-05,
      "loss": 0.0266,
      "step": 2430
    },
    {
      "epoch": 24.68,
      "learning_rate": 9.870377206703856e-05,
      "loss": 0.0048,
      "step": 2431
    },
    {
      "epoch": 24.69,
      "learning_rate": 9.870108474598599e-05,
      "loss": 0.0064,
      "step": 2432
    },
    {
      "epoch": 24.7,
      "learning_rate": 9.869839467881864e-05,
      "loss": 0.024,
      "step": 2433
    },
    {
      "epoch": 24.71,
      "learning_rate": 9.869570186568813e-05,
      "loss": 0.0081,
      "step": 2434
    },
    {
      "epoch": 24.72,
      "learning_rate": 9.869300630674637e-05,
      "loss": 0.0263,
      "step": 2435
    },
    {
      "epoch": 24.73,
      "learning_rate": 9.869030800214532e-05,
      "loss": 0.0293,
      "step": 2436
    },
    {
      "epoch": 24.74,
      "learning_rate": 9.868760695203713e-05,
      "loss": 0.0083,
      "step": 2437
    },
    {
      "epoch": 24.75,
      "learning_rate": 9.868490315657411e-05,
      "loss": 0.0093,
      "step": 2438
    },
    {
      "epoch": 24.76,
      "learning_rate": 9.868219661590872e-05,
      "loss": 0.0061,
      "step": 2439
    },
    {
      "epoch": 24.77,
      "learning_rate": 9.867948733019358e-05,
      "loss": 0.0027,
      "step": 2440
    },
    {
      "epoch": 24.78,
      "learning_rate": 9.867677529958144e-05,
      "loss": 0.005,
      "step": 2441
    },
    {
      "epoch": 24.79,
      "learning_rate": 9.867406052422524e-05,
      "loss": 0.0062,
      "step": 2442
    },
    {
      "epoch": 24.8,
      "learning_rate": 9.867134300427805e-05,
      "loss": 0.0255,
      "step": 2443
    },
    {
      "epoch": 24.81,
      "learning_rate": 9.866862273989311e-05,
      "loss": 0.0216,
      "step": 2444
    },
    {
      "epoch": 24.82,
      "learning_rate": 9.86658997312238e-05,
      "loss": 0.003,
      "step": 2445
    },
    {
      "epoch": 24.83,
      "learning_rate": 9.866317397842367e-05,
      "loss": 0.0055,
      "step": 2446
    },
    {
      "epoch": 24.84,
      "learning_rate": 9.866044548164641e-05,
      "loss": 0.0246,
      "step": 2447
    },
    {
      "epoch": 24.85,
      "learning_rate": 9.865771424104588e-05,
      "loss": 0.0095,
      "step": 2448
    },
    {
      "epoch": 24.86,
      "learning_rate": 9.86549802567761e-05,
      "loss": 0.0025,
      "step": 2449
    },
    {
      "epoch": 24.87,
      "learning_rate": 9.865224352899119e-05,
      "loss": 0.0143,
      "step": 2450
    },
    {
      "epoch": 24.88,
      "learning_rate": 9.864950405784551e-05,
      "loss": 0.0012,
      "step": 2451
    },
    {
      "epoch": 24.89,
      "learning_rate": 9.86467618434935e-05,
      "loss": 0.0065,
      "step": 2452
    },
    {
      "epoch": 24.9,
      "learning_rate": 9.86440168860898e-05,
      "loss": 0.0097,
      "step": 2453
    },
    {
      "epoch": 24.91,
      "learning_rate": 9.86412691857892e-05,
      "loss": 0.0143,
      "step": 2454
    },
    {
      "epoch": 24.92,
      "learning_rate": 9.86385187427466e-05,
      "loss": 0.0193,
      "step": 2455
    },
    {
      "epoch": 24.93,
      "learning_rate": 9.863576555711714e-05,
      "loss": 0.0029,
      "step": 2456
    },
    {
      "epoch": 24.94,
      "learning_rate": 9.863300962905602e-05,
      "loss": 0.0136,
      "step": 2457
    },
    {
      "epoch": 24.95,
      "learning_rate": 9.863025095871865e-05,
      "loss": 0.0042,
      "step": 2458
    },
    {
      "epoch": 24.96,
      "learning_rate": 9.86274895462606e-05,
      "loss": 0.0156,
      "step": 2459
    },
    {
      "epoch": 24.97,
      "learning_rate": 9.862472539183756e-05,
      "loss": 0.0256,
      "step": 2460
    },
    {
      "epoch": 24.98,
      "learning_rate": 9.86219584956054e-05,
      "loss": 0.0018,
      "step": 2461
    },
    {
      "epoch": 24.99,
      "learning_rate": 9.861918885772015e-05,
      "loss": 0.005,
      "step": 2462
    },
    {
      "epoch": 24.99,
      "eval_loss": 0.02087695337831974,
      "eval_runtime": 31.7378,
      "eval_samples_per_second": 99.251,
      "eval_steps_per_second": 6.207,
      "eval_wer": 0.007394366197183098,
      "step": 2462
    },
    {
      "epoch": 25.01,
      "learning_rate": 9.861641647833796e-05,
      "loss": 0.0051,
      "step": 2463
    },
    {
      "epoch": 25.02,
      "learning_rate": 9.861364135761517e-05,
      "loss": 0.004,
      "step": 2464
    },
    {
      "epoch": 25.03,
      "learning_rate": 9.861086349570825e-05,
      "loss": 0.0136,
      "step": 2465
    },
    {
      "epoch": 25.04,
      "learning_rate": 9.860808289277385e-05,
      "loss": 0.0097,
      "step": 2466
    },
    {
      "epoch": 25.05,
      "learning_rate": 9.860529954896875e-05,
      "loss": 0.0238,
      "step": 2467
    },
    {
      "epoch": 25.06,
      "learning_rate": 9.86025134644499e-05,
      "loss": 0.0171,
      "step": 2468
    },
    {
      "epoch": 25.07,
      "learning_rate": 9.859972463937441e-05,
      "loss": 0.0236,
      "step": 2469
    },
    {
      "epoch": 25.08,
      "learning_rate": 9.85969330738995e-05,
      "loss": 0.0053,
      "step": 2470
    },
    {
      "epoch": 25.09,
      "learning_rate": 9.859413876818261e-05,
      "loss": 0.0016,
      "step": 2471
    },
    {
      "epoch": 25.1,
      "learning_rate": 9.859134172238129e-05,
      "loss": 0.0024,
      "step": 2472
    },
    {
      "epoch": 25.11,
      "learning_rate": 9.858854193665325e-05,
      "loss": 0.0105,
      "step": 2473
    },
    {
      "epoch": 25.12,
      "learning_rate": 9.858573941115639e-05,
      "loss": 0.0023,
      "step": 2474
    },
    {
      "epoch": 25.13,
      "learning_rate": 9.858293414604871e-05,
      "loss": 0.0194,
      "step": 2475
    },
    {
      "epoch": 25.14,
      "learning_rate": 9.858012614148839e-05,
      "loss": 0.0071,
      "step": 2476
    },
    {
      "epoch": 25.15,
      "learning_rate": 9.857731539763379e-05,
      "loss": 0.04,
      "step": 2477
    },
    {
      "epoch": 25.16,
      "learning_rate": 9.857450191464337e-05,
      "loss": 0.0394,
      "step": 2478
    },
    {
      "epoch": 25.17,
      "learning_rate": 9.85716856926758e-05,
      "loss": 0.031,
      "step": 2479
    },
    {
      "epoch": 25.18,
      "learning_rate": 9.856886673188987e-05,
      "loss": 0.0217,
      "step": 2480
    },
    {
      "epoch": 25.19,
      "learning_rate": 9.856604503244452e-05,
      "loss": 0.0112,
      "step": 2481
    },
    {
      "epoch": 25.2,
      "learning_rate": 9.856322059449887e-05,
      "loss": 0.012,
      "step": 2482
    },
    {
      "epoch": 25.21,
      "learning_rate": 9.856039341821218e-05,
      "loss": 0.0013,
      "step": 2483
    },
    {
      "epoch": 25.22,
      "learning_rate": 9.855756350374387e-05,
      "loss": 0.0058,
      "step": 2484
    },
    {
      "epoch": 25.23,
      "learning_rate": 9.85547308512535e-05,
      "loss": 0.0352,
      "step": 2485
    },
    {
      "epoch": 25.24,
      "learning_rate": 9.85518954609008e-05,
      "loss": 0.0325,
      "step": 2486
    },
    {
      "epoch": 25.25,
      "learning_rate": 9.854905733284566e-05,
      "loss": 0.0222,
      "step": 2487
    },
    {
      "epoch": 25.26,
      "learning_rate": 9.854621646724811e-05,
      "loss": 0.0134,
      "step": 2488
    },
    {
      "epoch": 25.27,
      "learning_rate": 9.854337286426832e-05,
      "loss": 0.0159,
      "step": 2489
    },
    {
      "epoch": 25.28,
      "learning_rate": 9.854052652406666e-05,
      "loss": 0.0012,
      "step": 2490
    },
    {
      "epoch": 25.29,
      "learning_rate": 9.85376774468036e-05,
      "loss": 0.0018,
      "step": 2491
    },
    {
      "epoch": 25.3,
      "learning_rate": 9.853482563263981e-05,
      "loss": 0.0126,
      "step": 2492
    },
    {
      "epoch": 25.31,
      "learning_rate": 9.85319710817361e-05,
      "loss": 0.0061,
      "step": 2493
    },
    {
      "epoch": 25.32,
      "learning_rate": 9.85291137942534e-05,
      "loss": 0.0118,
      "step": 2494
    },
    {
      "epoch": 25.33,
      "learning_rate": 9.852625377035287e-05,
      "loss": 0.0012,
      "step": 2495
    },
    {
      "epoch": 25.34,
      "learning_rate": 9.852339101019574e-05,
      "loss": 0.0169,
      "step": 2496
    },
    {
      "epoch": 25.35,
      "learning_rate": 9.852052551394344e-05,
      "loss": 0.0211,
      "step": 2497
    },
    {
      "epoch": 25.36,
      "learning_rate": 9.851765728175756e-05,
      "loss": 0.015,
      "step": 2498
    },
    {
      "epoch": 25.37,
      "learning_rate": 9.851478631379982e-05,
      "loss": 0.0237,
      "step": 2499
    },
    {
      "epoch": 25.38,
      "learning_rate": 9.851191261023211e-05,
      "loss": 0.0038,
      "step": 2500
    },
    {
      "epoch": 25.39,
      "learning_rate": 9.85090361712165e-05,
      "loss": 0.0087,
      "step": 2501
    },
    {
      "epoch": 25.4,
      "learning_rate": 9.850615699691512e-05,
      "loss": 0.008,
      "step": 2502
    },
    {
      "epoch": 25.41,
      "learning_rate": 9.850327508749036e-05,
      "loss": 0.0076,
      "step": 2503
    },
    {
      "epoch": 25.42,
      "learning_rate": 9.850039044310472e-05,
      "loss": 0.0068,
      "step": 2504
    },
    {
      "epoch": 25.43,
      "learning_rate": 9.849750306392084e-05,
      "loss": 0.0053,
      "step": 2505
    },
    {
      "epoch": 25.44,
      "learning_rate": 9.849461295010156e-05,
      "loss": 0.0068,
      "step": 2506
    },
    {
      "epoch": 25.45,
      "learning_rate": 9.849172010180982e-05,
      "loss": 0.0109,
      "step": 2507
    },
    {
      "epoch": 25.46,
      "learning_rate": 9.848882451920875e-05,
      "loss": 0.0118,
      "step": 2508
    },
    {
      "epoch": 25.47,
      "learning_rate": 9.848592620246163e-05,
      "loss": 0.0083,
      "step": 2509
    },
    {
      "epoch": 25.48,
      "learning_rate": 9.848302515173187e-05,
      "loss": 0.0305,
      "step": 2510
    },
    {
      "epoch": 25.49,
      "learning_rate": 9.848012136718306e-05,
      "loss": 0.0161,
      "step": 2511
    },
    {
      "epoch": 25.5,
      "learning_rate": 9.847721484897893e-05,
      "loss": 0.0151,
      "step": 2512
    },
    {
      "epoch": 25.51,
      "learning_rate": 9.847430559728339e-05,
      "loss": 0.0026,
      "step": 2513
    },
    {
      "epoch": 25.52,
      "learning_rate": 9.847139361226046e-05,
      "loss": 0.0008,
      "step": 2514
    },
    {
      "epoch": 25.53,
      "learning_rate": 9.846847889407436e-05,
      "loss": 0.003,
      "step": 2515
    },
    {
      "epoch": 25.54,
      "learning_rate": 9.846556144288943e-05,
      "loss": 0.0132,
      "step": 2516
    },
    {
      "epoch": 25.55,
      "learning_rate": 9.846264125887019e-05,
      "loss": 0.0215,
      "step": 2517
    },
    {
      "epoch": 25.56,
      "learning_rate": 9.845971834218128e-05,
      "loss": 0.0229,
      "step": 2518
    },
    {
      "epoch": 25.57,
      "learning_rate": 9.845679269298754e-05,
      "loss": 0.0021,
      "step": 2519
    },
    {
      "epoch": 25.58,
      "learning_rate": 9.84538643114539e-05,
      "loss": 0.0114,
      "step": 2520
    },
    {
      "epoch": 25.59,
      "learning_rate": 9.845093319774553e-05,
      "loss": 0.0104,
      "step": 2521
    },
    {
      "epoch": 25.6,
      "learning_rate": 9.844799935202766e-05,
      "loss": 0.0251,
      "step": 2522
    },
    {
      "epoch": 25.61,
      "learning_rate": 9.844506277446577e-05,
      "loss": 0.0031,
      "step": 2523
    },
    {
      "epoch": 25.62,
      "learning_rate": 9.84421234652254e-05,
      "loss": 0.0023,
      "step": 2524
    },
    {
      "epoch": 25.63,
      "learning_rate": 9.843918142447234e-05,
      "loss": 0.0082,
      "step": 2525
    },
    {
      "epoch": 25.64,
      "learning_rate": 9.843623665237243e-05,
      "loss": 0.011,
      "step": 2526
    },
    {
      "epoch": 25.65,
      "learning_rate": 9.843328914909175e-05,
      "loss": 0.0078,
      "step": 2527
    },
    {
      "epoch": 25.66,
      "learning_rate": 9.84303389147965e-05,
      "loss": 0.0174,
      "step": 2528
    },
    {
      "epoch": 25.68,
      "learning_rate": 9.842738594965301e-05,
      "loss": 0.0321,
      "step": 2529
    },
    {
      "epoch": 25.69,
      "learning_rate": 9.842443025382781e-05,
      "loss": 0.0071,
      "step": 2530
    },
    {
      "epoch": 25.7,
      "learning_rate": 9.842147182748756e-05,
      "loss": 0.0057,
      "step": 2531
    },
    {
      "epoch": 25.71,
      "learning_rate": 9.841851067079908e-05,
      "loss": 0.0358,
      "step": 2532
    },
    {
      "epoch": 25.72,
      "learning_rate": 9.841554678392934e-05,
      "loss": 0.0401,
      "step": 2533
    },
    {
      "epoch": 25.73,
      "learning_rate": 9.841258016704546e-05,
      "loss": 0.0056,
      "step": 2534
    },
    {
      "epoch": 25.74,
      "learning_rate": 9.840961082031472e-05,
      "loss": 0.0264,
      "step": 2535
    },
    {
      "epoch": 25.75,
      "learning_rate": 9.840663874390456e-05,
      "loss": 0.0193,
      "step": 2536
    },
    {
      "epoch": 25.76,
      "learning_rate": 9.840366393798257e-05,
      "loss": 0.0049,
      "step": 2537
    },
    {
      "epoch": 25.77,
      "learning_rate": 9.840068640271648e-05,
      "loss": 0.0236,
      "step": 2538
    },
    {
      "epoch": 25.78,
      "learning_rate": 9.839770613827418e-05,
      "loss": 0.0018,
      "step": 2539
    },
    {
      "epoch": 25.79,
      "learning_rate": 9.839472314482373e-05,
      "loss": 0.0016,
      "step": 2540
    },
    {
      "epoch": 25.8,
      "learning_rate": 9.839173742253334e-05,
      "loss": 0.0334,
      "step": 2541
    },
    {
      "epoch": 25.81,
      "learning_rate": 9.838874897157133e-05,
      "loss": 0.01,
      "step": 2542
    },
    {
      "epoch": 25.82,
      "learning_rate": 9.838575779210626e-05,
      "loss": 0.0122,
      "step": 2543
    },
    {
      "epoch": 25.83,
      "learning_rate": 9.838276388430676e-05,
      "loss": 0.0219,
      "step": 2544
    },
    {
      "epoch": 25.84,
      "learning_rate": 9.837976724834164e-05,
      "loss": 0.0291,
      "step": 2545
    },
    {
      "epoch": 25.85,
      "learning_rate": 9.837676788437991e-05,
      "loss": 0.0091,
      "step": 2546
    },
    {
      "epoch": 25.86,
      "learning_rate": 9.837376579259066e-05,
      "loss": 0.0068,
      "step": 2547
    },
    {
      "epoch": 25.87,
      "learning_rate": 9.837076097314319e-05,
      "loss": 0.0077,
      "step": 2548
    },
    {
      "epoch": 25.88,
      "learning_rate": 9.836775342620694e-05,
      "loss": 0.0022,
      "step": 2549
    },
    {
      "epoch": 25.89,
      "learning_rate": 9.836474315195147e-05,
      "loss": 0.003,
      "step": 2550
    },
    {
      "epoch": 25.9,
      "learning_rate": 9.836173015054655e-05,
      "loss": 0.02,
      "step": 2551
    },
    {
      "epoch": 25.91,
      "learning_rate": 9.835871442216205e-05,
      "loss": 0.0103,
      "step": 2552
    },
    {
      "epoch": 25.92,
      "learning_rate": 9.835569596696802e-05,
      "loss": 0.0103,
      "step": 2553
    },
    {
      "epoch": 25.93,
      "learning_rate": 9.835267478513468e-05,
      "loss": 0.0193,
      "step": 2554
    },
    {
      "epoch": 25.94,
      "learning_rate": 9.834965087683236e-05,
      "loss": 0.0273,
      "step": 2555
    },
    {
      "epoch": 25.95,
      "learning_rate": 9.83466242422316e-05,
      "loss": 0.0073,
      "step": 2556
    },
    {
      "epoch": 25.96,
      "learning_rate": 9.834359488150304e-05,
      "loss": 0.0209,
      "step": 2557
    },
    {
      "epoch": 25.97,
      "learning_rate": 9.834056279481751e-05,
      "loss": 0.0084,
      "step": 2558
    },
    {
      "epoch": 25.98,
      "learning_rate": 9.833752798234599e-05,
      "loss": 0.0417,
      "step": 2559
    },
    {
      "epoch": 25.99,
      "learning_rate": 9.833449044425957e-05,
      "loss": 0.0049,
      "step": 2560
    },
    {
      "epoch": 26.0,
      "learning_rate": 9.833145018072956e-05,
      "loss": 0.0069,
      "step": 2561
    },
    {
      "epoch": 26.0,
      "eval_loss": 0.018065307289361954,
      "eval_runtime": 31.8556,
      "eval_samples_per_second": 98.884,
      "eval_steps_per_second": 6.184,
      "eval_wer": 0.008162612035851472,
      "step": 2561
    },
    {
      "epoch": 26.01,
      "learning_rate": 9.832840719192736e-05,
      "loss": 0.0018,
      "step": 2562
    },
    {
      "epoch": 26.02,
      "learning_rate": 9.83253614780246e-05,
      "loss": 0.0065,
      "step": 2563
    },
    {
      "epoch": 26.03,
      "learning_rate": 9.832231303919298e-05,
      "loss": 0.0012,
      "step": 2564
    },
    {
      "epoch": 26.04,
      "learning_rate": 9.83192618756044e-05,
      "loss": 0.0186,
      "step": 2565
    },
    {
      "epoch": 26.05,
      "learning_rate": 9.831620798743093e-05,
      "loss": 0.0009,
      "step": 2566
    },
    {
      "epoch": 26.06,
      "learning_rate": 9.831315137484475e-05,
      "loss": 0.0198,
      "step": 2567
    },
    {
      "epoch": 26.07,
      "learning_rate": 9.831009203801822e-05,
      "loss": 0.0263,
      "step": 2568
    },
    {
      "epoch": 26.08,
      "learning_rate": 9.830702997712384e-05,
      "loss": 0.0027,
      "step": 2569
    },
    {
      "epoch": 26.09,
      "learning_rate": 9.830396519233428e-05,
      "loss": 0.0051,
      "step": 2570
    },
    {
      "epoch": 26.1,
      "learning_rate": 9.830089768382235e-05,
      "loss": 0.0266,
      "step": 2571
    },
    {
      "epoch": 26.11,
      "learning_rate": 9.829782745176101e-05,
      "loss": 0.0065,
      "step": 2572
    },
    {
      "epoch": 26.12,
      "learning_rate": 9.82947544963234e-05,
      "loss": 0.0011,
      "step": 2573
    },
    {
      "epoch": 26.13,
      "learning_rate": 9.829167881768278e-05,
      "loss": 0.017,
      "step": 2574
    },
    {
      "epoch": 26.14,
      "learning_rate": 9.82886004160126e-05,
      "loss": 0.0163,
      "step": 2575
    },
    {
      "epoch": 26.15,
      "learning_rate": 9.82855192914864e-05,
      "loss": 0.0064,
      "step": 2576
    },
    {
      "epoch": 26.16,
      "learning_rate": 9.828243544427796e-05,
      "loss": 0.0102,
      "step": 2577
    },
    {
      "epoch": 26.17,
      "learning_rate": 9.827934887456113e-05,
      "loss": 0.0059,
      "step": 2578
    },
    {
      "epoch": 26.18,
      "learning_rate": 9.827625958250999e-05,
      "loss": 0.0153,
      "step": 2579
    },
    {
      "epoch": 26.19,
      "learning_rate": 9.827316756829871e-05,
      "loss": 0.0193,
      "step": 2580
    },
    {
      "epoch": 26.2,
      "learning_rate": 9.827007283210166e-05,
      "loss": 0.0162,
      "step": 2581
    },
    {
      "epoch": 26.21,
      "learning_rate": 9.826697537409333e-05,
      "loss": 0.0063,
      "step": 2582
    },
    {
      "epoch": 26.22,
      "learning_rate": 9.826387519444837e-05,
      "loss": 0.0029,
      "step": 2583
    },
    {
      "epoch": 26.23,
      "learning_rate": 9.826077229334161e-05,
      "loss": 0.0299,
      "step": 2584
    },
    {
      "epoch": 26.24,
      "learning_rate": 9.8257666670948e-05,
      "loss": 0.0028,
      "step": 2585
    },
    {
      "epoch": 26.25,
      "learning_rate": 9.825455832744267e-05,
      "loss": 0.0038,
      "step": 2586
    },
    {
      "epoch": 26.26,
      "learning_rate": 9.825144726300088e-05,
      "loss": 0.0008,
      "step": 2587
    },
    {
      "epoch": 26.27,
      "learning_rate": 9.824833347779805e-05,
      "loss": 0.0336,
      "step": 2588
    },
    {
      "epoch": 26.28,
      "learning_rate": 9.824521697200977e-05,
      "loss": 0.0463,
      "step": 2589
    },
    {
      "epoch": 26.29,
      "learning_rate": 9.824209774581174e-05,
      "loss": 0.0256,
      "step": 2590
    },
    {
      "epoch": 26.3,
      "learning_rate": 9.82389757993799e-05,
      "loss": 0.0101,
      "step": 2591
    },
    {
      "epoch": 26.31,
      "learning_rate": 9.823585113289024e-05,
      "loss": 0.0032,
      "step": 2592
    },
    {
      "epoch": 26.32,
      "learning_rate": 9.823272374651898e-05,
      "loss": 0.0113,
      "step": 2593
    },
    {
      "epoch": 26.34,
      "learning_rate": 9.822959364044244e-05,
      "loss": 0.0078,
      "step": 2594
    },
    {
      "epoch": 26.35,
      "learning_rate": 9.822646081483713e-05,
      "loss": 0.0245,
      "step": 2595
    },
    {
      "epoch": 26.36,
      "learning_rate": 9.82233252698797e-05,
      "loss": 0.007,
      "step": 2596
    },
    {
      "epoch": 26.37,
      "learning_rate": 9.822018700574695e-05,
      "loss": 0.0102,
      "step": 2597
    },
    {
      "epoch": 26.38,
      "learning_rate": 9.821704602261585e-05,
      "loss": 0.0049,
      "step": 2598
    },
    {
      "epoch": 26.39,
      "learning_rate": 9.82139023206635e-05,
      "loss": 0.0022,
      "step": 2599
    },
    {
      "epoch": 26.4,
      "learning_rate": 9.821075590006716e-05,
      "loss": 0.0014,
      "step": 2600
    },
    {
      "epoch": 26.41,
      "learning_rate": 9.820760676100426e-05,
      "loss": 0.0045,
      "step": 2601
    },
    {
      "epoch": 26.42,
      "learning_rate": 9.820445490365238e-05,
      "loss": 0.014,
      "step": 2602
    },
    {
      "epoch": 26.43,
      "learning_rate": 9.820130032818922e-05,
      "loss": 0.0098,
      "step": 2603
    },
    {
      "epoch": 26.44,
      "learning_rate": 9.819814303479267e-05,
      "loss": 0.0093,
      "step": 2604
    },
    {
      "epoch": 26.45,
      "learning_rate": 9.819498302364076e-05,
      "loss": 0.0036,
      "step": 2605
    },
    {
      "epoch": 26.46,
      "learning_rate": 9.819182029491168e-05,
      "loss": 0.0236,
      "step": 2606
    },
    {
      "epoch": 26.47,
      "learning_rate": 9.818865484878374e-05,
      "loss": 0.065,
      "step": 2607
    },
    {
      "epoch": 26.48,
      "learning_rate": 9.818548668543545e-05,
      "loss": 0.0234,
      "step": 2608
    },
    {
      "epoch": 26.49,
      "learning_rate": 9.818231580504546e-05,
      "loss": 0.0133,
      "step": 2609
    },
    {
      "epoch": 26.5,
      "learning_rate": 9.817914220779258e-05,
      "loss": 0.0009,
      "step": 2610
    },
    {
      "epoch": 26.51,
      "learning_rate": 9.817596589385572e-05,
      "loss": 0.0109,
      "step": 2611
    },
    {
      "epoch": 26.52,
      "learning_rate": 9.817278686341401e-05,
      "loss": 0.0135,
      "step": 2612
    },
    {
      "epoch": 26.53,
      "learning_rate": 9.81696051166467e-05,
      "loss": 0.0085,
      "step": 2613
    },
    {
      "epoch": 26.54,
      "learning_rate": 9.816642065373321e-05,
      "loss": 0.0018,
      "step": 2614
    },
    {
      "epoch": 26.55,
      "learning_rate": 9.816323347485307e-05,
      "loss": 0.003,
      "step": 2615
    },
    {
      "epoch": 26.56,
      "learning_rate": 9.816004358018603e-05,
      "loss": 0.0225,
      "step": 2616
    },
    {
      "epoch": 26.57,
      "learning_rate": 9.815685096991195e-05,
      "loss": 0.0034,
      "step": 2617
    },
    {
      "epoch": 26.58,
      "learning_rate": 9.815365564421085e-05,
      "loss": 0.015,
      "step": 2618
    },
    {
      "epoch": 26.59,
      "learning_rate": 9.815045760326291e-05,
      "loss": 0.0124,
      "step": 2619
    },
    {
      "epoch": 26.6,
      "learning_rate": 9.814725684724845e-05,
      "loss": 0.0278,
      "step": 2620
    },
    {
      "epoch": 26.61,
      "learning_rate": 9.814405337634795e-05,
      "loss": 0.0075,
      "step": 2621
    },
    {
      "epoch": 26.62,
      "learning_rate": 9.814084719074206e-05,
      "loss": 0.0113,
      "step": 2622
    },
    {
      "epoch": 26.63,
      "learning_rate": 9.813763829061155e-05,
      "loss": 0.0047,
      "step": 2623
    },
    {
      "epoch": 26.64,
      "learning_rate": 9.813442667613737e-05,
      "loss": 0.0131,
      "step": 2624
    },
    {
      "epoch": 26.65,
      "learning_rate": 9.81312123475006e-05,
      "loss": 0.0197,
      "step": 2625
    },
    {
      "epoch": 26.66,
      "learning_rate": 9.812799530488253e-05,
      "loss": 0.0407,
      "step": 2626
    },
    {
      "epoch": 26.67,
      "learning_rate": 9.81247755484645e-05,
      "loss": 0.0239,
      "step": 2627
    },
    {
      "epoch": 26.68,
      "learning_rate": 9.81215530784281e-05,
      "loss": 0.0221,
      "step": 2628
    },
    {
      "epoch": 26.69,
      "learning_rate": 9.811832789495501e-05,
      "loss": 0.0346,
      "step": 2629
    },
    {
      "epoch": 26.7,
      "learning_rate": 9.811509999822714e-05,
      "loss": 0.0051,
      "step": 2630
    },
    {
      "epoch": 26.71,
      "learning_rate": 9.811186938842645e-05,
      "loss": 0.0167,
      "step": 2631
    },
    {
      "epoch": 26.72,
      "learning_rate": 9.810863606573513e-05,
      "loss": 0.0068,
      "step": 2632
    },
    {
      "epoch": 26.73,
      "learning_rate": 9.810540003033547e-05,
      "loss": 0.016,
      "step": 2633
    },
    {
      "epoch": 26.74,
      "learning_rate": 9.810216128240997e-05,
      "loss": 0.017,
      "step": 2634
    },
    {
      "epoch": 26.75,
      "learning_rate": 9.809891982214126e-05,
      "loss": 0.0012,
      "step": 2635
    },
    {
      "epoch": 26.76,
      "learning_rate": 9.80956756497121e-05,
      "loss": 0.0074,
      "step": 2636
    },
    {
      "epoch": 26.77,
      "learning_rate": 9.80924287653054e-05,
      "loss": 0.0093,
      "step": 2637
    },
    {
      "epoch": 26.78,
      "learning_rate": 9.808917916910428e-05,
      "loss": 0.0054,
      "step": 2638
    },
    {
      "epoch": 26.79,
      "learning_rate": 9.808592686129196e-05,
      "loss": 0.0016,
      "step": 2639
    },
    {
      "epoch": 26.8,
      "learning_rate": 9.808267184205183e-05,
      "loss": 0.0137,
      "step": 2640
    },
    {
      "epoch": 26.81,
      "learning_rate": 9.80794141115674e-05,
      "loss": 0.0171,
      "step": 2641
    },
    {
      "epoch": 26.82,
      "learning_rate": 9.807615367002243e-05,
      "loss": 0.0096,
      "step": 2642
    },
    {
      "epoch": 26.83,
      "learning_rate": 9.807289051760072e-05,
      "loss": 0.0125,
      "step": 2643
    },
    {
      "epoch": 26.84,
      "learning_rate": 9.806962465448626e-05,
      "loss": 0.003,
      "step": 2644
    },
    {
      "epoch": 26.85,
      "learning_rate": 9.806635608086325e-05,
      "loss": 0.0264,
      "step": 2645
    },
    {
      "epoch": 26.86,
      "learning_rate": 9.806308479691595e-05,
      "loss": 0.0148,
      "step": 2646
    },
    {
      "epoch": 26.87,
      "learning_rate": 9.805981080282884e-05,
      "loss": 0.009,
      "step": 2647
    },
    {
      "epoch": 26.88,
      "learning_rate": 9.805653409878652e-05,
      "loss": 0.0215,
      "step": 2648
    },
    {
      "epoch": 26.89,
      "learning_rate": 9.805325468497377e-05,
      "loss": 0.0102,
      "step": 2649
    },
    {
      "epoch": 26.9,
      "learning_rate": 9.804997256157551e-05,
      "loss": 0.0054,
      "step": 2650
    },
    {
      "epoch": 26.91,
      "learning_rate": 9.804668772877679e-05,
      "loss": 0.0127,
      "step": 2651
    },
    {
      "epoch": 26.92,
      "learning_rate": 9.804340018676282e-05,
      "loss": 0.0128,
      "step": 2652
    },
    {
      "epoch": 26.93,
      "learning_rate": 9.804010993571902e-05,
      "loss": 0.0253,
      "step": 2653
    },
    {
      "epoch": 26.94,
      "learning_rate": 9.803681697583088e-05,
      "loss": 0.0133,
      "step": 2654
    },
    {
      "epoch": 26.95,
      "learning_rate": 9.80335213072841e-05,
      "loss": 0.0077,
      "step": 2655
    },
    {
      "epoch": 26.96,
      "learning_rate": 9.803022293026451e-05,
      "loss": 0.0189,
      "step": 2656
    },
    {
      "epoch": 26.97,
      "learning_rate": 9.802692184495807e-05,
      "loss": 0.0427,
      "step": 2657
    },
    {
      "epoch": 26.98,
      "learning_rate": 9.802361805155097e-05,
      "loss": 0.008,
      "step": 2658
    },
    {
      "epoch": 26.99,
      "learning_rate": 9.802031155022946e-05,
      "loss": 0.0042,
      "step": 2659
    },
    {
      "epoch": 26.99,
      "eval_loss": 0.019745469093322754,
      "eval_runtime": 31.7957,
      "eval_samples_per_second": 99.07,
      "eval_steps_per_second": 6.196,
      "eval_wer": 0.006338028169014085,
      "step": 2659
    },
    {
      "epoch": 27.01,
      "learning_rate": 9.801700234117999e-05,
      "loss": 0.0115,
      "step": 2660
    },
    {
      "epoch": 27.02,
      "learning_rate": 9.801369042458918e-05,
      "loss": 0.0013,
      "step": 2661
    },
    {
      "epoch": 27.03,
      "learning_rate": 9.801037580064376e-05,
      "loss": 0.0069,
      "step": 2662
    },
    {
      "epoch": 27.04,
      "learning_rate": 9.800705846953062e-05,
      "loss": 0.0081,
      "step": 2663
    },
    {
      "epoch": 27.05,
      "learning_rate": 9.800373843143684e-05,
      "loss": 0.0105,
      "step": 2664
    },
    {
      "epoch": 27.06,
      "learning_rate": 9.800041568654963e-05,
      "loss": 0.0172,
      "step": 2665
    },
    {
      "epoch": 27.07,
      "learning_rate": 9.799709023505632e-05,
      "loss": 0.0109,
      "step": 2666
    },
    {
      "epoch": 27.08,
      "learning_rate": 9.799376207714445e-05,
      "loss": 0.0147,
      "step": 2667
    },
    {
      "epoch": 27.09,
      "learning_rate": 9.799043121300168e-05,
      "loss": 0.0042,
      "step": 2668
    },
    {
      "epoch": 27.1,
      "learning_rate": 9.798709764281581e-05,
      "loss": 0.0122,
      "step": 2669
    },
    {
      "epoch": 27.11,
      "learning_rate": 9.798376136677486e-05,
      "loss": 0.016,
      "step": 2670
    },
    {
      "epoch": 27.12,
      "learning_rate": 9.798042238506687e-05,
      "loss": 0.0013,
      "step": 2671
    },
    {
      "epoch": 27.13,
      "learning_rate": 9.797708069788018e-05,
      "loss": 0.0061,
      "step": 2672
    },
    {
      "epoch": 27.14,
      "learning_rate": 9.797373630540321e-05,
      "loss": 0.0236,
      "step": 2673
    },
    {
      "epoch": 27.15,
      "learning_rate": 9.797038920782454e-05,
      "loss": 0.0166,
      "step": 2674
    },
    {
      "epoch": 27.16,
      "learning_rate": 9.796703940533287e-05,
      "loss": 0.0097,
      "step": 2675
    },
    {
      "epoch": 27.17,
      "learning_rate": 9.796368689811712e-05,
      "loss": 0.0032,
      "step": 2676
    },
    {
      "epoch": 27.18,
      "learning_rate": 9.796033168636634e-05,
      "loss": 0.0553,
      "step": 2677
    },
    {
      "epoch": 27.19,
      "learning_rate": 9.795697377026967e-05,
      "loss": 0.0273,
      "step": 2678
    },
    {
      "epoch": 27.2,
      "learning_rate": 9.795361315001649e-05,
      "loss": 0.0165,
      "step": 2679
    },
    {
      "epoch": 27.21,
      "learning_rate": 9.79502498257963e-05,
      "loss": 0.0011,
      "step": 2680
    },
    {
      "epoch": 27.22,
      "learning_rate": 9.794688379779873e-05,
      "loss": 0.0059,
      "step": 2681
    },
    {
      "epoch": 27.23,
      "learning_rate": 9.794351506621359e-05,
      "loss": 0.0043,
      "step": 2682
    },
    {
      "epoch": 27.24,
      "learning_rate": 9.794014363123082e-05,
      "loss": 0.0094,
      "step": 2683
    },
    {
      "epoch": 27.25,
      "learning_rate": 9.793676949304055e-05,
      "loss": 0.0034,
      "step": 2684
    },
    {
      "epoch": 27.26,
      "learning_rate": 9.793339265183303e-05,
      "loss": 0.0061,
      "step": 2685
    },
    {
      "epoch": 27.27,
      "learning_rate": 9.793001310779865e-05,
      "loss": 0.0115,
      "step": 2686
    },
    {
      "epoch": 27.28,
      "learning_rate": 9.792663086112801e-05,
      "loss": 0.0016,
      "step": 2687
    },
    {
      "epoch": 27.29,
      "learning_rate": 9.792324591201179e-05,
      "loss": 0.0047,
      "step": 2688
    },
    {
      "epoch": 27.3,
      "learning_rate": 9.791985826064087e-05,
      "loss": 0.0125,
      "step": 2689
    },
    {
      "epoch": 27.31,
      "learning_rate": 9.791646790720628e-05,
      "loss": 0.0027,
      "step": 2690
    },
    {
      "epoch": 27.32,
      "learning_rate": 9.791307485189916e-05,
      "loss": 0.019,
      "step": 2691
    },
    {
      "epoch": 27.33,
      "learning_rate": 9.790967909491088e-05,
      "loss": 0.0087,
      "step": 2692
    },
    {
      "epoch": 27.34,
      "learning_rate": 9.790628063643288e-05,
      "loss": 0.0282,
      "step": 2693
    },
    {
      "epoch": 27.35,
      "learning_rate": 9.790287947665682e-05,
      "loss": 0.0062,
      "step": 2694
    },
    {
      "epoch": 27.36,
      "learning_rate": 9.789947561577445e-05,
      "loss": 0.0029,
      "step": 2695
    },
    {
      "epoch": 27.37,
      "learning_rate": 9.789606905397772e-05,
      "loss": 0.0162,
      "step": 2696
    },
    {
      "epoch": 27.38,
      "learning_rate": 9.789265979145874e-05,
      "loss": 0.0087,
      "step": 2697
    },
    {
      "epoch": 27.39,
      "learning_rate": 9.788924782840969e-05,
      "loss": 0.0221,
      "step": 2698
    },
    {
      "epoch": 27.4,
      "learning_rate": 9.788583316502302e-05,
      "loss": 0.021,
      "step": 2699
    },
    {
      "epoch": 27.41,
      "learning_rate": 9.788241580149123e-05,
      "loss": 0.013,
      "step": 2700
    },
    {
      "epoch": 27.42,
      "learning_rate": 9.787899573800705e-05,
      "loss": 0.0058,
      "step": 2701
    },
    {
      "epoch": 27.43,
      "learning_rate": 9.78755729747633e-05,
      "loss": 0.0067,
      "step": 2702
    },
    {
      "epoch": 27.44,
      "learning_rate": 9.787214751195301e-05,
      "loss": 0.0039,
      "step": 2703
    },
    {
      "epoch": 27.45,
      "learning_rate": 9.786871934976929e-05,
      "loss": 0.0018,
      "step": 2704
    },
    {
      "epoch": 27.46,
      "learning_rate": 9.786528848840549e-05,
      "loss": 0.0078,
      "step": 2705
    },
    {
      "epoch": 27.47,
      "learning_rate": 9.786185492805502e-05,
      "loss": 0.0151,
      "step": 2706
    },
    {
      "epoch": 27.48,
      "learning_rate": 9.785841866891152e-05,
      "loss": 0.0136,
      "step": 2707
    },
    {
      "epoch": 27.49,
      "learning_rate": 9.785497971116875e-05,
      "loss": 0.0236,
      "step": 2708
    },
    {
      "epoch": 27.5,
      "learning_rate": 9.785153805502062e-05,
      "loss": 0.0025,
      "step": 2709
    },
    {
      "epoch": 27.51,
      "learning_rate": 9.784809370066119e-05,
      "loss": 0.0199,
      "step": 2710
    },
    {
      "epoch": 27.52,
      "learning_rate": 9.784464664828468e-05,
      "loss": 0.0082,
      "step": 2711
    },
    {
      "epoch": 27.53,
      "learning_rate": 9.784119689808544e-05,
      "loss": 0.0005,
      "step": 2712
    },
    {
      "epoch": 27.54,
      "learning_rate": 9.783774445025802e-05,
      "loss": 0.007,
      "step": 2713
    },
    {
      "epoch": 27.55,
      "learning_rate": 9.78342893049971e-05,
      "loss": 0.0106,
      "step": 2714
    },
    {
      "epoch": 27.56,
      "learning_rate": 9.783083146249748e-05,
      "loss": 0.0209,
      "step": 2715
    },
    {
      "epoch": 27.57,
      "learning_rate": 9.782737092295413e-05,
      "loss": 0.001,
      "step": 2716
    },
    {
      "epoch": 27.58,
      "learning_rate": 9.782390768656223e-05,
      "loss": 0.0292,
      "step": 2717
    },
    {
      "epoch": 27.59,
      "learning_rate": 9.7820441753517e-05,
      "loss": 0.0209,
      "step": 2718
    },
    {
      "epoch": 27.6,
      "learning_rate": 9.78169731240139e-05,
      "loss": 0.0131,
      "step": 2719
    },
    {
      "epoch": 27.61,
      "learning_rate": 9.781350179824854e-05,
      "loss": 0.0032,
      "step": 2720
    },
    {
      "epoch": 27.62,
      "learning_rate": 9.781002777641664e-05,
      "loss": 0.0045,
      "step": 2721
    },
    {
      "epoch": 27.63,
      "learning_rate": 9.780655105871406e-05,
      "loss": 0.0029,
      "step": 2722
    },
    {
      "epoch": 27.64,
      "learning_rate": 9.780307164533689e-05,
      "loss": 0.0184,
      "step": 2723
    },
    {
      "epoch": 27.65,
      "learning_rate": 9.77995895364813e-05,
      "loss": 0.003,
      "step": 2724
    },
    {
      "epoch": 27.66,
      "learning_rate": 9.779610473234364e-05,
      "loss": 0.0185,
      "step": 2725
    },
    {
      "epoch": 27.68,
      "learning_rate": 9.779261723312041e-05,
      "loss": 0.0178,
      "step": 2726
    },
    {
      "epoch": 27.69,
      "learning_rate": 9.778912703900825e-05,
      "loss": 0.006,
      "step": 2727
    },
    {
      "epoch": 27.7,
      "learning_rate": 9.778563415020399e-05,
      "loss": 0.0175,
      "step": 2728
    },
    {
      "epoch": 27.71,
      "learning_rate": 9.778213856690455e-05,
      "loss": 0.0115,
      "step": 2729
    },
    {
      "epoch": 27.72,
      "learning_rate": 9.777864028930705e-05,
      "loss": 0.0326,
      "step": 2730
    },
    {
      "epoch": 27.73,
      "learning_rate": 9.777513931760874e-05,
      "loss": 0.0204,
      "step": 2731
    },
    {
      "epoch": 27.74,
      "learning_rate": 9.777163565200705e-05,
      "loss": 0.0109,
      "step": 2732
    },
    {
      "epoch": 27.75,
      "learning_rate": 9.776812929269952e-05,
      "loss": 0.0129,
      "step": 2733
    },
    {
      "epoch": 27.76,
      "learning_rate": 9.776462023988389e-05,
      "loss": 0.0052,
      "step": 2734
    },
    {
      "epoch": 27.77,
      "learning_rate": 9.776110849375799e-05,
      "loss": 0.0023,
      "step": 2735
    },
    {
      "epoch": 27.78,
      "learning_rate": 9.775759405451987e-05,
      "loss": 0.0226,
      "step": 2736
    },
    {
      "epoch": 27.79,
      "learning_rate": 9.775407692236767e-05,
      "loss": 0.0479,
      "step": 2737
    },
    {
      "epoch": 27.8,
      "learning_rate": 9.775055709749974e-05,
      "loss": 0.0025,
      "step": 2738
    },
    {
      "epoch": 27.81,
      "learning_rate": 9.774703458011453e-05,
      "loss": 0.0062,
      "step": 2739
    },
    {
      "epoch": 27.82,
      "learning_rate": 9.774350937041068e-05,
      "loss": 0.0331,
      "step": 2740
    },
    {
      "epoch": 27.83,
      "learning_rate": 9.773998146858695e-05,
      "loss": 0.005,
      "step": 2741
    },
    {
      "epoch": 27.84,
      "learning_rate": 9.773645087484229e-05,
      "loss": 0.0047,
      "step": 2742
    },
    {
      "epoch": 27.85,
      "learning_rate": 9.773291758937576e-05,
      "loss": 0.003,
      "step": 2743
    },
    {
      "epoch": 27.86,
      "learning_rate": 9.77293816123866e-05,
      "loss": 0.0095,
      "step": 2744
    },
    {
      "epoch": 27.87,
      "learning_rate": 9.772584294407419e-05,
      "loss": 0.0083,
      "step": 2745
    },
    {
      "epoch": 27.88,
      "learning_rate": 9.772230158463809e-05,
      "loss": 0.0025,
      "step": 2746
    },
    {
      "epoch": 27.89,
      "learning_rate": 9.771875753427794e-05,
      "loss": 0.0031,
      "step": 2747
    },
    {
      "epoch": 27.9,
      "learning_rate": 9.771521079319363e-05,
      "loss": 0.0075,
      "step": 2748
    },
    {
      "epoch": 27.91,
      "learning_rate": 9.771166136158511e-05,
      "loss": 0.0056,
      "step": 2749
    },
    {
      "epoch": 27.92,
      "learning_rate": 9.770810923965254e-05,
      "loss": 0.0029,
      "step": 2750
    },
    {
      "epoch": 27.93,
      "learning_rate": 9.770455442759621e-05,
      "loss": 0.0067,
      "step": 2751
    },
    {
      "epoch": 27.94,
      "learning_rate": 9.770099692561658e-05,
      "loss": 0.008,
      "step": 2752
    },
    {
      "epoch": 27.95,
      "learning_rate": 9.769743673391422e-05,
      "loss": 0.0403,
      "step": 2753
    },
    {
      "epoch": 27.96,
      "learning_rate": 9.76938738526899e-05,
      "loss": 0.0311,
      "step": 2754
    },
    {
      "epoch": 27.97,
      "learning_rate": 9.769030828214452e-05,
      "loss": 0.005,
      "step": 2755
    },
    {
      "epoch": 27.98,
      "learning_rate": 9.768674002247913e-05,
      "loss": 0.0342,
      "step": 2756
    },
    {
      "epoch": 27.99,
      "learning_rate": 9.768316907389492e-05,
      "loss": 0.0028,
      "step": 2757
    },
    {
      "epoch": 28.0,
      "learning_rate": 9.767959543659326e-05,
      "loss": 0.0198,
      "step": 2758
    },
    {
      "epoch": 28.0,
      "eval_loss": 0.01734790951013565,
      "eval_runtime": 31.7141,
      "eval_samples_per_second": 99.325,
      "eval_steps_per_second": 6.212,
      "eval_wer": 0.006113956466069142,
      "step": 2758
    },
    {
      "epoch": 28.01,
      "learning_rate": 9.767601911077566e-05,
      "loss": 0.0017,
      "step": 2759
    },
    {
      "epoch": 28.02,
      "learning_rate": 9.767244009664376e-05,
      "loss": 0.0043,
      "step": 2760
    },
    {
      "epoch": 28.03,
      "learning_rate": 9.766885839439939e-05,
      "loss": 0.0027,
      "step": 2761
    },
    {
      "epoch": 28.04,
      "learning_rate": 9.766527400424451e-05,
      "loss": 0.0047,
      "step": 2762
    },
    {
      "epoch": 28.05,
      "learning_rate": 9.766168692638123e-05,
      "loss": 0.003,
      "step": 2763
    },
    {
      "epoch": 28.06,
      "learning_rate": 9.76580971610118e-05,
      "loss": 0.0025,
      "step": 2764
    },
    {
      "epoch": 28.07,
      "learning_rate": 9.765450470833865e-05,
      "loss": 0.0229,
      "step": 2765
    },
    {
      "epoch": 28.08,
      "learning_rate": 9.765090956856436e-05,
      "loss": 0.0068,
      "step": 2766
    },
    {
      "epoch": 28.09,
      "learning_rate": 9.764731174189163e-05,
      "loss": 0.0027,
      "step": 2767
    },
    {
      "epoch": 28.1,
      "learning_rate": 9.764371122852335e-05,
      "loss": 0.0136,
      "step": 2768
    },
    {
      "epoch": 28.11,
      "learning_rate": 9.764010802866252e-05,
      "loss": 0.0274,
      "step": 2769
    },
    {
      "epoch": 28.12,
      "learning_rate": 9.763650214251233e-05,
      "loss": 0.0235,
      "step": 2770
    },
    {
      "epoch": 28.13,
      "learning_rate": 9.763289357027611e-05,
      "loss": 0.003,
      "step": 2771
    },
    {
      "epoch": 28.14,
      "learning_rate": 9.76292823121573e-05,
      "loss": 0.0163,
      "step": 2772
    },
    {
      "epoch": 28.15,
      "learning_rate": 9.762566836835959e-05,
      "loss": 0.0021,
      "step": 2773
    },
    {
      "epoch": 28.16,
      "learning_rate": 9.762205173908672e-05,
      "loss": 0.0055,
      "step": 2774
    },
    {
      "epoch": 28.17,
      "learning_rate": 9.761843242454261e-05,
      "loss": 0.0107,
      "step": 2775
    },
    {
      "epoch": 28.18,
      "learning_rate": 9.761481042493138e-05,
      "loss": 0.0231,
      "step": 2776
    },
    {
      "epoch": 28.19,
      "learning_rate": 9.761118574045723e-05,
      "loss": 0.0267,
      "step": 2777
    },
    {
      "epoch": 28.2,
      "learning_rate": 9.760755837132458e-05,
      "loss": 0.0254,
      "step": 2778
    },
    {
      "epoch": 28.21,
      "learning_rate": 9.760392831773793e-05,
      "loss": 0.0073,
      "step": 2779
    },
    {
      "epoch": 28.22,
      "learning_rate": 9.7600295579902e-05,
      "loss": 0.0022,
      "step": 2780
    },
    {
      "epoch": 28.23,
      "learning_rate": 9.75966601580216e-05,
      "loss": 0.045,
      "step": 2781
    },
    {
      "epoch": 28.24,
      "learning_rate": 9.759302205230176e-05,
      "loss": 0.0167,
      "step": 2782
    },
    {
      "epoch": 28.25,
      "learning_rate": 9.758938126294758e-05,
      "loss": 0.0037,
      "step": 2783
    },
    {
      "epoch": 28.26,
      "learning_rate": 9.758573779016438e-05,
      "loss": 0.0169,
      "step": 2784
    },
    {
      "epoch": 28.27,
      "learning_rate": 9.75820916341576e-05,
      "loss": 0.0055,
      "step": 2785
    },
    {
      "epoch": 28.28,
      "learning_rate": 9.757844279513281e-05,
      "loss": 0.0046,
      "step": 2786
    },
    {
      "epoch": 28.29,
      "learning_rate": 9.757479127329581e-05,
      "loss": 0.0122,
      "step": 2787
    },
    {
      "epoch": 28.3,
      "learning_rate": 9.757113706885246e-05,
      "loss": 0.0022,
      "step": 2788
    },
    {
      "epoch": 28.31,
      "learning_rate": 9.756748018200883e-05,
      "loss": 0.0017,
      "step": 2789
    },
    {
      "epoch": 28.32,
      "learning_rate": 9.75638206129711e-05,
      "loss": 0.0069,
      "step": 2790
    },
    {
      "epoch": 28.34,
      "learning_rate": 9.756015836194564e-05,
      "loss": 0.0029,
      "step": 2791
    },
    {
      "epoch": 28.35,
      "learning_rate": 9.755649342913895e-05,
      "loss": 0.0136,
      "step": 2792
    },
    {
      "epoch": 28.36,
      "learning_rate": 9.755282581475769e-05,
      "loss": 0.0129,
      "step": 2793
    },
    {
      "epoch": 28.37,
      "learning_rate": 9.754915551900865e-05,
      "loss": 0.0181,
      "step": 2794
    },
    {
      "epoch": 28.38,
      "learning_rate": 9.75454825420988e-05,
      "loss": 0.0218,
      "step": 2795
    },
    {
      "epoch": 28.39,
      "learning_rate": 9.754180688423524e-05,
      "loss": 0.0186,
      "step": 2796
    },
    {
      "epoch": 28.4,
      "learning_rate": 9.753812854562525e-05,
      "loss": 0.0053,
      "step": 2797
    },
    {
      "epoch": 28.41,
      "learning_rate": 9.753444752647621e-05,
      "loss": 0.0011,
      "step": 2798
    },
    {
      "epoch": 28.42,
      "learning_rate": 9.753076382699571e-05,
      "loss": 0.0226,
      "step": 2799
    },
    {
      "epoch": 28.43,
      "learning_rate": 9.752707744739145e-05,
      "loss": 0.0007,
      "step": 2800
    },
    {
      "epoch": 28.44,
      "learning_rate": 9.752338838787131e-05,
      "loss": 0.0102,
      "step": 2801
    },
    {
      "epoch": 28.45,
      "learning_rate": 9.751969664864327e-05,
      "loss": 0.0075,
      "step": 2802
    },
    {
      "epoch": 28.46,
      "learning_rate": 9.751600222991553e-05,
      "loss": 0.0033,
      "step": 2803
    },
    {
      "epoch": 28.47,
      "learning_rate": 9.751230513189639e-05,
      "loss": 0.0079,
      "step": 2804
    },
    {
      "epoch": 28.48,
      "learning_rate": 9.750860535479433e-05,
      "loss": 0.0595,
      "step": 2805
    },
    {
      "epoch": 28.49,
      "learning_rate": 9.750490289881797e-05,
      "loss": 0.0275,
      "step": 2806
    },
    {
      "epoch": 28.5,
      "learning_rate": 9.750119776417608e-05,
      "loss": 0.0096,
      "step": 2807
    },
    {
      "epoch": 28.51,
      "learning_rate": 9.749748995107757e-05,
      "loss": 0.0228,
      "step": 2808
    },
    {
      "epoch": 28.52,
      "learning_rate": 9.749377945973152e-05,
      "loss": 0.0045,
      "step": 2809
    },
    {
      "epoch": 28.53,
      "learning_rate": 9.749006629034716e-05,
      "loss": 0.0026,
      "step": 2810
    },
    {
      "epoch": 28.54,
      "learning_rate": 9.748635044313386e-05,
      "loss": 0.0026,
      "step": 2811
    },
    {
      "epoch": 28.55,
      "learning_rate": 9.748263191830113e-05,
      "loss": 0.0044,
      "step": 2812
    },
    {
      "epoch": 28.56,
      "learning_rate": 9.747891071605868e-05,
      "loss": 0.0081,
      "step": 2813
    },
    {
      "epoch": 28.57,
      "learning_rate": 9.747518683661631e-05,
      "loss": 0.013,
      "step": 2814
    },
    {
      "epoch": 28.58,
      "learning_rate": 9.747146028018403e-05,
      "loss": 0.0091,
      "step": 2815
    },
    {
      "epoch": 28.59,
      "learning_rate": 9.746773104697193e-05,
      "loss": 0.0186,
      "step": 2816
    },
    {
      "epoch": 28.6,
      "learning_rate": 9.746399913719033e-05,
      "loss": 0.0083,
      "step": 2817
    },
    {
      "epoch": 28.61,
      "learning_rate": 9.746026455104962e-05,
      "loss": 0.0033,
      "step": 2818
    },
    {
      "epoch": 28.62,
      "learning_rate": 9.745652728876041e-05,
      "loss": 0.0361,
      "step": 2819
    },
    {
      "epoch": 28.63,
      "learning_rate": 9.745278735053343e-05,
      "loss": 0.0029,
      "step": 2820
    },
    {
      "epoch": 28.64,
      "learning_rate": 9.744904473657958e-05,
      "loss": 0.0256,
      "step": 2821
    },
    {
      "epoch": 28.65,
      "learning_rate": 9.744529944710985e-05,
      "loss": 0.0054,
      "step": 2822
    },
    {
      "epoch": 28.66,
      "learning_rate": 9.744155148233547e-05,
      "loss": 0.0098,
      "step": 2823
    },
    {
      "epoch": 28.67,
      "learning_rate": 9.743780084246776e-05,
      "loss": 0.0174,
      "step": 2824
    },
    {
      "epoch": 28.68,
      "learning_rate": 9.743404752771821e-05,
      "loss": 0.0016,
      "step": 2825
    },
    {
      "epoch": 28.69,
      "learning_rate": 9.743029153829846e-05,
      "loss": 0.0011,
      "step": 2826
    },
    {
      "epoch": 28.7,
      "learning_rate": 9.74265328744203e-05,
      "loss": 0.0058,
      "step": 2827
    },
    {
      "epoch": 28.71,
      "learning_rate": 9.742277153629564e-05,
      "loss": 0.0072,
      "step": 2828
    },
    {
      "epoch": 28.72,
      "learning_rate": 9.741900752413662e-05,
      "loss": 0.0507,
      "step": 2829
    },
    {
      "epoch": 28.73,
      "learning_rate": 9.741524083815548e-05,
      "loss": 0.0226,
      "step": 2830
    },
    {
      "epoch": 28.74,
      "learning_rate": 9.741147147856456e-05,
      "loss": 0.001,
      "step": 2831
    },
    {
      "epoch": 28.75,
      "learning_rate": 9.740769944557645e-05,
      "loss": 0.0075,
      "step": 2832
    },
    {
      "epoch": 28.76,
      "learning_rate": 9.740392473940383e-05,
      "loss": 0.0027,
      "step": 2833
    },
    {
      "epoch": 28.77,
      "learning_rate": 9.740014736025956e-05,
      "loss": 0.0138,
      "step": 2834
    },
    {
      "epoch": 28.78,
      "learning_rate": 9.73963673083566e-05,
      "loss": 0.0136,
      "step": 2835
    },
    {
      "epoch": 28.79,
      "learning_rate": 9.739258458390811e-05,
      "loss": 0.0018,
      "step": 2836
    },
    {
      "epoch": 28.8,
      "learning_rate": 9.738879918712742e-05,
      "loss": 0.0141,
      "step": 2837
    },
    {
      "epoch": 28.81,
      "learning_rate": 9.738501111822794e-05,
      "loss": 0.0012,
      "step": 2838
    },
    {
      "epoch": 28.82,
      "learning_rate": 9.738122037742328e-05,
      "loss": 0.0141,
      "step": 2839
    },
    {
      "epoch": 28.83,
      "learning_rate": 9.737742696492719e-05,
      "loss": 0.0058,
      "step": 2840
    },
    {
      "epoch": 28.84,
      "learning_rate": 9.737363088095358e-05,
      "loss": 0.0066,
      "step": 2841
    },
    {
      "epoch": 28.85,
      "learning_rate": 9.736983212571646e-05,
      "loss": 0.0217,
      "step": 2842
    },
    {
      "epoch": 28.86,
      "learning_rate": 9.736603069943009e-05,
      "loss": 0.0082,
      "step": 2843
    },
    {
      "epoch": 28.87,
      "learning_rate": 9.736222660230878e-05,
      "loss": 0.0073,
      "step": 2844
    },
    {
      "epoch": 28.88,
      "learning_rate": 9.735841983456705e-05,
      "loss": 0.0276,
      "step": 2845
    },
    {
      "epoch": 28.89,
      "learning_rate": 9.735461039641954e-05,
      "loss": 0.0057,
      "step": 2846
    },
    {
      "epoch": 28.9,
      "learning_rate": 9.735079828808107e-05,
      "loss": 0.0035,
      "step": 2847
    },
    {
      "epoch": 28.91,
      "learning_rate": 9.734698350976657e-05,
      "loss": 0.0044,
      "step": 2848
    },
    {
      "epoch": 28.92,
      "learning_rate": 9.734316606169116e-05,
      "loss": 0.0176,
      "step": 2849
    },
    {
      "epoch": 28.93,
      "learning_rate": 9.733934594407011e-05,
      "loss": 0.0118,
      "step": 2850
    },
    {
      "epoch": 28.94,
      "learning_rate": 9.73355231571188e-05,
      "loss": 0.004,
      "step": 2851
    },
    {
      "epoch": 28.95,
      "learning_rate": 9.73316977010528e-05,
      "loss": 0.009,
      "step": 2852
    },
    {
      "epoch": 28.96,
      "learning_rate": 9.732786957608781e-05,
      "loss": 0.0294,
      "step": 2853
    },
    {
      "epoch": 28.97,
      "learning_rate": 9.732403878243968e-05,
      "loss": 0.0095,
      "step": 2854
    },
    {
      "epoch": 28.98,
      "learning_rate": 9.732020532032443e-05,
      "loss": 0.0031,
      "step": 2855
    },
    {
      "epoch": 28.99,
      "learning_rate": 9.731636918995821e-05,
      "loss": 0.0029,
      "step": 2856
    },
    {
      "epoch": 28.99,
      "eval_loss": 0.01643305830657482,
      "eval_runtime": 32.5989,
      "eval_samples_per_second": 96.629,
      "eval_steps_per_second": 6.043,
      "eval_wer": 0.004961587708066581,
      "step": 2856
    },
    {
      "epoch": 29.01,
      "learning_rate": 9.731253039155734e-05,
      "loss": 0.019,
      "step": 2857
    },
    {
      "epoch": 29.02,
      "learning_rate": 9.730868892533827e-05,
      "loss": 0.005,
      "step": 2858
    },
    {
      "epoch": 29.03,
      "learning_rate": 9.73048447915176e-05,
      "loss": 0.0048,
      "step": 2859
    },
    {
      "epoch": 29.04,
      "learning_rate": 9.730099799031212e-05,
      "loss": 0.0101,
      "step": 2860
    },
    {
      "epoch": 29.05,
      "learning_rate": 9.729714852193871e-05,
      "loss": 0.0142,
      "step": 2861
    },
    {
      "epoch": 29.06,
      "learning_rate": 9.729329638661443e-05,
      "loss": 0.0084,
      "step": 2862
    },
    {
      "epoch": 29.07,
      "learning_rate": 9.728944158455653e-05,
      "loss": 0.0153,
      "step": 2863
    },
    {
      "epoch": 29.08,
      "learning_rate": 9.728558411598232e-05,
      "loss": 0.0115,
      "step": 2864
    },
    {
      "epoch": 29.09,
      "learning_rate": 9.728172398110934e-05,
      "loss": 0.0102,
      "step": 2865
    },
    {
      "epoch": 29.1,
      "learning_rate": 9.727786118015525e-05,
      "loss": 0.0134,
      "step": 2866
    },
    {
      "epoch": 29.11,
      "learning_rate": 9.727399571333786e-05,
      "loss": 0.003,
      "step": 2867
    },
    {
      "epoch": 29.12,
      "learning_rate": 9.727012758087513e-05,
      "loss": 0.0076,
      "step": 2868
    },
    {
      "epoch": 29.13,
      "learning_rate": 9.726625678298516e-05,
      "loss": 0.0086,
      "step": 2869
    },
    {
      "epoch": 29.14,
      "learning_rate": 9.726238331988624e-05,
      "loss": 0.0034,
      "step": 2870
    },
    {
      "epoch": 29.15,
      "learning_rate": 9.725850719179678e-05,
      "loss": 0.0235,
      "step": 2871
    },
    {
      "epoch": 29.16,
      "learning_rate": 9.725462839893532e-05,
      "loss": 0.004,
      "step": 2872
    },
    {
      "epoch": 29.17,
      "learning_rate": 9.72507469415206e-05,
      "loss": 0.041,
      "step": 2873
    },
    {
      "epoch": 29.18,
      "learning_rate": 9.724686281977146e-05,
      "loss": 0.0243,
      "step": 2874
    },
    {
      "epoch": 29.19,
      "learning_rate": 9.724297603390695e-05,
      "loss": 0.0018,
      "step": 2875
    },
    {
      "epoch": 29.2,
      "learning_rate": 9.723908658414619e-05,
      "loss": 0.0478,
      "step": 2876
    },
    {
      "epoch": 29.21,
      "learning_rate": 9.723519447070853e-05,
      "loss": 0.0116,
      "step": 2877
    },
    {
      "epoch": 29.22,
      "learning_rate": 9.723129969381342e-05,
      "loss": 0.0056,
      "step": 2878
    },
    {
      "epoch": 29.23,
      "learning_rate": 9.722740225368047e-05,
      "loss": 0.0342,
      "step": 2879
    },
    {
      "epoch": 29.24,
      "learning_rate": 9.722350215052946e-05,
      "loss": 0.0214,
      "step": 2880
    },
    {
      "epoch": 29.25,
      "learning_rate": 9.72195993845803e-05,
      "loss": 0.0152,
      "step": 2881
    },
    {
      "epoch": 29.26,
      "learning_rate": 9.721569395605306e-05,
      "loss": 0.0102,
      "step": 2882
    },
    {
      "epoch": 29.27,
      "learning_rate": 9.721178586516795e-05,
      "loss": 0.0011,
      "step": 2883
    },
    {
      "epoch": 29.28,
      "learning_rate": 9.720787511214533e-05,
      "loss": 0.007,
      "step": 2884
    },
    {
      "epoch": 29.29,
      "learning_rate": 9.720396169720571e-05,
      "loss": 0.0077,
      "step": 2885
    },
    {
      "epoch": 29.3,
      "learning_rate": 9.720004562056979e-05,
      "loss": 0.0049,
      "step": 2886
    },
    {
      "epoch": 29.31,
      "learning_rate": 9.719612688245837e-05,
      "loss": 0.0012,
      "step": 2887
    },
    {
      "epoch": 29.32,
      "learning_rate": 9.71922054830924e-05,
      "loss": 0.0196,
      "step": 2888
    },
    {
      "epoch": 29.33,
      "learning_rate": 9.7188281422693e-05,
      "loss": 0.0292,
      "step": 2889
    },
    {
      "epoch": 29.34,
      "learning_rate": 9.718435470148147e-05,
      "loss": 0.0123,
      "step": 2890
    },
    {
      "epoch": 29.35,
      "learning_rate": 9.718042531967918e-05,
      "loss": 0.0136,
      "step": 2891
    },
    {
      "epoch": 29.36,
      "learning_rate": 9.717649327750773e-05,
      "loss": 0.0277,
      "step": 2892
    },
    {
      "epoch": 29.37,
      "learning_rate": 9.717255857518883e-05,
      "loss": 0.0354,
      "step": 2893
    },
    {
      "epoch": 29.38,
      "learning_rate": 9.716862121294433e-05,
      "loss": 0.0246,
      "step": 2894
    },
    {
      "epoch": 29.39,
      "learning_rate": 9.716468119099625e-05,
      "loss": 0.0408,
      "step": 2895
    },
    {
      "epoch": 29.4,
      "learning_rate": 9.716073850956677e-05,
      "loss": 0.0207,
      "step": 2896
    },
    {
      "epoch": 29.41,
      "learning_rate": 9.715679316887821e-05,
      "loss": 0.0124,
      "step": 2897
    },
    {
      "epoch": 29.42,
      "learning_rate": 9.715284516915303e-05,
      "loss": 0.0032,
      "step": 2898
    },
    {
      "epoch": 29.43,
      "learning_rate": 9.714889451061384e-05,
      "loss": 0.0138,
      "step": 2899
    },
    {
      "epoch": 29.44,
      "learning_rate": 9.714494119348341e-05,
      "loss": 0.0166,
      "step": 2900
    },
    {
      "epoch": 29.45,
      "learning_rate": 9.714098521798465e-05,
      "loss": 0.0295,
      "step": 2901
    },
    {
      "epoch": 29.46,
      "learning_rate": 9.713702658434063e-05,
      "loss": 0.0079,
      "step": 2902
    },
    {
      "epoch": 29.47,
      "learning_rate": 9.713306529277458e-05,
      "loss": 0.0205,
      "step": 2903
    },
    {
      "epoch": 29.48,
      "learning_rate": 9.712910134350985e-05,
      "loss": 0.0241,
      "step": 2904
    },
    {
      "epoch": 29.49,
      "learning_rate": 9.712513473676996e-05,
      "loss": 0.0471,
      "step": 2905
    },
    {
      "epoch": 29.5,
      "learning_rate": 9.712116547277858e-05,
      "loss": 0.0016,
      "step": 2906
    },
    {
      "epoch": 29.51,
      "learning_rate": 9.711719355175953e-05,
      "loss": 0.0089,
      "step": 2907
    },
    {
      "epoch": 29.52,
      "learning_rate": 9.711321897393675e-05,
      "loss": 0.0192,
      "step": 2908
    },
    {
      "epoch": 29.53,
      "learning_rate": 9.710924173953438e-05,
      "loss": 0.0039,
      "step": 2909
    },
    {
      "epoch": 29.54,
      "learning_rate": 9.710526184877667e-05,
      "loss": 0.0053,
      "step": 2910
    },
    {
      "epoch": 29.55,
      "learning_rate": 9.710127930188805e-05,
      "loss": 0.0286,
      "step": 2911
    },
    {
      "epoch": 29.56,
      "learning_rate": 9.709729409909307e-05,
      "loss": 0.0067,
      "step": 2912
    },
    {
      "epoch": 29.57,
      "learning_rate": 9.709330624061646e-05,
      "loss": 0.0153,
      "step": 2913
    },
    {
      "epoch": 29.58,
      "learning_rate": 9.708931572668306e-05,
      "loss": 0.0054,
      "step": 2914
    },
    {
      "epoch": 29.59,
      "learning_rate": 9.70853225575179e-05,
      "loss": 0.0072,
      "step": 2915
    },
    {
      "epoch": 29.6,
      "learning_rate": 9.708132673334615e-05,
      "loss": 0.0018,
      "step": 2916
    },
    {
      "epoch": 29.61,
      "learning_rate": 9.70773282543931e-05,
      "loss": 0.0111,
      "step": 2917
    },
    {
      "epoch": 29.62,
      "learning_rate": 9.707332712088424e-05,
      "loss": 0.0018,
      "step": 2918
    },
    {
      "epoch": 29.63,
      "learning_rate": 9.706932333304517e-05,
      "loss": 0.013,
      "step": 2919
    },
    {
      "epoch": 29.64,
      "learning_rate": 9.706531689110164e-05,
      "loss": 0.0078,
      "step": 2920
    },
    {
      "epoch": 29.65,
      "learning_rate": 9.706130779527958e-05,
      "loss": 0.0028,
      "step": 2921
    },
    {
      "epoch": 29.66,
      "learning_rate": 9.705729604580505e-05,
      "loss": 0.0096,
      "step": 2922
    },
    {
      "epoch": 29.68,
      "learning_rate": 9.705328164290424e-05,
      "loss": 0.0048,
      "step": 2923
    },
    {
      "epoch": 29.69,
      "learning_rate": 9.704926458680353e-05,
      "loss": 0.0204,
      "step": 2924
    },
    {
      "epoch": 29.7,
      "learning_rate": 9.704524487772944e-05,
      "loss": 0.007,
      "step": 2925
    },
    {
      "epoch": 29.71,
      "learning_rate": 9.704122251590862e-05,
      "loss": 0.0191,
      "step": 2926
    },
    {
      "epoch": 29.72,
      "learning_rate": 9.703719750156786e-05,
      "loss": 0.0178,
      "step": 2927
    },
    {
      "epoch": 29.73,
      "learning_rate": 9.703316983493414e-05,
      "loss": 0.0073,
      "step": 2928
    },
    {
      "epoch": 29.74,
      "learning_rate": 9.702913951623455e-05,
      "loss": 0.031,
      "step": 2929
    },
    {
      "epoch": 29.75,
      "learning_rate": 9.702510654569639e-05,
      "loss": 0.0187,
      "step": 2930
    },
    {
      "epoch": 29.76,
      "learning_rate": 9.702107092354702e-05,
      "loss": 0.0034,
      "step": 2931
    },
    {
      "epoch": 29.77,
      "learning_rate": 9.701703265001402e-05,
      "loss": 0.0095,
      "step": 2932
    },
    {
      "epoch": 29.78,
      "learning_rate": 9.70129917253251e-05,
      "loss": 0.0207,
      "step": 2933
    },
    {
      "epoch": 29.79,
      "learning_rate": 9.70089481497081e-05,
      "loss": 0.0062,
      "step": 2934
    },
    {
      "epoch": 29.8,
      "learning_rate": 9.700490192339103e-05,
      "loss": 0.0041,
      "step": 2935
    },
    {
      "epoch": 29.81,
      "learning_rate": 9.700085304660207e-05,
      "loss": 0.0054,
      "step": 2936
    },
    {
      "epoch": 29.82,
      "learning_rate": 9.69968015195695e-05,
      "loss": 0.0022,
      "step": 2937
    },
    {
      "epoch": 29.83,
      "learning_rate": 9.699274734252177e-05,
      "loss": 0.0112,
      "step": 2938
    },
    {
      "epoch": 29.84,
      "learning_rate": 9.698869051568749e-05,
      "loss": 0.008,
      "step": 2939
    },
    {
      "epoch": 29.85,
      "learning_rate": 9.698463103929542e-05,
      "loss": 0.0013,
      "step": 2940
    },
    {
      "epoch": 29.86,
      "learning_rate": 9.698056891357446e-05,
      "loss": 0.0315,
      "step": 2941
    },
    {
      "epoch": 29.87,
      "learning_rate": 9.697650413875365e-05,
      "loss": 0.0137,
      "step": 2942
    },
    {
      "epoch": 29.88,
      "learning_rate": 9.697243671506222e-05,
      "loss": 0.0041,
      "step": 2943
    },
    {
      "epoch": 29.89,
      "learning_rate": 9.69683666427295e-05,
      "loss": 0.0021,
      "step": 2944
    },
    {
      "epoch": 29.9,
      "learning_rate": 9.696429392198497e-05,
      "loss": 0.0236,
      "step": 2945
    },
    {
      "epoch": 29.91,
      "learning_rate": 9.696021855305831e-05,
      "loss": 0.0023,
      "step": 2946
    },
    {
      "epoch": 29.92,
      "learning_rate": 9.695614053617929e-05,
      "loss": 0.0014,
      "step": 2947
    },
    {
      "epoch": 29.93,
      "learning_rate": 9.69520598715779e-05,
      "loss": 0.0087,
      "step": 2948
    },
    {
      "epoch": 29.94,
      "learning_rate": 9.694797655948422e-05,
      "loss": 0.018,
      "step": 2949
    },
    {
      "epoch": 29.95,
      "learning_rate": 9.694389060012846e-05,
      "loss": 0.0339,
      "step": 2950
    },
    {
      "epoch": 29.96,
      "learning_rate": 9.693980199374106e-05,
      "loss": 0.0036,
      "step": 2951
    },
    {
      "epoch": 29.97,
      "learning_rate": 9.693571074055255e-05,
      "loss": 0.0011,
      "step": 2952
    },
    {
      "epoch": 29.98,
      "learning_rate": 9.693161684079361e-05,
      "loss": 0.013,
      "step": 2953
    },
    {
      "epoch": 29.99,
      "learning_rate": 9.692752029469512e-05,
      "loss": 0.0043,
      "step": 2954
    },
    {
      "epoch": 30.0,
      "learning_rate": 9.692342110248802e-05,
      "loss": 0.0263,
      "step": 2955
    },
    {
      "epoch": 30.0,
      "eval_loss": 0.017199883237481117,
      "eval_runtime": 31.8684,
      "eval_samples_per_second": 98.844,
      "eval_steps_per_second": 6.182,
      "eval_wer": 0.006658130601792573,
      "step": 2955
    },
    {
      "epoch": 30.01,
      "learning_rate": 9.69193192644035e-05,
      "loss": 0.0136,
      "step": 2956
    },
    {
      "epoch": 30.02,
      "learning_rate": 9.691521478067282e-05,
      "loss": 0.0117,
      "step": 2957
    },
    {
      "epoch": 30.03,
      "learning_rate": 9.691110765152744e-05,
      "loss": 0.0046,
      "step": 2958
    },
    {
      "epoch": 30.04,
      "learning_rate": 9.690699787719895e-05,
      "loss": 0.008,
      "step": 2959
    },
    {
      "epoch": 30.05,
      "learning_rate": 9.690288545791905e-05,
      "loss": 0.0223,
      "step": 2960
    },
    {
      "epoch": 30.06,
      "learning_rate": 9.689877039391968e-05,
      "loss": 0.0038,
      "step": 2961
    },
    {
      "epoch": 30.07,
      "learning_rate": 9.689465268543285e-05,
      "loss": 0.0014,
      "step": 2962
    },
    {
      "epoch": 30.08,
      "learning_rate": 9.689053233269076e-05,
      "loss": 0.0048,
      "step": 2963
    },
    {
      "epoch": 30.09,
      "learning_rate": 9.688640933592572e-05,
      "loss": 0.0219,
      "step": 2964
    },
    {
      "epoch": 30.1,
      "learning_rate": 9.688228369537024e-05,
      "loss": 0.0174,
      "step": 2965
    },
    {
      "epoch": 30.11,
      "learning_rate": 9.687815541125693e-05,
      "loss": 0.002,
      "step": 2966
    },
    {
      "epoch": 30.12,
      "learning_rate": 9.687402448381859e-05,
      "loss": 0.0005,
      "step": 2967
    },
    {
      "epoch": 30.13,
      "learning_rate": 9.686989091328813e-05,
      "loss": 0.0273,
      "step": 2968
    },
    {
      "epoch": 30.14,
      "learning_rate": 9.686575469989866e-05,
      "loss": 0.0195,
      "step": 2969
    },
    {
      "epoch": 30.15,
      "learning_rate": 9.68616158438834e-05,
      "loss": 0.0264,
      "step": 2970
    },
    {
      "epoch": 30.16,
      "learning_rate": 9.68574743454757e-05,
      "loss": 0.0225,
      "step": 2971
    },
    {
      "epoch": 30.17,
      "learning_rate": 9.685333020490913e-05,
      "loss": 0.0043,
      "step": 2972
    },
    {
      "epoch": 30.18,
      "learning_rate": 9.684918342241733e-05,
      "loss": 0.003,
      "step": 2973
    },
    {
      "epoch": 30.19,
      "learning_rate": 9.684503399823414e-05,
      "loss": 0.0161,
      "step": 2974
    },
    {
      "epoch": 30.2,
      "learning_rate": 9.684088193259355e-05,
      "loss": 0.0107,
      "step": 2975
    },
    {
      "epoch": 30.21,
      "learning_rate": 9.683672722572966e-05,
      "loss": 0.0025,
      "step": 2976
    },
    {
      "epoch": 30.22,
      "learning_rate": 9.683256987787675e-05,
      "loss": 0.0055,
      "step": 2977
    },
    {
      "epoch": 30.23,
      "learning_rate": 9.682840988926924e-05,
      "loss": 0.0034,
      "step": 2978
    },
    {
      "epoch": 30.24,
      "learning_rate": 9.682424726014172e-05,
      "loss": 0.0187,
      "step": 2979
    },
    {
      "epoch": 30.25,
      "learning_rate": 9.682008199072887e-05,
      "loss": 0.0013,
      "step": 2980
    },
    {
      "epoch": 30.26,
      "learning_rate": 9.681591408126558e-05,
      "loss": 0.0111,
      "step": 2981
    },
    {
      "epoch": 30.27,
      "learning_rate": 9.681174353198687e-05,
      "loss": 0.0141,
      "step": 2982
    },
    {
      "epoch": 30.28,
      "learning_rate": 9.680757034312788e-05,
      "loss": 0.0033,
      "step": 2983
    },
    {
      "epoch": 30.29,
      "learning_rate": 9.680339451492397e-05,
      "loss": 0.0011,
      "step": 2984
    },
    {
      "epoch": 30.3,
      "learning_rate": 9.679921604761057e-05,
      "loss": 0.0079,
      "step": 2985
    },
    {
      "epoch": 30.31,
      "learning_rate": 9.679503494142327e-05,
      "loss": 0.0139,
      "step": 2986
    },
    {
      "epoch": 30.32,
      "learning_rate": 9.67908511965979e-05,
      "loss": 0.0015,
      "step": 2987
    },
    {
      "epoch": 30.34,
      "learning_rate": 9.678666481337031e-05,
      "loss": 0.0068,
      "step": 2988
    },
    {
      "epoch": 30.35,
      "learning_rate": 9.678247579197657e-05,
      "loss": 0.006,
      "step": 2989
    },
    {
      "epoch": 30.36,
      "learning_rate": 9.677828413265291e-05,
      "loss": 0.013,
      "step": 2990
    },
    {
      "epoch": 30.37,
      "learning_rate": 9.677408983563565e-05,
      "loss": 0.0123,
      "step": 2991
    },
    {
      "epoch": 30.38,
      "learning_rate": 9.676989290116133e-05,
      "loss": 0.0081,
      "step": 2992
    },
    {
      "epoch": 30.39,
      "learning_rate": 9.676569332946658e-05,
      "loss": 0.0108,
      "step": 2993
    },
    {
      "epoch": 30.4,
      "learning_rate": 9.67614911207882e-05,
      "loss": 0.0186,
      "step": 2994
    },
    {
      "epoch": 30.41,
      "learning_rate": 9.675728627536315e-05,
      "loss": 0.0054,
      "step": 2995
    },
    {
      "epoch": 30.42,
      "learning_rate": 9.675307879342854e-05,
      "loss": 0.0068,
      "step": 2996
    },
    {
      "epoch": 30.43,
      "learning_rate": 9.674886867522161e-05,
      "loss": 0.0191,
      "step": 2997
    },
    {
      "epoch": 30.44,
      "learning_rate": 9.674465592097974e-05,
      "loss": 0.0132,
      "step": 2998
    },
    {
      "epoch": 30.45,
      "learning_rate": 9.674044053094049e-05,
      "loss": 0.0075,
      "step": 2999
    },
    {
      "epoch": 30.46,
      "learning_rate": 9.673622250534156e-05,
      "loss": 0.0089,
      "step": 3000
    },
    {
      "epoch": 30.47,
      "learning_rate": 9.673200184442077e-05,
      "loss": 0.0229,
      "step": 3001
    },
    {
      "epoch": 30.48,
      "learning_rate": 9.672777854841614e-05,
      "loss": 0.0024,
      "step": 3002
    },
    {
      "epoch": 30.49,
      "learning_rate": 9.672355261756578e-05,
      "loss": 0.0096,
      "step": 3003
    },
    {
      "epoch": 30.5,
      "learning_rate": 9.671932405210799e-05,
      "loss": 0.0006,
      "step": 3004
    },
    {
      "epoch": 30.51,
      "learning_rate": 9.671509285228121e-05,
      "loss": 0.017,
      "step": 3005
    },
    {
      "epoch": 30.52,
      "learning_rate": 9.671085901832406e-05,
      "loss": 0.0113,
      "step": 3006
    },
    {
      "epoch": 30.53,
      "learning_rate": 9.67066225504752e-05,
      "loss": 0.0136,
      "step": 3007
    },
    {
      "epoch": 30.54,
      "learning_rate": 9.670238344897355e-05,
      "loss": 0.0185,
      "step": 3008
    },
    {
      "epoch": 30.55,
      "learning_rate": 9.669814171405816e-05,
      "loss": 0.0036,
      "step": 3009
    },
    {
      "epoch": 30.56,
      "learning_rate": 9.669389734596819e-05,
      "loss": 0.0132,
      "step": 3010
    },
    {
      "epoch": 30.57,
      "learning_rate": 9.668965034494296e-05,
      "loss": 0.0111,
      "step": 3011
    },
    {
      "epoch": 30.58,
      "learning_rate": 9.668540071122196e-05,
      "loss": 0.001,
      "step": 3012
    },
    {
      "epoch": 30.59,
      "learning_rate": 9.66811484450448e-05,
      "loss": 0.0046,
      "step": 3013
    },
    {
      "epoch": 30.6,
      "learning_rate": 9.667689354665127e-05,
      "loss": 0.0034,
      "step": 3014
    },
    {
      "epoch": 30.61,
      "learning_rate": 9.667263601628128e-05,
      "loss": 0.0207,
      "step": 3015
    },
    {
      "epoch": 30.62,
      "learning_rate": 9.666837585417491e-05,
      "loss": 0.0044,
      "step": 3016
    },
    {
      "epoch": 30.63,
      "learning_rate": 9.666411306057237e-05,
      "loss": 0.0062,
      "step": 3017
    },
    {
      "epoch": 30.64,
      "learning_rate": 9.665984763571403e-05,
      "loss": 0.0198,
      "step": 3018
    },
    {
      "epoch": 30.65,
      "learning_rate": 9.66555795798404e-05,
      "loss": 0.0021,
      "step": 3019
    },
    {
      "epoch": 30.66,
      "learning_rate": 9.665130889319215e-05,
      "loss": 0.0312,
      "step": 3020
    },
    {
      "epoch": 30.67,
      "learning_rate": 9.664703557601009e-05,
      "loss": 0.038,
      "step": 3021
    },
    {
      "epoch": 30.68,
      "learning_rate": 9.664275962853518e-05,
      "loss": 0.0159,
      "step": 3022
    },
    {
      "epoch": 30.69,
      "learning_rate": 9.663848105100852e-05,
      "loss": 0.0104,
      "step": 3023
    },
    {
      "epoch": 30.7,
      "learning_rate": 9.663419984367139e-05,
      "loss": 0.0086,
      "step": 3024
    },
    {
      "epoch": 30.71,
      "learning_rate": 9.662991600676516e-05,
      "loss": 0.0039,
      "step": 3025
    },
    {
      "epoch": 30.72,
      "learning_rate": 9.662562954053143e-05,
      "loss": 0.0073,
      "step": 3026
    },
    {
      "epoch": 30.73,
      "learning_rate": 9.662134044521185e-05,
      "loss": 0.0271,
      "step": 3027
    },
    {
      "epoch": 30.74,
      "learning_rate": 9.661704872104831e-05,
      "loss": 0.0074,
      "step": 3028
    },
    {
      "epoch": 30.75,
      "learning_rate": 9.661275436828278e-05,
      "loss": 0.0021,
      "step": 3029
    },
    {
      "epoch": 30.76,
      "learning_rate": 9.660845738715743e-05,
      "loss": 0.0086,
      "step": 3030
    },
    {
      "epoch": 30.77,
      "learning_rate": 9.660415777791454e-05,
      "loss": 0.0017,
      "step": 3031
    },
    {
      "epoch": 30.78,
      "learning_rate": 9.659985554079656e-05,
      "loss": 0.008,
      "step": 3032
    },
    {
      "epoch": 30.79,
      "learning_rate": 9.659555067604607e-05,
      "loss": 0.0018,
      "step": 3033
    },
    {
      "epoch": 30.8,
      "learning_rate": 9.659124318390582e-05,
      "loss": 0.004,
      "step": 3034
    },
    {
      "epoch": 30.81,
      "learning_rate": 9.658693306461868e-05,
      "loss": 0.0041,
      "step": 3035
    },
    {
      "epoch": 30.82,
      "learning_rate": 9.65826203184277e-05,
      "loss": 0.0249,
      "step": 3036
    },
    {
      "epoch": 30.83,
      "learning_rate": 9.657830494557608e-05,
      "loss": 0.0029,
      "step": 3037
    },
    {
      "epoch": 30.84,
      "learning_rate": 9.657398694630712e-05,
      "loss": 0.0208,
      "step": 3038
    },
    {
      "epoch": 30.85,
      "learning_rate": 9.656966632086432e-05,
      "loss": 0.0033,
      "step": 3039
    },
    {
      "epoch": 30.86,
      "learning_rate": 9.65653430694913e-05,
      "loss": 0.0194,
      "step": 3040
    },
    {
      "epoch": 30.87,
      "learning_rate": 9.656101719243183e-05,
      "loss": 0.009,
      "step": 3041
    },
    {
      "epoch": 30.88,
      "learning_rate": 9.655668868992985e-05,
      "loss": 0.0362,
      "step": 3042
    },
    {
      "epoch": 30.89,
      "learning_rate": 9.65523575622294e-05,
      "loss": 0.0091,
      "step": 3043
    },
    {
      "epoch": 30.9,
      "learning_rate": 9.654802380957474e-05,
      "loss": 0.0069,
      "step": 3044
    },
    {
      "epoch": 30.91,
      "learning_rate": 9.654368743221022e-05,
      "loss": 0.0175,
      "step": 3045
    },
    {
      "epoch": 30.92,
      "learning_rate": 9.653934843038035e-05,
      "loss": 0.0384,
      "step": 3046
    },
    {
      "epoch": 30.93,
      "learning_rate": 9.653500680432981e-05,
      "loss": 0.0313,
      "step": 3047
    },
    {
      "epoch": 30.94,
      "learning_rate": 9.653066255430339e-05,
      "loss": 0.0035,
      "step": 3048
    },
    {
      "epoch": 30.95,
      "learning_rate": 9.652631568054607e-05,
      "loss": 0.0261,
      "step": 3049
    },
    {
      "epoch": 30.96,
      "learning_rate": 9.652196618330294e-05,
      "loss": 0.0043,
      "step": 3050
    },
    {
      "epoch": 30.97,
      "learning_rate": 9.651761406281927e-05,
      "loss": 0.0072,
      "step": 3051
    },
    {
      "epoch": 30.98,
      "learning_rate": 9.651325931934046e-05,
      "loss": 0.0042,
      "step": 3052
    },
    {
      "epoch": 30.99,
      "learning_rate": 9.650890195311204e-05,
      "loss": 0.0035,
      "step": 3053
    },
    {
      "epoch": 30.99,
      "eval_loss": 0.0178507249802351,
      "eval_runtime": 32.1398,
      "eval_samples_per_second": 98.009,
      "eval_steps_per_second": 6.129,
      "eval_wer": 0.0074583866837387965,
      "step": 3053
    },
    {
      "epoch": 31.01,
      "learning_rate": 9.650454196437974e-05,
      "loss": 0.0065,
      "step": 3054
    },
    {
      "epoch": 31.02,
      "learning_rate": 9.650017935338941e-05,
      "loss": 0.0084,
      "step": 3055
    },
    {
      "epoch": 31.03,
      "learning_rate": 9.649581412038702e-05,
      "loss": 0.0085,
      "step": 3056
    },
    {
      "epoch": 31.04,
      "learning_rate": 9.649144626561873e-05,
      "loss": 0.0181,
      "step": 3057
    },
    {
      "epoch": 31.05,
      "learning_rate": 9.648707578933082e-05,
      "loss": 0.0032,
      "step": 3058
    },
    {
      "epoch": 31.06,
      "learning_rate": 9.648270269176975e-05,
      "loss": 0.0236,
      "step": 3059
    },
    {
      "epoch": 31.07,
      "learning_rate": 9.647832697318207e-05,
      "loss": 0.0043,
      "step": 3060
    },
    {
      "epoch": 31.08,
      "learning_rate": 9.647394863381455e-05,
      "loss": 0.0099,
      "step": 3061
    },
    {
      "epoch": 31.09,
      "learning_rate": 9.646956767391405e-05,
      "loss": 0.0012,
      "step": 3062
    },
    {
      "epoch": 31.1,
      "learning_rate": 9.64651840937276e-05,
      "loss": 0.0365,
      "step": 3063
    },
    {
      "epoch": 31.11,
      "learning_rate": 9.64607978935024e-05,
      "loss": 0.004,
      "step": 3064
    },
    {
      "epoch": 31.12,
      "learning_rate": 9.645640907348575e-05,
      "loss": 0.0051,
      "step": 3065
    },
    {
      "epoch": 31.13,
      "learning_rate": 9.645201763392513e-05,
      "loss": 0.0134,
      "step": 3066
    },
    {
      "epoch": 31.14,
      "learning_rate": 9.644762357506818e-05,
      "loss": 0.0041,
      "step": 3067
    },
    {
      "epoch": 31.15,
      "learning_rate": 9.644322689716264e-05,
      "loss": 0.0048,
      "step": 3068
    },
    {
      "epoch": 31.16,
      "learning_rate": 9.643882760045644e-05,
      "loss": 0.0327,
      "step": 3069
    },
    {
      "epoch": 31.17,
      "learning_rate": 9.643442568519763e-05,
      "loss": 0.0049,
      "step": 3070
    },
    {
      "epoch": 31.18,
      "learning_rate": 9.643002115163444e-05,
      "loss": 0.0224,
      "step": 3071
    },
    {
      "epoch": 31.19,
      "learning_rate": 9.642561400001522e-05,
      "loss": 0.004,
      "step": 3072
    },
    {
      "epoch": 31.2,
      "learning_rate": 9.642120423058849e-05,
      "loss": 0.0021,
      "step": 3073
    },
    {
      "epoch": 31.21,
      "learning_rate": 9.641679184360289e-05,
      "loss": 0.0027,
      "step": 3074
    },
    {
      "epoch": 31.22,
      "learning_rate": 9.641237683930722e-05,
      "loss": 0.0051,
      "step": 3075
    },
    {
      "epoch": 31.23,
      "learning_rate": 9.640795921795043e-05,
      "loss": 0.0142,
      "step": 3076
    },
    {
      "epoch": 31.24,
      "learning_rate": 9.640353897978163e-05,
      "loss": 0.0074,
      "step": 3077
    },
    {
      "epoch": 31.25,
      "learning_rate": 9.639911612505004e-05,
      "loss": 0.0417,
      "step": 3078
    },
    {
      "epoch": 31.26,
      "learning_rate": 9.639469065400508e-05,
      "loss": 0.0144,
      "step": 3079
    },
    {
      "epoch": 31.27,
      "learning_rate": 9.639026256689628e-05,
      "loss": 0.0009,
      "step": 3080
    },
    {
      "epoch": 31.28,
      "learning_rate": 9.638583186397331e-05,
      "loss": 0.0013,
      "step": 3081
    },
    {
      "epoch": 31.29,
      "learning_rate": 9.638139854548604e-05,
      "loss": 0.0063,
      "step": 3082
    },
    {
      "epoch": 31.3,
      "learning_rate": 9.637696261168443e-05,
      "loss": 0.0084,
      "step": 3083
    },
    {
      "epoch": 31.31,
      "learning_rate": 9.63725240628186e-05,
      "loss": 0.0052,
      "step": 3084
    },
    {
      "epoch": 31.32,
      "learning_rate": 9.636808289913883e-05,
      "loss": 0.0192,
      "step": 3085
    },
    {
      "epoch": 31.33,
      "learning_rate": 9.636363912089558e-05,
      "loss": 0.0116,
      "step": 3086
    },
    {
      "epoch": 31.34,
      "learning_rate": 9.635919272833938e-05,
      "loss": 0.0056,
      "step": 3087
    },
    {
      "epoch": 31.35,
      "learning_rate": 9.635474372172095e-05,
      "loss": 0.0206,
      "step": 3088
    },
    {
      "epoch": 31.36,
      "learning_rate": 9.635029210129119e-05,
      "loss": 0.0081,
      "step": 3089
    },
    {
      "epoch": 31.37,
      "learning_rate": 9.63458378673011e-05,
      "loss": 0.002,
      "step": 3090
    },
    {
      "epoch": 31.38,
      "learning_rate": 9.634138102000182e-05,
      "loss": 0.0092,
      "step": 3091
    },
    {
      "epoch": 31.39,
      "learning_rate": 9.633692155964468e-05,
      "loss": 0.0113,
      "step": 3092
    },
    {
      "epoch": 31.4,
      "learning_rate": 9.633245948648113e-05,
      "loss": 0.0174,
      "step": 3093
    },
    {
      "epoch": 31.41,
      "learning_rate": 9.632799480076278e-05,
      "loss": 0.0033,
      "step": 3094
    },
    {
      "epoch": 31.42,
      "learning_rate": 9.632352750274138e-05,
      "loss": 0.0166,
      "step": 3095
    },
    {
      "epoch": 31.43,
      "learning_rate": 9.631905759266882e-05,
      "loss": 0.0154,
      "step": 3096
    },
    {
      "epoch": 31.44,
      "learning_rate": 9.631458507079713e-05,
      "loss": 0.0201,
      "step": 3097
    },
    {
      "epoch": 31.45,
      "learning_rate": 9.631010993737854e-05,
      "loss": 0.0106,
      "step": 3098
    },
    {
      "epoch": 31.46,
      "learning_rate": 9.630563219266538e-05,
      "loss": 0.0191,
      "step": 3099
    },
    {
      "epoch": 31.47,
      "learning_rate": 9.630115183691014e-05,
      "loss": 0.011,
      "step": 3100
    },
    {
      "epoch": 31.48,
      "learning_rate": 9.629666887036541e-05,
      "loss": 0.0194,
      "step": 3101
    },
    {
      "epoch": 31.49,
      "learning_rate": 9.629218329328403e-05,
      "loss": 0.0243,
      "step": 3102
    },
    {
      "epoch": 31.5,
      "learning_rate": 9.628769510591889e-05,
      "loss": 0.0026,
      "step": 3103
    },
    {
      "epoch": 31.51,
      "learning_rate": 9.628320430852309e-05,
      "loss": 0.0076,
      "step": 3104
    },
    {
      "epoch": 31.52,
      "learning_rate": 9.627871090134983e-05,
      "loss": 0.0046,
      "step": 3105
    },
    {
      "epoch": 31.53,
      "learning_rate": 9.62742148846525e-05,
      "loss": 0.0069,
      "step": 3106
    },
    {
      "epoch": 31.54,
      "learning_rate": 9.626971625868462e-05,
      "loss": 0.0031,
      "step": 3107
    },
    {
      "epoch": 31.55,
      "learning_rate": 9.626521502369984e-05,
      "loss": 0.029,
      "step": 3108
    },
    {
      "epoch": 31.56,
      "learning_rate": 9.626071117995198e-05,
      "loss": 0.0011,
      "step": 3109
    },
    {
      "epoch": 31.57,
      "learning_rate": 9.625620472769498e-05,
      "loss": 0.0046,
      "step": 3110
    },
    {
      "epoch": 31.58,
      "learning_rate": 9.6251695667183e-05,
      "loss": 0.0016,
      "step": 3111
    },
    {
      "epoch": 31.59,
      "learning_rate": 9.624718399867024e-05,
      "loss": 0.0159,
      "step": 3112
    },
    {
      "epoch": 31.6,
      "learning_rate": 9.624266972241109e-05,
      "loss": 0.0023,
      "step": 3113
    },
    {
      "epoch": 31.61,
      "learning_rate": 9.623815283866015e-05,
      "loss": 0.0017,
      "step": 3114
    },
    {
      "epoch": 31.62,
      "learning_rate": 9.623363334767208e-05,
      "loss": 0.0188,
      "step": 3115
    },
    {
      "epoch": 31.63,
      "learning_rate": 9.622911124970173e-05,
      "loss": 0.0088,
      "step": 3116
    },
    {
      "epoch": 31.64,
      "learning_rate": 9.622458654500409e-05,
      "loss": 0.0033,
      "step": 3117
    },
    {
      "epoch": 31.65,
      "learning_rate": 9.622005923383428e-05,
      "loss": 0.0051,
      "step": 3118
    },
    {
      "epoch": 31.66,
      "learning_rate": 9.621552931644759e-05,
      "loss": 0.0016,
      "step": 3119
    },
    {
      "epoch": 31.68,
      "learning_rate": 9.621099679309947e-05,
      "loss": 0.0044,
      "step": 3120
    },
    {
      "epoch": 31.69,
      "learning_rate": 9.620646166404547e-05,
      "loss": 0.004,
      "step": 3121
    },
    {
      "epoch": 31.7,
      "learning_rate": 9.620192392954132e-05,
      "loss": 0.0017,
      "step": 3122
    },
    {
      "epoch": 31.71,
      "learning_rate": 9.61973835898429e-05,
      "loss": 0.0183,
      "step": 3123
    },
    {
      "epoch": 31.72,
      "learning_rate": 9.619284064520621e-05,
      "loss": 0.0168,
      "step": 3124
    },
    {
      "epoch": 31.73,
      "learning_rate": 9.618829509588743e-05,
      "loss": 0.0213,
      "step": 3125
    },
    {
      "epoch": 31.74,
      "learning_rate": 9.618374694214285e-05,
      "loss": 0.0073,
      "step": 3126
    },
    {
      "epoch": 31.75,
      "learning_rate": 9.617919618422895e-05,
      "loss": 0.004,
      "step": 3127
    },
    {
      "epoch": 31.76,
      "learning_rate": 9.617464282240233e-05,
      "loss": 0.0197,
      "step": 3128
    },
    {
      "epoch": 31.77,
      "learning_rate": 9.617008685691972e-05,
      "loss": 0.0133,
      "step": 3129
    },
    {
      "epoch": 31.78,
      "learning_rate": 9.616552828803804e-05,
      "loss": 0.0071,
      "step": 3130
    },
    {
      "epoch": 31.79,
      "learning_rate": 9.616096711601433e-05,
      "loss": 0.0211,
      "step": 3131
    },
    {
      "epoch": 31.8,
      "learning_rate": 9.615640334110579e-05,
      "loss": 0.0025,
      "step": 3132
    },
    {
      "epoch": 31.81,
      "learning_rate": 9.615183696356973e-05,
      "loss": 0.0323,
      "step": 3133
    },
    {
      "epoch": 31.82,
      "learning_rate": 9.614726798366365e-05,
      "loss": 0.0042,
      "step": 3134
    },
    {
      "epoch": 31.83,
      "learning_rate": 9.614269640164519e-05,
      "loss": 0.0068,
      "step": 3135
    },
    {
      "epoch": 31.84,
      "learning_rate": 9.613812221777212e-05,
      "loss": 0.0102,
      "step": 3136
    },
    {
      "epoch": 31.85,
      "learning_rate": 9.613354543230237e-05,
      "loss": 0.0226,
      "step": 3137
    },
    {
      "epoch": 31.86,
      "learning_rate": 9.612896604549402e-05,
      "loss": 0.0161,
      "step": 3138
    },
    {
      "epoch": 31.87,
      "learning_rate": 9.612438405760526e-05,
      "loss": 0.0071,
      "step": 3139
    },
    {
      "epoch": 31.88,
      "learning_rate": 9.61197994688945e-05,
      "loss": 0.0051,
      "step": 3140
    },
    {
      "epoch": 31.89,
      "learning_rate": 9.611521227962019e-05,
      "loss": 0.0185,
      "step": 3141
    },
    {
      "epoch": 31.9,
      "learning_rate": 9.611062249004104e-05,
      "loss": 0.0312,
      "step": 3142
    },
    {
      "epoch": 31.91,
      "learning_rate": 9.610603010041583e-05,
      "loss": 0.011,
      "step": 3143
    },
    {
      "epoch": 31.92,
      "learning_rate": 9.610143511100354e-05,
      "loss": 0.018,
      "step": 3144
    },
    {
      "epoch": 31.93,
      "learning_rate": 9.609683752206323e-05,
      "loss": 0.0125,
      "step": 3145
    },
    {
      "epoch": 31.94,
      "learning_rate": 9.609223733385418e-05,
      "loss": 0.0146,
      "step": 3146
    },
    {
      "epoch": 31.95,
      "learning_rate": 9.608763454663574e-05,
      "loss": 0.0224,
      "step": 3147
    },
    {
      "epoch": 31.96,
      "learning_rate": 9.608302916066749e-05,
      "loss": 0.0105,
      "step": 3148
    },
    {
      "epoch": 31.97,
      "learning_rate": 9.607842117620909e-05,
      "loss": 0.0097,
      "step": 3149
    },
    {
      "epoch": 31.98,
      "learning_rate": 9.607381059352038e-05,
      "loss": 0.0292,
      "step": 3150
    },
    {
      "epoch": 31.99,
      "learning_rate": 9.606919741286134e-05,
      "loss": 0.0004,
      "step": 3151
    },
    {
      "epoch": 32.0,
      "learning_rate": 9.60645816344921e-05,
      "loss": 0.0159,
      "step": 3152
    },
    {
      "epoch": 32.0,
      "eval_loss": 0.019436046481132507,
      "eval_runtime": 32.0865,
      "eval_samples_per_second": 98.172,
      "eval_steps_per_second": 6.14,
      "eval_wer": 0.007394366197183098,
      "step": 3152
    },
    {
      "epoch": 32.01,
      "learning_rate": 9.605996325867291e-05,
      "loss": 0.0009,
      "step": 3153
    },
    {
      "epoch": 32.02,
      "learning_rate": 9.60553422856642e-05,
      "loss": 0.009,
      "step": 3154
    },
    {
      "epoch": 32.03,
      "learning_rate": 9.605071871572653e-05,
      "loss": 0.0002,
      "step": 3155
    },
    {
      "epoch": 32.04,
      "learning_rate": 9.60460925491206e-05,
      "loss": 0.0029,
      "step": 3156
    },
    {
      "epoch": 32.05,
      "learning_rate": 9.60414637861073e-05,
      "loss": 0.0079,
      "step": 3157
    },
    {
      "epoch": 32.06,
      "learning_rate": 9.603683242694759e-05,
      "loss": 0.0159,
      "step": 3158
    },
    {
      "epoch": 32.07,
      "learning_rate": 9.603219847190264e-05,
      "loss": 0.0014,
      "step": 3159
    },
    {
      "epoch": 32.08,
      "learning_rate": 9.602756192123374e-05,
      "loss": 0.0234,
      "step": 3160
    },
    {
      "epoch": 32.09,
      "learning_rate": 9.602292277520236e-05,
      "loss": 0.0268,
      "step": 3161
    },
    {
      "epoch": 32.1,
      "learning_rate": 9.601828103407004e-05,
      "loss": 0.0098,
      "step": 3162
    },
    {
      "epoch": 32.11,
      "learning_rate": 9.601363669809856e-05,
      "loss": 0.0528,
      "step": 3163
    },
    {
      "epoch": 32.12,
      "learning_rate": 9.600898976754977e-05,
      "loss": 0.0127,
      "step": 3164
    },
    {
      "epoch": 32.13,
      "learning_rate": 9.60043402426857e-05,
      "loss": 0.025,
      "step": 3165
    },
    {
      "epoch": 32.14,
      "learning_rate": 9.599968812376854e-05,
      "loss": 0.0178,
      "step": 3166
    },
    {
      "epoch": 32.15,
      "learning_rate": 9.59950334110606e-05,
      "loss": 0.0119,
      "step": 3167
    },
    {
      "epoch": 32.16,
      "learning_rate": 9.599037610482435e-05,
      "loss": 0.0028,
      "step": 3168
    },
    {
      "epoch": 32.17,
      "learning_rate": 9.598571620532238e-05,
      "loss": 0.0062,
      "step": 3169
    },
    {
      "epoch": 32.18,
      "learning_rate": 9.598105371281747e-05,
      "loss": 0.0131,
      "step": 3170
    },
    {
      "epoch": 32.19,
      "learning_rate": 9.597638862757255e-05,
      "loss": 0.0006,
      "step": 3171
    },
    {
      "epoch": 32.2,
      "learning_rate": 9.59717209498506e-05,
      "loss": 0.0027,
      "step": 3172
    },
    {
      "epoch": 32.21,
      "learning_rate": 9.596705067991489e-05,
      "loss": 0.0028,
      "step": 3173
    },
    {
      "epoch": 32.22,
      "learning_rate": 9.596237781802872e-05,
      "loss": 0.0228,
      "step": 3174
    },
    {
      "epoch": 32.23,
      "learning_rate": 9.595770236445558e-05,
      "loss": 0.0052,
      "step": 3175
    },
    {
      "epoch": 32.24,
      "learning_rate": 9.595302431945913e-05,
      "loss": 0.0067,
      "step": 3176
    },
    {
      "epoch": 32.25,
      "learning_rate": 9.594834368330314e-05,
      "loss": 0.0081,
      "step": 3177
    },
    {
      "epoch": 32.26,
      "learning_rate": 9.594366045625154e-05,
      "loss": 0.0106,
      "step": 3178
    },
    {
      "epoch": 32.27,
      "learning_rate": 9.593897463856841e-05,
      "loss": 0.0181,
      "step": 3179
    },
    {
      "epoch": 32.28,
      "learning_rate": 9.593428623051792e-05,
      "loss": 0.0123,
      "step": 3180
    },
    {
      "epoch": 32.29,
      "learning_rate": 9.59295952323645e-05,
      "loss": 0.0197,
      "step": 3181
    },
    {
      "epoch": 32.3,
      "learning_rate": 9.592490164437265e-05,
      "loss": 0.0064,
      "step": 3182
    },
    {
      "epoch": 32.31,
      "learning_rate": 9.5920205466807e-05,
      "loss": 0.0012,
      "step": 3183
    },
    {
      "epoch": 32.32,
      "learning_rate": 9.591550669993237e-05,
      "loss": 0.0111,
      "step": 3184
    },
    {
      "epoch": 32.34,
      "learning_rate": 9.591080534401371e-05,
      "loss": 0.005,
      "step": 3185
    },
    {
      "epoch": 32.35,
      "learning_rate": 9.590610139931611e-05,
      "loss": 0.0088,
      "step": 3186
    },
    {
      "epoch": 32.36,
      "learning_rate": 9.590139486610484e-05,
      "loss": 0.004,
      "step": 3187
    },
    {
      "epoch": 32.37,
      "learning_rate": 9.589668574464524e-05,
      "loss": 0.0052,
      "step": 3188
    },
    {
      "epoch": 32.38,
      "learning_rate": 9.589197403520287e-05,
      "loss": 0.0032,
      "step": 3189
    },
    {
      "epoch": 32.39,
      "learning_rate": 9.588725973804342e-05,
      "loss": 0.0584,
      "step": 3190
    },
    {
      "epoch": 32.4,
      "learning_rate": 9.58825428534327e-05,
      "loss": 0.009,
      "step": 3191
    },
    {
      "epoch": 32.41,
      "learning_rate": 9.587782338163669e-05,
      "loss": 0.0126,
      "step": 3192
    },
    {
      "epoch": 32.42,
      "learning_rate": 9.587310132292151e-05,
      "loss": 0.0079,
      "step": 3193
    },
    {
      "epoch": 32.43,
      "learning_rate": 9.58683766775534e-05,
      "loss": 0.0021,
      "step": 3194
    },
    {
      "epoch": 32.44,
      "learning_rate": 9.58636494457988e-05,
      "loss": 0.0076,
      "step": 3195
    },
    {
      "epoch": 32.45,
      "learning_rate": 9.585891962792426e-05,
      "loss": 0.0023,
      "step": 3196
    },
    {
      "epoch": 32.46,
      "learning_rate": 9.585418722419645e-05,
      "loss": 0.0065,
      "step": 3197
    },
    {
      "epoch": 32.47,
      "learning_rate": 9.584945223488227e-05,
      "loss": 0.0134,
      "step": 3198
    },
    {
      "epoch": 32.48,
      "learning_rate": 9.584471466024865e-05,
      "loss": 0.0115,
      "step": 3199
    },
    {
      "epoch": 32.49,
      "learning_rate": 9.583997450056277e-05,
      "loss": 0.0054,
      "step": 3200
    },
    {
      "epoch": 32.5,
      "learning_rate": 9.583523175609192e-05,
      "loss": 0.0146,
      "step": 3201
    },
    {
      "epoch": 32.51,
      "learning_rate": 9.58304864271035e-05,
      "loss": 0.0207,
      "step": 3202
    },
    {
      "epoch": 32.52,
      "learning_rate": 9.582573851386509e-05,
      "loss": 0.0066,
      "step": 3203
    },
    {
      "epoch": 32.53,
      "learning_rate": 9.582098801664444e-05,
      "loss": 0.0291,
      "step": 3204
    },
    {
      "epoch": 32.54,
      "learning_rate": 9.581623493570939e-05,
      "loss": 0.0011,
      "step": 3205
    },
    {
      "epoch": 32.55,
      "learning_rate": 9.581147927132797e-05,
      "loss": 0.0147,
      "step": 3206
    },
    {
      "epoch": 32.56,
      "learning_rate": 9.58067210237683e-05,
      "loss": 0.003,
      "step": 3207
    },
    {
      "epoch": 32.57,
      "learning_rate": 9.580196019329873e-05,
      "loss": 0.0115,
      "step": 3208
    },
    {
      "epoch": 32.58,
      "learning_rate": 9.57971967801877e-05,
      "loss": 0.0027,
      "step": 3209
    },
    {
      "epoch": 32.59,
      "learning_rate": 9.579243078470379e-05,
      "loss": 0.0193,
      "step": 3210
    },
    {
      "epoch": 32.6,
      "learning_rate": 9.578766220711574e-05,
      "loss": 0.0039,
      "step": 3211
    },
    {
      "epoch": 32.61,
      "learning_rate": 9.578289104769246e-05,
      "loss": 0.0033,
      "step": 3212
    },
    {
      "epoch": 32.62,
      "learning_rate": 9.577811730670297e-05,
      "loss": 0.0055,
      "step": 3213
    },
    {
      "epoch": 32.63,
      "learning_rate": 9.577334098441642e-05,
      "loss": 0.003,
      "step": 3214
    },
    {
      "epoch": 32.64,
      "learning_rate": 9.576856208110217e-05,
      "loss": 0.0063,
      "step": 3215
    },
    {
      "epoch": 32.65,
      "learning_rate": 9.576378059702968e-05,
      "loss": 0.0026,
      "step": 3216
    },
    {
      "epoch": 32.66,
      "learning_rate": 9.575899653246856e-05,
      "loss": 0.0178,
      "step": 3217
    },
    {
      "epoch": 32.67,
      "learning_rate": 9.575420988768857e-05,
      "loss": 0.0017,
      "step": 3218
    },
    {
      "epoch": 32.68,
      "learning_rate": 9.57494206629596e-05,
      "loss": 0.0113,
      "step": 3219
    },
    {
      "epoch": 32.69,
      "learning_rate": 9.574462885855174e-05,
      "loss": 0.0073,
      "step": 3220
    },
    {
      "epoch": 32.7,
      "learning_rate": 9.573983447473516e-05,
      "loss": 0.0061,
      "step": 3221
    },
    {
      "epoch": 32.71,
      "learning_rate": 9.573503751178019e-05,
      "loss": 0.0088,
      "step": 3222
    },
    {
      "epoch": 32.72,
      "learning_rate": 9.573023796995733e-05,
      "loss": 0.0238,
      "step": 3223
    },
    {
      "epoch": 32.73,
      "learning_rate": 9.572543584953722e-05,
      "loss": 0.0191,
      "step": 3224
    },
    {
      "epoch": 32.74,
      "learning_rate": 9.572063115079063e-05,
      "loss": 0.0003,
      "step": 3225
    },
    {
      "epoch": 32.75,
      "learning_rate": 9.571582387398847e-05,
      "loss": 0.0012,
      "step": 3226
    },
    {
      "epoch": 32.76,
      "learning_rate": 9.571101401940186e-05,
      "loss": 0.0152,
      "step": 3227
    },
    {
      "epoch": 32.77,
      "learning_rate": 9.570620158730194e-05,
      "loss": 0.0012,
      "step": 3228
    },
    {
      "epoch": 32.78,
      "learning_rate": 9.570138657796011e-05,
      "loss": 0.0045,
      "step": 3229
    },
    {
      "epoch": 32.79,
      "learning_rate": 9.569656899164789e-05,
      "loss": 0.0064,
      "step": 3230
    },
    {
      "epoch": 32.8,
      "learning_rate": 9.569174882863689e-05,
      "loss": 0.0007,
      "step": 3231
    },
    {
      "epoch": 32.81,
      "learning_rate": 9.568692608919894e-05,
      "loss": 0.0024,
      "step": 3232
    },
    {
      "epoch": 32.82,
      "learning_rate": 9.568210077360597e-05,
      "loss": 0.0055,
      "step": 3233
    },
    {
      "epoch": 32.83,
      "learning_rate": 9.567727288213005e-05,
      "loss": 0.0211,
      "step": 3234
    },
    {
      "epoch": 32.84,
      "learning_rate": 9.567244241504343e-05,
      "loss": 0.0045,
      "step": 3235
    },
    {
      "epoch": 32.85,
      "learning_rate": 9.566760937261848e-05,
      "loss": 0.0009,
      "step": 3236
    },
    {
      "epoch": 32.86,
      "learning_rate": 9.566277375512771e-05,
      "loss": 0.0006,
      "step": 3237
    },
    {
      "epoch": 32.87,
      "learning_rate": 9.56579355628438e-05,
      "loss": 0.0091,
      "step": 3238
    },
    {
      "epoch": 32.88,
      "learning_rate": 9.565309479603956e-05,
      "loss": 0.0166,
      "step": 3239
    },
    {
      "epoch": 32.89,
      "learning_rate": 9.564825145498795e-05,
      "loss": 0.0059,
      "step": 3240
    },
    {
      "epoch": 32.9,
      "learning_rate": 9.564340553996208e-05,
      "loss": 0.0111,
      "step": 3241
    },
    {
      "epoch": 32.91,
      "learning_rate": 9.563855705123516e-05,
      "loss": 0.0065,
      "step": 3242
    },
    {
      "epoch": 32.92,
      "learning_rate": 9.563370598908062e-05,
      "loss": 0.0016,
      "step": 3243
    },
    {
      "epoch": 32.93,
      "learning_rate": 9.562885235377197e-05,
      "loss": 0.01,
      "step": 3244
    },
    {
      "epoch": 32.94,
      "learning_rate": 9.562399614558293e-05,
      "loss": 0.0017,
      "step": 3245
    },
    {
      "epoch": 32.95,
      "learning_rate": 9.561913736478729e-05,
      "loss": 0.002,
      "step": 3246
    },
    {
      "epoch": 32.96,
      "learning_rate": 9.561427601165905e-05,
      "loss": 0.0271,
      "step": 3247
    },
    {
      "epoch": 32.97,
      "learning_rate": 9.560941208647231e-05,
      "loss": 0.0211,
      "step": 3248
    },
    {
      "epoch": 32.98,
      "learning_rate": 9.560454558950134e-05,
      "loss": 0.0007,
      "step": 3249
    },
    {
      "epoch": 32.99,
      "learning_rate": 9.559967652102055e-05,
      "loss": 0.001,
      "step": 3250
    },
    {
      "epoch": 32.99,
      "eval_loss": 0.01855819672346115,
      "eval_runtime": 31.7265,
      "eval_samples_per_second": 99.286,
      "eval_steps_per_second": 6.209,
      "eval_wer": 0.005857874519846351,
      "step": 3250
    },
    {
      "epoch": 33.01,
      "learning_rate": 9.559480488130449e-05,
      "loss": 0.0368,
      "step": 3251
    },
    {
      "epoch": 33.02,
      "learning_rate": 9.558993067062785e-05,
      "loss": 0.0058,
      "step": 3252
    },
    {
      "epoch": 33.03,
      "learning_rate": 9.558505388926549e-05,
      "loss": 0.0051,
      "step": 3253
    },
    {
      "epoch": 33.04,
      "learning_rate": 9.558017453749237e-05,
      "loss": 0.0068,
      "step": 3254
    },
    {
      "epoch": 33.05,
      "learning_rate": 9.557529261558367e-05,
      "loss": 0.0154,
      "step": 3255
    },
    {
      "epoch": 33.06,
      "learning_rate": 9.557040812381462e-05,
      "loss": 0.0052,
      "step": 3256
    },
    {
      "epoch": 33.07,
      "learning_rate": 9.556552106246066e-05,
      "loss": 0.001,
      "step": 3257
    },
    {
      "epoch": 33.08,
      "learning_rate": 9.556063143179735e-05,
      "loss": 0.0009,
      "step": 3258
    },
    {
      "epoch": 33.09,
      "learning_rate": 9.555573923210042e-05,
      "loss": 0.0083,
      "step": 3259
    },
    {
      "epoch": 33.1,
      "learning_rate": 9.555084446364573e-05,
      "loss": 0.0111,
      "step": 3260
    },
    {
      "epoch": 33.11,
      "learning_rate": 9.554594712670926e-05,
      "loss": 0.0099,
      "step": 3261
    },
    {
      "epoch": 33.12,
      "learning_rate": 9.554104722156716e-05,
      "loss": 0.0008,
      "step": 3262
    },
    {
      "epoch": 33.13,
      "learning_rate": 9.553614474849573e-05,
      "loss": 0.001,
      "step": 3263
    },
    {
      "epoch": 33.14,
      "learning_rate": 9.55312397077714e-05,
      "loss": 0.0031,
      "step": 3264
    },
    {
      "epoch": 33.15,
      "learning_rate": 9.552633209967077e-05,
      "loss": 0.0012,
      "step": 3265
    },
    {
      "epoch": 33.16,
      "learning_rate": 9.552142192447054e-05,
      "loss": 0.0039,
      "step": 3266
    },
    {
      "epoch": 33.17,
      "learning_rate": 9.551650918244759e-05,
      "loss": 0.0158,
      "step": 3267
    },
    {
      "epoch": 33.18,
      "learning_rate": 9.551159387387896e-05,
      "loss": 0.0123,
      "step": 3268
    },
    {
      "epoch": 33.19,
      "learning_rate": 9.550667599904177e-05,
      "loss": 0.0246,
      "step": 3269
    },
    {
      "epoch": 33.2,
      "learning_rate": 9.550175555821333e-05,
      "loss": 0.019,
      "step": 3270
    },
    {
      "epoch": 33.21,
      "learning_rate": 9.549683255167113e-05,
      "loss": 0.0146,
      "step": 3271
    },
    {
      "epoch": 33.22,
      "learning_rate": 9.549190697969271e-05,
      "loss": 0.012,
      "step": 3272
    },
    {
      "epoch": 33.23,
      "learning_rate": 9.548697884255587e-05,
      "loss": 0.0022,
      "step": 3273
    },
    {
      "epoch": 33.24,
      "learning_rate": 9.548204814053842e-05,
      "loss": 0.0079,
      "step": 3274
    },
    {
      "epoch": 33.25,
      "learning_rate": 9.547711487391845e-05,
      "loss": 0.0224,
      "step": 3275
    },
    {
      "epoch": 33.26,
      "learning_rate": 9.547217904297411e-05,
      "loss": 0.0063,
      "step": 3276
    },
    {
      "epoch": 33.27,
      "learning_rate": 9.546724064798372e-05,
      "loss": 0.0113,
      "step": 3277
    },
    {
      "epoch": 33.28,
      "learning_rate": 9.546229968922574e-05,
      "loss": 0.0182,
      "step": 3278
    },
    {
      "epoch": 33.29,
      "learning_rate": 9.545735616697875e-05,
      "loss": 0.0025,
      "step": 3279
    },
    {
      "epoch": 33.3,
      "learning_rate": 9.545241008152155e-05,
      "loss": 0.0015,
      "step": 3280
    },
    {
      "epoch": 33.31,
      "learning_rate": 9.5447461433133e-05,
      "loss": 0.0018,
      "step": 3281
    },
    {
      "epoch": 33.32,
      "learning_rate": 9.544251022209217e-05,
      "loss": 0.0164,
      "step": 3282
    },
    {
      "epoch": 33.33,
      "learning_rate": 9.543755644867822e-05,
      "loss": 0.0248,
      "step": 3283
    },
    {
      "epoch": 33.34,
      "learning_rate": 9.543260011317048e-05,
      "loss": 0.0336,
      "step": 3284
    },
    {
      "epoch": 33.35,
      "learning_rate": 9.542764121584844e-05,
      "loss": 0.0185,
      "step": 3285
    },
    {
      "epoch": 33.36,
      "learning_rate": 9.542267975699171e-05,
      "loss": 0.0038,
      "step": 3286
    },
    {
      "epoch": 33.37,
      "learning_rate": 9.541771573688003e-05,
      "loss": 0.0226,
      "step": 3287
    },
    {
      "epoch": 33.38,
      "learning_rate": 9.541274915579335e-05,
      "loss": 0.0157,
      "step": 3288
    },
    {
      "epoch": 33.39,
      "learning_rate": 9.540778001401169e-05,
      "loss": 0.0027,
      "step": 3289
    },
    {
      "epoch": 33.4,
      "learning_rate": 9.540280831181525e-05,
      "loss": 0.0041,
      "step": 3290
    },
    {
      "epoch": 33.41,
      "learning_rate": 9.539783404948438e-05,
      "loss": 0.0067,
      "step": 3291
    },
    {
      "epoch": 33.42,
      "learning_rate": 9.539285722729956e-05,
      "loss": 0.0093,
      "step": 3292
    },
    {
      "epoch": 33.43,
      "learning_rate": 9.538787784554142e-05,
      "loss": 0.0257,
      "step": 3293
    },
    {
      "epoch": 33.44,
      "learning_rate": 9.538289590449072e-05,
      "loss": 0.0037,
      "step": 3294
    },
    {
      "epoch": 33.45,
      "learning_rate": 9.53779114044284e-05,
      "loss": 0.0194,
      "step": 3295
    },
    {
      "epoch": 33.46,
      "learning_rate": 9.537292434563551e-05,
      "loss": 0.0087,
      "step": 3296
    },
    {
      "epoch": 33.47,
      "learning_rate": 9.536793472839325e-05,
      "loss": 0.0023,
      "step": 3297
    },
    {
      "epoch": 33.48,
      "learning_rate": 9.536294255298297e-05,
      "loss": 0.0383,
      "step": 3298
    },
    {
      "epoch": 33.49,
      "learning_rate": 9.535794781968618e-05,
      "loss": 0.0027,
      "step": 3299
    },
    {
      "epoch": 33.5,
      "learning_rate": 9.53529505287845e-05,
      "loss": 0.0026,
      "step": 3300
    },
    {
      "epoch": 33.51,
      "learning_rate": 9.534795068055974e-05,
      "loss": 0.0028,
      "step": 3301
    },
    {
      "epoch": 33.52,
      "learning_rate": 9.53429482752938e-05,
      "loss": 0.0096,
      "step": 3302
    },
    {
      "epoch": 33.53,
      "learning_rate": 9.533794331326875e-05,
      "loss": 0.0111,
      "step": 3303
    },
    {
      "epoch": 33.54,
      "learning_rate": 9.533293579476683e-05,
      "loss": 0.0087,
      "step": 3304
    },
    {
      "epoch": 33.55,
      "learning_rate": 9.532792572007039e-05,
      "loss": 0.0047,
      "step": 3305
    },
    {
      "epoch": 33.56,
      "learning_rate": 9.53229130894619e-05,
      "loss": 0.0027,
      "step": 3306
    },
    {
      "epoch": 33.57,
      "learning_rate": 9.531789790322407e-05,
      "loss": 0.0089,
      "step": 3307
    },
    {
      "epoch": 33.58,
      "learning_rate": 9.531288016163966e-05,
      "loss": 0.0054,
      "step": 3308
    },
    {
      "epoch": 33.59,
      "learning_rate": 9.530785986499157e-05,
      "loss": 0.0168,
      "step": 3309
    },
    {
      "epoch": 33.6,
      "learning_rate": 9.530283701356296e-05,
      "loss": 0.0227,
      "step": 3310
    },
    {
      "epoch": 33.61,
      "learning_rate": 9.529781160763698e-05,
      "loss": 0.0212,
      "step": 3311
    },
    {
      "epoch": 33.62,
      "learning_rate": 9.529278364749703e-05,
      "loss": 0.0009,
      "step": 3312
    },
    {
      "epoch": 33.63,
      "learning_rate": 9.528775313342663e-05,
      "loss": 0.0266,
      "step": 3313
    },
    {
      "epoch": 33.64,
      "learning_rate": 9.528272006570942e-05,
      "loss": 0.0019,
      "step": 3314
    },
    {
      "epoch": 33.65,
      "learning_rate": 9.527768444462922e-05,
      "loss": 0.002,
      "step": 3315
    },
    {
      "epoch": 33.66,
      "learning_rate": 9.527264627046995e-05,
      "loss": 0.0221,
      "step": 3316
    },
    {
      "epoch": 33.68,
      "learning_rate": 9.526760554351573e-05,
      "loss": 0.0111,
      "step": 3317
    },
    {
      "epoch": 33.69,
      "learning_rate": 9.526256226405075e-05,
      "loss": 0.0145,
      "step": 3318
    },
    {
      "epoch": 33.7,
      "learning_rate": 9.52575164323594e-05,
      "loss": 0.01,
      "step": 3319
    },
    {
      "epoch": 33.71,
      "learning_rate": 9.525246804872623e-05,
      "loss": 0.0104,
      "step": 3320
    },
    {
      "epoch": 33.72,
      "learning_rate": 9.524741711343586e-05,
      "loss": 0.0094,
      "step": 3321
    },
    {
      "epoch": 33.73,
      "learning_rate": 9.524236362677315e-05,
      "loss": 0.0293,
      "step": 3322
    },
    {
      "epoch": 33.74,
      "learning_rate": 9.523730758902299e-05,
      "loss": 0.0315,
      "step": 3323
    },
    {
      "epoch": 33.75,
      "learning_rate": 9.523224900047052e-05,
      "loss": 0.005,
      "step": 3324
    },
    {
      "epoch": 33.76,
      "learning_rate": 9.522718786140097e-05,
      "loss": 0.003,
      "step": 3325
    },
    {
      "epoch": 33.77,
      "learning_rate": 9.52221241720997e-05,
      "loss": 0.0046,
      "step": 3326
    },
    {
      "epoch": 33.78,
      "learning_rate": 9.521705793285229e-05,
      "loss": 0.0165,
      "step": 3327
    },
    {
      "epoch": 33.79,
      "learning_rate": 9.521198914394434e-05,
      "loss": 0.0278,
      "step": 3328
    },
    {
      "epoch": 33.8,
      "learning_rate": 9.520691780566174e-05,
      "loss": 0.013,
      "step": 3329
    },
    {
      "epoch": 33.81,
      "learning_rate": 9.520184391829036e-05,
      "loss": 0.0113,
      "step": 3330
    },
    {
      "epoch": 33.82,
      "learning_rate": 9.51967674821164e-05,
      "loss": 0.0013,
      "step": 3331
    },
    {
      "epoch": 33.83,
      "learning_rate": 9.519168849742604e-05,
      "loss": 0.0126,
      "step": 3332
    },
    {
      "epoch": 33.84,
      "learning_rate": 9.518660696450568e-05,
      "loss": 0.0105,
      "step": 3333
    },
    {
      "epoch": 33.85,
      "learning_rate": 9.518152288364186e-05,
      "loss": 0.0077,
      "step": 3334
    },
    {
      "epoch": 33.86,
      "learning_rate": 9.517643625512126e-05,
      "loss": 0.0049,
      "step": 3335
    },
    {
      "epoch": 33.87,
      "learning_rate": 9.51713470792307e-05,
      "loss": 0.0135,
      "step": 3336
    },
    {
      "epoch": 33.88,
      "learning_rate": 9.516625535625714e-05,
      "loss": 0.03,
      "step": 3337
    },
    {
      "epoch": 33.89,
      "learning_rate": 9.516116108648769e-05,
      "loss": 0.0185,
      "step": 3338
    },
    {
      "epoch": 33.9,
      "learning_rate": 9.515606427020959e-05,
      "loss": 0.0034,
      "step": 3339
    },
    {
      "epoch": 33.91,
      "learning_rate": 9.515096490771025e-05,
      "loss": 0.0106,
      "step": 3340
    },
    {
      "epoch": 33.92,
      "learning_rate": 9.514586299927721e-05,
      "loss": 0.0138,
      "step": 3341
    },
    {
      "epoch": 33.93,
      "learning_rate": 9.514075854519814e-05,
      "loss": 0.0012,
      "step": 3342
    },
    {
      "epoch": 33.94,
      "learning_rate": 9.513565154576087e-05,
      "loss": 0.0089,
      "step": 3343
    },
    {
      "epoch": 33.95,
      "learning_rate": 9.513054200125337e-05,
      "loss": 0.0214,
      "step": 3344
    },
    {
      "epoch": 33.96,
      "learning_rate": 9.512542991196376e-05,
      "loss": 0.0157,
      "step": 3345
    },
    {
      "epoch": 33.97,
      "learning_rate": 9.512031527818028e-05,
      "loss": 0.0022,
      "step": 3346
    },
    {
      "epoch": 33.98,
      "learning_rate": 9.511519810019133e-05,
      "loss": 0.066,
      "step": 3347
    },
    {
      "epoch": 33.99,
      "learning_rate": 9.51100783782855e-05,
      "loss": 0.0019,
      "step": 3348
    },
    {
      "epoch": 34.0,
      "learning_rate": 9.510495611275139e-05,
      "loss": 0.0046,
      "step": 3349
    },
    {
      "epoch": 34.0,
      "eval_loss": 0.020754743367433548,
      "eval_runtime": 32.4644,
      "eval_samples_per_second": 97.029,
      "eval_steps_per_second": 6.068,
      "eval_wer": 0.006402048655569782,
      "step": 3349
    },
    {
      "epoch": 34.01,
      "learning_rate": 9.50998313038779e-05,
      "loss": 0.0082,
      "step": 3350
    },
    {
      "epoch": 34.02,
      "learning_rate": 9.509470395195399e-05,
      "loss": 0.0245,
      "step": 3351
    },
    {
      "epoch": 34.03,
      "learning_rate": 9.508957405726875e-05,
      "loss": 0.001,
      "step": 3352
    },
    {
      "epoch": 34.04,
      "learning_rate": 9.508444162011148e-05,
      "loss": 0.0013,
      "step": 3353
    },
    {
      "epoch": 34.05,
      "learning_rate": 9.507930664077153e-05,
      "loss": 0.0321,
      "step": 3354
    },
    {
      "epoch": 34.06,
      "learning_rate": 9.50741691195385e-05,
      "loss": 0.0139,
      "step": 3355
    },
    {
      "epoch": 34.07,
      "learning_rate": 9.506902905670205e-05,
      "loss": 0.0052,
      "step": 3356
    },
    {
      "epoch": 34.08,
      "learning_rate": 9.506388645255202e-05,
      "loss": 0.0028,
      "step": 3357
    },
    {
      "epoch": 34.09,
      "learning_rate": 9.50587413073784e-05,
      "loss": 0.0085,
      "step": 3358
    },
    {
      "epoch": 34.1,
      "learning_rate": 9.505359362147129e-05,
      "loss": 0.0022,
      "step": 3359
    },
    {
      "epoch": 34.11,
      "learning_rate": 9.504844339512095e-05,
      "loss": 0.0018,
      "step": 3360
    },
    {
      "epoch": 34.12,
      "learning_rate": 9.504329062861782e-05,
      "loss": 0.0072,
      "step": 3361
    },
    {
      "epoch": 34.13,
      "learning_rate": 9.503813532225242e-05,
      "loss": 0.0147,
      "step": 3362
    },
    {
      "epoch": 34.14,
      "learning_rate": 9.503297747631546e-05,
      "loss": 0.0044,
      "step": 3363
    },
    {
      "epoch": 34.15,
      "learning_rate": 9.502781709109775e-05,
      "loss": 0.011,
      "step": 3364
    },
    {
      "epoch": 34.16,
      "learning_rate": 9.50226541668903e-05,
      "loss": 0.0146,
      "step": 3365
    },
    {
      "epoch": 34.17,
      "learning_rate": 9.50174887039842e-05,
      "loss": 0.011,
      "step": 3366
    },
    {
      "epoch": 34.18,
      "learning_rate": 9.501232070267074e-05,
      "loss": 0.0033,
      "step": 3367
    },
    {
      "epoch": 34.19,
      "learning_rate": 9.500715016324133e-05,
      "loss": 0.0097,
      "step": 3368
    },
    {
      "epoch": 34.2,
      "learning_rate": 9.500197708598753e-05,
      "loss": 0.005,
      "step": 3369
    },
    {
      "epoch": 34.21,
      "learning_rate": 9.499680147120101e-05,
      "loss": 0.01,
      "step": 3370
    },
    {
      "epoch": 34.22,
      "learning_rate": 9.499162331917359e-05,
      "loss": 0.0036,
      "step": 3371
    },
    {
      "epoch": 34.23,
      "learning_rate": 9.498644263019731e-05,
      "loss": 0.0172,
      "step": 3372
    },
    {
      "epoch": 34.24,
      "learning_rate": 9.498125940456427e-05,
      "loss": 0.0297,
      "step": 3373
    },
    {
      "epoch": 34.25,
      "learning_rate": 9.497607364256672e-05,
      "loss": 0.0039,
      "step": 3374
    },
    {
      "epoch": 34.26,
      "learning_rate": 9.497088534449708e-05,
      "loss": 0.0018,
      "step": 3375
    },
    {
      "epoch": 34.27,
      "learning_rate": 9.49656945106479e-05,
      "loss": 0.0013,
      "step": 3376
    },
    {
      "epoch": 34.28,
      "learning_rate": 9.496050114131188e-05,
      "loss": 0.0043,
      "step": 3377
    },
    {
      "epoch": 34.29,
      "learning_rate": 9.495530523678187e-05,
      "loss": 0.0037,
      "step": 3378
    },
    {
      "epoch": 34.3,
      "learning_rate": 9.495010679735083e-05,
      "loss": 0.0092,
      "step": 3379
    },
    {
      "epoch": 34.31,
      "learning_rate": 9.49449058233119e-05,
      "loss": 0.0018,
      "step": 3380
    },
    {
      "epoch": 34.32,
      "learning_rate": 9.493970231495835e-05,
      "loss": 0.0098,
      "step": 3381
    },
    {
      "epoch": 34.34,
      "learning_rate": 9.49344962725836e-05,
      "loss": 0.003,
      "step": 3382
    },
    {
      "epoch": 34.35,
      "learning_rate": 9.492928769648118e-05,
      "loss": 0.0202,
      "step": 3383
    },
    {
      "epoch": 34.36,
      "learning_rate": 9.492407658694478e-05,
      "loss": 0.0106,
      "step": 3384
    },
    {
      "epoch": 34.37,
      "learning_rate": 9.491886294426828e-05,
      "loss": 0.0031,
      "step": 3385
    },
    {
      "epoch": 34.38,
      "learning_rate": 9.491364676874562e-05,
      "loss": 0.0146,
      "step": 3386
    },
    {
      "epoch": 34.39,
      "learning_rate": 9.490842806067095e-05,
      "loss": 0.0014,
      "step": 3387
    },
    {
      "epoch": 34.4,
      "learning_rate": 9.490320682033855e-05,
      "loss": 0.0015,
      "step": 3388
    },
    {
      "epoch": 34.41,
      "learning_rate": 9.48979830480428e-05,
      "loss": 0.0045,
      "step": 3389
    },
    {
      "epoch": 34.42,
      "learning_rate": 9.489275674407826e-05,
      "loss": 0.0046,
      "step": 3390
    },
    {
      "epoch": 34.43,
      "learning_rate": 9.488752790873963e-05,
      "loss": 0.0308,
      "step": 3391
    },
    {
      "epoch": 34.44,
      "learning_rate": 9.488229654232178e-05,
      "loss": 0.0044,
      "step": 3392
    },
    {
      "epoch": 34.45,
      "learning_rate": 9.487706264511963e-05,
      "loss": 0.0447,
      "step": 3393
    },
    {
      "epoch": 34.46,
      "learning_rate": 9.487182621742836e-05,
      "loss": 0.0039,
      "step": 3394
    },
    {
      "epoch": 34.47,
      "learning_rate": 9.486658725954321e-05,
      "loss": 0.0016,
      "step": 3395
    },
    {
      "epoch": 34.48,
      "learning_rate": 9.486134577175958e-05,
      "loss": 0.0442,
      "step": 3396
    },
    {
      "epoch": 34.49,
      "learning_rate": 9.485610175437305e-05,
      "loss": 0.0445,
      "step": 3397
    },
    {
      "epoch": 34.5,
      "learning_rate": 9.48508552076793e-05,
      "loss": 0.0018,
      "step": 3398
    },
    {
      "epoch": 34.51,
      "learning_rate": 9.484560613197418e-05,
      "loss": 0.0038,
      "step": 3399
    },
    {
      "epoch": 34.52,
      "learning_rate": 9.484035452755367e-05,
      "loss": 0.0126,
      "step": 3400
    },
    {
      "epoch": 34.53,
      "learning_rate": 9.483510039471386e-05,
      "loss": 0.0025,
      "step": 3401
    },
    {
      "epoch": 34.54,
      "learning_rate": 9.482984373375105e-05,
      "loss": 0.0235,
      "step": 3402
    },
    {
      "epoch": 34.55,
      "learning_rate": 9.482458454496164e-05,
      "loss": 0.0078,
      "step": 3403
    },
    {
      "epoch": 34.56,
      "learning_rate": 9.481932282864217e-05,
      "loss": 0.0093,
      "step": 3404
    },
    {
      "epoch": 34.57,
      "learning_rate": 9.481405858508934e-05,
      "loss": 0.0267,
      "step": 3405
    },
    {
      "epoch": 34.58,
      "learning_rate": 9.480879181459999e-05,
      "loss": 0.0094,
      "step": 3406
    },
    {
      "epoch": 34.59,
      "learning_rate": 9.48035225174711e-05,
      "loss": 0.0176,
      "step": 3407
    },
    {
      "epoch": 34.6,
      "learning_rate": 9.479825069399978e-05,
      "loss": 0.0102,
      "step": 3408
    },
    {
      "epoch": 34.61,
      "learning_rate": 9.47929763444833e-05,
      "loss": 0.0216,
      "step": 3409
    },
    {
      "epoch": 34.62,
      "learning_rate": 9.478769946921906e-05,
      "loss": 0.017,
      "step": 3410
    },
    {
      "epoch": 34.63,
      "learning_rate": 9.478242006850461e-05,
      "loss": 0.0029,
      "step": 3411
    },
    {
      "epoch": 34.64,
      "learning_rate": 9.477713814263767e-05,
      "loss": 0.005,
      "step": 3412
    },
    {
      "epoch": 34.65,
      "learning_rate": 9.477185369191602e-05,
      "loss": 0.0015,
      "step": 3413
    },
    {
      "epoch": 34.66,
      "learning_rate": 9.476656671663765e-05,
      "loss": 0.0119,
      "step": 3414
    },
    {
      "epoch": 34.67,
      "learning_rate": 9.476127721710071e-05,
      "loss": 0.0014,
      "step": 3415
    },
    {
      "epoch": 34.68,
      "learning_rate": 9.475598519360344e-05,
      "loss": 0.0074,
      "step": 3416
    },
    {
      "epoch": 34.69,
      "learning_rate": 9.475069064644422e-05,
      "loss": 0.0053,
      "step": 3417
    },
    {
      "epoch": 34.7,
      "learning_rate": 9.474539357592162e-05,
      "loss": 0.0335,
      "step": 3418
    },
    {
      "epoch": 34.71,
      "learning_rate": 9.474009398233432e-05,
      "loss": 0.0028,
      "step": 3419
    },
    {
      "epoch": 34.72,
      "learning_rate": 9.473479186598116e-05,
      "loss": 0.0009,
      "step": 3420
    },
    {
      "epoch": 34.73,
      "learning_rate": 9.472948722716109e-05,
      "loss": 0.0017,
      "step": 3421
    },
    {
      "epoch": 34.74,
      "learning_rate": 9.472418006617323e-05,
      "loss": 0.0003,
      "step": 3422
    },
    {
      "epoch": 34.75,
      "learning_rate": 9.471887038331685e-05,
      "loss": 0.0019,
      "step": 3423
    },
    {
      "epoch": 34.76,
      "learning_rate": 9.471355817889133e-05,
      "loss": 0.0067,
      "step": 3424
    },
    {
      "epoch": 34.77,
      "learning_rate": 9.470824345319622e-05,
      "loss": 0.0008,
      "step": 3425
    },
    {
      "epoch": 34.78,
      "learning_rate": 9.470292620653119e-05,
      "loss": 0.012,
      "step": 3426
    },
    {
      "epoch": 34.79,
      "learning_rate": 9.469760643919608e-05,
      "loss": 0.008,
      "step": 3427
    },
    {
      "epoch": 34.8,
      "learning_rate": 9.469228415149085e-05,
      "loss": 0.0216,
      "step": 3428
    },
    {
      "epoch": 34.81,
      "learning_rate": 9.468695934371561e-05,
      "loss": 0.0012,
      "step": 3429
    },
    {
      "epoch": 34.82,
      "learning_rate": 9.468163201617062e-05,
      "loss": 0.0185,
      "step": 3430
    },
    {
      "epoch": 34.83,
      "learning_rate": 9.467630216915625e-05,
      "loss": 0.0119,
      "step": 3431
    },
    {
      "epoch": 34.84,
      "learning_rate": 9.467096980297305e-05,
      "loss": 0.024,
      "step": 3432
    },
    {
      "epoch": 34.85,
      "learning_rate": 9.466563491792168e-05,
      "loss": 0.0047,
      "step": 3433
    },
    {
      "epoch": 34.86,
      "learning_rate": 9.4660297514303e-05,
      "loss": 0.018,
      "step": 3434
    },
    {
      "epoch": 34.87,
      "learning_rate": 9.465495759241792e-05,
      "loss": 0.0036,
      "step": 3435
    },
    {
      "epoch": 34.88,
      "learning_rate": 9.464961515256758e-05,
      "loss": 0.0054,
      "step": 3436
    },
    {
      "epoch": 34.89,
      "learning_rate": 9.46442701950532e-05,
      "loss": 0.0161,
      "step": 3437
    },
    {
      "epoch": 34.9,
      "learning_rate": 9.46389227201762e-05,
      "loss": 0.0027,
      "step": 3438
    },
    {
      "epoch": 34.91,
      "learning_rate": 9.463357272823806e-05,
      "loss": 0.0013,
      "step": 3439
    },
    {
      "epoch": 34.92,
      "learning_rate": 9.46282202195405e-05,
      "loss": 0.0177,
      "step": 3440
    },
    {
      "epoch": 34.93,
      "learning_rate": 9.46228651943853e-05,
      "loss": 0.0069,
      "step": 3441
    },
    {
      "epoch": 34.94,
      "learning_rate": 9.461750765307442e-05,
      "loss": 0.0013,
      "step": 3442
    },
    {
      "epoch": 34.95,
      "learning_rate": 9.461214759590998e-05,
      "loss": 0.001,
      "step": 3443
    },
    {
      "epoch": 34.96,
      "learning_rate": 9.460678502319418e-05,
      "loss": 0.0403,
      "step": 3444
    },
    {
      "epoch": 34.97,
      "learning_rate": 9.460141993522942e-05,
      "loss": 0.0098,
      "step": 3445
    },
    {
      "epoch": 34.98,
      "learning_rate": 9.459605233231823e-05,
      "loss": 0.0028,
      "step": 3446
    },
    {
      "epoch": 34.99,
      "learning_rate": 9.459068221476327e-05,
      "loss": 0.0131,
      "step": 3447
    },
    {
      "epoch": 34.99,
      "eval_loss": 0.017536770552396774,
      "eval_runtime": 32.024,
      "eval_samples_per_second": 98.364,
      "eval_steps_per_second": 6.152,
      "eval_wer": 0.005121638924455826,
      "step": 3447
    },
    {
      "epoch": 35.01,
      "learning_rate": 9.458530958286733e-05,
      "loss": 0.0022,
      "step": 3448
    },
    {
      "epoch": 35.02,
      "learning_rate": 9.457993443693337e-05,
      "loss": 0.0005,
      "step": 3449
    },
    {
      "epoch": 35.03,
      "learning_rate": 9.457455677726448e-05,
      "loss": 0.0035,
      "step": 3450
    },
    {
      "epoch": 35.04,
      "learning_rate": 9.456917660416389e-05,
      "loss": 0.0143,
      "step": 3451
    },
    {
      "epoch": 35.05,
      "learning_rate": 9.456379391793497e-05,
      "loss": 0.0034,
      "step": 3452
    },
    {
      "epoch": 35.06,
      "learning_rate": 9.455840871888125e-05,
      "loss": 0.0086,
      "step": 3453
    },
    {
      "epoch": 35.07,
      "learning_rate": 9.455302100730634e-05,
      "loss": 0.0022,
      "step": 3454
    },
    {
      "epoch": 35.08,
      "learning_rate": 9.45476307835141e-05,
      "loss": 0.0199,
      "step": 3455
    },
    {
      "epoch": 35.09,
      "learning_rate": 9.454223804780841e-05,
      "loss": 0.0106,
      "step": 3456
    },
    {
      "epoch": 35.1,
      "learning_rate": 9.45368428004934e-05,
      "loss": 0.0095,
      "step": 3457
    },
    {
      "epoch": 35.11,
      "learning_rate": 9.453144504187327e-05,
      "loss": 0.0133,
      "step": 3458
    },
    {
      "epoch": 35.12,
      "learning_rate": 9.452604477225238e-05,
      "loss": 0.0006,
      "step": 3459
    },
    {
      "epoch": 35.13,
      "learning_rate": 9.452064199193525e-05,
      "loss": 0.0081,
      "step": 3460
    },
    {
      "epoch": 35.14,
      "learning_rate": 9.45152367012265e-05,
      "loss": 0.0019,
      "step": 3461
    },
    {
      "epoch": 35.15,
      "learning_rate": 9.450982890043096e-05,
      "loss": 0.0108,
      "step": 3462
    },
    {
      "epoch": 35.16,
      "learning_rate": 9.450441858985352e-05,
      "loss": 0.015,
      "step": 3463
    },
    {
      "epoch": 35.17,
      "learning_rate": 9.449900576979927e-05,
      "loss": 0.0193,
      "step": 3464
    },
    {
      "epoch": 35.18,
      "learning_rate": 9.449359044057345e-05,
      "loss": 0.0024,
      "step": 3465
    },
    {
      "epoch": 35.19,
      "learning_rate": 9.448817260248135e-05,
      "loss": 0.0109,
      "step": 3466
    },
    {
      "epoch": 35.2,
      "learning_rate": 9.448275225582852e-05,
      "loss": 0.0026,
      "step": 3467
    },
    {
      "epoch": 35.21,
      "learning_rate": 9.44773294009206e-05,
      "loss": 0.0034,
      "step": 3468
    },
    {
      "epoch": 35.22,
      "learning_rate": 9.447190403806335e-05,
      "loss": 0.0046,
      "step": 3469
    },
    {
      "epoch": 35.23,
      "learning_rate": 9.446647616756267e-05,
      "loss": 0.0094,
      "step": 3470
    },
    {
      "epoch": 35.24,
      "learning_rate": 9.446104578972466e-05,
      "loss": 0.0143,
      "step": 3471
    },
    {
      "epoch": 35.25,
      "learning_rate": 9.445561290485549e-05,
      "loss": 0.0035,
      "step": 3472
    },
    {
      "epoch": 35.26,
      "learning_rate": 9.445017751326156e-05,
      "loss": 0.0041,
      "step": 3473
    },
    {
      "epoch": 35.27,
      "learning_rate": 9.444473961524927e-05,
      "loss": 0.0014,
      "step": 3474
    },
    {
      "epoch": 35.28,
      "learning_rate": 9.443929921112533e-05,
      "loss": 0.0019,
      "step": 3475
    },
    {
      "epoch": 35.29,
      "learning_rate": 9.443385630119648e-05,
      "loss": 0.0004,
      "step": 3476
    },
    {
      "epoch": 35.3,
      "learning_rate": 9.442841088576962e-05,
      "loss": 0.0189,
      "step": 3477
    },
    {
      "epoch": 35.31,
      "learning_rate": 9.442296296515179e-05,
      "loss": 0.0046,
      "step": 3478
    },
    {
      "epoch": 35.32,
      "learning_rate": 9.441751253965021e-05,
      "loss": 0.0019,
      "step": 3479
    },
    {
      "epoch": 35.33,
      "learning_rate": 9.44120596095722e-05,
      "loss": 0.0129,
      "step": 3480
    },
    {
      "epoch": 35.34,
      "learning_rate": 9.440660417522525e-05,
      "loss": 0.0114,
      "step": 3481
    },
    {
      "epoch": 35.35,
      "learning_rate": 9.440114623691696e-05,
      "loss": 0.0175,
      "step": 3482
    },
    {
      "epoch": 35.36,
      "learning_rate": 9.439568579495508e-05,
      "loss": 0.0016,
      "step": 3483
    },
    {
      "epoch": 35.37,
      "learning_rate": 9.439022284964753e-05,
      "loss": 0.0244,
      "step": 3484
    },
    {
      "epoch": 35.38,
      "learning_rate": 9.438475740130234e-05,
      "loss": 0.0061,
      "step": 3485
    },
    {
      "epoch": 35.39,
      "learning_rate": 9.437928945022771e-05,
      "loss": 0.0072,
      "step": 3486
    },
    {
      "epoch": 35.4,
      "learning_rate": 9.437381899673192e-05,
      "loss": 0.0024,
      "step": 3487
    },
    {
      "epoch": 35.41,
      "learning_rate": 9.436834604112348e-05,
      "loss": 0.0012,
      "step": 3488
    },
    {
      "epoch": 35.42,
      "learning_rate": 9.436287058371096e-05,
      "loss": 0.01,
      "step": 3489
    },
    {
      "epoch": 35.43,
      "learning_rate": 9.43573926248031e-05,
      "loss": 0.0058,
      "step": 3490
    },
    {
      "epoch": 35.44,
      "learning_rate": 9.435191216470882e-05,
      "loss": 0.0285,
      "step": 3491
    },
    {
      "epoch": 35.45,
      "learning_rate": 9.434642920373715e-05,
      "loss": 0.0204,
      "step": 3492
    },
    {
      "epoch": 35.46,
      "learning_rate": 9.434094374219722e-05,
      "loss": 0.0029,
      "step": 3493
    },
    {
      "epoch": 35.47,
      "learning_rate": 9.433545578039835e-05,
      "loss": 0.0011,
      "step": 3494
    },
    {
      "epoch": 35.48,
      "learning_rate": 9.432996531865002e-05,
      "loss": 0.008,
      "step": 3495
    },
    {
      "epoch": 35.49,
      "learning_rate": 9.432447235726178e-05,
      "loss": 0.0005,
      "step": 3496
    },
    {
      "epoch": 35.5,
      "learning_rate": 9.431897689654338e-05,
      "loss": 0.0017,
      "step": 3497
    },
    {
      "epoch": 35.51,
      "learning_rate": 9.431347893680473e-05,
      "loss": 0.0161,
      "step": 3498
    },
    {
      "epoch": 35.52,
      "learning_rate": 9.430797847835577e-05,
      "loss": 0.013,
      "step": 3499
    },
    {
      "epoch": 35.53,
      "learning_rate": 9.430247552150673e-05,
      "loss": 0.0078,
      "step": 3500
    },
    {
      "epoch": 35.54,
      "learning_rate": 9.429697006656785e-05,
      "loss": 0.0036,
      "step": 3501
    },
    {
      "epoch": 35.55,
      "learning_rate": 9.429146211384961e-05,
      "loss": 0.0175,
      "step": 3502
    },
    {
      "epoch": 35.56,
      "learning_rate": 9.428595166366254e-05,
      "loss": 0.0116,
      "step": 3503
    },
    {
      "epoch": 35.57,
      "learning_rate": 9.42804387163174e-05,
      "loss": 0.0093,
      "step": 3504
    },
    {
      "epoch": 35.58,
      "learning_rate": 9.427492327212504e-05,
      "loss": 0.0053,
      "step": 3505
    },
    {
      "epoch": 35.59,
      "learning_rate": 9.426940533139643e-05,
      "loss": 0.0022,
      "step": 3506
    },
    {
      "epoch": 35.6,
      "learning_rate": 9.426388489444276e-05,
      "loss": 0.0075,
      "step": 3507
    },
    {
      "epoch": 35.61,
      "learning_rate": 9.425836196157527e-05,
      "loss": 0.0155,
      "step": 3508
    },
    {
      "epoch": 35.62,
      "learning_rate": 9.425283653310542e-05,
      "loss": 0.0177,
      "step": 3509
    },
    {
      "epoch": 35.63,
      "learning_rate": 9.424730860934472e-05,
      "loss": 0.0098,
      "step": 3510
    },
    {
      "epoch": 35.64,
      "learning_rate": 9.424177819060494e-05,
      "loss": 0.0214,
      "step": 3511
    },
    {
      "epoch": 35.65,
      "learning_rate": 9.423624527719788e-05,
      "loss": 0.0284,
      "step": 3512
    },
    {
      "epoch": 35.66,
      "learning_rate": 9.423070986943553e-05,
      "loss": 0.0217,
      "step": 3513
    },
    {
      "epoch": 35.68,
      "learning_rate": 9.422517196763002e-05,
      "loss": 0.0086,
      "step": 3514
    },
    {
      "epoch": 35.69,
      "learning_rate": 9.421963157209363e-05,
      "loss": 0.0006,
      "step": 3515
    },
    {
      "epoch": 35.7,
      "learning_rate": 9.421408868313874e-05,
      "loss": 0.0021,
      "step": 3516
    },
    {
      "epoch": 35.71,
      "learning_rate": 9.420854330107792e-05,
      "loss": 0.0209,
      "step": 3517
    },
    {
      "epoch": 35.72,
      "learning_rate": 9.420299542622385e-05,
      "loss": 0.0022,
      "step": 3518
    },
    {
      "epoch": 35.73,
      "learning_rate": 9.419744505888937e-05,
      "loss": 0.0057,
      "step": 3519
    },
    {
      "epoch": 35.74,
      "learning_rate": 9.419189219938742e-05,
      "loss": 0.0108,
      "step": 3520
    },
    {
      "epoch": 35.75,
      "learning_rate": 9.418633684803114e-05,
      "loss": 0.0008,
      "step": 3521
    },
    {
      "epoch": 35.76,
      "learning_rate": 9.418077900513377e-05,
      "loss": 0.015,
      "step": 3522
    },
    {
      "epoch": 35.77,
      "learning_rate": 9.41752186710087e-05,
      "loss": 0.0032,
      "step": 3523
    },
    {
      "epoch": 35.78,
      "learning_rate": 9.416965584596946e-05,
      "loss": 0.0065,
      "step": 3524
    },
    {
      "epoch": 35.79,
      "learning_rate": 9.416409053032972e-05,
      "loss": 0.0041,
      "step": 3525
    },
    {
      "epoch": 35.8,
      "learning_rate": 9.41585227244033e-05,
      "loss": 0.0135,
      "step": 3526
    },
    {
      "epoch": 35.81,
      "learning_rate": 9.415295242850415e-05,
      "loss": 0.0153,
      "step": 3527
    },
    {
      "epoch": 35.82,
      "learning_rate": 9.414737964294636e-05,
      "loss": 0.0091,
      "step": 3528
    },
    {
      "epoch": 35.83,
      "learning_rate": 9.414180436804416e-05,
      "loss": 0.0022,
      "step": 3529
    },
    {
      "epoch": 35.84,
      "learning_rate": 9.413622660411192e-05,
      "loss": 0.0042,
      "step": 3530
    },
    {
      "epoch": 35.85,
      "learning_rate": 9.413064635146418e-05,
      "loss": 0.0268,
      "step": 3531
    },
    {
      "epoch": 35.86,
      "learning_rate": 9.412506361041557e-05,
      "loss": 0.0018,
      "step": 3532
    },
    {
      "epoch": 35.87,
      "learning_rate": 9.411947838128089e-05,
      "loss": 0.0023,
      "step": 3533
    },
    {
      "epoch": 35.88,
      "learning_rate": 9.411389066437508e-05,
      "loss": 0.0039,
      "step": 3534
    },
    {
      "epoch": 35.89,
      "learning_rate": 9.410830046001321e-05,
      "loss": 0.0017,
      "step": 3535
    },
    {
      "epoch": 35.9,
      "learning_rate": 9.41027077685105e-05,
      "loss": 0.0026,
      "step": 3536
    },
    {
      "epoch": 35.91,
      "learning_rate": 9.40971125901823e-05,
      "loss": 0.0375,
      "step": 3537
    },
    {
      "epoch": 35.92,
      "learning_rate": 9.409151492534412e-05,
      "loss": 0.0209,
      "step": 3538
    },
    {
      "epoch": 35.93,
      "learning_rate": 9.408591477431156e-05,
      "loss": 0.0024,
      "step": 3539
    },
    {
      "epoch": 35.94,
      "learning_rate": 9.408031213740045e-05,
      "loss": 0.0053,
      "step": 3540
    },
    {
      "epoch": 35.95,
      "learning_rate": 9.407470701492667e-05,
      "loss": 0.0106,
      "step": 3541
    },
    {
      "epoch": 35.96,
      "learning_rate": 9.40690994072063e-05,
      "loss": 0.0118,
      "step": 3542
    },
    {
      "epoch": 35.97,
      "learning_rate": 9.40634893145555e-05,
      "loss": 0.0031,
      "step": 3543
    },
    {
      "epoch": 35.98,
      "learning_rate": 9.405787673729065e-05,
      "loss": 0.002,
      "step": 3544
    },
    {
      "epoch": 35.99,
      "learning_rate": 9.405226167572819e-05,
      "loss": 0.0062,
      "step": 3545
    },
    {
      "epoch": 36.0,
      "learning_rate": 9.404664413018476e-05,
      "loss": 0.0057,
      "step": 3546
    },
    {
      "epoch": 36.0,
      "eval_loss": 0.016344914212822914,
      "eval_runtime": 31.9319,
      "eval_samples_per_second": 98.647,
      "eval_steps_per_second": 6.169,
      "eval_wer": 0.006338028169014085,
      "step": 3546
    },
    {
      "epoch": 36.01,
      "learning_rate": 9.404102410097713e-05,
      "loss": 0.0008,
      "step": 3547
    },
    {
      "epoch": 36.02,
      "learning_rate": 9.403540158842215e-05,
      "loss": 0.0009,
      "step": 3548
    },
    {
      "epoch": 36.03,
      "learning_rate": 9.40297765928369e-05,
      "loss": 0.0024,
      "step": 3549
    },
    {
      "epoch": 36.04,
      "learning_rate": 9.402414911453854e-05,
      "loss": 0.0045,
      "step": 3550
    },
    {
      "epoch": 36.05,
      "learning_rate": 9.40185191538444e-05,
      "loss": 0.0012,
      "step": 3551
    },
    {
      "epoch": 36.06,
      "learning_rate": 9.401288671107194e-05,
      "loss": 0.0087,
      "step": 3552
    },
    {
      "epoch": 36.07,
      "learning_rate": 9.400725178653872e-05,
      "loss": 0.0109,
      "step": 3553
    },
    {
      "epoch": 36.08,
      "learning_rate": 9.400161438056252e-05,
      "loss": 0.0029,
      "step": 3554
    },
    {
      "epoch": 36.09,
      "learning_rate": 9.39959744934612e-05,
      "loss": 0.0175,
      "step": 3555
    },
    {
      "epoch": 36.1,
      "learning_rate": 9.399033212555275e-05,
      "loss": 0.0099,
      "step": 3556
    },
    {
      "epoch": 36.11,
      "learning_rate": 9.39846872771554e-05,
      "loss": 0.0009,
      "step": 3557
    },
    {
      "epoch": 36.12,
      "learning_rate": 9.397903994858737e-05,
      "loss": 0.0223,
      "step": 3558
    },
    {
      "epoch": 36.13,
      "learning_rate": 9.397339014016712e-05,
      "loss": 0.0061,
      "step": 3559
    },
    {
      "epoch": 36.14,
      "learning_rate": 9.396773785221326e-05,
      "loss": 0.0121,
      "step": 3560
    },
    {
      "epoch": 36.15,
      "learning_rate": 9.396208308504448e-05,
      "loss": 0.0023,
      "step": 3561
    },
    {
      "epoch": 36.16,
      "learning_rate": 9.395642583897963e-05,
      "loss": 0.0102,
      "step": 3562
    },
    {
      "epoch": 36.17,
      "learning_rate": 9.39507661143377e-05,
      "loss": 0.0056,
      "step": 3563
    },
    {
      "epoch": 36.18,
      "learning_rate": 9.394510391143787e-05,
      "loss": 0.0079,
      "step": 3564
    },
    {
      "epoch": 36.19,
      "learning_rate": 9.393943923059936e-05,
      "loss": 0.0054,
      "step": 3565
    },
    {
      "epoch": 36.2,
      "learning_rate": 9.393377207214162e-05,
      "loss": 0.0057,
      "step": 3566
    },
    {
      "epoch": 36.21,
      "learning_rate": 9.392810243638419e-05,
      "loss": 0.0193,
      "step": 3567
    },
    {
      "epoch": 36.22,
      "learning_rate": 9.392243032364677e-05,
      "loss": 0.0051,
      "step": 3568
    },
    {
      "epoch": 36.23,
      "learning_rate": 9.391675573424919e-05,
      "loss": 0.0094,
      "step": 3569
    },
    {
      "epoch": 36.24,
      "learning_rate": 9.391107866851143e-05,
      "loss": 0.0135,
      "step": 3570
    },
    {
      "epoch": 36.25,
      "learning_rate": 9.39053991267536e-05,
      "loss": 0.0201,
      "step": 3571
    },
    {
      "epoch": 36.26,
      "learning_rate": 9.389971710929595e-05,
      "loss": 0.0291,
      "step": 3572
    },
    {
      "epoch": 36.27,
      "learning_rate": 9.389403261645888e-05,
      "loss": 0.004,
      "step": 3573
    },
    {
      "epoch": 36.28,
      "learning_rate": 9.388834564856292e-05,
      "loss": 0.0098,
      "step": 3574
    },
    {
      "epoch": 36.29,
      "learning_rate": 9.388265620592873e-05,
      "loss": 0.0474,
      "step": 3575
    },
    {
      "epoch": 36.3,
      "learning_rate": 9.387696428887716e-05,
      "loss": 0.0176,
      "step": 3576
    },
    {
      "epoch": 36.31,
      "learning_rate": 9.38712698977291e-05,
      "loss": 0.0276,
      "step": 3577
    },
    {
      "epoch": 36.32,
      "learning_rate": 9.386557303280569e-05,
      "loss": 0.0191,
      "step": 3578
    },
    {
      "epoch": 36.34,
      "learning_rate": 9.385987369442814e-05,
      "loss": 0.0201,
      "step": 3579
    },
    {
      "epoch": 36.35,
      "learning_rate": 9.385417188291782e-05,
      "loss": 0.0122,
      "step": 3580
    },
    {
      "epoch": 36.36,
      "learning_rate": 9.384846759859624e-05,
      "loss": 0.0065,
      "step": 3581
    },
    {
      "epoch": 36.37,
      "learning_rate": 9.384276084178506e-05,
      "loss": 0.0053,
      "step": 3582
    },
    {
      "epoch": 36.38,
      "learning_rate": 9.383705161280603e-05,
      "loss": 0.0041,
      "step": 3583
    },
    {
      "epoch": 36.39,
      "learning_rate": 9.383133991198112e-05,
      "loss": 0.0045,
      "step": 3584
    },
    {
      "epoch": 36.4,
      "learning_rate": 9.382562573963238e-05,
      "loss": 0.0084,
      "step": 3585
    },
    {
      "epoch": 36.41,
      "learning_rate": 9.381990909608203e-05,
      "loss": 0.0062,
      "step": 3586
    },
    {
      "epoch": 36.42,
      "learning_rate": 9.381418998165239e-05,
      "loss": 0.0039,
      "step": 3587
    },
    {
      "epoch": 36.43,
      "learning_rate": 9.380846839666596e-05,
      "loss": 0.0029,
      "step": 3588
    },
    {
      "epoch": 36.44,
      "learning_rate": 9.380274434144535e-05,
      "loss": 0.0006,
      "step": 3589
    },
    {
      "epoch": 36.45,
      "learning_rate": 9.379701781631335e-05,
      "loss": 0.0148,
      "step": 3590
    },
    {
      "epoch": 36.46,
      "learning_rate": 9.379128882159283e-05,
      "loss": 0.0025,
      "step": 3591
    },
    {
      "epoch": 36.47,
      "learning_rate": 9.378555735760686e-05,
      "loss": 0.0115,
      "step": 3592
    },
    {
      "epoch": 36.48,
      "learning_rate": 9.377982342467859e-05,
      "loss": 0.0314,
      "step": 3593
    },
    {
      "epoch": 36.49,
      "learning_rate": 9.377408702313138e-05,
      "loss": 0.0236,
      "step": 3594
    },
    {
      "epoch": 36.5,
      "learning_rate": 9.376834815328866e-05,
      "loss": 0.0005,
      "step": 3595
    },
    {
      "epoch": 36.51,
      "learning_rate": 9.376260681547402e-05,
      "loss": 0.0011,
      "step": 3596
    },
    {
      "epoch": 36.52,
      "learning_rate": 9.375686301001123e-05,
      "loss": 0.0019,
      "step": 3597
    },
    {
      "epoch": 36.53,
      "learning_rate": 9.375111673722414e-05,
      "loss": 0.0041,
      "step": 3598
    },
    {
      "epoch": 36.54,
      "learning_rate": 9.374536799743678e-05,
      "loss": 0.022,
      "step": 3599
    },
    {
      "epoch": 36.55,
      "learning_rate": 9.373961679097331e-05,
      "loss": 0.0021,
      "step": 3600
    },
    {
      "epoch": 36.56,
      "learning_rate": 9.3733863118158e-05,
      "loss": 0.0026,
      "step": 3601
    },
    {
      "epoch": 36.57,
      "learning_rate": 9.372810697931531e-05,
      "loss": 0.0043,
      "step": 3602
    },
    {
      "epoch": 36.58,
      "learning_rate": 9.372234837476978e-05,
      "loss": 0.0096,
      "step": 3603
    },
    {
      "epoch": 36.59,
      "learning_rate": 9.371658730484616e-05,
      "loss": 0.0038,
      "step": 3604
    },
    {
      "epoch": 36.6,
      "learning_rate": 9.371082376986928e-05,
      "loss": 0.0007,
      "step": 3605
    },
    {
      "epoch": 36.61,
      "learning_rate": 9.370505777016414e-05,
      "loss": 0.0066,
      "step": 3606
    },
    {
      "epoch": 36.62,
      "learning_rate": 9.369928930605585e-05,
      "loss": 0.0024,
      "step": 3607
    },
    {
      "epoch": 36.63,
      "learning_rate": 9.369351837786968e-05,
      "loss": 0.002,
      "step": 3608
    },
    {
      "epoch": 36.64,
      "learning_rate": 9.368774498593104e-05,
      "loss": 0.0001,
      "step": 3609
    },
    {
      "epoch": 36.65,
      "learning_rate": 9.36819691305655e-05,
      "loss": 0.002,
      "step": 3610
    },
    {
      "epoch": 36.66,
      "learning_rate": 9.367619081209871e-05,
      "loss": 0.0036,
      "step": 3611
    },
    {
      "epoch": 36.67,
      "learning_rate": 9.367041003085649e-05,
      "loss": 0.0009,
      "step": 3612
    },
    {
      "epoch": 36.68,
      "learning_rate": 9.366462678716483e-05,
      "loss": 0.0155,
      "step": 3613
    },
    {
      "epoch": 36.69,
      "learning_rate": 9.365884108134981e-05,
      "loss": 0.001,
      "step": 3614
    },
    {
      "epoch": 36.7,
      "learning_rate": 9.365305291373769e-05,
      "loss": 0.0016,
      "step": 3615
    },
    {
      "epoch": 36.71,
      "learning_rate": 9.364726228465482e-05,
      "loss": 0.0012,
      "step": 3616
    },
    {
      "epoch": 36.72,
      "learning_rate": 9.364146919442773e-05,
      "loss": 0.012,
      "step": 3617
    },
    {
      "epoch": 36.73,
      "learning_rate": 9.363567364338308e-05,
      "loss": 0.0339,
      "step": 3618
    },
    {
      "epoch": 36.74,
      "learning_rate": 9.362987563184768e-05,
      "loss": 0.0001,
      "step": 3619
    },
    {
      "epoch": 36.75,
      "learning_rate": 9.362407516014842e-05,
      "loss": 0.0009,
      "step": 3620
    },
    {
      "epoch": 36.76,
      "learning_rate": 9.361827222861241e-05,
      "loss": 0.0089,
      "step": 3621
    },
    {
      "epoch": 36.77,
      "learning_rate": 9.361246683756684e-05,
      "loss": 0.022,
      "step": 3622
    },
    {
      "epoch": 36.78,
      "learning_rate": 9.360665898733907e-05,
      "loss": 0.0154,
      "step": 3623
    },
    {
      "epoch": 36.79,
      "learning_rate": 9.360084867825659e-05,
      "loss": 0.0051,
      "step": 3624
    },
    {
      "epoch": 36.8,
      "learning_rate": 9.359503591064702e-05,
      "loss": 0.0043,
      "step": 3625
    },
    {
      "epoch": 36.81,
      "learning_rate": 9.358922068483812e-05,
      "loss": 0.0088,
      "step": 3626
    },
    {
      "epoch": 36.82,
      "learning_rate": 9.358340300115781e-05,
      "loss": 0.0011,
      "step": 3627
    },
    {
      "epoch": 36.83,
      "learning_rate": 9.357758285993412e-05,
      "loss": 0.004,
      "step": 3628
    },
    {
      "epoch": 36.84,
      "learning_rate": 9.357176026149524e-05,
      "loss": 0.0014,
      "step": 3629
    },
    {
      "epoch": 36.85,
      "learning_rate": 9.356593520616948e-05,
      "loss": 0.0011,
      "step": 3630
    },
    {
      "epoch": 36.86,
      "learning_rate": 9.35601076942853e-05,
      "loss": 0.0176,
      "step": 3631
    },
    {
      "epoch": 36.87,
      "learning_rate": 9.355427772617129e-05,
      "loss": 0.0218,
      "step": 3632
    },
    {
      "epoch": 36.88,
      "learning_rate": 9.354844530215621e-05,
      "loss": 0.0002,
      "step": 3633
    },
    {
      "epoch": 36.89,
      "learning_rate": 9.354261042256892e-05,
      "loss": 0.0005,
      "step": 3634
    },
    {
      "epoch": 36.9,
      "learning_rate": 9.353677308773842e-05,
      "loss": 0.0165,
      "step": 3635
    },
    {
      "epoch": 36.91,
      "learning_rate": 9.353093329799387e-05,
      "loss": 0.0077,
      "step": 3636
    },
    {
      "epoch": 36.92,
      "learning_rate": 9.352509105366456e-05,
      "loss": 0.0018,
      "step": 3637
    },
    {
      "epoch": 36.93,
      "learning_rate": 9.351924635507993e-05,
      "loss": 0.0133,
      "step": 3638
    },
    {
      "epoch": 36.94,
      "learning_rate": 9.351339920256952e-05,
      "loss": 0.0009,
      "step": 3639
    },
    {
      "epoch": 36.95,
      "learning_rate": 9.350754959646306e-05,
      "loss": 0.0239,
      "step": 3640
    },
    {
      "epoch": 36.96,
      "learning_rate": 9.350169753709037e-05,
      "loss": 0.0041,
      "step": 3641
    },
    {
      "epoch": 36.97,
      "learning_rate": 9.349584302478145e-05,
      "loss": 0.0033,
      "step": 3642
    },
    {
      "epoch": 36.98,
      "learning_rate": 9.348998605986638e-05,
      "loss": 0.0033,
      "step": 3643
    },
    {
      "epoch": 36.99,
      "learning_rate": 9.348412664267549e-05,
      "loss": 0.0148,
      "step": 3644
    },
    {
      "epoch": 36.99,
      "eval_loss": 0.019544072449207306,
      "eval_runtime": 31.8576,
      "eval_samples_per_second": 98.877,
      "eval_steps_per_second": 6.184,
      "eval_wer": 0.005409731113956466,
      "step": 3644
    },
    {
      "epoch": 37.01,
      "learning_rate": 9.347826477353911e-05,
      "loss": 0.0051,
      "step": 3645
    },
    {
      "epoch": 37.02,
      "learning_rate": 9.34724004527878e-05,
      "loss": 0.0002,
      "step": 3646
    },
    {
      "epoch": 37.03,
      "learning_rate": 9.346653368075222e-05,
      "loss": 0.0051,
      "step": 3647
    },
    {
      "epoch": 37.04,
      "learning_rate": 9.346066445776321e-05,
      "loss": 0.0016,
      "step": 3648
    },
    {
      "epoch": 37.05,
      "learning_rate": 9.345479278415168e-05,
      "loss": 0.0013,
      "step": 3649
    },
    {
      "epoch": 37.06,
      "learning_rate": 9.344891866024876e-05,
      "loss": 0.0021,
      "step": 3650
    },
    {
      "epoch": 37.07,
      "learning_rate": 9.344304208638564e-05,
      "loss": 0.0011,
      "step": 3651
    },
    {
      "epoch": 37.08,
      "learning_rate": 9.343716306289368e-05,
      "loss": 0.0084,
      "step": 3652
    },
    {
      "epoch": 37.09,
      "learning_rate": 9.343128159010442e-05,
      "loss": 0.02,
      "step": 3653
    },
    {
      "epoch": 37.1,
      "learning_rate": 9.342539766834946e-05,
      "loss": 0.0201,
      "step": 3654
    },
    {
      "epoch": 37.11,
      "learning_rate": 9.341951129796059e-05,
      "loss": 0.015,
      "step": 3655
    },
    {
      "epoch": 37.12,
      "learning_rate": 9.341362247926973e-05,
      "loss": 0.0096,
      "step": 3656
    },
    {
      "epoch": 37.13,
      "learning_rate": 9.340773121260893e-05,
      "loss": 0.0006,
      "step": 3657
    },
    {
      "epoch": 37.14,
      "learning_rate": 9.340183749831038e-05,
      "loss": 0.0106,
      "step": 3658
    },
    {
      "epoch": 37.15,
      "learning_rate": 9.339594133670642e-05,
      "loss": 0.0089,
      "step": 3659
    },
    {
      "epoch": 37.16,
      "learning_rate": 9.33900427281295e-05,
      "loss": 0.0033,
      "step": 3660
    },
    {
      "epoch": 37.17,
      "learning_rate": 9.338414167291225e-05,
      "loss": 0.0005,
      "step": 3661
    },
    {
      "epoch": 37.18,
      "learning_rate": 9.33782381713874e-05,
      "loss": 0.0141,
      "step": 3662
    },
    {
      "epoch": 37.19,
      "learning_rate": 9.337233222388782e-05,
      "loss": 0.0034,
      "step": 3663
    },
    {
      "epoch": 37.2,
      "learning_rate": 9.336642383074654e-05,
      "loss": 0.0004,
      "step": 3664
    },
    {
      "epoch": 37.21,
      "learning_rate": 9.336051299229673e-05,
      "loss": 0.0174,
      "step": 3665
    },
    {
      "epoch": 37.22,
      "learning_rate": 9.335459970887166e-05,
      "loss": 0.0032,
      "step": 3666
    },
    {
      "epoch": 37.23,
      "learning_rate": 9.334868398080479e-05,
      "loss": 0.0164,
      "step": 3667
    },
    {
      "epoch": 37.24,
      "learning_rate": 9.334276580842967e-05,
      "loss": 0.0259,
      "step": 3668
    },
    {
      "epoch": 37.25,
      "learning_rate": 9.333684519208001e-05,
      "loss": 0.0008,
      "step": 3669
    },
    {
      "epoch": 37.26,
      "learning_rate": 9.333092213208967e-05,
      "loss": 0.0032,
      "step": 3670
    },
    {
      "epoch": 37.27,
      "learning_rate": 9.332499662879263e-05,
      "loss": 0.0035,
      "step": 3671
    },
    {
      "epoch": 37.28,
      "learning_rate": 9.3319068682523e-05,
      "loss": 0.0166,
      "step": 3672
    },
    {
      "epoch": 37.29,
      "learning_rate": 9.331313829361505e-05,
      "loss": 0.0339,
      "step": 3673
    },
    {
      "epoch": 37.3,
      "learning_rate": 9.330720546240319e-05,
      "loss": 0.0049,
      "step": 3674
    },
    {
      "epoch": 37.31,
      "learning_rate": 9.330127018922194e-05,
      "loss": 0.0138,
      "step": 3675
    },
    {
      "epoch": 37.32,
      "learning_rate": 9.329533247440596e-05,
      "loss": 0.004,
      "step": 3676
    },
    {
      "epoch": 37.33,
      "learning_rate": 9.32893923182901e-05,
      "loss": 0.0024,
      "step": 3677
    },
    {
      "epoch": 37.34,
      "learning_rate": 9.328344972120926e-05,
      "loss": 0.0016,
      "step": 3678
    },
    {
      "epoch": 37.35,
      "learning_rate": 9.327750468349856e-05,
      "loss": 0.0131,
      "step": 3679
    },
    {
      "epoch": 37.36,
      "learning_rate": 9.327155720549323e-05,
      "loss": 0.0038,
      "step": 3680
    },
    {
      "epoch": 37.37,
      "learning_rate": 9.32656072875286e-05,
      "loss": 0.025,
      "step": 3681
    },
    {
      "epoch": 37.38,
      "learning_rate": 9.325965492994018e-05,
      "loss": 0.003,
      "step": 3682
    },
    {
      "epoch": 37.39,
      "learning_rate": 9.325370013306362e-05,
      "loss": 0.0049,
      "step": 3683
    },
    {
      "epoch": 37.4,
      "learning_rate": 9.324774289723468e-05,
      "loss": 0.0072,
      "step": 3684
    },
    {
      "epoch": 37.41,
      "learning_rate": 9.324178322278927e-05,
      "loss": 0.0029,
      "step": 3685
    },
    {
      "epoch": 37.42,
      "learning_rate": 9.323582111006346e-05,
      "loss": 0.0061,
      "step": 3686
    },
    {
      "epoch": 37.43,
      "learning_rate": 9.322985655939343e-05,
      "loss": 0.0024,
      "step": 3687
    },
    {
      "epoch": 37.44,
      "learning_rate": 9.322388957111547e-05,
      "loss": 0.006,
      "step": 3688
    },
    {
      "epoch": 37.45,
      "learning_rate": 9.321792014556608e-05,
      "loss": 0.0193,
      "step": 3689
    },
    {
      "epoch": 37.46,
      "learning_rate": 9.321194828308185e-05,
      "loss": 0.0013,
      "step": 3690
    },
    {
      "epoch": 37.47,
      "learning_rate": 9.32059739839995e-05,
      "loss": 0.0296,
      "step": 3691
    },
    {
      "epoch": 37.48,
      "learning_rate": 9.319999724865591e-05,
      "loss": 0.0131,
      "step": 3692
    },
    {
      "epoch": 37.49,
      "learning_rate": 9.319401807738813e-05,
      "loss": 0.0007,
      "step": 3693
    },
    {
      "epoch": 37.5,
      "learning_rate": 9.318803647053325e-05,
      "loss": 0.0013,
      "step": 3694
    },
    {
      "epoch": 37.51,
      "learning_rate": 9.318205242842857e-05,
      "loss": 0.0006,
      "step": 3695
    },
    {
      "epoch": 37.52,
      "learning_rate": 9.317606595141154e-05,
      "loss": 0.0144,
      "step": 3696
    },
    {
      "epoch": 37.53,
      "learning_rate": 9.317007703981972e-05,
      "loss": 0.0005,
      "step": 3697
    },
    {
      "epoch": 37.54,
      "learning_rate": 9.316408569399077e-05,
      "loss": 0.0054,
      "step": 3698
    },
    {
      "epoch": 37.55,
      "learning_rate": 9.315809191426254e-05,
      "loss": 0.0132,
      "step": 3699
    },
    {
      "epoch": 37.56,
      "learning_rate": 9.315209570097303e-05,
      "loss": 0.0023,
      "step": 3700
    },
    {
      "epoch": 37.57,
      "learning_rate": 9.314609705446031e-05,
      "loss": 0.0021,
      "step": 3701
    },
    {
      "epoch": 37.58,
      "learning_rate": 9.314009597506266e-05,
      "loss": 0.0066,
      "step": 3702
    },
    {
      "epoch": 37.59,
      "learning_rate": 9.313409246311844e-05,
      "loss": 0.0122,
      "step": 3703
    },
    {
      "epoch": 37.6,
      "learning_rate": 9.312808651896618e-05,
      "loss": 0.0009,
      "step": 3704
    },
    {
      "epoch": 37.61,
      "learning_rate": 9.312207814294454e-05,
      "loss": 0.0104,
      "step": 3705
    },
    {
      "epoch": 37.62,
      "learning_rate": 9.311606733539232e-05,
      "loss": 0.0016,
      "step": 3706
    },
    {
      "epoch": 37.63,
      "learning_rate": 9.311005409664842e-05,
      "loss": 0.0378,
      "step": 3707
    },
    {
      "epoch": 37.64,
      "learning_rate": 9.310403842705194e-05,
      "loss": 0.0081,
      "step": 3708
    },
    {
      "epoch": 37.65,
      "learning_rate": 9.30980203269421e-05,
      "loss": 0.029,
      "step": 3709
    },
    {
      "epoch": 37.66,
      "learning_rate": 9.30919997966582e-05,
      "loss": 0.0108,
      "step": 3710
    },
    {
      "epoch": 37.68,
      "learning_rate": 9.308597683653975e-05,
      "loss": 0.0199,
      "step": 3711
    },
    {
      "epoch": 37.69,
      "learning_rate": 9.307995144692637e-05,
      "loss": 0.0118,
      "step": 3712
    },
    {
      "epoch": 37.7,
      "learning_rate": 9.307392362815781e-05,
      "loss": 0.0193,
      "step": 3713
    },
    {
      "epoch": 37.71,
      "learning_rate": 9.306789338057394e-05,
      "loss": 0.0026,
      "step": 3714
    },
    {
      "epoch": 37.72,
      "learning_rate": 9.306186070451482e-05,
      "loss": 0.0123,
      "step": 3715
    },
    {
      "epoch": 37.73,
      "learning_rate": 9.30558256003206e-05,
      "loss": 0.0057,
      "step": 3716
    },
    {
      "epoch": 37.74,
      "learning_rate": 9.304978806833158e-05,
      "loss": 0.0028,
      "step": 3717
    },
    {
      "epoch": 37.75,
      "learning_rate": 9.30437481088882e-05,
      "loss": 0.0006,
      "step": 3718
    },
    {
      "epoch": 37.76,
      "learning_rate": 9.303770572233103e-05,
      "loss": 0.0061,
      "step": 3719
    },
    {
      "epoch": 37.77,
      "learning_rate": 9.303166090900082e-05,
      "loss": 0.0015,
      "step": 3720
    },
    {
      "epoch": 37.78,
      "learning_rate": 9.302561366923836e-05,
      "loss": 0.0018,
      "step": 3721
    },
    {
      "epoch": 37.79,
      "learning_rate": 9.30195640033847e-05,
      "loss": 0.0081,
      "step": 3722
    },
    {
      "epoch": 37.8,
      "learning_rate": 9.301351191178092e-05,
      "loss": 0.0048,
      "step": 3723
    },
    {
      "epoch": 37.81,
      "learning_rate": 9.300745739476829e-05,
      "loss": 0.0094,
      "step": 3724
    },
    {
      "epoch": 37.82,
      "learning_rate": 9.30014004526882e-05,
      "loss": 0.0023,
      "step": 3725
    },
    {
      "epoch": 37.83,
      "learning_rate": 9.299534108588218e-05,
      "loss": 0.0127,
      "step": 3726
    },
    {
      "epoch": 37.84,
      "learning_rate": 9.298927929469192e-05,
      "loss": 0.0055,
      "step": 3727
    },
    {
      "epoch": 37.85,
      "learning_rate": 9.298321507945923e-05,
      "loss": 0.0074,
      "step": 3728
    },
    {
      "epoch": 37.86,
      "learning_rate": 9.297714844052604e-05,
      "loss": 0.0173,
      "step": 3729
    },
    {
      "epoch": 37.87,
      "learning_rate": 9.297107937823444e-05,
      "loss": 0.0207,
      "step": 3730
    },
    {
      "epoch": 37.88,
      "learning_rate": 9.296500789292663e-05,
      "loss": 0.023,
      "step": 3731
    },
    {
      "epoch": 37.89,
      "learning_rate": 9.295893398494498e-05,
      "loss": 0.0019,
      "step": 3732
    },
    {
      "epoch": 37.9,
      "learning_rate": 9.295285765463197e-05,
      "loss": 0.0008,
      "step": 3733
    },
    {
      "epoch": 37.91,
      "learning_rate": 9.294677890233024e-05,
      "loss": 0.0088,
      "step": 3734
    },
    {
      "epoch": 37.92,
      "learning_rate": 9.294069772838253e-05,
      "loss": 0.0118,
      "step": 3735
    },
    {
      "epoch": 37.93,
      "learning_rate": 9.293461413313176e-05,
      "loss": 0.0038,
      "step": 3736
    },
    {
      "epoch": 37.94,
      "learning_rate": 9.292852811692097e-05,
      "loss": 0.0159,
      "step": 3737
    },
    {
      "epoch": 37.95,
      "learning_rate": 9.292243968009331e-05,
      "loss": 0.0173,
      "step": 3738
    },
    {
      "epoch": 37.96,
      "learning_rate": 9.291634882299211e-05,
      "loss": 0.002,
      "step": 3739
    },
    {
      "epoch": 37.97,
      "learning_rate": 9.29102555459608e-05,
      "loss": 0.0094,
      "step": 3740
    },
    {
      "epoch": 37.98,
      "learning_rate": 9.2904159849343e-05,
      "loss": 0.0016,
      "step": 3741
    },
    {
      "epoch": 37.99,
      "learning_rate": 9.289806173348238e-05,
      "loss": 0.0011,
      "step": 3742
    },
    {
      "epoch": 38.0,
      "learning_rate": 9.289196119872283e-05,
      "loss": 0.0088,
      "step": 3743
    },
    {
      "epoch": 38.0,
      "eval_loss": 0.01726321317255497,
      "eval_runtime": 32.5694,
      "eval_samples_per_second": 96.717,
      "eval_steps_per_second": 6.049,
      "eval_wer": 0.0048655569782330346,
      "step": 3743
    },
    {
      "epoch": 38.01,
      "learning_rate": 9.288585824540832e-05,
      "loss": 0.0139,
      "step": 3744
    },
    {
      "epoch": 38.02,
      "learning_rate": 9.287975287388298e-05,
      "loss": 0.0035,
      "step": 3745
    },
    {
      "epoch": 38.03,
      "learning_rate": 9.287364508449108e-05,
      "loss": 0.0152,
      "step": 3746
    },
    {
      "epoch": 38.04,
      "learning_rate": 9.286753487757703e-05,
      "loss": 0.0003,
      "step": 3747
    },
    {
      "epoch": 38.05,
      "learning_rate": 9.286142225348536e-05,
      "loss": 0.0045,
      "step": 3748
    },
    {
      "epoch": 38.06,
      "learning_rate": 9.285530721256073e-05,
      "loss": 0.0098,
      "step": 3749
    },
    {
      "epoch": 38.07,
      "learning_rate": 9.284918975514797e-05,
      "loss": 0.0031,
      "step": 3750
    },
    {
      "epoch": 38.08,
      "learning_rate": 9.284306988159203e-05,
      "loss": 0.0189,
      "step": 3751
    },
    {
      "epoch": 38.09,
      "learning_rate": 9.283694759223796e-05,
      "loss": 0.0071,
      "step": 3752
    },
    {
      "epoch": 38.1,
      "learning_rate": 9.283082288743101e-05,
      "loss": 0.0145,
      "step": 3753
    },
    {
      "epoch": 38.11,
      "learning_rate": 9.282469576751651e-05,
      "loss": 0.0136,
      "step": 3754
    },
    {
      "epoch": 38.12,
      "learning_rate": 9.281856623283997e-05,
      "loss": 0.0076,
      "step": 3755
    },
    {
      "epoch": 38.13,
      "learning_rate": 9.281243428374702e-05,
      "loss": 0.0033,
      "step": 3756
    },
    {
      "epoch": 38.14,
      "learning_rate": 9.280629992058341e-05,
      "loss": 0.0064,
      "step": 3757
    },
    {
      "epoch": 38.15,
      "learning_rate": 9.280016314369502e-05,
      "loss": 0.0039,
      "step": 3758
    },
    {
      "epoch": 38.16,
      "learning_rate": 9.279402395342794e-05,
      "loss": 0.0007,
      "step": 3759
    },
    {
      "epoch": 38.17,
      "learning_rate": 9.278788235012828e-05,
      "loss": 0.0118,
      "step": 3760
    },
    {
      "epoch": 38.18,
      "learning_rate": 9.278173833414239e-05,
      "loss": 0.006,
      "step": 3761
    },
    {
      "epoch": 38.19,
      "learning_rate": 9.277559190581671e-05,
      "loss": 0.0013,
      "step": 3762
    },
    {
      "epoch": 38.2,
      "learning_rate": 9.27694430654978e-05,
      "loss": 0.0159,
      "step": 3763
    },
    {
      "epoch": 38.21,
      "learning_rate": 9.276329181353238e-05,
      "loss": 0.0013,
      "step": 3764
    },
    {
      "epoch": 38.22,
      "learning_rate": 9.275713815026731e-05,
      "loss": 0.0103,
      "step": 3765
    },
    {
      "epoch": 38.23,
      "learning_rate": 9.275098207604957e-05,
      "loss": 0.0152,
      "step": 3766
    },
    {
      "epoch": 38.24,
      "learning_rate": 9.274482359122631e-05,
      "loss": 0.0032,
      "step": 3767
    },
    {
      "epoch": 38.25,
      "learning_rate": 9.273866269614474e-05,
      "loss": 0.0176,
      "step": 3768
    },
    {
      "epoch": 38.26,
      "learning_rate": 9.27324993911523e-05,
      "loss": 0.0249,
      "step": 3769
    },
    {
      "epoch": 38.27,
      "learning_rate": 9.272633367659649e-05,
      "loss": 0.0023,
      "step": 3770
    },
    {
      "epoch": 38.28,
      "learning_rate": 9.2720165552825e-05,
      "loss": 0.0018,
      "step": 3771
    },
    {
      "epoch": 38.29,
      "learning_rate": 9.271399502018561e-05,
      "loss": 0.0192,
      "step": 3772
    },
    {
      "epoch": 38.3,
      "learning_rate": 9.270782207902629e-05,
      "loss": 0.0124,
      "step": 3773
    },
    {
      "epoch": 38.31,
      "learning_rate": 9.270164672969509e-05,
      "loss": 0.0017,
      "step": 3774
    },
    {
      "epoch": 38.32,
      "learning_rate": 9.269546897254021e-05,
      "loss": 0.0134,
      "step": 3775
    },
    {
      "epoch": 38.34,
      "learning_rate": 9.268928880791003e-05,
      "loss": 0.0099,
      "step": 3776
    },
    {
      "epoch": 38.35,
      "learning_rate": 9.268310623615302e-05,
      "loss": 0.0059,
      "step": 3777
    },
    {
      "epoch": 38.36,
      "learning_rate": 9.267692125761778e-05,
      "loss": 0.033,
      "step": 3778
    },
    {
      "epoch": 38.37,
      "learning_rate": 9.267073387265306e-05,
      "loss": 0.0101,
      "step": 3779
    },
    {
      "epoch": 38.38,
      "learning_rate": 9.266454408160779e-05,
      "loss": 0.0022,
      "step": 3780
    },
    {
      "epoch": 38.39,
      "learning_rate": 9.265835188483096e-05,
      "loss": 0.0032,
      "step": 3781
    },
    {
      "epoch": 38.4,
      "learning_rate": 9.265215728267174e-05,
      "loss": 0.0014,
      "step": 3782
    },
    {
      "epoch": 38.41,
      "learning_rate": 9.264596027547943e-05,
      "loss": 0.0217,
      "step": 3783
    },
    {
      "epoch": 38.42,
      "learning_rate": 9.263976086360344e-05,
      "loss": 0.0014,
      "step": 3784
    },
    {
      "epoch": 38.43,
      "learning_rate": 9.263355904739336e-05,
      "loss": 0.0038,
      "step": 3785
    },
    {
      "epoch": 38.44,
      "learning_rate": 9.262735482719889e-05,
      "loss": 0.0033,
      "step": 3786
    },
    {
      "epoch": 38.45,
      "learning_rate": 9.262114820336987e-05,
      "loss": 0.0072,
      "step": 3787
    },
    {
      "epoch": 38.46,
      "learning_rate": 9.261493917625626e-05,
      "loss": 0.024,
      "step": 3788
    },
    {
      "epoch": 38.47,
      "learning_rate": 9.260872774620816e-05,
      "loss": 0.0206,
      "step": 3789
    },
    {
      "epoch": 38.48,
      "learning_rate": 9.260251391357586e-05,
      "loss": 0.0155,
      "step": 3790
    },
    {
      "epoch": 38.49,
      "learning_rate": 9.25962976787097e-05,
      "loss": 0.003,
      "step": 3791
    },
    {
      "epoch": 38.5,
      "learning_rate": 9.259007904196023e-05,
      "loss": 0.0018,
      "step": 3792
    },
    {
      "epoch": 38.51,
      "learning_rate": 9.258385800367804e-05,
      "loss": 0.0003,
      "step": 3793
    },
    {
      "epoch": 38.52,
      "learning_rate": 9.257763456421398e-05,
      "loss": 0.0009,
      "step": 3794
    },
    {
      "epoch": 38.53,
      "learning_rate": 9.257140872391895e-05,
      "loss": 0.0021,
      "step": 3795
    },
    {
      "epoch": 38.54,
      "learning_rate": 9.256518048314399e-05,
      "loss": 0.0162,
      "step": 3796
    },
    {
      "epoch": 38.55,
      "learning_rate": 9.255894984224032e-05,
      "loss": 0.0051,
      "step": 3797
    },
    {
      "epoch": 38.56,
      "learning_rate": 9.255271680155925e-05,
      "loss": 0.0009,
      "step": 3798
    },
    {
      "epoch": 38.57,
      "learning_rate": 9.254648136145224e-05,
      "loss": 0.01,
      "step": 3799
    },
    {
      "epoch": 38.58,
      "learning_rate": 9.25402435222709e-05,
      "loss": 0.0015,
      "step": 3800
    },
    {
      "epoch": 38.59,
      "learning_rate": 9.253400328436699e-05,
      "loss": 0.0198,
      "step": 3801
    },
    {
      "epoch": 38.6,
      "learning_rate": 9.252776064809233e-05,
      "loss": 0.0004,
      "step": 3802
    },
    {
      "epoch": 38.61,
      "learning_rate": 9.252151561379893e-05,
      "loss": 0.0205,
      "step": 3803
    },
    {
      "epoch": 38.62,
      "learning_rate": 9.251526818183896e-05,
      "loss": 0.0116,
      "step": 3804
    },
    {
      "epoch": 38.63,
      "learning_rate": 9.250901835256468e-05,
      "loss": 0.0056,
      "step": 3805
    },
    {
      "epoch": 38.64,
      "learning_rate": 9.25027661263285e-05,
      "loss": 0.0022,
      "step": 3806
    },
    {
      "epoch": 38.65,
      "learning_rate": 9.249651150348296e-05,
      "loss": 0.0009,
      "step": 3807
    },
    {
      "epoch": 38.66,
      "learning_rate": 9.249025448438076e-05,
      "loss": 0.0121,
      "step": 3808
    },
    {
      "epoch": 38.67,
      "learning_rate": 9.248399506937468e-05,
      "loss": 0.0028,
      "step": 3809
    },
    {
      "epoch": 38.68,
      "learning_rate": 9.24777332588177e-05,
      "loss": 0.005,
      "step": 3810
    },
    {
      "epoch": 38.69,
      "learning_rate": 9.24714690530629e-05,
      "loss": 0.0105,
      "step": 3811
    },
    {
      "epoch": 38.7,
      "learning_rate": 9.246520245246349e-05,
      "loss": 0.0023,
      "step": 3812
    },
    {
      "epoch": 38.71,
      "learning_rate": 9.245893345737283e-05,
      "loss": 0.0343,
      "step": 3813
    },
    {
      "epoch": 38.72,
      "learning_rate": 9.245266206814442e-05,
      "loss": 0.0011,
      "step": 3814
    },
    {
      "epoch": 38.73,
      "learning_rate": 9.244638828513187e-05,
      "loss": 0.0277,
      "step": 3815
    },
    {
      "epoch": 38.74,
      "learning_rate": 9.244011210868895e-05,
      "loss": 0.0021,
      "step": 3816
    },
    {
      "epoch": 38.75,
      "learning_rate": 9.243383353916957e-05,
      "loss": 0.0046,
      "step": 3817
    },
    {
      "epoch": 38.76,
      "learning_rate": 9.242755257692775e-05,
      "loss": 0.0057,
      "step": 3818
    },
    {
      "epoch": 38.77,
      "learning_rate": 9.242126922231763e-05,
      "loss": 0.0009,
      "step": 3819
    },
    {
      "epoch": 38.78,
      "learning_rate": 9.241498347569354e-05,
      "loss": 0.0138,
      "step": 3820
    },
    {
      "epoch": 38.79,
      "learning_rate": 9.240869533740991e-05,
      "loss": 0.0022,
      "step": 3821
    },
    {
      "epoch": 38.8,
      "learning_rate": 9.24024048078213e-05,
      "loss": 0.0009,
      "step": 3822
    },
    {
      "epoch": 38.81,
      "learning_rate": 9.239611188728243e-05,
      "loss": 0.0047,
      "step": 3823
    },
    {
      "epoch": 38.82,
      "learning_rate": 9.238981657614813e-05,
      "loss": 0.0101,
      "step": 3824
    },
    {
      "epoch": 38.83,
      "learning_rate": 9.238351887477337e-05,
      "loss": 0.0027,
      "step": 3825
    },
    {
      "epoch": 38.84,
      "learning_rate": 9.237721878351328e-05,
      "loss": 0.003,
      "step": 3826
    },
    {
      "epoch": 38.85,
      "learning_rate": 9.237091630272308e-05,
      "loss": 0.0038,
      "step": 3827
    },
    {
      "epoch": 38.86,
      "learning_rate": 9.236461143275817e-05,
      "loss": 0.0052,
      "step": 3828
    },
    {
      "epoch": 38.87,
      "learning_rate": 9.235830417397403e-05,
      "loss": 0.0037,
      "step": 3829
    },
    {
      "epoch": 38.88,
      "learning_rate": 9.235199452672634e-05,
      "loss": 0.0063,
      "step": 3830
    },
    {
      "epoch": 38.89,
      "learning_rate": 9.234568249137088e-05,
      "loss": 0.0007,
      "step": 3831
    },
    {
      "epoch": 38.9,
      "learning_rate": 9.233936806826356e-05,
      "loss": 0.0023,
      "step": 3832
    },
    {
      "epoch": 38.91,
      "learning_rate": 9.233305125776045e-05,
      "loss": 0.0342,
      "step": 3833
    },
    {
      "epoch": 38.92,
      "learning_rate": 9.232673206021769e-05,
      "loss": 0.0146,
      "step": 3834
    },
    {
      "epoch": 38.93,
      "learning_rate": 9.232041047599164e-05,
      "loss": 0.0031,
      "step": 3835
    },
    {
      "epoch": 38.94,
      "learning_rate": 9.231408650543874e-05,
      "loss": 0.0039,
      "step": 3836
    },
    {
      "epoch": 38.95,
      "learning_rate": 9.230776014891561e-05,
      "loss": 0.0005,
      "step": 3837
    },
    {
      "epoch": 38.96,
      "learning_rate": 9.230143140677893e-05,
      "loss": 0.0059,
      "step": 3838
    },
    {
      "epoch": 38.97,
      "learning_rate": 9.229510027938562e-05,
      "loss": 0.0207,
      "step": 3839
    },
    {
      "epoch": 38.98,
      "learning_rate": 9.22887667670926e-05,
      "loss": 0.002,
      "step": 3840
    },
    {
      "epoch": 38.99,
      "learning_rate": 9.228243087025706e-05,
      "loss": 0.0007,
      "step": 3841
    },
    {
      "epoch": 38.99,
      "eval_loss": 0.014501598663628101,
      "eval_runtime": 31.7409,
      "eval_samples_per_second": 99.241,
      "eval_steps_per_second": 6.206,
      "eval_wer": 0.005505761843790013,
      "step": 3841
    },
    {
      "epoch": 39.01,
      "learning_rate": 9.227609258923623e-05,
      "loss": 0.0002,
      "step": 3842
    },
    {
      "epoch": 39.02,
      "learning_rate": 9.226975192438752e-05,
      "loss": 0.002,
      "step": 3843
    },
    {
      "epoch": 39.03,
      "learning_rate": 9.226340887606844e-05,
      "loss": 0.0007,
      "step": 3844
    },
    {
      "epoch": 39.04,
      "learning_rate": 9.225706344463669e-05,
      "loss": 0.0045,
      "step": 3845
    },
    {
      "epoch": 39.05,
      "learning_rate": 9.225071563045007e-05,
      "loss": 0.0258,
      "step": 3846
    },
    {
      "epoch": 39.06,
      "learning_rate": 9.224436543386647e-05,
      "loss": 0.0172,
      "step": 3847
    },
    {
      "epoch": 39.07,
      "learning_rate": 9.223801285524402e-05,
      "loss": 0.001,
      "step": 3848
    },
    {
      "epoch": 39.08,
      "learning_rate": 9.223165789494088e-05,
      "loss": 0.0002,
      "step": 3849
    },
    {
      "epoch": 39.09,
      "learning_rate": 9.22253005533154e-05,
      "loss": 0.0012,
      "step": 3850
    },
    {
      "epoch": 39.1,
      "learning_rate": 9.221894083072605e-05,
      "loss": 0.025,
      "step": 3851
    },
    {
      "epoch": 39.11,
      "learning_rate": 9.221257872753145e-05,
      "loss": 0.0008,
      "step": 3852
    },
    {
      "epoch": 39.12,
      "learning_rate": 9.220621424409033e-05,
      "loss": 0.0006,
      "step": 3853
    },
    {
      "epoch": 39.13,
      "learning_rate": 9.219984738076158e-05,
      "loss": 0.0125,
      "step": 3854
    },
    {
      "epoch": 39.14,
      "learning_rate": 9.219347813790416e-05,
      "loss": 0.0074,
      "step": 3855
    },
    {
      "epoch": 39.15,
      "learning_rate": 9.218710651587727e-05,
      "loss": 0.002,
      "step": 3856
    },
    {
      "epoch": 39.16,
      "learning_rate": 9.218073251504018e-05,
      "loss": 0.0231,
      "step": 3857
    },
    {
      "epoch": 39.17,
      "learning_rate": 9.217435613575227e-05,
      "loss": 0.0083,
      "step": 3858
    },
    {
      "epoch": 39.18,
      "learning_rate": 9.21679773783731e-05,
      "loss": 0.0309,
      "step": 3859
    },
    {
      "epoch": 39.19,
      "learning_rate": 9.216159624326238e-05,
      "loss": 0.005,
      "step": 3860
    },
    {
      "epoch": 39.2,
      "learning_rate": 9.215521273077988e-05,
      "loss": 0.0121,
      "step": 3861
    },
    {
      "epoch": 39.21,
      "learning_rate": 9.214882684128556e-05,
      "loss": 0.005,
      "step": 3862
    },
    {
      "epoch": 39.22,
      "learning_rate": 9.214243857513952e-05,
      "loss": 0.0136,
      "step": 3863
    },
    {
      "epoch": 39.23,
      "learning_rate": 9.213604793270196e-05,
      "loss": 0.0019,
      "step": 3864
    },
    {
      "epoch": 39.24,
      "learning_rate": 9.212965491433323e-05,
      "loss": 0.002,
      "step": 3865
    },
    {
      "epoch": 39.25,
      "learning_rate": 9.212325952039382e-05,
      "loss": 0.0004,
      "step": 3866
    },
    {
      "epoch": 39.26,
      "learning_rate": 9.211686175124435e-05,
      "loss": 0.0068,
      "step": 3867
    },
    {
      "epoch": 39.27,
      "learning_rate": 9.211046160724556e-05,
      "loss": 0.0008,
      "step": 3868
    },
    {
      "epoch": 39.28,
      "learning_rate": 9.210405908875837e-05,
      "loss": 0.0252,
      "step": 3869
    },
    {
      "epoch": 39.29,
      "learning_rate": 9.209765419614375e-05,
      "loss": 0.025,
      "step": 3870
    },
    {
      "epoch": 39.3,
      "learning_rate": 9.209124692976287e-05,
      "loss": 0.0101,
      "step": 3871
    },
    {
      "epoch": 39.31,
      "learning_rate": 9.208483728997704e-05,
      "loss": 0.0072,
      "step": 3872
    },
    {
      "epoch": 39.32,
      "learning_rate": 9.207842527714767e-05,
      "loss": 0.0337,
      "step": 3873
    },
    {
      "epoch": 39.33,
      "learning_rate": 9.207201089163629e-05,
      "loss": 0.0047,
      "step": 3874
    },
    {
      "epoch": 39.34,
      "learning_rate": 9.206559413380462e-05,
      "loss": 0.012,
      "step": 3875
    },
    {
      "epoch": 39.35,
      "learning_rate": 9.205917500401447e-05,
      "loss": 0.0183,
      "step": 3876
    },
    {
      "epoch": 39.36,
      "learning_rate": 9.205275350262781e-05,
      "loss": 0.0061,
      "step": 3877
    },
    {
      "epoch": 39.37,
      "learning_rate": 9.204632963000671e-05,
      "loss": 0.0003,
      "step": 3878
    },
    {
      "epoch": 39.38,
      "learning_rate": 9.20399033865134e-05,
      "loss": 0.005,
      "step": 3879
    },
    {
      "epoch": 39.39,
      "learning_rate": 9.203347477251025e-05,
      "loss": 0.0057,
      "step": 3880
    },
    {
      "epoch": 39.4,
      "learning_rate": 9.202704378835973e-05,
      "loss": 0.0147,
      "step": 3881
    },
    {
      "epoch": 39.41,
      "learning_rate": 9.202061043442449e-05,
      "loss": 0.0272,
      "step": 3882
    },
    {
      "epoch": 39.42,
      "learning_rate": 9.201417471106726e-05,
      "loss": 0.0037,
      "step": 3883
    },
    {
      "epoch": 39.43,
      "learning_rate": 9.200773661865094e-05,
      "loss": 0.0019,
      "step": 3884
    },
    {
      "epoch": 39.44,
      "learning_rate": 9.200129615753859e-05,
      "loss": 0.0232,
      "step": 3885
    },
    {
      "epoch": 39.45,
      "learning_rate": 9.199485332809331e-05,
      "loss": 0.0154,
      "step": 3886
    },
    {
      "epoch": 39.46,
      "learning_rate": 9.198840813067844e-05,
      "loss": 0.0012,
      "step": 3887
    },
    {
      "epoch": 39.47,
      "learning_rate": 9.198196056565738e-05,
      "loss": 0.0021,
      "step": 3888
    },
    {
      "epoch": 39.48,
      "learning_rate": 9.197551063339371e-05,
      "loss": 0.0013,
      "step": 3889
    },
    {
      "epoch": 39.49,
      "learning_rate": 9.196905833425111e-05,
      "loss": 0.001,
      "step": 3890
    },
    {
      "epoch": 39.5,
      "learning_rate": 9.196260366859342e-05,
      "loss": 0.0012,
      "step": 3891
    },
    {
      "epoch": 39.51,
      "learning_rate": 9.195614663678458e-05,
      "loss": 0.0024,
      "step": 3892
    },
    {
      "epoch": 39.52,
      "learning_rate": 9.194968723918869e-05,
      "loss": 0.0193,
      "step": 3893
    },
    {
      "epoch": 39.53,
      "learning_rate": 9.194322547616999e-05,
      "loss": 0.0012,
      "step": 3894
    },
    {
      "epoch": 39.54,
      "learning_rate": 9.193676134809281e-05,
      "loss": 0.0033,
      "step": 3895
    },
    {
      "epoch": 39.55,
      "learning_rate": 9.193029485532167e-05,
      "loss": 0.0277,
      "step": 3896
    },
    {
      "epoch": 39.56,
      "learning_rate": 9.19238259982212e-05,
      "loss": 0.0022,
      "step": 3897
    },
    {
      "epoch": 39.57,
      "learning_rate": 9.191735477715616e-05,
      "loss": 0.0133,
      "step": 3898
    },
    {
      "epoch": 39.58,
      "learning_rate": 9.191088119249143e-05,
      "loss": 0.0213,
      "step": 3899
    },
    {
      "epoch": 39.59,
      "learning_rate": 9.190440524459203e-05,
      "loss": 0.0046,
      "step": 3900
    },
    {
      "epoch": 39.6,
      "learning_rate": 9.189792693382316e-05,
      "loss": 0.0055,
      "step": 3901
    },
    {
      "epoch": 39.61,
      "learning_rate": 9.189144626055006e-05,
      "loss": 0.0039,
      "step": 3902
    },
    {
      "epoch": 39.62,
      "learning_rate": 9.188496322513819e-05,
      "loss": 0.0028,
      "step": 3903
    },
    {
      "epoch": 39.63,
      "learning_rate": 9.187847782795308e-05,
      "loss": 0.0027,
      "step": 3904
    },
    {
      "epoch": 39.64,
      "learning_rate": 9.18719900693605e-05,
      "loss": 0.0025,
      "step": 3905
    },
    {
      "epoch": 39.65,
      "learning_rate": 9.186549994972618e-05,
      "loss": 0.0174,
      "step": 3906
    },
    {
      "epoch": 39.66,
      "learning_rate": 9.185900746941612e-05,
      "loss": 0.0015,
      "step": 3907
    },
    {
      "epoch": 39.68,
      "learning_rate": 9.185251262879641e-05,
      "loss": 0.0074,
      "step": 3908
    },
    {
      "epoch": 39.69,
      "learning_rate": 9.18460154282333e-05,
      "loss": 0.0036,
      "step": 3909
    },
    {
      "epoch": 39.7,
      "learning_rate": 9.183951586809312e-05,
      "loss": 0.0054,
      "step": 3910
    },
    {
      "epoch": 39.71,
      "learning_rate": 9.183301394874238e-05,
      "loss": 0.0047,
      "step": 3911
    },
    {
      "epoch": 39.72,
      "learning_rate": 9.182650967054767e-05,
      "loss": 0.0112,
      "step": 3912
    },
    {
      "epoch": 39.73,
      "learning_rate": 9.182000303387577e-05,
      "loss": 0.0097,
      "step": 3913
    },
    {
      "epoch": 39.74,
      "learning_rate": 9.18134940390936e-05,
      "loss": 0.0129,
      "step": 3914
    },
    {
      "epoch": 39.75,
      "learning_rate": 9.180698268656813e-05,
      "loss": 0.0032,
      "step": 3915
    },
    {
      "epoch": 39.76,
      "learning_rate": 9.180046897666654e-05,
      "loss": 0.0005,
      "step": 3916
    },
    {
      "epoch": 39.77,
      "learning_rate": 9.179395290975614e-05,
      "loss": 0.0002,
      "step": 3917
    },
    {
      "epoch": 39.78,
      "learning_rate": 9.178743448620433e-05,
      "loss": 0.002,
      "step": 3918
    },
    {
      "epoch": 39.79,
      "learning_rate": 9.178091370637866e-05,
      "loss": 0.0044,
      "step": 3919
    },
    {
      "epoch": 39.8,
      "learning_rate": 9.177439057064683e-05,
      "loss": 0.0025,
      "step": 3920
    },
    {
      "epoch": 39.81,
      "learning_rate": 9.176786507937664e-05,
      "loss": 0.0012,
      "step": 3921
    },
    {
      "epoch": 39.82,
      "learning_rate": 9.176133723293609e-05,
      "loss": 0.0003,
      "step": 3922
    },
    {
      "epoch": 39.83,
      "learning_rate": 9.175480703169324e-05,
      "loss": 0.0011,
      "step": 3923
    },
    {
      "epoch": 39.84,
      "learning_rate": 9.174827447601629e-05,
      "loss": 0.0036,
      "step": 3924
    },
    {
      "epoch": 39.85,
      "learning_rate": 9.174173956627361e-05,
      "loss": 0.0101,
      "step": 3925
    },
    {
      "epoch": 39.86,
      "learning_rate": 9.17352023028337e-05,
      "loss": 0.0005,
      "step": 3926
    },
    {
      "epoch": 39.87,
      "learning_rate": 9.172866268606513e-05,
      "loss": 0.0057,
      "step": 3927
    },
    {
      "epoch": 39.88,
      "learning_rate": 9.172212071633671e-05,
      "loss": 0.0212,
      "step": 3928
    },
    {
      "epoch": 39.89,
      "learning_rate": 9.171557639401728e-05,
      "loss": 0.017,
      "step": 3929
    },
    {
      "epoch": 39.9,
      "learning_rate": 9.170902971947589e-05,
      "loss": 0.0116,
      "step": 3930
    },
    {
      "epoch": 39.91,
      "learning_rate": 9.170248069308166e-05,
      "loss": 0.0059,
      "step": 3931
    },
    {
      "epoch": 39.92,
      "learning_rate": 9.169592931520387e-05,
      "loss": 0.0165,
      "step": 3932
    },
    {
      "epoch": 39.93,
      "learning_rate": 9.168937558621196e-05,
      "loss": 0.0164,
      "step": 3933
    },
    {
      "epoch": 39.94,
      "learning_rate": 9.168281950647545e-05,
      "loss": 0.0083,
      "step": 3934
    },
    {
      "epoch": 39.95,
      "learning_rate": 9.167626107636403e-05,
      "loss": 0.0049,
      "step": 3935
    },
    {
      "epoch": 39.96,
      "learning_rate": 9.166970029624751e-05,
      "loss": 0.002,
      "step": 3936
    },
    {
      "epoch": 39.97,
      "learning_rate": 9.166313716649583e-05,
      "loss": 0.0111,
      "step": 3937
    },
    {
      "epoch": 39.98,
      "learning_rate": 9.165657168747907e-05,
      "loss": 0.0041,
      "step": 3938
    },
    {
      "epoch": 39.99,
      "learning_rate": 9.165000385956743e-05,
      "loss": 0.0233,
      "step": 3939
    },
    {
      "epoch": 40.0,
      "learning_rate": 9.164343368313128e-05,
      "loss": 0.0005,
      "step": 3940
    },
    {
      "epoch": 40.0,
      "eval_loss": 0.015820246189832687,
      "eval_runtime": 31.7406,
      "eval_samples_per_second": 99.242,
      "eval_steps_per_second": 6.207,
      "eval_wer": 0.0046414852752880926,
      "step": 3940
    },
    {
      "epoch": 40.01,
      "learning_rate": 9.163686115854106e-05,
      "loss": 0.0041,
      "step": 3941
    },
    {
      "epoch": 40.02,
      "learning_rate": 9.163028628616738e-05,
      "loss": 0.0017,
      "step": 3942
    },
    {
      "epoch": 40.03,
      "learning_rate": 9.1623709066381e-05,
      "loss": 0.0007,
      "step": 3943
    },
    {
      "epoch": 40.04,
      "learning_rate": 9.161712949955276e-05,
      "loss": 0.0008,
      "step": 3944
    },
    {
      "epoch": 40.05,
      "learning_rate": 9.16105475860537e-05,
      "loss": 0.0066,
      "step": 3945
    },
    {
      "epoch": 40.06,
      "learning_rate": 9.160396332625492e-05,
      "loss": 0.0089,
      "step": 3946
    },
    {
      "epoch": 40.07,
      "learning_rate": 9.159737672052771e-05,
      "loss": 0.0004,
      "step": 3947
    },
    {
      "epoch": 40.08,
      "learning_rate": 9.159078776924346e-05,
      "loss": 0.0012,
      "step": 3948
    },
    {
      "epoch": 40.09,
      "learning_rate": 9.15841964727737e-05,
      "loss": 0.0029,
      "step": 3949
    },
    {
      "epoch": 40.1,
      "learning_rate": 9.157760283149011e-05,
      "loss": 0.007,
      "step": 3950
    },
    {
      "epoch": 40.11,
      "learning_rate": 9.157100684576446e-05,
      "loss": 0.0005,
      "step": 3951
    },
    {
      "epoch": 40.12,
      "learning_rate": 9.15644085159687e-05,
      "loss": 0.0025,
      "step": 3952
    },
    {
      "epoch": 40.13,
      "learning_rate": 9.155780784247487e-05,
      "loss": 0.016,
      "step": 3953
    },
    {
      "epoch": 40.14,
      "learning_rate": 9.155120482565521e-05,
      "loss": 0.0101,
      "step": 3954
    },
    {
      "epoch": 40.15,
      "learning_rate": 9.154459946588198e-05,
      "loss": 0.0016,
      "step": 3955
    },
    {
      "epoch": 40.16,
      "learning_rate": 9.15379917635277e-05,
      "loss": 0.0002,
      "step": 3956
    },
    {
      "epoch": 40.17,
      "learning_rate": 9.153138171896491e-05,
      "loss": 0.0018,
      "step": 3957
    },
    {
      "epoch": 40.18,
      "learning_rate": 9.152476933256638e-05,
      "loss": 0.006,
      "step": 3958
    },
    {
      "epoch": 40.19,
      "learning_rate": 9.151815460470489e-05,
      "loss": 0.0111,
      "step": 3959
    },
    {
      "epoch": 40.2,
      "learning_rate": 9.151153753575351e-05,
      "loss": 0.0015,
      "step": 3960
    },
    {
      "epoch": 40.21,
      "learning_rate": 9.15049181260853e-05,
      "loss": 0.0081,
      "step": 3961
    },
    {
      "epoch": 40.22,
      "learning_rate": 9.149829637607353e-05,
      "loss": 0.0095,
      "step": 3962
    },
    {
      "epoch": 40.23,
      "learning_rate": 9.149167228609159e-05,
      "loss": 0.0006,
      "step": 3963
    },
    {
      "epoch": 40.24,
      "learning_rate": 9.148504585651296e-05,
      "loss": 0.0041,
      "step": 3964
    },
    {
      "epoch": 40.25,
      "learning_rate": 9.147841708771133e-05,
      "loss": 0.0016,
      "step": 3965
    },
    {
      "epoch": 40.26,
      "learning_rate": 9.147178598006045e-05,
      "loss": 0.0003,
      "step": 3966
    },
    {
      "epoch": 40.27,
      "learning_rate": 9.146515253393423e-05,
      "loss": 0.0023,
      "step": 3967
    },
    {
      "epoch": 40.28,
      "learning_rate": 9.145851674970672e-05,
      "loss": 0.002,
      "step": 3968
    },
    {
      "epoch": 40.29,
      "learning_rate": 9.145187862775209e-05,
      "loss": 0.0053,
      "step": 3969
    },
    {
      "epoch": 40.3,
      "learning_rate": 9.144523816844463e-05,
      "loss": 0.0417,
      "step": 3970
    },
    {
      "epoch": 40.31,
      "learning_rate": 9.143859537215881e-05,
      "loss": 0.0048,
      "step": 3971
    },
    {
      "epoch": 40.32,
      "learning_rate": 9.143195023926917e-05,
      "loss": 0.0143,
      "step": 3972
    },
    {
      "epoch": 40.34,
      "learning_rate": 9.142530277015042e-05,
      "loss": 0.0279,
      "step": 3973
    },
    {
      "epoch": 40.35,
      "learning_rate": 9.141865296517738e-05,
      "loss": 0.0057,
      "step": 3974
    },
    {
      "epoch": 40.36,
      "learning_rate": 9.141200082472503e-05,
      "loss": 0.0143,
      "step": 3975
    },
    {
      "epoch": 40.37,
      "learning_rate": 9.140534634916846e-05,
      "loss": 0.0137,
      "step": 3976
    },
    {
      "epoch": 40.38,
      "learning_rate": 9.139868953888288e-05,
      "loss": 0.005,
      "step": 3977
    },
    {
      "epoch": 40.39,
      "learning_rate": 9.139203039424369e-05,
      "loss": 0.0045,
      "step": 3978
    },
    {
      "epoch": 40.4,
      "learning_rate": 9.138536891562634e-05,
      "loss": 0.0065,
      "step": 3979
    },
    {
      "epoch": 40.41,
      "learning_rate": 9.137870510340647e-05,
      "loss": 0.002,
      "step": 3980
    },
    {
      "epoch": 40.42,
      "learning_rate": 9.137203895795983e-05,
      "loss": 0.003,
      "step": 3981
    },
    {
      "epoch": 40.43,
      "learning_rate": 9.136537047966229e-05,
      "loss": 0.0301,
      "step": 3982
    },
    {
      "epoch": 40.44,
      "learning_rate": 9.13586996688899e-05,
      "loss": 0.0257,
      "step": 3983
    },
    {
      "epoch": 40.45,
      "learning_rate": 9.135202652601877e-05,
      "loss": 0.005,
      "step": 3984
    },
    {
      "epoch": 40.46,
      "learning_rate": 9.134535105142521e-05,
      "loss": 0.0274,
      "step": 3985
    },
    {
      "epoch": 40.47,
      "learning_rate": 9.133867324548562e-05,
      "loss": 0.0003,
      "step": 3986
    },
    {
      "epoch": 40.48,
      "learning_rate": 9.133199310857655e-05,
      "loss": 0.0046,
      "step": 3987
    },
    {
      "epoch": 40.49,
      "learning_rate": 9.132531064107464e-05,
      "loss": 0.0076,
      "step": 3988
    },
    {
      "epoch": 40.5,
      "learning_rate": 9.131862584335673e-05,
      "loss": 0.0059,
      "step": 3989
    },
    {
      "epoch": 40.51,
      "learning_rate": 9.131193871579975e-05,
      "loss": 0.0094,
      "step": 3990
    },
    {
      "epoch": 40.52,
      "learning_rate": 9.130524925878076e-05,
      "loss": 0.02,
      "step": 3991
    },
    {
      "epoch": 40.53,
      "learning_rate": 9.129855747267697e-05,
      "loss": 0.0006,
      "step": 3992
    },
    {
      "epoch": 40.54,
      "learning_rate": 9.12918633578657e-05,
      "loss": 0.0087,
      "step": 3993
    },
    {
      "epoch": 40.55,
      "learning_rate": 9.128516691472442e-05,
      "loss": 0.0002,
      "step": 3994
    },
    {
      "epoch": 40.56,
      "learning_rate": 9.127846814363072e-05,
      "loss": 0.001,
      "step": 3995
    },
    {
      "epoch": 40.57,
      "learning_rate": 9.127176704496232e-05,
      "loss": 0.008,
      "step": 3996
    },
    {
      "epoch": 40.58,
      "learning_rate": 9.126506361909708e-05,
      "loss": 0.0285,
      "step": 3997
    },
    {
      "epoch": 40.59,
      "learning_rate": 9.125835786641299e-05,
      "loss": 0.0022,
      "step": 3998
    },
    {
      "epoch": 40.6,
      "learning_rate": 9.125164978728816e-05,
      "loss": 0.0065,
      "step": 3999
    },
    {
      "epoch": 40.61,
      "learning_rate": 9.124493938210084e-05,
      "loss": 0.0044,
      "step": 4000
    },
    {
      "epoch": 40.62,
      "learning_rate": 9.123822665122942e-05,
      "loss": 0.0012,
      "step": 4001
    },
    {
      "epoch": 40.63,
      "learning_rate": 9.123151159505242e-05,
      "loss": 0.0153,
      "step": 4002
    },
    {
      "epoch": 40.64,
      "learning_rate": 9.122479421394847e-05,
      "loss": 0.0145,
      "step": 4003
    },
    {
      "epoch": 40.65,
      "learning_rate": 9.121807450829632e-05,
      "loss": 0.0031,
      "step": 4004
    },
    {
      "epoch": 40.66,
      "learning_rate": 9.121135247847492e-05,
      "loss": 0.0092,
      "step": 4005
    },
    {
      "epoch": 40.67,
      "learning_rate": 9.120462812486328e-05,
      "loss": 0.0073,
      "step": 4006
    },
    {
      "epoch": 40.68,
      "learning_rate": 9.119790144784057e-05,
      "loss": 0.0189,
      "step": 4007
    },
    {
      "epoch": 40.69,
      "learning_rate": 9.119117244778607e-05,
      "loss": 0.0141,
      "step": 4008
    },
    {
      "epoch": 40.7,
      "learning_rate": 9.118444112507927e-05,
      "loss": 0.0015,
      "step": 4009
    },
    {
      "epoch": 40.71,
      "learning_rate": 9.117770748009966e-05,
      "loss": 0.0112,
      "step": 4010
    },
    {
      "epoch": 40.72,
      "learning_rate": 9.117097151322697e-05,
      "loss": 0.0026,
      "step": 4011
    },
    {
      "epoch": 40.73,
      "learning_rate": 9.116423322484101e-05,
      "loss": 0.0069,
      "step": 4012
    },
    {
      "epoch": 40.74,
      "learning_rate": 9.115749261532173e-05,
      "loss": 0.0004,
      "step": 4013
    },
    {
      "epoch": 40.75,
      "learning_rate": 9.115074968504922e-05,
      "loss": 0.0266,
      "step": 4014
    },
    {
      "epoch": 40.76,
      "learning_rate": 9.11440044344037e-05,
      "loss": 0.0008,
      "step": 4015
    },
    {
      "epoch": 40.77,
      "learning_rate": 9.113725686376549e-05,
      "loss": 0.0024,
      "step": 4016
    },
    {
      "epoch": 40.78,
      "learning_rate": 9.11305069735151e-05,
      "loss": 0.0131,
      "step": 4017
    },
    {
      "epoch": 40.79,
      "learning_rate": 9.112375476403312e-05,
      "loss": 0.0007,
      "step": 4018
    },
    {
      "epoch": 40.8,
      "learning_rate": 9.11170002357003e-05,
      "loss": 0.0109,
      "step": 4019
    },
    {
      "epoch": 40.81,
      "learning_rate": 9.111024338889747e-05,
      "loss": 0.004,
      "step": 4020
    },
    {
      "epoch": 40.82,
      "learning_rate": 9.110348422400567e-05,
      "loss": 0.0011,
      "step": 4021
    },
    {
      "epoch": 40.83,
      "learning_rate": 9.109672274140601e-05,
      "loss": 0.0216,
      "step": 4022
    },
    {
      "epoch": 40.84,
      "learning_rate": 9.108995894147978e-05,
      "loss": 0.0032,
      "step": 4023
    },
    {
      "epoch": 40.85,
      "learning_rate": 9.108319282460833e-05,
      "loss": 0.02,
      "step": 4024
    },
    {
      "epoch": 40.86,
      "learning_rate": 9.107642439117321e-05,
      "loss": 0.0025,
      "step": 4025
    },
    {
      "epoch": 40.87,
      "learning_rate": 9.106965364155605e-05,
      "loss": 0.0156,
      "step": 4026
    },
    {
      "epoch": 40.88,
      "learning_rate": 9.106288057613865e-05,
      "loss": 0.009,
      "step": 4027
    },
    {
      "epoch": 40.89,
      "learning_rate": 9.105610519530294e-05,
      "loss": 0.0162,
      "step": 4028
    },
    {
      "epoch": 40.9,
      "learning_rate": 9.104932749943092e-05,
      "loss": 0.0121,
      "step": 4029
    },
    {
      "epoch": 40.91,
      "learning_rate": 9.10425474889048e-05,
      "loss": 0.0063,
      "step": 4030
    },
    {
      "epoch": 40.92,
      "learning_rate": 9.103576516410688e-05,
      "loss": 0.0008,
      "step": 4031
    },
    {
      "epoch": 40.93,
      "learning_rate": 9.102898052541958e-05,
      "loss": 0.0208,
      "step": 4032
    },
    {
      "epoch": 40.94,
      "learning_rate": 9.102219357322548e-05,
      "loss": 0.0087,
      "step": 4033
    },
    {
      "epoch": 40.95,
      "learning_rate": 9.101540430790728e-05,
      "loss": 0.0125,
      "step": 4034
    },
    {
      "epoch": 40.96,
      "learning_rate": 9.10086127298478e-05,
      "loss": 0.0094,
      "step": 4035
    },
    {
      "epoch": 40.97,
      "learning_rate": 9.100181883943e-05,
      "loss": 0.0204,
      "step": 4036
    },
    {
      "epoch": 40.98,
      "learning_rate": 9.099502263703696e-05,
      "loss": 0.0045,
      "step": 4037
    },
    {
      "epoch": 40.99,
      "learning_rate": 9.098822412305191e-05,
      "loss": 0.0026,
      "step": 4038
    },
    {
      "epoch": 40.99,
      "eval_loss": 0.021311014890670776,
      "eval_runtime": 31.9047,
      "eval_samples_per_second": 98.732,
      "eval_steps_per_second": 6.175,
      "eval_wer": 0.005857874519846351,
      "step": 4038
    },
    {
      "epoch": 41.01,
      "learning_rate": 9.098142329785819e-05,
      "loss": 0.0164,
      "step": 4039
    },
    {
      "epoch": 41.02,
      "learning_rate": 9.097462016183928e-05,
      "loss": 0.0139,
      "step": 4040
    },
    {
      "epoch": 41.03,
      "learning_rate": 9.09678147153788e-05,
      "loss": 0.0133,
      "step": 4041
    },
    {
      "epoch": 41.04,
      "learning_rate": 9.096100695886049e-05,
      "loss": 0.0219,
      "step": 4042
    },
    {
      "epoch": 41.05,
      "learning_rate": 9.09541968926682e-05,
      "loss": 0.0038,
      "step": 4043
    },
    {
      "epoch": 41.06,
      "learning_rate": 9.094738451718594e-05,
      "loss": 0.0028,
      "step": 4044
    },
    {
      "epoch": 41.07,
      "learning_rate": 9.094056983279786e-05,
      "loss": 0.009,
      "step": 4045
    },
    {
      "epoch": 41.08,
      "learning_rate": 9.093375283988819e-05,
      "loss": 0.002,
      "step": 4046
    },
    {
      "epoch": 41.09,
      "learning_rate": 9.092693353884133e-05,
      "loss": 0.0024,
      "step": 4047
    },
    {
      "epoch": 41.1,
      "learning_rate": 9.092011193004182e-05,
      "loss": 0.0055,
      "step": 4048
    },
    {
      "epoch": 41.11,
      "learning_rate": 9.091328801387428e-05,
      "loss": 0.0127,
      "step": 4049
    },
    {
      "epoch": 41.12,
      "learning_rate": 9.090646179072351e-05,
      "loss": 0.0018,
      "step": 4050
    },
    {
      "epoch": 41.13,
      "learning_rate": 9.089963326097442e-05,
      "loss": 0.0111,
      "step": 4051
    },
    {
      "epoch": 41.14,
      "learning_rate": 9.089280242501205e-05,
      "loss": 0.0099,
      "step": 4052
    },
    {
      "epoch": 41.15,
      "learning_rate": 9.088596928322158e-05,
      "loss": 0.0197,
      "step": 4053
    },
    {
      "epoch": 41.16,
      "learning_rate": 9.08791338359883e-05,
      "loss": 0.0021,
      "step": 4054
    },
    {
      "epoch": 41.17,
      "learning_rate": 9.087229608369763e-05,
      "loss": 0.004,
      "step": 4055
    },
    {
      "epoch": 41.18,
      "learning_rate": 9.086545602673514e-05,
      "loss": 0.0047,
      "step": 4056
    },
    {
      "epoch": 41.19,
      "learning_rate": 9.085861366548654e-05,
      "loss": 0.024,
      "step": 4057
    },
    {
      "epoch": 41.2,
      "learning_rate": 9.085176900033763e-05,
      "loss": 0.0256,
      "step": 4058
    },
    {
      "epoch": 41.21,
      "learning_rate": 9.084492203167436e-05,
      "loss": 0.0002,
      "step": 4059
    },
    {
      "epoch": 41.22,
      "learning_rate": 9.083807275988284e-05,
      "loss": 0.0157,
      "step": 4060
    },
    {
      "epoch": 41.23,
      "learning_rate": 9.083122118534925e-05,
      "loss": 0.0047,
      "step": 4061
    },
    {
      "epoch": 41.24,
      "learning_rate": 9.082436730845993e-05,
      "loss": 0.0099,
      "step": 4062
    },
    {
      "epoch": 41.25,
      "learning_rate": 9.081751112960138e-05,
      "loss": 0.0209,
      "step": 4063
    },
    {
      "epoch": 41.26,
      "learning_rate": 9.081065264916017e-05,
      "loss": 0.0215,
      "step": 4064
    },
    {
      "epoch": 41.27,
      "learning_rate": 9.080379186752304e-05,
      "loss": 0.0029,
      "step": 4065
    },
    {
      "epoch": 41.28,
      "learning_rate": 9.079692878507686e-05,
      "loss": 0.0027,
      "step": 4066
    },
    {
      "epoch": 41.29,
      "learning_rate": 9.079006340220862e-05,
      "loss": 0.0063,
      "step": 4067
    },
    {
      "epoch": 41.3,
      "learning_rate": 9.07831957193054e-05,
      "loss": 0.0128,
      "step": 4068
    },
    {
      "epoch": 41.31,
      "learning_rate": 9.077632573675449e-05,
      "loss": 0.0012,
      "step": 4069
    },
    {
      "epoch": 41.32,
      "learning_rate": 9.076945345494327e-05,
      "loss": 0.0025,
      "step": 4070
    },
    {
      "epoch": 41.33,
      "learning_rate": 9.076257887425923e-05,
      "loss": 0.0032,
      "step": 4071
    },
    {
      "epoch": 41.34,
      "learning_rate": 9.075570199509001e-05,
      "loss": 0.0222,
      "step": 4072
    },
    {
      "epoch": 41.35,
      "learning_rate": 9.074882281782339e-05,
      "loss": 0.0101,
      "step": 4073
    },
    {
      "epoch": 41.36,
      "learning_rate": 9.074194134284726e-05,
      "loss": 0.006,
      "step": 4074
    },
    {
      "epoch": 41.37,
      "learning_rate": 9.073505757054964e-05,
      "loss": 0.0007,
      "step": 4075
    },
    {
      "epoch": 41.38,
      "learning_rate": 9.072817150131867e-05,
      "loss": 0.0069,
      "step": 4076
    },
    {
      "epoch": 41.39,
      "learning_rate": 9.07212831355427e-05,
      "loss": 0.0014,
      "step": 4077
    },
    {
      "epoch": 41.4,
      "learning_rate": 9.071439247361006e-05,
      "loss": 0.0018,
      "step": 4078
    },
    {
      "epoch": 41.41,
      "learning_rate": 9.070749951590936e-05,
      "loss": 0.001,
      "step": 4079
    },
    {
      "epoch": 41.42,
      "learning_rate": 9.070060426282925e-05,
      "loss": 0.008,
      "step": 4080
    },
    {
      "epoch": 41.43,
      "learning_rate": 9.069370671475853e-05,
      "loss": 0.0056,
      "step": 4081
    },
    {
      "epoch": 41.44,
      "learning_rate": 9.068680687208613e-05,
      "loss": 0.0007,
      "step": 4082
    },
    {
      "epoch": 41.45,
      "learning_rate": 9.067990473520114e-05,
      "loss": 0.0102,
      "step": 4083
    },
    {
      "epoch": 41.46,
      "learning_rate": 9.067300030449272e-05,
      "loss": 0.0022,
      "step": 4084
    },
    {
      "epoch": 41.47,
      "learning_rate": 9.06660935803502e-05,
      "loss": 0.0005,
      "step": 4085
    },
    {
      "epoch": 41.48,
      "learning_rate": 9.065918456316305e-05,
      "loss": 0.028,
      "step": 4086
    },
    {
      "epoch": 41.49,
      "learning_rate": 9.065227325332082e-05,
      "loss": 0.0221,
      "step": 4087
    },
    {
      "epoch": 41.5,
      "learning_rate": 9.064535965121324e-05,
      "loss": 0.0073,
      "step": 4088
    },
    {
      "epoch": 41.51,
      "learning_rate": 9.063844375723014e-05,
      "loss": 0.0128,
      "step": 4089
    },
    {
      "epoch": 41.52,
      "learning_rate": 9.063152557176149e-05,
      "loss": 0.001,
      "step": 4090
    },
    {
      "epoch": 41.53,
      "learning_rate": 9.062460509519737e-05,
      "loss": 0.0042,
      "step": 4091
    },
    {
      "epoch": 41.54,
      "learning_rate": 9.061768232792804e-05,
      "loss": 0.001,
      "step": 4092
    },
    {
      "epoch": 41.55,
      "learning_rate": 9.061075727034383e-05,
      "loss": 0.0048,
      "step": 4093
    },
    {
      "epoch": 41.56,
      "learning_rate": 9.060382992283522e-05,
      "loss": 0.0119,
      "step": 4094
    },
    {
      "epoch": 41.57,
      "learning_rate": 9.059690028579284e-05,
      "loss": 0.0028,
      "step": 4095
    },
    {
      "epoch": 41.58,
      "learning_rate": 9.058996835960741e-05,
      "loss": 0.0096,
      "step": 4096
    },
    {
      "epoch": 41.59,
      "learning_rate": 9.058303414466984e-05,
      "loss": 0.0011,
      "step": 4097
    },
    {
      "epoch": 41.6,
      "learning_rate": 9.05760976413711e-05,
      "loss": 0.003,
      "step": 4098
    },
    {
      "epoch": 41.61,
      "learning_rate": 9.056915885010231e-05,
      "loss": 0.007,
      "step": 4099
    },
    {
      "epoch": 41.62,
      "learning_rate": 9.056221777125477e-05,
      "loss": 0.0277,
      "step": 4100
    },
    {
      "epoch": 41.63,
      "learning_rate": 9.055527440521982e-05,
      "loss": 0.0126,
      "step": 4101
    },
    {
      "epoch": 41.64,
      "learning_rate": 9.054832875238903e-05,
      "loss": 0.0027,
      "step": 4102
    },
    {
      "epoch": 41.65,
      "learning_rate": 9.0541380813154e-05,
      "loss": 0.0119,
      "step": 4103
    },
    {
      "epoch": 41.66,
      "learning_rate": 9.053443058790651e-05,
      "loss": 0.021,
      "step": 4104
    },
    {
      "epoch": 41.68,
      "learning_rate": 9.052747807703848e-05,
      "loss": 0.0062,
      "step": 4105
    },
    {
      "epoch": 41.69,
      "learning_rate": 9.052052328094194e-05,
      "loss": 0.0026,
      "step": 4106
    },
    {
      "epoch": 41.7,
      "learning_rate": 9.051356620000904e-05,
      "loss": 0.0005,
      "step": 4107
    },
    {
      "epoch": 41.71,
      "learning_rate": 9.050660683463208e-05,
      "loss": 0.0019,
      "step": 4108
    },
    {
      "epoch": 41.72,
      "learning_rate": 9.049964518520347e-05,
      "loss": 0.0016,
      "step": 4109
    },
    {
      "epoch": 41.73,
      "learning_rate": 9.049268125211577e-05,
      "loss": 0.0011,
      "step": 4110
    },
    {
      "epoch": 41.74,
      "learning_rate": 9.048571503576164e-05,
      "loss": 0.0003,
      "step": 4111
    },
    {
      "epoch": 41.75,
      "learning_rate": 9.04787465365339e-05,
      "loss": 0.0034,
      "step": 4112
    },
    {
      "epoch": 41.76,
      "learning_rate": 9.047177575482548e-05,
      "loss": 0.0065,
      "step": 4113
    },
    {
      "epoch": 41.77,
      "learning_rate": 9.046480269102944e-05,
      "loss": 0.0006,
      "step": 4114
    },
    {
      "epoch": 41.78,
      "learning_rate": 9.045782734553895e-05,
      "loss": 0.0008,
      "step": 4115
    },
    {
      "epoch": 41.79,
      "learning_rate": 9.045084971874738e-05,
      "loss": 0.0005,
      "step": 4116
    },
    {
      "epoch": 41.8,
      "learning_rate": 9.044386981104813e-05,
      "loss": 0.0012,
      "step": 4117
    },
    {
      "epoch": 41.81,
      "learning_rate": 9.04368876228348e-05,
      "loss": 0.0069,
      "step": 4118
    },
    {
      "epoch": 41.82,
      "learning_rate": 9.04299031545011e-05,
      "loss": 0.0097,
      "step": 4119
    },
    {
      "epoch": 41.83,
      "learning_rate": 9.042291640644085e-05,
      "loss": 0.019,
      "step": 4120
    },
    {
      "epoch": 41.84,
      "learning_rate": 9.0415927379048e-05,
      "loss": 0.0036,
      "step": 4121
    },
    {
      "epoch": 41.85,
      "learning_rate": 9.040893607271669e-05,
      "loss": 0.0026,
      "step": 4122
    },
    {
      "epoch": 41.86,
      "learning_rate": 9.04019424878411e-05,
      "loss": 0.0194,
      "step": 4123
    },
    {
      "epoch": 41.87,
      "learning_rate": 9.039494662481558e-05,
      "loss": 0.0045,
      "step": 4124
    },
    {
      "epoch": 41.88,
      "learning_rate": 9.038794848403463e-05,
      "loss": 0.0016,
      "step": 4125
    },
    {
      "epoch": 41.89,
      "learning_rate": 9.038094806589283e-05,
      "loss": 0.0065,
      "step": 4126
    },
    {
      "epoch": 41.9,
      "learning_rate": 9.037394537078492e-05,
      "loss": 0.0059,
      "step": 4127
    },
    {
      "epoch": 41.91,
      "learning_rate": 9.036694039910576e-05,
      "loss": 0.0073,
      "step": 4128
    },
    {
      "epoch": 41.92,
      "learning_rate": 9.035993315125036e-05,
      "loss": 0.0174,
      "step": 4129
    },
    {
      "epoch": 41.93,
      "learning_rate": 9.035292362761381e-05,
      "loss": 0.0251,
      "step": 4130
    },
    {
      "epoch": 41.94,
      "learning_rate": 9.034591182859138e-05,
      "loss": 0.0039,
      "step": 4131
    },
    {
      "epoch": 41.95,
      "learning_rate": 9.033889775457843e-05,
      "loss": 0.0029,
      "step": 4132
    },
    {
      "epoch": 41.96,
      "learning_rate": 9.033188140597048e-05,
      "loss": 0.009,
      "step": 4133
    },
    {
      "epoch": 41.97,
      "learning_rate": 9.032486278316315e-05,
      "loss": 0.0243,
      "step": 4134
    },
    {
      "epoch": 41.98,
      "learning_rate": 9.03178418865522e-05,
      "loss": 0.0016,
      "step": 4135
    },
    {
      "epoch": 41.99,
      "learning_rate": 9.031081871653351e-05,
      "loss": 0.0041,
      "step": 4136
    },
    {
      "epoch": 42.0,
      "learning_rate": 9.030379327350311e-05,
      "loss": 0.0352,
      "step": 4137
    },
    {
      "epoch": 42.0,
      "eval_loss": 0.019763773307204247,
      "eval_runtime": 32.0675,
      "eval_samples_per_second": 98.23,
      "eval_steps_per_second": 6.143,
      "eval_wer": 0.004385403329065301,
      "step": 4137
    },
    {
      "epoch": 42.01,
      "learning_rate": 9.029676555785714e-05,
      "loss": 0.0004,
      "step": 4138
    },
    {
      "epoch": 42.02,
      "learning_rate": 9.028973556999188e-05,
      "loss": 0.0008,
      "step": 4139
    },
    {
      "epoch": 42.03,
      "learning_rate": 9.028270331030373e-05,
      "loss": 0.0004,
      "step": 4140
    },
    {
      "epoch": 42.04,
      "learning_rate": 9.02756687791892e-05,
      "loss": 0.0005,
      "step": 4141
    },
    {
      "epoch": 42.05,
      "learning_rate": 9.026863197704497e-05,
      "loss": 0.0007,
      "step": 4142
    },
    {
      "epoch": 42.06,
      "learning_rate": 9.02615929042678e-05,
      "loss": 0.0016,
      "step": 4143
    },
    {
      "epoch": 42.07,
      "learning_rate": 9.025455156125466e-05,
      "loss": 0.0015,
      "step": 4144
    },
    {
      "epoch": 42.08,
      "learning_rate": 9.024750794840252e-05,
      "loss": 0.0122,
      "step": 4145
    },
    {
      "epoch": 42.09,
      "learning_rate": 9.024046206610858e-05,
      "loss": 0.0004,
      "step": 4146
    },
    {
      "epoch": 42.1,
      "learning_rate": 9.023341391477014e-05,
      "loss": 0.0029,
      "step": 4147
    },
    {
      "epoch": 42.11,
      "learning_rate": 9.022636349478462e-05,
      "loss": 0.001,
      "step": 4148
    },
    {
      "epoch": 42.12,
      "learning_rate": 9.021931080654958e-05,
      "loss": 0.0088,
      "step": 4149
    },
    {
      "epoch": 42.13,
      "learning_rate": 9.021225585046269e-05,
      "loss": 0.0008,
      "step": 4150
    },
    {
      "epoch": 42.14,
      "learning_rate": 9.020519862692176e-05,
      "loss": 0.0006,
      "step": 4151
    },
    {
      "epoch": 42.15,
      "learning_rate": 9.019813913632476e-05,
      "loss": 0.0009,
      "step": 4152
    },
    {
      "epoch": 42.16,
      "learning_rate": 9.019107737906968e-05,
      "loss": 0.001,
      "step": 4153
    },
    {
      "epoch": 42.17,
      "learning_rate": 9.01840133555548e-05,
      "loss": 0.0044,
      "step": 4154
    },
    {
      "epoch": 42.18,
      "learning_rate": 9.017694706617837e-05,
      "loss": 0.0003,
      "step": 4155
    },
    {
      "epoch": 42.19,
      "learning_rate": 9.016987851133888e-05,
      "loss": 0.0171,
      "step": 4156
    },
    {
      "epoch": 42.2,
      "learning_rate": 9.016280769143487e-05,
      "loss": 0.0209,
      "step": 4157
    },
    {
      "epoch": 42.21,
      "learning_rate": 9.015573460686509e-05,
      "loss": 0.0036,
      "step": 4158
    },
    {
      "epoch": 42.22,
      "learning_rate": 9.014865925802834e-05,
      "loss": 0.0224,
      "step": 4159
    },
    {
      "epoch": 42.23,
      "learning_rate": 9.014158164532358e-05,
      "loss": 0.0123,
      "step": 4160
    },
    {
      "epoch": 42.24,
      "learning_rate": 9.01345017691499e-05,
      "loss": 0.0113,
      "step": 4161
    },
    {
      "epoch": 42.25,
      "learning_rate": 9.012741962990652e-05,
      "loss": 0.023,
      "step": 4162
    },
    {
      "epoch": 42.26,
      "learning_rate": 9.012033522799277e-05,
      "loss": 0.0148,
      "step": 4163
    },
    {
      "epoch": 42.27,
      "learning_rate": 9.011324856380814e-05,
      "loss": 0.001,
      "step": 4164
    },
    {
      "epoch": 42.28,
      "learning_rate": 9.01061596377522e-05,
      "loss": 0.0002,
      "step": 4165
    },
    {
      "epoch": 42.29,
      "learning_rate": 9.009906845022467e-05,
      "loss": 0.0011,
      "step": 4166
    },
    {
      "epoch": 42.3,
      "learning_rate": 9.009197500162545e-05,
      "loss": 0.0053,
      "step": 4167
    },
    {
      "epoch": 42.31,
      "learning_rate": 9.008487929235448e-05,
      "loss": 0.0034,
      "step": 4168
    },
    {
      "epoch": 42.32,
      "learning_rate": 9.007778132281185e-05,
      "loss": 0.0038,
      "step": 4169
    },
    {
      "epoch": 42.34,
      "learning_rate": 9.007068109339784e-05,
      "loss": 0.0035,
      "step": 4170
    },
    {
      "epoch": 42.35,
      "learning_rate": 9.006357860451278e-05,
      "loss": 0.0081,
      "step": 4171
    },
    {
      "epoch": 42.36,
      "learning_rate": 9.005647385655718e-05,
      "loss": 0.0095,
      "step": 4172
    },
    {
      "epoch": 42.37,
      "learning_rate": 9.004936684993164e-05,
      "loss": 0.0009,
      "step": 4173
    },
    {
      "epoch": 42.38,
      "learning_rate": 9.004225758503691e-05,
      "loss": 0.0095,
      "step": 4174
    },
    {
      "epoch": 42.39,
      "learning_rate": 9.003514606227386e-05,
      "loss": 0.0048,
      "step": 4175
    },
    {
      "epoch": 42.4,
      "learning_rate": 9.002803228204348e-05,
      "loss": 0.0021,
      "step": 4176
    },
    {
      "epoch": 42.41,
      "learning_rate": 9.002091624474691e-05,
      "loss": 0.0026,
      "step": 4177
    },
    {
      "epoch": 42.42,
      "learning_rate": 9.00137979507854e-05,
      "loss": 0.0015,
      "step": 4178
    },
    {
      "epoch": 42.43,
      "learning_rate": 9.000667740056032e-05,
      "loss": 0.0043,
      "step": 4179
    },
    {
      "epoch": 42.44,
      "learning_rate": 8.999955459447319e-05,
      "loss": 0.0039,
      "step": 4180
    },
    {
      "epoch": 42.45,
      "learning_rate": 8.999242953292564e-05,
      "loss": 0.0004,
      "step": 4181
    },
    {
      "epoch": 42.46,
      "learning_rate": 8.998530221631942e-05,
      "loss": 0.0185,
      "step": 4182
    },
    {
      "epoch": 42.47,
      "learning_rate": 8.997817264505645e-05,
      "loss": 0.0011,
      "step": 4183
    },
    {
      "epoch": 42.48,
      "learning_rate": 8.997104081953872e-05,
      "loss": 0.0028,
      "step": 4184
    },
    {
      "epoch": 42.49,
      "learning_rate": 8.996390674016837e-05,
      "loss": 0.0022,
      "step": 4185
    },
    {
      "epoch": 42.5,
      "learning_rate": 8.995677040734769e-05,
      "loss": 0.0021,
      "step": 4186
    },
    {
      "epoch": 42.51,
      "learning_rate": 8.994963182147908e-05,
      "loss": 0.0004,
      "step": 4187
    },
    {
      "epoch": 42.52,
      "learning_rate": 8.994249098296503e-05,
      "loss": 0.0079,
      "step": 4188
    },
    {
      "epoch": 42.53,
      "learning_rate": 8.993534789220823e-05,
      "loss": 0.0012,
      "step": 4189
    },
    {
      "epoch": 42.54,
      "learning_rate": 8.992820254961143e-05,
      "loss": 0.0028,
      "step": 4190
    },
    {
      "epoch": 42.55,
      "learning_rate": 8.992105495557755e-05,
      "loss": 0.0149,
      "step": 4191
    },
    {
      "epoch": 42.56,
      "learning_rate": 8.991390511050962e-05,
      "loss": 0.0211,
      "step": 4192
    },
    {
      "epoch": 42.57,
      "learning_rate": 8.99067530148108e-05,
      "loss": 0.0236,
      "step": 4193
    },
    {
      "epoch": 42.58,
      "learning_rate": 8.989959866888438e-05,
      "loss": 0.0044,
      "step": 4194
    },
    {
      "epoch": 42.59,
      "learning_rate": 8.989244207313377e-05,
      "loss": 0.0079,
      "step": 4195
    },
    {
      "epoch": 42.6,
      "learning_rate": 8.98852832279625e-05,
      "loss": 0.0006,
      "step": 4196
    },
    {
      "epoch": 42.61,
      "learning_rate": 8.987812213377424e-05,
      "loss": 0.0037,
      "step": 4197
    },
    {
      "epoch": 42.62,
      "learning_rate": 8.987095879097278e-05,
      "loss": 0.0298,
      "step": 4198
    },
    {
      "epoch": 42.63,
      "learning_rate": 8.986379319996208e-05,
      "loss": 0.0005,
      "step": 4199
    },
    {
      "epoch": 42.64,
      "learning_rate": 8.985662536114613e-05,
      "loss": 0.0059,
      "step": 4200
    },
    {
      "epoch": 42.65,
      "learning_rate": 8.984945527492914e-05,
      "loss": 0.0097,
      "step": 4201
    },
    {
      "epoch": 42.66,
      "learning_rate": 8.98422829417154e-05,
      "loss": 0.0048,
      "step": 4202
    },
    {
      "epoch": 42.67,
      "learning_rate": 8.983510836190934e-05,
      "loss": 0.003,
      "step": 4203
    },
    {
      "epoch": 42.68,
      "learning_rate": 8.982793153591551e-05,
      "loss": 0.0024,
      "step": 4204
    },
    {
      "epoch": 42.69,
      "learning_rate": 8.98207524641386e-05,
      "loss": 0.0021,
      "step": 4205
    },
    {
      "epoch": 42.7,
      "learning_rate": 8.981357114698339e-05,
      "loss": 0.0172,
      "step": 4206
    },
    {
      "epoch": 42.71,
      "learning_rate": 8.980638758485485e-05,
      "loss": 0.0168,
      "step": 4207
    },
    {
      "epoch": 42.72,
      "learning_rate": 8.979920177815802e-05,
      "loss": 0.0046,
      "step": 4208
    },
    {
      "epoch": 42.73,
      "learning_rate": 8.979201372729809e-05,
      "loss": 0.0009,
      "step": 4209
    },
    {
      "epoch": 42.74,
      "learning_rate": 8.978482343268039e-05,
      "loss": 0.0183,
      "step": 4210
    },
    {
      "epoch": 42.75,
      "learning_rate": 8.977763089471033e-05,
      "loss": 0.0025,
      "step": 4211
    },
    {
      "epoch": 42.76,
      "learning_rate": 8.97704361137935e-05,
      "loss": 0.0004,
      "step": 4212
    },
    {
      "epoch": 42.77,
      "learning_rate": 8.976323909033557e-05,
      "loss": 0.0006,
      "step": 4213
    },
    {
      "epoch": 42.78,
      "learning_rate": 8.97560398247424e-05,
      "loss": 0.0014,
      "step": 4214
    },
    {
      "epoch": 42.79,
      "learning_rate": 8.974883831741989e-05,
      "loss": 0.0111,
      "step": 4215
    },
    {
      "epoch": 42.8,
      "learning_rate": 8.974163456877413e-05,
      "loss": 0.0026,
      "step": 4216
    },
    {
      "epoch": 42.81,
      "learning_rate": 8.973442857921134e-05,
      "loss": 0.0201,
      "step": 4217
    },
    {
      "epoch": 42.82,
      "learning_rate": 8.972722034913782e-05,
      "loss": 0.011,
      "step": 4218
    },
    {
      "epoch": 42.83,
      "learning_rate": 8.972000987896004e-05,
      "loss": 0.0097,
      "step": 4219
    },
    {
      "epoch": 42.84,
      "learning_rate": 8.971279716908454e-05,
      "loss": 0.0029,
      "step": 4220
    },
    {
      "epoch": 42.85,
      "learning_rate": 8.970558221991807e-05,
      "loss": 0.0092,
      "step": 4221
    },
    {
      "epoch": 42.86,
      "learning_rate": 8.969836503186743e-05,
      "loss": 0.0017,
      "step": 4222
    },
    {
      "epoch": 42.87,
      "learning_rate": 8.969114560533957e-05,
      "loss": 0.0015,
      "step": 4223
    },
    {
      "epoch": 42.88,
      "learning_rate": 8.968392394074164e-05,
      "loss": 0.0101,
      "step": 4224
    },
    {
      "epoch": 42.89,
      "learning_rate": 8.967670003848076e-05,
      "loss": 0.0038,
      "step": 4225
    },
    {
      "epoch": 42.9,
      "learning_rate": 8.966947389896431e-05,
      "loss": 0.0049,
      "step": 4226
    },
    {
      "epoch": 42.91,
      "learning_rate": 8.966224552259974e-05,
      "loss": 0.0215,
      "step": 4227
    },
    {
      "epoch": 42.92,
      "learning_rate": 8.965501490979467e-05,
      "loss": 0.0013,
      "step": 4228
    },
    {
      "epoch": 42.93,
      "learning_rate": 8.964778206095677e-05,
      "loss": 0.0015,
      "step": 4229
    },
    {
      "epoch": 42.94,
      "learning_rate": 8.964054697649389e-05,
      "loss": 0.0017,
      "step": 4230
    },
    {
      "epoch": 42.95,
      "learning_rate": 8.9633309656814e-05,
      "loss": 0.0246,
      "step": 4231
    },
    {
      "epoch": 42.96,
      "learning_rate": 8.96260701023252e-05,
      "loss": 0.0057,
      "step": 4232
    },
    {
      "epoch": 42.97,
      "learning_rate": 8.961882831343571e-05,
      "loss": 0.0165,
      "step": 4233
    },
    {
      "epoch": 42.98,
      "learning_rate": 8.961158429055385e-05,
      "loss": 0.0057,
      "step": 4234
    },
    {
      "epoch": 42.99,
      "learning_rate": 8.960433803408813e-05,
      "loss": 0.0006,
      "step": 4235
    },
    {
      "epoch": 42.99,
      "eval_loss": 0.01745019666850567,
      "eval_runtime": 32.022,
      "eval_samples_per_second": 98.37,
      "eval_steps_per_second": 6.152,
      "eval_wer": 0.0046414852752880926,
      "step": 4235
    },
    {
      "epoch": 43.01,
      "learning_rate": 8.959708954444708e-05,
      "loss": 0.0033,
      "step": 4236
    },
    {
      "epoch": 43.02,
      "learning_rate": 8.95898388220395e-05,
      "loss": 0.0017,
      "step": 4237
    },
    {
      "epoch": 43.03,
      "learning_rate": 8.958258586727418e-05,
      "loss": 0.0013,
      "step": 4238
    },
    {
      "epoch": 43.04,
      "learning_rate": 8.957533068056012e-05,
      "loss": 0.0015,
      "step": 4239
    },
    {
      "epoch": 43.05,
      "learning_rate": 8.956807326230641e-05,
      "loss": 0.02,
      "step": 4240
    },
    {
      "epoch": 43.06,
      "learning_rate": 8.956081361292228e-05,
      "loss": 0.0123,
      "step": 4241
    },
    {
      "epoch": 43.07,
      "learning_rate": 8.955355173281708e-05,
      "loss": 0.0012,
      "step": 4242
    },
    {
      "epoch": 43.08,
      "learning_rate": 8.954628762240028e-05,
      "loss": 0.0147,
      "step": 4243
    },
    {
      "epoch": 43.09,
      "learning_rate": 8.953902128208147e-05,
      "loss": 0.0012,
      "step": 4244
    },
    {
      "epoch": 43.1,
      "learning_rate": 8.953175271227041e-05,
      "loss": 0.0061,
      "step": 4245
    },
    {
      "epoch": 43.11,
      "learning_rate": 8.952448191337694e-05,
      "loss": 0.0085,
      "step": 4246
    },
    {
      "epoch": 43.12,
      "learning_rate": 8.951720888581105e-05,
      "loss": 0.0014,
      "step": 4247
    },
    {
      "epoch": 43.13,
      "learning_rate": 8.950993362998281e-05,
      "loss": 0.0008,
      "step": 4248
    },
    {
      "epoch": 43.14,
      "learning_rate": 8.95026561463025e-05,
      "loss": 0.0011,
      "step": 4249
    },
    {
      "epoch": 43.15,
      "learning_rate": 8.949537643518043e-05,
      "loss": 0.0212,
      "step": 4250
    },
    {
      "epoch": 43.16,
      "learning_rate": 8.948809449702711e-05,
      "loss": 0.0164,
      "step": 4251
    },
    {
      "epoch": 43.17,
      "learning_rate": 8.948081033225315e-05,
      "loss": 0.0019,
      "step": 4252
    },
    {
      "epoch": 43.18,
      "learning_rate": 8.947352394126927e-05,
      "loss": 0.0008,
      "step": 4253
    },
    {
      "epoch": 43.19,
      "learning_rate": 8.946623532448632e-05,
      "loss": 0.0023,
      "step": 4254
    },
    {
      "epoch": 43.2,
      "learning_rate": 8.945894448231532e-05,
      "loss": 0.008,
      "step": 4255
    },
    {
      "epoch": 43.21,
      "learning_rate": 8.945165141516734e-05,
      "loss": 0.0029,
      "step": 4256
    },
    {
      "epoch": 43.22,
      "learning_rate": 8.944435612345364e-05,
      "loss": 0.0022,
      "step": 4257
    },
    {
      "epoch": 43.23,
      "learning_rate": 8.943705860758557e-05,
      "loss": 0.009,
      "step": 4258
    },
    {
      "epoch": 43.24,
      "learning_rate": 8.942975886797462e-05,
      "loss": 0.0162,
      "step": 4259
    },
    {
      "epoch": 43.25,
      "learning_rate": 8.942245690503239e-05,
      "loss": 0.0117,
      "step": 4260
    },
    {
      "epoch": 43.26,
      "learning_rate": 8.941515271917065e-05,
      "loss": 0.0003,
      "step": 4261
    },
    {
      "epoch": 43.27,
      "learning_rate": 8.940784631080122e-05,
      "loss": 0.0008,
      "step": 4262
    },
    {
      "epoch": 43.28,
      "learning_rate": 8.940053768033609e-05,
      "loss": 0.0003,
      "step": 4263
    },
    {
      "epoch": 43.29,
      "learning_rate": 8.939322682818742e-05,
      "loss": 0.0002,
      "step": 4264
    },
    {
      "epoch": 43.3,
      "learning_rate": 8.938591375476742e-05,
      "loss": 0.0076,
      "step": 4265
    },
    {
      "epoch": 43.31,
      "learning_rate": 8.937859846048842e-05,
      "loss": 0.0002,
      "step": 4266
    },
    {
      "epoch": 43.32,
      "learning_rate": 8.937128094576297e-05,
      "loss": 0.0015,
      "step": 4267
    },
    {
      "epoch": 43.33,
      "learning_rate": 8.936396121100363e-05,
      "loss": 0.0047,
      "step": 4268
    },
    {
      "epoch": 43.34,
      "learning_rate": 8.935663925662317e-05,
      "loss": 0.0038,
      "step": 4269
    },
    {
      "epoch": 43.35,
      "learning_rate": 8.934931508303445e-05,
      "loss": 0.0005,
      "step": 4270
    },
    {
      "epoch": 43.36,
      "learning_rate": 8.934198869065045e-05,
      "loss": 0.0011,
      "step": 4271
    },
    {
      "epoch": 43.37,
      "learning_rate": 8.933466007988429e-05,
      "loss": 0.0084,
      "step": 4272
    },
    {
      "epoch": 43.38,
      "learning_rate": 8.932732925114922e-05,
      "loss": 0.0141,
      "step": 4273
    },
    {
      "epoch": 43.39,
      "learning_rate": 8.931999620485859e-05,
      "loss": 0.0147,
      "step": 4274
    },
    {
      "epoch": 43.4,
      "learning_rate": 8.931266094142587e-05,
      "loss": 0.0012,
      "step": 4275
    },
    {
      "epoch": 43.41,
      "learning_rate": 8.930532346126472e-05,
      "loss": 0.0057,
      "step": 4276
    },
    {
      "epoch": 43.42,
      "learning_rate": 8.929798376478884e-05,
      "loss": 0.0116,
      "step": 4277
    },
    {
      "epoch": 43.43,
      "learning_rate": 8.929064185241213e-05,
      "loss": 0.0003,
      "step": 4278
    },
    {
      "epoch": 43.44,
      "learning_rate": 8.928329772454855e-05,
      "loss": 0.0006,
      "step": 4279
    },
    {
      "epoch": 43.45,
      "learning_rate": 8.927595138161222e-05,
      "loss": 0.0187,
      "step": 4280
    },
    {
      "epoch": 43.46,
      "learning_rate": 8.926860282401739e-05,
      "loss": 0.0059,
      "step": 4281
    },
    {
      "epoch": 43.47,
      "learning_rate": 8.926125205217842e-05,
      "loss": 0.0016,
      "step": 4282
    },
    {
      "epoch": 43.48,
      "learning_rate": 8.925389906650979e-05,
      "loss": 0.0072,
      "step": 4283
    },
    {
      "epoch": 43.49,
      "learning_rate": 8.924654386742613e-05,
      "loss": 0.0026,
      "step": 4284
    },
    {
      "epoch": 43.5,
      "learning_rate": 8.923918645534218e-05,
      "loss": 0.0022,
      "step": 4285
    },
    {
      "epoch": 43.51,
      "learning_rate": 8.923182683067278e-05,
      "loss": 0.023,
      "step": 4286
    },
    {
      "epoch": 43.52,
      "learning_rate": 8.92244649938329e-05,
      "loss": 0.0274,
      "step": 4287
    },
    {
      "epoch": 43.53,
      "learning_rate": 8.921710094523773e-05,
      "loss": 0.0147,
      "step": 4288
    },
    {
      "epoch": 43.54,
      "learning_rate": 8.920973468530244e-05,
      "loss": 0.0027,
      "step": 4289
    },
    {
      "epoch": 43.55,
      "learning_rate": 8.920236621444243e-05,
      "loss": 0.0098,
      "step": 4290
    },
    {
      "epoch": 43.56,
      "learning_rate": 8.919499553307316e-05,
      "loss": 0.0037,
      "step": 4291
    },
    {
      "epoch": 43.57,
      "learning_rate": 8.918762264161025e-05,
      "loss": 0.0028,
      "step": 4292
    },
    {
      "epoch": 43.58,
      "learning_rate": 8.918024754046946e-05,
      "loss": 0.0099,
      "step": 4293
    },
    {
      "epoch": 43.59,
      "learning_rate": 8.91728702300666e-05,
      "loss": 0.0112,
      "step": 4294
    },
    {
      "epoch": 43.6,
      "learning_rate": 8.91654907108177e-05,
      "loss": 0.008,
      "step": 4295
    },
    {
      "epoch": 43.61,
      "learning_rate": 8.915810898313885e-05,
      "loss": 0.0201,
      "step": 4296
    },
    {
      "epoch": 43.62,
      "learning_rate": 8.91507250474463e-05,
      "loss": 0.0154,
      "step": 4297
    },
    {
      "epoch": 43.63,
      "learning_rate": 8.914333890415639e-05,
      "loss": 0.0162,
      "step": 4298
    },
    {
      "epoch": 43.64,
      "learning_rate": 8.913595055368562e-05,
      "loss": 0.0009,
      "step": 4299
    },
    {
      "epoch": 43.65,
      "learning_rate": 8.912855999645058e-05,
      "loss": 0.0127,
      "step": 4300
    },
    {
      "epoch": 43.66,
      "learning_rate": 8.912116723286802e-05,
      "loss": 0.0006,
      "step": 4301
    },
    {
      "epoch": 43.68,
      "learning_rate": 8.911377226335479e-05,
      "loss": 0.0072,
      "step": 4302
    },
    {
      "epoch": 43.69,
      "learning_rate": 8.910637508832787e-05,
      "loss": 0.0024,
      "step": 4303
    },
    {
      "epoch": 43.7,
      "learning_rate": 8.909897570820436e-05,
      "loss": 0.0024,
      "step": 4304
    },
    {
      "epoch": 43.71,
      "learning_rate": 8.90915741234015e-05,
      "loss": 0.0123,
      "step": 4305
    },
    {
      "epoch": 43.72,
      "learning_rate": 8.908417033433663e-05,
      "loss": 0.005,
      "step": 4306
    },
    {
      "epoch": 43.73,
      "learning_rate": 8.907676434142725e-05,
      "loss": 0.014,
      "step": 4307
    },
    {
      "epoch": 43.74,
      "learning_rate": 8.906935614509095e-05,
      "loss": 0.0015,
      "step": 4308
    },
    {
      "epoch": 43.75,
      "learning_rate": 8.906194574574546e-05,
      "loss": 0.0018,
      "step": 4309
    },
    {
      "epoch": 43.76,
      "learning_rate": 8.905453314380863e-05,
      "loss": 0.0009,
      "step": 4310
    },
    {
      "epoch": 43.77,
      "learning_rate": 8.904711833969844e-05,
      "loss": 0.0009,
      "step": 4311
    },
    {
      "epoch": 43.78,
      "learning_rate": 8.903970133383297e-05,
      "loss": 0.0107,
      "step": 4312
    },
    {
      "epoch": 43.79,
      "learning_rate": 8.903228212663046e-05,
      "loss": 0.0146,
      "step": 4313
    },
    {
      "epoch": 43.8,
      "learning_rate": 8.902486071850926e-05,
      "loss": 0.0005,
      "step": 4314
    },
    {
      "epoch": 43.81,
      "learning_rate": 8.901743710988784e-05,
      "loss": 0.0015,
      "step": 4315
    },
    {
      "epoch": 43.82,
      "learning_rate": 8.90100113011848e-05,
      "loss": 0.0024,
      "step": 4316
    },
    {
      "epoch": 43.83,
      "learning_rate": 8.900258329281886e-05,
      "loss": 0.0078,
      "step": 4317
    },
    {
      "epoch": 43.84,
      "learning_rate": 8.899515308520883e-05,
      "loss": 0.0092,
      "step": 4318
    },
    {
      "epoch": 43.85,
      "learning_rate": 8.898772067877372e-05,
      "loss": 0.0139,
      "step": 4319
    },
    {
      "epoch": 43.86,
      "learning_rate": 8.89802860739326e-05,
      "loss": 0.0187,
      "step": 4320
    },
    {
      "epoch": 43.87,
      "learning_rate": 8.897284927110472e-05,
      "loss": 0.0018,
      "step": 4321
    },
    {
      "epoch": 43.88,
      "learning_rate": 8.896541027070939e-05,
      "loss": 0.0043,
      "step": 4322
    },
    {
      "epoch": 43.89,
      "learning_rate": 8.895796907316607e-05,
      "loss": 0.0002,
      "step": 4323
    },
    {
      "epoch": 43.9,
      "learning_rate": 8.895052567889434e-05,
      "loss": 0.0034,
      "step": 4324
    },
    {
      "epoch": 43.91,
      "learning_rate": 8.894308008831396e-05,
      "loss": 0.001,
      "step": 4325
    },
    {
      "epoch": 43.92,
      "learning_rate": 8.89356323018447e-05,
      "loss": 0.0039,
      "step": 4326
    },
    {
      "epoch": 43.93,
      "learning_rate": 8.892818231990658e-05,
      "loss": 0.0067,
      "step": 4327
    },
    {
      "epoch": 43.94,
      "learning_rate": 8.892073014291964e-05,
      "loss": 0.0106,
      "step": 4328
    },
    {
      "epoch": 43.95,
      "learning_rate": 8.891327577130412e-05,
      "loss": 0.0056,
      "step": 4329
    },
    {
      "epoch": 43.96,
      "learning_rate": 8.890581920548032e-05,
      "loss": 0.0007,
      "step": 4330
    },
    {
      "epoch": 43.97,
      "learning_rate": 8.889836044586872e-05,
      "loss": 0.0066,
      "step": 4331
    },
    {
      "epoch": 43.98,
      "learning_rate": 8.889089949288986e-05,
      "loss": 0.0073,
      "step": 4332
    },
    {
      "epoch": 43.99,
      "learning_rate": 8.88834363469645e-05,
      "loss": 0.0147,
      "step": 4333
    },
    {
      "epoch": 44.0,
      "learning_rate": 8.887597100851343e-05,
      "loss": 0.0094,
      "step": 4334
    },
    {
      "epoch": 44.0,
      "eval_loss": 0.01819690689444542,
      "eval_runtime": 31.8709,
      "eval_samples_per_second": 98.836,
      "eval_steps_per_second": 6.181,
      "eval_wer": 0.00560179257362356,
      "step": 4334
    },
    {
      "epoch": 44.01,
      "learning_rate": 8.886850347795758e-05,
      "loss": 0.0022,
      "step": 4335
    },
    {
      "epoch": 44.02,
      "learning_rate": 8.886103375571808e-05,
      "loss": 0.0009,
      "step": 4336
    },
    {
      "epoch": 44.03,
      "learning_rate": 8.885356184221607e-05,
      "loss": 0.013,
      "step": 4337
    },
    {
      "epoch": 44.04,
      "learning_rate": 8.884608773787288e-05,
      "loss": 0.0007,
      "step": 4338
    },
    {
      "epoch": 44.05,
      "learning_rate": 8.883861144310999e-05,
      "loss": 0.0024,
      "step": 4339
    },
    {
      "epoch": 44.06,
      "learning_rate": 8.883113295834892e-05,
      "loss": 0.0056,
      "step": 4340
    },
    {
      "epoch": 44.07,
      "learning_rate": 8.882365228401139e-05,
      "loss": 0.0013,
      "step": 4341
    },
    {
      "epoch": 44.08,
      "learning_rate": 8.881616942051922e-05,
      "loss": 0.0096,
      "step": 4342
    },
    {
      "epoch": 44.09,
      "learning_rate": 8.880868436829433e-05,
      "loss": 0.0084,
      "step": 4343
    },
    {
      "epoch": 44.1,
      "learning_rate": 8.880119712775876e-05,
      "loss": 0.0162,
      "step": 4344
    },
    {
      "epoch": 44.11,
      "learning_rate": 8.879370769933474e-05,
      "loss": 0.0208,
      "step": 4345
    },
    {
      "epoch": 44.12,
      "learning_rate": 8.878621608344455e-05,
      "loss": 0.0018,
      "step": 4346
    },
    {
      "epoch": 44.13,
      "learning_rate": 8.877872228051061e-05,
      "loss": 0.0011,
      "step": 4347
    },
    {
      "epoch": 44.14,
      "learning_rate": 8.87712262909555e-05,
      "loss": 0.0031,
      "step": 4348
    },
    {
      "epoch": 44.15,
      "learning_rate": 8.876372811520191e-05,
      "loss": 0.0038,
      "step": 4349
    },
    {
      "epoch": 44.16,
      "learning_rate": 8.87562277536726e-05,
      "loss": 0.0118,
      "step": 4350
    },
    {
      "epoch": 44.17,
      "learning_rate": 8.87487252067905e-05,
      "loss": 0.017,
      "step": 4351
    },
    {
      "epoch": 44.18,
      "learning_rate": 8.87412204749787e-05,
      "loss": 0.002,
      "step": 4352
    },
    {
      "epoch": 44.19,
      "learning_rate": 8.873371355866031e-05,
      "loss": 0.0063,
      "step": 4353
    },
    {
      "epoch": 44.2,
      "learning_rate": 8.872620445825868e-05,
      "loss": 0.0153,
      "step": 4354
    },
    {
      "epoch": 44.21,
      "learning_rate": 8.871869317419717e-05,
      "loss": 0.0043,
      "step": 4355
    },
    {
      "epoch": 44.22,
      "learning_rate": 8.871117970689937e-05,
      "loss": 0.0056,
      "step": 4356
    },
    {
      "epoch": 44.23,
      "learning_rate": 8.870366405678892e-05,
      "loss": 0.0113,
      "step": 4357
    },
    {
      "epoch": 44.24,
      "learning_rate": 8.869614622428961e-05,
      "loss": 0.0197,
      "step": 4358
    },
    {
      "epoch": 44.25,
      "learning_rate": 8.868862620982534e-05,
      "loss": 0.0004,
      "step": 4359
    },
    {
      "epoch": 44.26,
      "learning_rate": 8.868110401382015e-05,
      "loss": 0.0003,
      "step": 4360
    },
    {
      "epoch": 44.27,
      "learning_rate": 8.86735796366982e-05,
      "loss": 0.0015,
      "step": 4361
    },
    {
      "epoch": 44.28,
      "learning_rate": 8.866605307888377e-05,
      "loss": 0.0108,
      "step": 4362
    },
    {
      "epoch": 44.29,
      "learning_rate": 8.865852434080124e-05,
      "loss": 0.0221,
      "step": 4363
    },
    {
      "epoch": 44.3,
      "learning_rate": 8.865099342287516e-05,
      "loss": 0.0085,
      "step": 4364
    },
    {
      "epoch": 44.31,
      "learning_rate": 8.864346032553016e-05,
      "loss": 0.0071,
      "step": 4365
    },
    {
      "epoch": 44.32,
      "learning_rate": 8.863592504919101e-05,
      "loss": 0.0156,
      "step": 4366
    },
    {
      "epoch": 44.34,
      "learning_rate": 8.862838759428262e-05,
      "loss": 0.0008,
      "step": 4367
    },
    {
      "epoch": 44.35,
      "learning_rate": 8.862084796122998e-05,
      "loss": 0.0154,
      "step": 4368
    },
    {
      "epoch": 44.36,
      "learning_rate": 8.861330615045824e-05,
      "loss": 0.0014,
      "step": 4369
    },
    {
      "epoch": 44.37,
      "learning_rate": 8.860576216239267e-05,
      "loss": 0.0021,
      "step": 4370
    },
    {
      "epoch": 44.38,
      "learning_rate": 8.859821599745866e-05,
      "loss": 0.003,
      "step": 4371
    },
    {
      "epoch": 44.39,
      "learning_rate": 8.859066765608168e-05,
      "loss": 0.0018,
      "step": 4372
    },
    {
      "epoch": 44.4,
      "learning_rate": 8.858311713868738e-05,
      "loss": 0.004,
      "step": 4373
    },
    {
      "epoch": 44.41,
      "learning_rate": 8.857556444570155e-05,
      "loss": 0.0036,
      "step": 4374
    },
    {
      "epoch": 44.42,
      "learning_rate": 8.856800957755e-05,
      "loss": 0.0117,
      "step": 4375
    },
    {
      "epoch": 44.43,
      "learning_rate": 8.856045253465875e-05,
      "loss": 0.027,
      "step": 4376
    },
    {
      "epoch": 44.44,
      "learning_rate": 8.855289331745395e-05,
      "loss": 0.0008,
      "step": 4377
    },
    {
      "epoch": 44.45,
      "learning_rate": 8.854533192636179e-05,
      "loss": 0.0005,
      "step": 4378
    },
    {
      "epoch": 44.46,
      "learning_rate": 8.853776836180869e-05,
      "loss": 0.0115,
      "step": 4379
    },
    {
      "epoch": 44.47,
      "learning_rate": 8.853020262422111e-05,
      "loss": 0.0021,
      "step": 4380
    },
    {
      "epoch": 44.48,
      "learning_rate": 8.852263471402566e-05,
      "loss": 0.0218,
      "step": 4381
    },
    {
      "epoch": 44.49,
      "learning_rate": 8.851506463164907e-05,
      "loss": 0.0019,
      "step": 4382
    },
    {
      "epoch": 44.5,
      "learning_rate": 8.850749237751819e-05,
      "loss": 0.0059,
      "step": 4383
    },
    {
      "epoch": 44.51,
      "learning_rate": 8.849991795206003e-05,
      "loss": 0.0059,
      "step": 4384
    },
    {
      "epoch": 44.52,
      "learning_rate": 8.849234135570166e-05,
      "loss": 0.0025,
      "step": 4385
    },
    {
      "epoch": 44.53,
      "learning_rate": 8.848476258887031e-05,
      "loss": 0.0119,
      "step": 4386
    },
    {
      "epoch": 44.54,
      "learning_rate": 8.847718165199332e-05,
      "loss": 0.0066,
      "step": 4387
    },
    {
      "epoch": 44.55,
      "learning_rate": 8.846959854549817e-05,
      "loss": 0.0059,
      "step": 4388
    },
    {
      "epoch": 44.56,
      "learning_rate": 8.846201326981245e-05,
      "loss": 0.0014,
      "step": 4389
    },
    {
      "epoch": 44.57,
      "learning_rate": 8.845442582536385e-05,
      "loss": 0.0154,
      "step": 4390
    },
    {
      "epoch": 44.58,
      "learning_rate": 8.844683621258023e-05,
      "loss": 0.0012,
      "step": 4391
    },
    {
      "epoch": 44.59,
      "learning_rate": 8.843924443188954e-05,
      "loss": 0.0084,
      "step": 4392
    },
    {
      "epoch": 44.6,
      "learning_rate": 8.843165048371985e-05,
      "loss": 0.0022,
      "step": 4393
    },
    {
      "epoch": 44.61,
      "learning_rate": 8.842405436849935e-05,
      "loss": 0.0075,
      "step": 4394
    },
    {
      "epoch": 44.62,
      "learning_rate": 8.84164560866564e-05,
      "loss": 0.0105,
      "step": 4395
    },
    {
      "epoch": 44.63,
      "learning_rate": 8.84088556386194e-05,
      "loss": 0.0094,
      "step": 4396
    },
    {
      "epoch": 44.64,
      "learning_rate": 8.840125302481697e-05,
      "loss": 0.0045,
      "step": 4397
    },
    {
      "epoch": 44.65,
      "learning_rate": 8.839364824567775e-05,
      "loss": 0.0042,
      "step": 4398
    },
    {
      "epoch": 44.66,
      "learning_rate": 8.838604130163059e-05,
      "loss": 0.0167,
      "step": 4399
    },
    {
      "epoch": 44.67,
      "learning_rate": 8.83784321931044e-05,
      "loss": 0.005,
      "step": 4400
    },
    {
      "epoch": 44.68,
      "learning_rate": 8.837082092052825e-05,
      "loss": 0.0029,
      "step": 4401
    },
    {
      "epoch": 44.69,
      "learning_rate": 8.836320748433129e-05,
      "loss": 0.0229,
      "step": 4402
    },
    {
      "epoch": 44.7,
      "learning_rate": 8.835559188494286e-05,
      "loss": 0.0151,
      "step": 4403
    },
    {
      "epoch": 44.71,
      "learning_rate": 8.834797412279237e-05,
      "loss": 0.0198,
      "step": 4404
    },
    {
      "epoch": 44.72,
      "learning_rate": 8.834035419830933e-05,
      "loss": 0.0013,
      "step": 4405
    },
    {
      "epoch": 44.73,
      "learning_rate": 8.833273211192345e-05,
      "loss": 0.0004,
      "step": 4406
    },
    {
      "epoch": 44.74,
      "learning_rate": 8.832510786406449e-05,
      "loss": 0.0131,
      "step": 4407
    },
    {
      "epoch": 44.75,
      "learning_rate": 8.831748145516237e-05,
      "loss": 0.0013,
      "step": 4408
    },
    {
      "epoch": 44.76,
      "learning_rate": 8.830985288564713e-05,
      "loss": 0.0237,
      "step": 4409
    },
    {
      "epoch": 44.77,
      "learning_rate": 8.83022221559489e-05,
      "loss": 0.0011,
      "step": 4410
    },
    {
      "epoch": 44.78,
      "learning_rate": 8.829458926649799e-05,
      "loss": 0.0016,
      "step": 4411
    },
    {
      "epoch": 44.79,
      "learning_rate": 8.828695421772475e-05,
      "loss": 0.0007,
      "step": 4412
    },
    {
      "epoch": 44.8,
      "learning_rate": 8.827931701005974e-05,
      "loss": 0.002,
      "step": 4413
    },
    {
      "epoch": 44.81,
      "learning_rate": 8.827167764393358e-05,
      "loss": 0.0005,
      "step": 4414
    },
    {
      "epoch": 44.82,
      "learning_rate": 8.826403611977704e-05,
      "loss": 0.0007,
      "step": 4415
    },
    {
      "epoch": 44.83,
      "learning_rate": 8.8256392438021e-05,
      "loss": 0.0208,
      "step": 4416
    },
    {
      "epoch": 44.84,
      "learning_rate": 8.824874659909646e-05,
      "loss": 0.0021,
      "step": 4417
    },
    {
      "epoch": 44.85,
      "learning_rate": 8.824109860343455e-05,
      "loss": 0.0004,
      "step": 4418
    },
    {
      "epoch": 44.86,
      "learning_rate": 8.823344845146652e-05,
      "loss": 0.0015,
      "step": 4419
    },
    {
      "epoch": 44.87,
      "learning_rate": 8.822579614362377e-05,
      "loss": 0.0122,
      "step": 4420
    },
    {
      "epoch": 44.88,
      "learning_rate": 8.821814168033772e-05,
      "loss": 0.007,
      "step": 4421
    },
    {
      "epoch": 44.89,
      "learning_rate": 8.821048506204007e-05,
      "loss": 0.001,
      "step": 4422
    },
    {
      "epoch": 44.9,
      "learning_rate": 8.820282628916247e-05,
      "loss": 0.0184,
      "step": 4423
    },
    {
      "epoch": 44.91,
      "learning_rate": 8.819516536213683e-05,
      "loss": 0.0364,
      "step": 4424
    },
    {
      "epoch": 44.92,
      "learning_rate": 8.818750228139512e-05,
      "loss": 0.0061,
      "step": 4425
    },
    {
      "epoch": 44.93,
      "learning_rate": 8.817983704736943e-05,
      "loss": 0.0039,
      "step": 4426
    },
    {
      "epoch": 44.94,
      "learning_rate": 8.8172169660492e-05,
      "loss": 0.0234,
      "step": 4427
    },
    {
      "epoch": 44.95,
      "learning_rate": 8.816450012119514e-05,
      "loss": 0.0034,
      "step": 4428
    },
    {
      "epoch": 44.96,
      "learning_rate": 8.815682842991133e-05,
      "loss": 0.0068,
      "step": 4429
    },
    {
      "epoch": 44.97,
      "learning_rate": 8.814915458707316e-05,
      "loss": 0.0036,
      "step": 4430
    },
    {
      "epoch": 44.98,
      "learning_rate": 8.814147859311332e-05,
      "loss": 0.0018,
      "step": 4431
    },
    {
      "epoch": 44.99,
      "learning_rate": 8.813380044846466e-05,
      "loss": 0.0047,
      "step": 4432
    },
    {
      "epoch": 44.99,
      "eval_loss": 0.018555624410510063,
      "eval_runtime": 31.7204,
      "eval_samples_per_second": 99.305,
      "eval_steps_per_second": 6.211,
      "eval_wer": 0.0046414852752880926,
      "step": 4432
    },
    {
      "epoch": 45.01,
      "learning_rate": 8.812612015356012e-05,
      "loss": 0.0003,
      "step": 4433
    },
    {
      "epoch": 45.02,
      "learning_rate": 8.811843770883277e-05,
      "loss": 0.0001,
      "step": 4434
    },
    {
      "epoch": 45.03,
      "learning_rate": 8.81107531147158e-05,
      "loss": 0.0007,
      "step": 4435
    },
    {
      "epoch": 45.04,
      "learning_rate": 8.81030663716425e-05,
      "loss": 0.0005,
      "step": 4436
    },
    {
      "epoch": 45.05,
      "learning_rate": 8.809537748004633e-05,
      "loss": 0.0002,
      "step": 4437
    },
    {
      "epoch": 45.06,
      "learning_rate": 8.808768644036085e-05,
      "loss": 0.0096,
      "step": 4438
    },
    {
      "epoch": 45.07,
      "learning_rate": 8.807999325301972e-05,
      "loss": 0.0147,
      "step": 4439
    },
    {
      "epoch": 45.08,
      "learning_rate": 8.807229791845673e-05,
      "loss": 0.0038,
      "step": 4440
    },
    {
      "epoch": 45.09,
      "learning_rate": 8.80646004371058e-05,
      "loss": 0.0035,
      "step": 4441
    },
    {
      "epoch": 45.1,
      "learning_rate": 8.805690080940102e-05,
      "loss": 0.0047,
      "step": 4442
    },
    {
      "epoch": 45.11,
      "learning_rate": 8.804919903577646e-05,
      "loss": 0.0008,
      "step": 4443
    },
    {
      "epoch": 45.12,
      "learning_rate": 8.804149511666648e-05,
      "loss": 0.0109,
      "step": 4444
    },
    {
      "epoch": 45.13,
      "learning_rate": 8.803378905250544e-05,
      "loss": 0.0037,
      "step": 4445
    },
    {
      "epoch": 45.14,
      "learning_rate": 8.802608084372787e-05,
      "loss": 0.0008,
      "step": 4446
    },
    {
      "epoch": 45.15,
      "learning_rate": 8.80183704907684e-05,
      "loss": 0.0007,
      "step": 4447
    },
    {
      "epoch": 45.16,
      "learning_rate": 8.801065799406186e-05,
      "loss": 0.0005,
      "step": 4448
    },
    {
      "epoch": 45.17,
      "learning_rate": 8.800294335404305e-05,
      "loss": 0.0049,
      "step": 4449
    },
    {
      "epoch": 45.18,
      "learning_rate": 8.7995226571147e-05,
      "loss": 0.0003,
      "step": 4450
    },
    {
      "epoch": 45.19,
      "learning_rate": 8.798750764580889e-05,
      "loss": 0.0012,
      "step": 4451
    },
    {
      "epoch": 45.2,
      "learning_rate": 8.797978657846391e-05,
      "loss": 0.0069,
      "step": 4452
    },
    {
      "epoch": 45.21,
      "learning_rate": 8.797206336954745e-05,
      "loss": 0.0046,
      "step": 4453
    },
    {
      "epoch": 45.22,
      "learning_rate": 8.796433801949499e-05,
      "loss": 0.0088,
      "step": 4454
    },
    {
      "epoch": 45.23,
      "learning_rate": 8.795661052874217e-05,
      "loss": 0.0051,
      "step": 4455
    },
    {
      "epoch": 45.24,
      "learning_rate": 8.794888089772468e-05,
      "loss": 0.0039,
      "step": 4456
    },
    {
      "epoch": 45.25,
      "learning_rate": 8.794114912687841e-05,
      "loss": 0.0059,
      "step": 4457
    },
    {
      "epoch": 45.26,
      "learning_rate": 8.79334152166393e-05,
      "loss": 0.0065,
      "step": 4458
    },
    {
      "epoch": 45.27,
      "learning_rate": 8.792567916744346e-05,
      "loss": 0.0124,
      "step": 4459
    },
    {
      "epoch": 45.28,
      "learning_rate": 8.79179409797271e-05,
      "loss": 0.0036,
      "step": 4460
    },
    {
      "epoch": 45.29,
      "learning_rate": 8.791020065392654e-05,
      "loss": 0.0019,
      "step": 4461
    },
    {
      "epoch": 45.3,
      "learning_rate": 8.790245819047826e-05,
      "loss": 0.0121,
      "step": 4462
    },
    {
      "epoch": 45.31,
      "learning_rate": 8.789471358981884e-05,
      "loss": 0.0009,
      "step": 4463
    },
    {
      "epoch": 45.32,
      "learning_rate": 8.788696685238494e-05,
      "loss": 0.0019,
      "step": 4464
    },
    {
      "epoch": 45.33,
      "learning_rate": 8.787921797861341e-05,
      "loss": 0.0203,
      "step": 4465
    },
    {
      "epoch": 45.34,
      "learning_rate": 8.787146696894118e-05,
      "loss": 0.0142,
      "step": 4466
    },
    {
      "epoch": 45.35,
      "learning_rate": 8.786371382380528e-05,
      "loss": 0.0085,
      "step": 4467
    },
    {
      "epoch": 45.36,
      "learning_rate": 8.785595854364292e-05,
      "loss": 0.0004,
      "step": 4468
    },
    {
      "epoch": 45.37,
      "learning_rate": 8.784820112889138e-05,
      "loss": 0.0167,
      "step": 4469
    },
    {
      "epoch": 45.38,
      "learning_rate": 8.78404415799881e-05,
      "loss": 0.0008,
      "step": 4470
    },
    {
      "epoch": 45.39,
      "learning_rate": 8.783267989737059e-05,
      "loss": 0.0244,
      "step": 4471
    },
    {
      "epoch": 45.4,
      "learning_rate": 8.782491608147651e-05,
      "loss": 0.0009,
      "step": 4472
    },
    {
      "epoch": 45.41,
      "learning_rate": 8.781715013274367e-05,
      "loss": 0.0024,
      "step": 4473
    },
    {
      "epoch": 45.42,
      "learning_rate": 8.780938205160995e-05,
      "loss": 0.0066,
      "step": 4474
    },
    {
      "epoch": 45.43,
      "learning_rate": 8.780161183851339e-05,
      "loss": 0.0044,
      "step": 4475
    },
    {
      "epoch": 45.44,
      "learning_rate": 8.779383949389209e-05,
      "loss": 0.0006,
      "step": 4476
    },
    {
      "epoch": 45.45,
      "learning_rate": 8.778606501818433e-05,
      "loss": 0.002,
      "step": 4477
    },
    {
      "epoch": 45.46,
      "learning_rate": 8.777828841182852e-05,
      "loss": 0.0043,
      "step": 4478
    },
    {
      "epoch": 45.47,
      "learning_rate": 8.77705096752631e-05,
      "loss": 0.002,
      "step": 4479
    },
    {
      "epoch": 45.48,
      "learning_rate": 8.776272880892675e-05,
      "loss": 0.0116,
      "step": 4480
    },
    {
      "epoch": 45.49,
      "learning_rate": 8.775494581325817e-05,
      "loss": 0.0073,
      "step": 4481
    },
    {
      "epoch": 45.5,
      "learning_rate": 8.774716068869623e-05,
      "loss": 0.0014,
      "step": 4482
    },
    {
      "epoch": 45.51,
      "learning_rate": 8.773937343567993e-05,
      "loss": 0.0016,
      "step": 4483
    },
    {
      "epoch": 45.52,
      "learning_rate": 8.773158405464836e-05,
      "loss": 0.0076,
      "step": 4484
    },
    {
      "epoch": 45.53,
      "learning_rate": 8.772379254604073e-05,
      "loss": 0.0137,
      "step": 4485
    },
    {
      "epoch": 45.54,
      "learning_rate": 8.771599891029638e-05,
      "loss": 0.0065,
      "step": 4486
    },
    {
      "epoch": 45.55,
      "learning_rate": 8.77082031478548e-05,
      "loss": 0.0167,
      "step": 4487
    },
    {
      "epoch": 45.56,
      "learning_rate": 8.770040525915554e-05,
      "loss": 0.0156,
      "step": 4488
    },
    {
      "epoch": 45.57,
      "learning_rate": 8.769260524463832e-05,
      "loss": 0.0016,
      "step": 4489
    },
    {
      "epoch": 45.58,
      "learning_rate": 8.768480310474294e-05,
      "loss": 0.0014,
      "step": 4490
    },
    {
      "epoch": 45.59,
      "learning_rate": 8.767699883990933e-05,
      "loss": 0.0019,
      "step": 4491
    },
    {
      "epoch": 45.6,
      "learning_rate": 8.766919245057761e-05,
      "loss": 0.0012,
      "step": 4492
    },
    {
      "epoch": 45.61,
      "learning_rate": 8.766138393718792e-05,
      "loss": 0.0021,
      "step": 4493
    },
    {
      "epoch": 45.62,
      "learning_rate": 8.765357330018056e-05,
      "loss": 0.005,
      "step": 4494
    },
    {
      "epoch": 45.63,
      "learning_rate": 8.764576053999594e-05,
      "loss": 0.0088,
      "step": 4495
    },
    {
      "epoch": 45.64,
      "learning_rate": 8.763794565707462e-05,
      "loss": 0.0238,
      "step": 4496
    },
    {
      "epoch": 45.65,
      "learning_rate": 8.763012865185723e-05,
      "loss": 0.0029,
      "step": 4497
    },
    {
      "epoch": 45.66,
      "learning_rate": 8.762230952478458e-05,
      "loss": 0.0042,
      "step": 4498
    },
    {
      "epoch": 45.68,
      "learning_rate": 8.761448827629757e-05,
      "loss": 0.0117,
      "step": 4499
    },
    {
      "epoch": 45.69,
      "learning_rate": 8.76066649068372e-05,
      "loss": 0.0196,
      "step": 4500
    },
    {
      "epoch": 45.7,
      "learning_rate": 8.75988394168446e-05,
      "loss": 0.0312,
      "step": 4501
    },
    {
      "epoch": 45.71,
      "learning_rate": 8.759101180676104e-05,
      "loss": 0.0098,
      "step": 4502
    },
    {
      "epoch": 45.72,
      "learning_rate": 8.75831820770279e-05,
      "loss": 0.003,
      "step": 4503
    },
    {
      "epoch": 45.73,
      "learning_rate": 8.757535022808667e-05,
      "loss": 0.0101,
      "step": 4504
    },
    {
      "epoch": 45.74,
      "learning_rate": 8.756751626037897e-05,
      "loss": 0.056,
      "step": 4505
    },
    {
      "epoch": 45.75,
      "learning_rate": 8.755968017434653e-05,
      "loss": 0.0256,
      "step": 4506
    },
    {
      "epoch": 45.76,
      "learning_rate": 8.75518419704312e-05,
      "loss": 0.0005,
      "step": 4507
    },
    {
      "epoch": 45.77,
      "learning_rate": 8.754400164907497e-05,
      "loss": 0.0038,
      "step": 4508
    },
    {
      "epoch": 45.78,
      "learning_rate": 8.753615921071991e-05,
      "loss": 0.0223,
      "step": 4509
    },
    {
      "epoch": 45.79,
      "learning_rate": 8.752831465580825e-05,
      "loss": 0.0009,
      "step": 4510
    },
    {
      "epoch": 45.8,
      "learning_rate": 8.752046798478233e-05,
      "loss": 0.0053,
      "step": 4511
    },
    {
      "epoch": 45.81,
      "learning_rate": 8.751261919808458e-05,
      "loss": 0.0085,
      "step": 4512
    },
    {
      "epoch": 45.82,
      "learning_rate": 8.750476829615758e-05,
      "loss": 0.0161,
      "step": 4513
    },
    {
      "epoch": 45.83,
      "learning_rate": 8.749691527944401e-05,
      "loss": 0.0038,
      "step": 4514
    },
    {
      "epoch": 45.84,
      "learning_rate": 8.748906014838672e-05,
      "loss": 0.0084,
      "step": 4515
    },
    {
      "epoch": 45.85,
      "learning_rate": 8.748120290342858e-05,
      "loss": 0.003,
      "step": 4516
    },
    {
      "epoch": 45.86,
      "learning_rate": 8.747334354501268e-05,
      "loss": 0.0029,
      "step": 4517
    },
    {
      "epoch": 45.87,
      "learning_rate": 8.746548207358216e-05,
      "loss": 0.0085,
      "step": 4518
    },
    {
      "epoch": 45.88,
      "learning_rate": 8.745761848958032e-05,
      "loss": 0.0023,
      "step": 4519
    },
    {
      "epoch": 45.89,
      "learning_rate": 8.744975279345056e-05,
      "loss": 0.0245,
      "step": 4520
    },
    {
      "epoch": 45.9,
      "learning_rate": 8.744188498563641e-05,
      "loss": 0.0065,
      "step": 4521
    },
    {
      "epoch": 45.91,
      "learning_rate": 8.74340150665815e-05,
      "loss": 0.0074,
      "step": 4522
    },
    {
      "epoch": 45.92,
      "learning_rate": 8.742614303672964e-05,
      "loss": 0.0111,
      "step": 4523
    },
    {
      "epoch": 45.93,
      "learning_rate": 8.741826889652463e-05,
      "loss": 0.0067,
      "step": 4524
    },
    {
      "epoch": 45.94,
      "learning_rate": 8.741039264641053e-05,
      "loss": 0.0035,
      "step": 4525
    },
    {
      "epoch": 45.95,
      "learning_rate": 8.740251428683145e-05,
      "loss": 0.001,
      "step": 4526
    },
    {
      "epoch": 45.96,
      "learning_rate": 8.73946338182316e-05,
      "loss": 0.0017,
      "step": 4527
    },
    {
      "epoch": 45.97,
      "learning_rate": 8.738675124105539e-05,
      "loss": 0.0136,
      "step": 4528
    },
    {
      "epoch": 45.98,
      "learning_rate": 8.737886655574725e-05,
      "loss": 0.0013,
      "step": 4529
    },
    {
      "epoch": 45.99,
      "learning_rate": 8.737097976275178e-05,
      "loss": 0.0009,
      "step": 4530
    },
    {
      "epoch": 46.0,
      "learning_rate": 8.736309086251369e-05,
      "loss": 0.0472,
      "step": 4531
    },
    {
      "epoch": 46.0,
      "eval_loss": 0.016420207917690277,
      "eval_runtime": 31.7316,
      "eval_samples_per_second": 99.27,
      "eval_steps_per_second": 6.208,
      "eval_wer": 0.004897567221510884,
      "step": 4531
    },
    {
      "epoch": 46.01,
      "learning_rate": 8.735519985547785e-05,
      "loss": 0.0239,
      "step": 4532
    },
    {
      "epoch": 46.02,
      "learning_rate": 8.734730674208917e-05,
      "loss": 0.0093,
      "step": 4533
    },
    {
      "epoch": 46.03,
      "learning_rate": 8.733941152279274e-05,
      "loss": 0.0103,
      "step": 4534
    },
    {
      "epoch": 46.04,
      "learning_rate": 8.733151419803376e-05,
      "loss": 0.0009,
      "step": 4535
    },
    {
      "epoch": 46.05,
      "learning_rate": 8.732361476825752e-05,
      "loss": 0.0018,
      "step": 4536
    },
    {
      "epoch": 46.06,
      "learning_rate": 8.731571323390943e-05,
      "loss": 0.0045,
      "step": 4537
    },
    {
      "epoch": 46.07,
      "learning_rate": 8.730780959543508e-05,
      "loss": 0.0112,
      "step": 4538
    },
    {
      "epoch": 46.08,
      "learning_rate": 8.729990385328008e-05,
      "loss": 0.0354,
      "step": 4539
    },
    {
      "epoch": 46.09,
      "learning_rate": 8.729199600789025e-05,
      "loss": 0.0009,
      "step": 4540
    },
    {
      "epoch": 46.1,
      "learning_rate": 8.728408605971148e-05,
      "loss": 0.001,
      "step": 4541
    },
    {
      "epoch": 46.11,
      "learning_rate": 8.72761740091898e-05,
      "loss": 0.0136,
      "step": 4542
    },
    {
      "epoch": 46.12,
      "learning_rate": 8.726825985677132e-05,
      "loss": 0.0028,
      "step": 4543
    },
    {
      "epoch": 46.13,
      "learning_rate": 8.726034360290233e-05,
      "loss": 0.0014,
      "step": 4544
    },
    {
      "epoch": 46.14,
      "learning_rate": 8.725242524802918e-05,
      "loss": 0.0349,
      "step": 4545
    },
    {
      "epoch": 46.15,
      "learning_rate": 8.724450479259838e-05,
      "loss": 0.0014,
      "step": 4546
    },
    {
      "epoch": 46.16,
      "learning_rate": 8.723658223705653e-05,
      "loss": 0.0006,
      "step": 4547
    },
    {
      "epoch": 46.17,
      "learning_rate": 8.722865758185035e-05,
      "loss": 0.0201,
      "step": 4548
    },
    {
      "epoch": 46.18,
      "learning_rate": 8.722073082742673e-05,
      "loss": 0.0019,
      "step": 4549
    },
    {
      "epoch": 46.19,
      "learning_rate": 8.721280197423258e-05,
      "loss": 0.0002,
      "step": 4550
    },
    {
      "epoch": 46.2,
      "learning_rate": 8.720487102271504e-05,
      "loss": 0.0031,
      "step": 4551
    },
    {
      "epoch": 46.21,
      "learning_rate": 8.719693797332127e-05,
      "loss": 0.0002,
      "step": 4552
    },
    {
      "epoch": 46.22,
      "learning_rate": 8.718900282649862e-05,
      "loss": 0.0036,
      "step": 4553
    },
    {
      "epoch": 46.23,
      "learning_rate": 8.718106558269453e-05,
      "loss": 0.0266,
      "step": 4554
    },
    {
      "epoch": 46.24,
      "learning_rate": 8.717312624235653e-05,
      "loss": 0.0068,
      "step": 4555
    },
    {
      "epoch": 46.25,
      "learning_rate": 8.716518480593234e-05,
      "loss": 0.0007,
      "step": 4556
    },
    {
      "epoch": 46.26,
      "learning_rate": 8.715724127386972e-05,
      "loss": 0.001,
      "step": 4557
    },
    {
      "epoch": 46.27,
      "learning_rate": 8.714929564661659e-05,
      "loss": 0.0166,
      "step": 4558
    },
    {
      "epoch": 46.28,
      "learning_rate": 8.714134792462098e-05,
      "loss": 0.0057,
      "step": 4559
    },
    {
      "epoch": 46.29,
      "learning_rate": 8.713339810833106e-05,
      "loss": 0.0015,
      "step": 4560
    },
    {
      "epoch": 46.3,
      "learning_rate": 8.712544619819507e-05,
      "loss": 0.0074,
      "step": 4561
    },
    {
      "epoch": 46.31,
      "learning_rate": 8.711749219466142e-05,
      "loss": 0.0023,
      "step": 4562
    },
    {
      "epoch": 46.32,
      "learning_rate": 8.71095360981786e-05,
      "loss": 0.0013,
      "step": 4563
    },
    {
      "epoch": 46.34,
      "learning_rate": 8.710157790919522e-05,
      "loss": 0.0027,
      "step": 4564
    },
    {
      "epoch": 46.35,
      "learning_rate": 8.709361762816004e-05,
      "loss": 0.0039,
      "step": 4565
    },
    {
      "epoch": 46.36,
      "learning_rate": 8.70856552555219e-05,
      "loss": 0.0041,
      "step": 4566
    },
    {
      "epoch": 46.37,
      "learning_rate": 8.70776907917298e-05,
      "loss": 0.0015,
      "step": 4567
    },
    {
      "epoch": 46.38,
      "learning_rate": 8.706972423723281e-05,
      "loss": 0.0138,
      "step": 4568
    },
    {
      "epoch": 46.39,
      "learning_rate": 8.706175559248016e-05,
      "loss": 0.0005,
      "step": 4569
    },
    {
      "epoch": 46.4,
      "learning_rate": 8.705378485792115e-05,
      "loss": 0.0119,
      "step": 4570
    },
    {
      "epoch": 46.41,
      "learning_rate": 8.704581203400525e-05,
      "loss": 0.0015,
      "step": 4571
    },
    {
      "epoch": 46.42,
      "learning_rate": 8.703783712118203e-05,
      "loss": 0.003,
      "step": 4572
    },
    {
      "epoch": 46.43,
      "learning_rate": 8.702986011990115e-05,
      "loss": 0.0036,
      "step": 4573
    },
    {
      "epoch": 46.44,
      "learning_rate": 8.702188103061243e-05,
      "loss": 0.0036,
      "step": 4574
    },
    {
      "epoch": 46.45,
      "learning_rate": 8.701389985376578e-05,
      "loss": 0.0168,
      "step": 4575
    },
    {
      "epoch": 46.46,
      "learning_rate": 8.700591658981124e-05,
      "loss": 0.0026,
      "step": 4576
    },
    {
      "epoch": 46.47,
      "learning_rate": 8.699793123919895e-05,
      "loss": 0.0252,
      "step": 4577
    },
    {
      "epoch": 46.48,
      "learning_rate": 8.69899438023792e-05,
      "loss": 0.0008,
      "step": 4578
    },
    {
      "epoch": 46.49,
      "learning_rate": 8.698195427980238e-05,
      "loss": 0.0176,
      "step": 4579
    },
    {
      "epoch": 46.5,
      "learning_rate": 8.697396267191897e-05,
      "loss": 0.0058,
      "step": 4580
    },
    {
      "epoch": 46.51,
      "learning_rate": 8.696596897917961e-05,
      "loss": 0.0029,
      "step": 4581
    },
    {
      "epoch": 46.52,
      "learning_rate": 8.695797320203505e-05,
      "loss": 0.0017,
      "step": 4582
    },
    {
      "epoch": 46.53,
      "learning_rate": 8.694997534093615e-05,
      "loss": 0.0026,
      "step": 4583
    },
    {
      "epoch": 46.54,
      "learning_rate": 8.694197539633386e-05,
      "loss": 0.0033,
      "step": 4584
    },
    {
      "epoch": 46.55,
      "learning_rate": 8.69339733686793e-05,
      "loss": 0.0014,
      "step": 4585
    },
    {
      "epoch": 46.56,
      "learning_rate": 8.692596925842366e-05,
      "loss": 0.0165,
      "step": 4586
    },
    {
      "epoch": 46.57,
      "learning_rate": 8.69179630660183e-05,
      "loss": 0.0023,
      "step": 4587
    },
    {
      "epoch": 46.58,
      "learning_rate": 8.690995479191462e-05,
      "loss": 0.0064,
      "step": 4588
    },
    {
      "epoch": 46.59,
      "learning_rate": 8.690194443656423e-05,
      "loss": 0.0041,
      "step": 4589
    },
    {
      "epoch": 46.6,
      "learning_rate": 8.689393200041879e-05,
      "loss": 0.0017,
      "step": 4590
    },
    {
      "epoch": 46.61,
      "learning_rate": 8.688591748393009e-05,
      "loss": 0.0258,
      "step": 4591
    },
    {
      "epoch": 46.62,
      "learning_rate": 8.687790088755008e-05,
      "loss": 0.0027,
      "step": 4592
    },
    {
      "epoch": 46.63,
      "learning_rate": 8.686988221173075e-05,
      "loss": 0.002,
      "step": 4593
    },
    {
      "epoch": 46.64,
      "learning_rate": 8.686186145692428e-05,
      "loss": 0.0011,
      "step": 4594
    },
    {
      "epoch": 46.65,
      "learning_rate": 8.685383862358292e-05,
      "loss": 0.0038,
      "step": 4595
    },
    {
      "epoch": 46.66,
      "learning_rate": 8.684581371215905e-05,
      "loss": 0.003,
      "step": 4596
    },
    {
      "epoch": 46.67,
      "learning_rate": 8.683778672310521e-05,
      "loss": 0.0017,
      "step": 4597
    },
    {
      "epoch": 46.68,
      "learning_rate": 8.682975765687397e-05,
      "loss": 0.0004,
      "step": 4598
    },
    {
      "epoch": 46.69,
      "learning_rate": 8.68217265139181e-05,
      "loss": 0.001,
      "step": 4599
    },
    {
      "epoch": 46.7,
      "learning_rate": 8.681369329469044e-05,
      "loss": 0.0008,
      "step": 4600
    },
    {
      "epoch": 46.71,
      "learning_rate": 8.680565799964397e-05,
      "loss": 0.0012,
      "step": 4601
    },
    {
      "epoch": 46.72,
      "learning_rate": 8.679762062923175e-05,
      "loss": 0.0087,
      "step": 4602
    },
    {
      "epoch": 46.73,
      "learning_rate": 8.678958118390702e-05,
      "loss": 0.0301,
      "step": 4603
    },
    {
      "epoch": 46.74,
      "learning_rate": 8.678153966412306e-05,
      "loss": 0.0003,
      "step": 4604
    },
    {
      "epoch": 46.75,
      "learning_rate": 8.677349607033336e-05,
      "loss": 0.001,
      "step": 4605
    },
    {
      "epoch": 46.76,
      "learning_rate": 8.676545040299145e-05,
      "loss": 0.0046,
      "step": 4606
    },
    {
      "epoch": 46.77,
      "learning_rate": 8.675740266255096e-05,
      "loss": 0.0037,
      "step": 4607
    },
    {
      "epoch": 46.78,
      "learning_rate": 8.674935284946577e-05,
      "loss": 0.0096,
      "step": 4608
    },
    {
      "epoch": 46.79,
      "learning_rate": 8.674130096418972e-05,
      "loss": 0.0202,
      "step": 4609
    },
    {
      "epoch": 46.8,
      "learning_rate": 8.673324700717682e-05,
      "loss": 0.0053,
      "step": 4610
    },
    {
      "epoch": 46.81,
      "learning_rate": 8.672519097888126e-05,
      "loss": 0.0043,
      "step": 4611
    },
    {
      "epoch": 46.82,
      "learning_rate": 8.671713287975726e-05,
      "loss": 0.0016,
      "step": 4612
    },
    {
      "epoch": 46.83,
      "learning_rate": 8.670907271025923e-05,
      "loss": 0.0033,
      "step": 4613
    },
    {
      "epoch": 46.84,
      "learning_rate": 8.670101047084162e-05,
      "loss": 0.001,
      "step": 4614
    },
    {
      "epoch": 46.85,
      "learning_rate": 8.669294616195906e-05,
      "loss": 0.001,
      "step": 4615
    },
    {
      "epoch": 46.86,
      "learning_rate": 8.668487978406628e-05,
      "loss": 0.0014,
      "step": 4616
    },
    {
      "epoch": 46.87,
      "learning_rate": 8.66768113376181e-05,
      "loss": 0.0117,
      "step": 4617
    },
    {
      "epoch": 46.88,
      "learning_rate": 8.666874082306947e-05,
      "loss": 0.0114,
      "step": 4618
    },
    {
      "epoch": 46.89,
      "learning_rate": 8.666066824087549e-05,
      "loss": 0.0003,
      "step": 4619
    },
    {
      "epoch": 46.9,
      "learning_rate": 8.665259359149132e-05,
      "loss": 0.0072,
      "step": 4620
    },
    {
      "epoch": 46.91,
      "learning_rate": 8.664451687537229e-05,
      "loss": 0.0018,
      "step": 4621
    },
    {
      "epoch": 46.92,
      "learning_rate": 8.663643809297383e-05,
      "loss": 0.0236,
      "step": 4622
    },
    {
      "epoch": 46.93,
      "learning_rate": 8.662835724475145e-05,
      "loss": 0.0006,
      "step": 4623
    },
    {
      "epoch": 46.94,
      "learning_rate": 8.662027433116082e-05,
      "loss": 0.0043,
      "step": 4624
    },
    {
      "epoch": 46.95,
      "learning_rate": 8.661218935265773e-05,
      "loss": 0.0018,
      "step": 4625
    },
    {
      "epoch": 46.96,
      "learning_rate": 8.660410230969804e-05,
      "loss": 0.0027,
      "step": 4626
    },
    {
      "epoch": 46.97,
      "learning_rate": 8.659601320273775e-05,
      "loss": 0.0005,
      "step": 4627
    },
    {
      "epoch": 46.98,
      "learning_rate": 8.658792203223302e-05,
      "loss": 0.0106,
      "step": 4628
    },
    {
      "epoch": 46.99,
      "learning_rate": 8.657982879864007e-05,
      "loss": 0.0132,
      "step": 4629
    },
    {
      "epoch": 46.99,
      "eval_loss": 0.02166632190346718,
      "eval_runtime": 32.7939,
      "eval_samples_per_second": 96.054,
      "eval_steps_per_second": 6.007,
      "eval_wer": 0.005505761843790013,
      "step": 4629
    },
    {
      "epoch": 47.01,
      "learning_rate": 8.657173350241526e-05,
      "loss": 0.0021,
      "step": 4630
    },
    {
      "epoch": 47.02,
      "learning_rate": 8.656363614401502e-05,
      "loss": 0.0262,
      "step": 4631
    },
    {
      "epoch": 47.03,
      "learning_rate": 8.655553672389599e-05,
      "loss": 0.0108,
      "step": 4632
    },
    {
      "epoch": 47.04,
      "learning_rate": 8.654743524251485e-05,
      "loss": 0.01,
      "step": 4633
    },
    {
      "epoch": 47.05,
      "learning_rate": 8.653933170032842e-05,
      "loss": 0.0022,
      "step": 4634
    },
    {
      "epoch": 47.06,
      "learning_rate": 8.653122609779363e-05,
      "loss": 0.0015,
      "step": 4635
    },
    {
      "epoch": 47.07,
      "learning_rate": 8.652311843536755e-05,
      "loss": 0.0025,
      "step": 4636
    },
    {
      "epoch": 47.08,
      "learning_rate": 8.651500871350733e-05,
      "loss": 0.0056,
      "step": 4637
    },
    {
      "epoch": 47.09,
      "learning_rate": 8.650689693267027e-05,
      "loss": 0.0027,
      "step": 4638
    },
    {
      "epoch": 47.1,
      "learning_rate": 8.649878309331376e-05,
      "loss": 0.0085,
      "step": 4639
    },
    {
      "epoch": 47.11,
      "learning_rate": 8.64906671958953e-05,
      "loss": 0.0133,
      "step": 4640
    },
    {
      "epoch": 47.12,
      "learning_rate": 8.648254924087254e-05,
      "loss": 0.0004,
      "step": 4641
    },
    {
      "epoch": 47.13,
      "learning_rate": 8.647442922870325e-05,
      "loss": 0.0068,
      "step": 4642
    },
    {
      "epoch": 47.14,
      "learning_rate": 8.646630715984526e-05,
      "loss": 0.0011,
      "step": 4643
    },
    {
      "epoch": 47.15,
      "learning_rate": 8.645818303475655e-05,
      "loss": 0.0239,
      "step": 4644
    },
    {
      "epoch": 47.16,
      "learning_rate": 8.645005685389524e-05,
      "loss": 0.0097,
      "step": 4645
    },
    {
      "epoch": 47.17,
      "learning_rate": 8.644192861771953e-05,
      "loss": 0.0005,
      "step": 4646
    },
    {
      "epoch": 47.18,
      "learning_rate": 8.643379832668775e-05,
      "loss": 0.0129,
      "step": 4647
    },
    {
      "epoch": 47.19,
      "learning_rate": 8.642566598125831e-05,
      "loss": 0.0008,
      "step": 4648
    },
    {
      "epoch": 47.2,
      "learning_rate": 8.641753158188984e-05,
      "loss": 0.0019,
      "step": 4649
    },
    {
      "epoch": 47.21,
      "learning_rate": 8.640939512904096e-05,
      "loss": 0.0027,
      "step": 4650
    },
    {
      "epoch": 47.22,
      "learning_rate": 8.64012566231705e-05,
      "loss": 0.0018,
      "step": 4651
    },
    {
      "epoch": 47.23,
      "learning_rate": 8.639311606473733e-05,
      "loss": 0.0157,
      "step": 4652
    },
    {
      "epoch": 47.24,
      "learning_rate": 8.638497345420047e-05,
      "loss": 0.0034,
      "step": 4653
    },
    {
      "epoch": 47.25,
      "learning_rate": 8.637682879201909e-05,
      "loss": 0.0066,
      "step": 4654
    },
    {
      "epoch": 47.26,
      "learning_rate": 8.636868207865244e-05,
      "loss": 0.0052,
      "step": 4655
    },
    {
      "epoch": 47.27,
      "learning_rate": 8.636053331455987e-05,
      "loss": 0.0002,
      "step": 4656
    },
    {
      "epoch": 47.28,
      "learning_rate": 8.635238250020088e-05,
      "loss": 0.0064,
      "step": 4657
    },
    {
      "epoch": 47.29,
      "learning_rate": 8.634422963603508e-05,
      "loss": 0.0011,
      "step": 4658
    },
    {
      "epoch": 47.3,
      "learning_rate": 8.633607472252215e-05,
      "loss": 0.0005,
      "step": 4659
    },
    {
      "epoch": 47.31,
      "learning_rate": 8.632791776012197e-05,
      "loss": 0.0005,
      "step": 4660
    },
    {
      "epoch": 47.32,
      "learning_rate": 8.631975874929444e-05,
      "loss": 0.0022,
      "step": 4661
    },
    {
      "epoch": 47.33,
      "learning_rate": 8.631159769049965e-05,
      "loss": 0.0086,
      "step": 4662
    },
    {
      "epoch": 47.34,
      "learning_rate": 8.63034345841978e-05,
      "loss": 0.0095,
      "step": 4663
    },
    {
      "epoch": 47.35,
      "learning_rate": 8.629526943084913e-05,
      "loss": 0.0027,
      "step": 4664
    },
    {
      "epoch": 47.36,
      "learning_rate": 8.62871022309141e-05,
      "loss": 0.0049,
      "step": 4665
    },
    {
      "epoch": 47.37,
      "learning_rate": 8.627893298485321e-05,
      "loss": 0.0008,
      "step": 4666
    },
    {
      "epoch": 47.38,
      "learning_rate": 8.627076169312711e-05,
      "loss": 0.0094,
      "step": 4667
    },
    {
      "epoch": 47.39,
      "learning_rate": 8.626258835619653e-05,
      "loss": 0.0002,
      "step": 4668
    },
    {
      "epoch": 47.4,
      "learning_rate": 8.62544129745224e-05,
      "loss": 0.0267,
      "step": 4669
    },
    {
      "epoch": 47.41,
      "learning_rate": 8.624623554856564e-05,
      "loss": 0.0016,
      "step": 4670
    },
    {
      "epoch": 47.42,
      "learning_rate": 8.623805607878739e-05,
      "loss": 0.0139,
      "step": 4671
    },
    {
      "epoch": 47.43,
      "learning_rate": 8.622987456564885e-05,
      "loss": 0.0021,
      "step": 4672
    },
    {
      "epoch": 47.44,
      "learning_rate": 8.622169100961137e-05,
      "loss": 0.0059,
      "step": 4673
    },
    {
      "epoch": 47.45,
      "learning_rate": 8.621350541113637e-05,
      "loss": 0.001,
      "step": 4674
    },
    {
      "epoch": 47.46,
      "learning_rate": 8.620531777068544e-05,
      "loss": 0.0117,
      "step": 4675
    },
    {
      "epoch": 47.47,
      "learning_rate": 8.619712808872024e-05,
      "loss": 0.0048,
      "step": 4676
    },
    {
      "epoch": 47.48,
      "learning_rate": 8.618893636570258e-05,
      "loss": 0.0005,
      "step": 4677
    },
    {
      "epoch": 47.49,
      "learning_rate": 8.618074260209435e-05,
      "loss": 0.0101,
      "step": 4678
    },
    {
      "epoch": 47.5,
      "learning_rate": 8.617254679835758e-05,
      "loss": 0.0086,
      "step": 4679
    },
    {
      "epoch": 47.51,
      "learning_rate": 8.616434895495439e-05,
      "loss": 0.0039,
      "step": 4680
    },
    {
      "epoch": 47.52,
      "learning_rate": 8.615614907234708e-05,
      "loss": 0.0007,
      "step": 4681
    },
    {
      "epoch": 47.53,
      "learning_rate": 8.614794715099799e-05,
      "loss": 0.0156,
      "step": 4682
    },
    {
      "epoch": 47.54,
      "learning_rate": 8.613974319136958e-05,
      "loss": 0.0137,
      "step": 4683
    },
    {
      "epoch": 47.55,
      "learning_rate": 8.613153719392448e-05,
      "loss": 0.0032,
      "step": 4684
    },
    {
      "epoch": 47.56,
      "learning_rate": 8.61233291591254e-05,
      "loss": 0.0034,
      "step": 4685
    },
    {
      "epoch": 47.57,
      "learning_rate": 8.611511908743514e-05,
      "loss": 0.0009,
      "step": 4686
    },
    {
      "epoch": 47.58,
      "learning_rate": 8.610690697931667e-05,
      "loss": 0.002,
      "step": 4687
    },
    {
      "epoch": 47.59,
      "learning_rate": 8.609869283523305e-05,
      "loss": 0.0014,
      "step": 4688
    },
    {
      "epoch": 47.6,
      "learning_rate": 8.609047665564742e-05,
      "loss": 0.0049,
      "step": 4689
    },
    {
      "epoch": 47.61,
      "learning_rate": 8.60822584410231e-05,
      "loss": 0.0148,
      "step": 4690
    },
    {
      "epoch": 47.62,
      "learning_rate": 8.607403819182349e-05,
      "loss": 0.0024,
      "step": 4691
    },
    {
      "epoch": 47.63,
      "learning_rate": 8.60658159085121e-05,
      "loss": 0.0033,
      "step": 4692
    },
    {
      "epoch": 47.64,
      "learning_rate": 8.605759159155254e-05,
      "loss": 0.0016,
      "step": 4693
    },
    {
      "epoch": 47.65,
      "learning_rate": 8.604936524140857e-05,
      "loss": 0.0011,
      "step": 4694
    },
    {
      "epoch": 47.66,
      "learning_rate": 8.604113685854407e-05,
      "loss": 0.0124,
      "step": 4695
    },
    {
      "epoch": 47.68,
      "learning_rate": 8.603290644342299e-05,
      "loss": 0.0039,
      "step": 4696
    },
    {
      "epoch": 47.69,
      "learning_rate": 8.602467399650942e-05,
      "loss": 0.0018,
      "step": 4697
    },
    {
      "epoch": 47.7,
      "learning_rate": 8.601643951826759e-05,
      "loss": 0.0007,
      "step": 4698
    },
    {
      "epoch": 47.71,
      "learning_rate": 8.600820300916178e-05,
      "loss": 0.0002,
      "step": 4699
    },
    {
      "epoch": 47.72,
      "learning_rate": 8.599996446965646e-05,
      "loss": 0.0007,
      "step": 4700
    },
    {
      "epoch": 47.73,
      "learning_rate": 8.599172390021615e-05,
      "loss": 0.0162,
      "step": 4701
    },
    {
      "epoch": 47.74,
      "learning_rate": 8.598348130130554e-05,
      "loss": 0.0006,
      "step": 4702
    },
    {
      "epoch": 47.75,
      "learning_rate": 8.597523667338937e-05,
      "loss": 0.0004,
      "step": 4703
    },
    {
      "epoch": 47.76,
      "learning_rate": 8.596699001693255e-05,
      "loss": 0.0055,
      "step": 4704
    },
    {
      "epoch": 47.77,
      "learning_rate": 8.595874133240011e-05,
      "loss": 0.0014,
      "step": 4705
    },
    {
      "epoch": 47.78,
      "learning_rate": 8.595049062025712e-05,
      "loss": 0.0004,
      "step": 4706
    },
    {
      "epoch": 47.79,
      "learning_rate": 8.594223788096887e-05,
      "loss": 0.0003,
      "step": 4707
    },
    {
      "epoch": 47.8,
      "learning_rate": 8.593398311500065e-05,
      "loss": 0.0007,
      "step": 4708
    },
    {
      "epoch": 47.81,
      "learning_rate": 8.592572632281797e-05,
      "loss": 0.0032,
      "step": 4709
    },
    {
      "epoch": 47.82,
      "learning_rate": 8.591746750488639e-05,
      "loss": 0.0009,
      "step": 4710
    },
    {
      "epoch": 47.83,
      "learning_rate": 8.590920666167159e-05,
      "loss": 0.0013,
      "step": 4711
    },
    {
      "epoch": 47.84,
      "learning_rate": 8.590094379363938e-05,
      "loss": 0.0006,
      "step": 4712
    },
    {
      "epoch": 47.85,
      "learning_rate": 8.58926789012557e-05,
      "loss": 0.0204,
      "step": 4713
    },
    {
      "epoch": 47.86,
      "learning_rate": 8.588441198498655e-05,
      "loss": 0.0004,
      "step": 4714
    },
    {
      "epoch": 47.87,
      "learning_rate": 8.58761430452981e-05,
      "loss": 0.0078,
      "step": 4715
    },
    {
      "epoch": 47.88,
      "learning_rate": 8.586787208265661e-05,
      "loss": 0.0013,
      "step": 4716
    },
    {
      "epoch": 47.89,
      "learning_rate": 8.585959909752846e-05,
      "loss": 0.0086,
      "step": 4717
    },
    {
      "epoch": 47.9,
      "learning_rate": 8.585132409038013e-05,
      "loss": 0.0067,
      "step": 4718
    },
    {
      "epoch": 47.91,
      "learning_rate": 8.58430470616782e-05,
      "loss": 0.0022,
      "step": 4719
    },
    {
      "epoch": 47.92,
      "learning_rate": 8.583476801188946e-05,
      "loss": 0.0011,
      "step": 4720
    },
    {
      "epoch": 47.93,
      "learning_rate": 8.582648694148067e-05,
      "loss": 0.0014,
      "step": 4721
    },
    {
      "epoch": 47.94,
      "learning_rate": 8.581820385091881e-05,
      "loss": 0.0041,
      "step": 4722
    },
    {
      "epoch": 47.95,
      "learning_rate": 8.580991874067092e-05,
      "loss": 0.0051,
      "step": 4723
    },
    {
      "epoch": 47.96,
      "learning_rate": 8.58016316112042e-05,
      "loss": 0.001,
      "step": 4724
    },
    {
      "epoch": 47.97,
      "learning_rate": 8.579334246298593e-05,
      "loss": 0.001,
      "step": 4725
    },
    {
      "epoch": 47.98,
      "learning_rate": 8.578505129648349e-05,
      "loss": 0.0146,
      "step": 4726
    },
    {
      "epoch": 47.99,
      "learning_rate": 8.577675811216442e-05,
      "loss": 0.0001,
      "step": 4727
    },
    {
      "epoch": 48.0,
      "learning_rate": 8.576846291049634e-05,
      "loss": 0.0039,
      "step": 4728
    },
    {
      "epoch": 48.0,
      "eval_loss": 0.019433969631791115,
      "eval_runtime": 31.936,
      "eval_samples_per_second": 98.635,
      "eval_steps_per_second": 6.169,
      "eval_wer": 0.0034571062740076826,
      "step": 4728
    },
    {
      "epoch": 48.01,
      "learning_rate": 8.576016569194698e-05,
      "loss": 0.0001,
      "step": 4729
    },
    {
      "epoch": 48.02,
      "learning_rate": 8.575186645698422e-05,
      "loss": 0.0001,
      "step": 4730
    },
    {
      "epoch": 48.03,
      "learning_rate": 8.574356520607603e-05,
      "loss": 0.0007,
      "step": 4731
    },
    {
      "epoch": 48.04,
      "learning_rate": 8.573526193969046e-05,
      "loss": 0.0002,
      "step": 4732
    },
    {
      "epoch": 48.05,
      "learning_rate": 8.572695665829574e-05,
      "loss": 0.0005,
      "step": 4733
    },
    {
      "epoch": 48.06,
      "learning_rate": 8.571864936236016e-05,
      "loss": 0.0008,
      "step": 4734
    },
    {
      "epoch": 48.07,
      "learning_rate": 8.571034005235217e-05,
      "loss": 0.0006,
      "step": 4735
    },
    {
      "epoch": 48.08,
      "learning_rate": 8.570202872874028e-05,
      "loss": 0.0268,
      "step": 4736
    },
    {
      "epoch": 48.09,
      "learning_rate": 8.569371539199316e-05,
      "loss": 0.0188,
      "step": 4737
    },
    {
      "epoch": 48.1,
      "learning_rate": 8.568540004257956e-05,
      "loss": 0.0024,
      "step": 4738
    },
    {
      "epoch": 48.11,
      "learning_rate": 8.56770826809684e-05,
      "loss": 0.0009,
      "step": 4739
    },
    {
      "epoch": 48.12,
      "learning_rate": 8.56687633076286e-05,
      "loss": 0.003,
      "step": 4740
    },
    {
      "epoch": 48.13,
      "learning_rate": 8.566044192302936e-05,
      "loss": 0.0004,
      "step": 4741
    },
    {
      "epoch": 48.14,
      "learning_rate": 8.56521185276398e-05,
      "loss": 0.002,
      "step": 4742
    },
    {
      "epoch": 48.15,
      "learning_rate": 8.564379312192932e-05,
      "loss": 0.0003,
      "step": 4743
    },
    {
      "epoch": 48.16,
      "learning_rate": 8.563546570636734e-05,
      "loss": 0.0067,
      "step": 4744
    },
    {
      "epoch": 48.17,
      "learning_rate": 8.562713628142343e-05,
      "loss": 0.0079,
      "step": 4745
    },
    {
      "epoch": 48.18,
      "learning_rate": 8.561880484756725e-05,
      "loss": 0.0065,
      "step": 4746
    },
    {
      "epoch": 48.19,
      "learning_rate": 8.561047140526858e-05,
      "loss": 0.0417,
      "step": 4747
    },
    {
      "epoch": 48.2,
      "learning_rate": 8.560213595499735e-05,
      "loss": 0.0118,
      "step": 4748
    },
    {
      "epoch": 48.21,
      "learning_rate": 8.559379849722355e-05,
      "loss": 0.0028,
      "step": 4749
    },
    {
      "epoch": 48.22,
      "learning_rate": 8.55854590324173e-05,
      "loss": 0.0007,
      "step": 4750
    },
    {
      "epoch": 48.23,
      "learning_rate": 8.557711756104885e-05,
      "loss": 0.0015,
      "step": 4751
    },
    {
      "epoch": 48.24,
      "learning_rate": 8.556877408358855e-05,
      "loss": 0.0015,
      "step": 4752
    },
    {
      "epoch": 48.25,
      "learning_rate": 8.556042860050687e-05,
      "loss": 0.0006,
      "step": 4753
    },
    {
      "epoch": 48.26,
      "learning_rate": 8.555208111227438e-05,
      "loss": 0.0102,
      "step": 4754
    },
    {
      "epoch": 48.27,
      "learning_rate": 8.554373161936175e-05,
      "loss": 0.0045,
      "step": 4755
    },
    {
      "epoch": 48.28,
      "learning_rate": 8.553538012223982e-05,
      "loss": 0.0015,
      "step": 4756
    },
    {
      "epoch": 48.29,
      "learning_rate": 8.552702662137951e-05,
      "loss": 0.0022,
      "step": 4757
    },
    {
      "epoch": 48.3,
      "learning_rate": 8.551867111725182e-05,
      "loss": 0.003,
      "step": 4758
    },
    {
      "epoch": 48.31,
      "learning_rate": 8.55103136103279e-05,
      "loss": 0.0062,
      "step": 4759
    },
    {
      "epoch": 48.32,
      "learning_rate": 8.550195410107902e-05,
      "loss": 0.0005,
      "step": 4760
    },
    {
      "epoch": 48.34,
      "learning_rate": 8.549359258997654e-05,
      "loss": 0.0019,
      "step": 4761
    },
    {
      "epoch": 48.35,
      "learning_rate": 8.548522907749195e-05,
      "loss": 0.0003,
      "step": 4762
    },
    {
      "epoch": 48.36,
      "learning_rate": 8.547686356409684e-05,
      "loss": 0.001,
      "step": 4763
    },
    {
      "epoch": 48.37,
      "learning_rate": 8.54684960502629e-05,
      "loss": 0.0001,
      "step": 4764
    },
    {
      "epoch": 48.38,
      "learning_rate": 8.546012653646196e-05,
      "loss": 0.0094,
      "step": 4765
    },
    {
      "epoch": 48.39,
      "learning_rate": 8.545175502316597e-05,
      "loss": 0.0063,
      "step": 4766
    },
    {
      "epoch": 48.4,
      "learning_rate": 8.544338151084696e-05,
      "loss": 0.0015,
      "step": 4767
    },
    {
      "epoch": 48.41,
      "learning_rate": 8.54350059999771e-05,
      "loss": 0.0004,
      "step": 4768
    },
    {
      "epoch": 48.42,
      "learning_rate": 8.542662849102863e-05,
      "loss": 0.001,
      "step": 4769
    },
    {
      "epoch": 48.43,
      "learning_rate": 8.541824898447398e-05,
      "loss": 0.0045,
      "step": 4770
    },
    {
      "epoch": 48.44,
      "learning_rate": 8.54098674807856e-05,
      "loss": 0.0015,
      "step": 4771
    },
    {
      "epoch": 48.45,
      "learning_rate": 8.540148398043615e-05,
      "loss": 0.014,
      "step": 4772
    },
    {
      "epoch": 48.46,
      "learning_rate": 8.539309848389831e-05,
      "loss": 0.0014,
      "step": 4773
    },
    {
      "epoch": 48.47,
      "learning_rate": 8.538471099164493e-05,
      "loss": 0.005,
      "step": 4774
    },
    {
      "epoch": 48.48,
      "learning_rate": 8.537632150414896e-05,
      "loss": 0.0042,
      "step": 4775
    },
    {
      "epoch": 48.49,
      "learning_rate": 8.536793002188344e-05,
      "loss": 0.0214,
      "step": 4776
    },
    {
      "epoch": 48.5,
      "learning_rate": 8.535953654532157e-05,
      "loss": 0.0046,
      "step": 4777
    },
    {
      "epoch": 48.51,
      "learning_rate": 8.535114107493661e-05,
      "loss": 0.002,
      "step": 4778
    },
    {
      "epoch": 48.52,
      "learning_rate": 8.534274361120196e-05,
      "loss": 0.0076,
      "step": 4779
    },
    {
      "epoch": 48.53,
      "learning_rate": 8.533434415459114e-05,
      "loss": 0.0063,
      "step": 4780
    },
    {
      "epoch": 48.54,
      "learning_rate": 8.532594270557777e-05,
      "loss": 0.013,
      "step": 4781
    },
    {
      "epoch": 48.55,
      "learning_rate": 8.531753926463557e-05,
      "loss": 0.0009,
      "step": 4782
    },
    {
      "epoch": 48.56,
      "learning_rate": 8.530913383223842e-05,
      "loss": 0.0049,
      "step": 4783
    },
    {
      "epoch": 48.57,
      "learning_rate": 8.530072640886023e-05,
      "loss": 0.0106,
      "step": 4784
    },
    {
      "epoch": 48.58,
      "learning_rate": 8.52923169949751e-05,
      "loss": 0.0057,
      "step": 4785
    },
    {
      "epoch": 48.59,
      "learning_rate": 8.528390559105721e-05,
      "loss": 0.0096,
      "step": 4786
    },
    {
      "epoch": 48.6,
      "learning_rate": 8.527549219758087e-05,
      "loss": 0.0229,
      "step": 4787
    },
    {
      "epoch": 48.61,
      "learning_rate": 8.526707681502044e-05,
      "loss": 0.0007,
      "step": 4788
    },
    {
      "epoch": 48.62,
      "learning_rate": 8.52586594438505e-05,
      "loss": 0.0025,
      "step": 4789
    },
    {
      "epoch": 48.63,
      "learning_rate": 8.525024008454561e-05,
      "loss": 0.0006,
      "step": 4790
    },
    {
      "epoch": 48.64,
      "learning_rate": 8.524181873758059e-05,
      "loss": 0.0256,
      "step": 4791
    },
    {
      "epoch": 48.65,
      "learning_rate": 8.523339540343026e-05,
      "loss": 0.0016,
      "step": 4792
    },
    {
      "epoch": 48.66,
      "learning_rate": 8.522497008256957e-05,
      "loss": 0.0039,
      "step": 4793
    },
    {
      "epoch": 48.67,
      "learning_rate": 8.521654277547362e-05,
      "loss": 0.0036,
      "step": 4794
    },
    {
      "epoch": 48.68,
      "learning_rate": 8.520811348261759e-05,
      "loss": 0.0013,
      "step": 4795
    },
    {
      "epoch": 48.69,
      "learning_rate": 8.519968220447681e-05,
      "loss": 0.0011,
      "step": 4796
    },
    {
      "epoch": 48.7,
      "learning_rate": 8.519124894152669e-05,
      "loss": 0.0046,
      "step": 4797
    },
    {
      "epoch": 48.71,
      "learning_rate": 8.518281369424271e-05,
      "loss": 0.0014,
      "step": 4798
    },
    {
      "epoch": 48.72,
      "learning_rate": 8.517437646310056e-05,
      "loss": 0.0213,
      "step": 4799
    },
    {
      "epoch": 48.73,
      "learning_rate": 8.516593724857598e-05,
      "loss": 0.0245,
      "step": 4800
    },
    {
      "epoch": 48.74,
      "learning_rate": 8.515749605114483e-05,
      "loss": 0.0006,
      "step": 4801
    },
    {
      "epoch": 48.75,
      "learning_rate": 8.51490528712831e-05,
      "loss": 0.0144,
      "step": 4802
    },
    {
      "epoch": 48.76,
      "learning_rate": 8.514060770946683e-05,
      "loss": 0.0012,
      "step": 4803
    },
    {
      "epoch": 48.77,
      "learning_rate": 8.513216056617227e-05,
      "loss": 0.0011,
      "step": 4804
    },
    {
      "epoch": 48.78,
      "learning_rate": 8.512371144187571e-05,
      "loss": 0.0006,
      "step": 4805
    },
    {
      "epoch": 48.79,
      "learning_rate": 8.511526033705356e-05,
      "loss": 0.0162,
      "step": 4806
    },
    {
      "epoch": 48.8,
      "learning_rate": 8.510680725218239e-05,
      "loss": 0.0051,
      "step": 4807
    },
    {
      "epoch": 48.81,
      "learning_rate": 8.50983521877388e-05,
      "loss": 0.003,
      "step": 4808
    },
    {
      "epoch": 48.82,
      "learning_rate": 8.508989514419958e-05,
      "loss": 0.0036,
      "step": 4809
    },
    {
      "epoch": 48.83,
      "learning_rate": 8.508143612204158e-05,
      "loss": 0.0106,
      "step": 4810
    },
    {
      "epoch": 48.84,
      "learning_rate": 8.507297512174178e-05,
      "loss": 0.0035,
      "step": 4811
    },
    {
      "epoch": 48.85,
      "learning_rate": 8.506451214377728e-05,
      "loss": 0.0043,
      "step": 4812
    },
    {
      "epoch": 48.86,
      "learning_rate": 8.50560471886253e-05,
      "loss": 0.0011,
      "step": 4813
    },
    {
      "epoch": 48.87,
      "learning_rate": 8.504758025676312e-05,
      "loss": 0.001,
      "step": 4814
    },
    {
      "epoch": 48.88,
      "learning_rate": 8.503911134866817e-05,
      "loss": 0.0007,
      "step": 4815
    },
    {
      "epoch": 48.89,
      "learning_rate": 8.503064046481803e-05,
      "loss": 0.003,
      "step": 4816
    },
    {
      "epoch": 48.9,
      "learning_rate": 8.50221676056903e-05,
      "loss": 0.0173,
      "step": 4817
    },
    {
      "epoch": 48.91,
      "learning_rate": 8.501369277176276e-05,
      "loss": 0.0033,
      "step": 4818
    },
    {
      "epoch": 48.92,
      "learning_rate": 8.500521596351327e-05,
      "loss": 0.0275,
      "step": 4819
    },
    {
      "epoch": 48.93,
      "learning_rate": 8.499673718141984e-05,
      "loss": 0.0017,
      "step": 4820
    },
    {
      "epoch": 48.94,
      "learning_rate": 8.498825642596054e-05,
      "loss": 0.0029,
      "step": 4821
    },
    {
      "epoch": 48.95,
      "learning_rate": 8.497977369761359e-05,
      "loss": 0.0196,
      "step": 4822
    },
    {
      "epoch": 48.96,
      "learning_rate": 8.497128899685728e-05,
      "loss": 0.0092,
      "step": 4823
    },
    {
      "epoch": 48.97,
      "learning_rate": 8.496280232417008e-05,
      "loss": 0.0058,
      "step": 4824
    },
    {
      "epoch": 48.98,
      "learning_rate": 8.49543136800305e-05,
      "loss": 0.0038,
      "step": 4825
    },
    {
      "epoch": 48.99,
      "learning_rate": 8.49458230649172e-05,
      "loss": 0.0005,
      "step": 4826
    },
    {
      "epoch": 48.99,
      "eval_loss": 0.017862390726804733,
      "eval_runtime": 32.2045,
      "eval_samples_per_second": 97.812,
      "eval_steps_per_second": 6.117,
      "eval_wer": 0.005441741357234315,
      "step": 4826
    },
    {
      "epoch": 49.01,
      "learning_rate": 8.493733047930892e-05,
      "loss": 0.0005,
      "step": 4827
    },
    {
      "epoch": 49.02,
      "learning_rate": 8.492883592368457e-05,
      "loss": 0.0008,
      "step": 4828
    },
    {
      "epoch": 49.03,
      "learning_rate": 8.492033939852311e-05,
      "loss": 0.007,
      "step": 4829
    },
    {
      "epoch": 49.04,
      "learning_rate": 8.491184090430364e-05,
      "loss": 0.0113,
      "step": 4830
    },
    {
      "epoch": 49.05,
      "learning_rate": 8.490334044150539e-05,
      "loss": 0.0049,
      "step": 4831
    },
    {
      "epoch": 49.06,
      "learning_rate": 8.48948380106076e-05,
      "loss": 0.026,
      "step": 4832
    },
    {
      "epoch": 49.07,
      "learning_rate": 8.488633361208979e-05,
      "loss": 0.0033,
      "step": 4833
    },
    {
      "epoch": 49.08,
      "learning_rate": 8.487782724643145e-05,
      "loss": 0.0026,
      "step": 4834
    },
    {
      "epoch": 49.09,
      "learning_rate": 8.486931891411224e-05,
      "loss": 0.0111,
      "step": 4835
    },
    {
      "epoch": 49.1,
      "learning_rate": 8.486080861561191e-05,
      "loss": 0.0013,
      "step": 4836
    },
    {
      "epoch": 49.11,
      "learning_rate": 8.485229635141034e-05,
      "loss": 0.0023,
      "step": 4837
    },
    {
      "epoch": 49.12,
      "learning_rate": 8.484378212198751e-05,
      "loss": 0.0005,
      "step": 4838
    },
    {
      "epoch": 49.13,
      "learning_rate": 8.483526592782354e-05,
      "loss": 0.0004,
      "step": 4839
    },
    {
      "epoch": 49.14,
      "learning_rate": 8.482674776939858e-05,
      "loss": 0.0006,
      "step": 4840
    },
    {
      "epoch": 49.15,
      "learning_rate": 8.4818227647193e-05,
      "loss": 0.0051,
      "step": 4841
    },
    {
      "epoch": 49.16,
      "learning_rate": 8.480970556168718e-05,
      "loss": 0.001,
      "step": 4842
    },
    {
      "epoch": 49.17,
      "learning_rate": 8.480118151336168e-05,
      "loss": 0.0007,
      "step": 4843
    },
    {
      "epoch": 49.18,
      "learning_rate": 8.479265550269714e-05,
      "loss": 0.0035,
      "step": 4844
    },
    {
      "epoch": 49.19,
      "learning_rate": 8.478412753017433e-05,
      "loss": 0.0007,
      "step": 4845
    },
    {
      "epoch": 49.2,
      "learning_rate": 8.477559759627409e-05,
      "loss": 0.0001,
      "step": 4846
    },
    {
      "epoch": 49.21,
      "learning_rate": 8.476706570147743e-05,
      "loss": 0.011,
      "step": 4847
    },
    {
      "epoch": 49.22,
      "learning_rate": 8.475853184626541e-05,
      "loss": 0.0072,
      "step": 4848
    },
    {
      "epoch": 49.23,
      "learning_rate": 8.474999603111926e-05,
      "loss": 0.0118,
      "step": 4849
    },
    {
      "epoch": 49.24,
      "learning_rate": 8.474145825652026e-05,
      "loss": 0.0095,
      "step": 4850
    },
    {
      "epoch": 49.25,
      "learning_rate": 8.473291852294987e-05,
      "loss": 0.0047,
      "step": 4851
    },
    {
      "epoch": 49.26,
      "learning_rate": 8.472437683088958e-05,
      "loss": 0.0117,
      "step": 4852
    },
    {
      "epoch": 49.27,
      "learning_rate": 8.471583318082105e-05,
      "loss": 0.0104,
      "step": 4853
    },
    {
      "epoch": 49.28,
      "learning_rate": 8.470728757322603e-05,
      "loss": 0.0009,
      "step": 4854
    },
    {
      "epoch": 49.29,
      "learning_rate": 8.469874000858639e-05,
      "loss": 0.0005,
      "step": 4855
    },
    {
      "epoch": 49.3,
      "learning_rate": 8.469019048738408e-05,
      "loss": 0.0079,
      "step": 4856
    },
    {
      "epoch": 49.31,
      "learning_rate": 8.46816390101012e-05,
      "loss": 0.0013,
      "step": 4857
    },
    {
      "epoch": 49.32,
      "learning_rate": 8.467308557721996e-05,
      "loss": 0.0083,
      "step": 4858
    },
    {
      "epoch": 49.33,
      "learning_rate": 8.466453018922262e-05,
      "loss": 0.0055,
      "step": 4859
    },
    {
      "epoch": 49.34,
      "learning_rate": 8.465597284659164e-05,
      "loss": 0.0069,
      "step": 4860
    },
    {
      "epoch": 49.35,
      "learning_rate": 8.464741354980951e-05,
      "loss": 0.0073,
      "step": 4861
    },
    {
      "epoch": 49.36,
      "learning_rate": 8.463885229935888e-05,
      "loss": 0.0005,
      "step": 4862
    },
    {
      "epoch": 49.37,
      "learning_rate": 8.463028909572251e-05,
      "loss": 0.0009,
      "step": 4863
    },
    {
      "epoch": 49.38,
      "learning_rate": 8.462172393938321e-05,
      "loss": 0.0041,
      "step": 4864
    },
    {
      "epoch": 49.39,
      "learning_rate": 8.461315683082399e-05,
      "loss": 0.0026,
      "step": 4865
    },
    {
      "epoch": 49.4,
      "learning_rate": 8.460458777052789e-05,
      "loss": 0.0017,
      "step": 4866
    },
    {
      "epoch": 49.41,
      "learning_rate": 8.459601675897813e-05,
      "loss": 0.0009,
      "step": 4867
    },
    {
      "epoch": 49.42,
      "learning_rate": 8.458744379665797e-05,
      "loss": 0.009,
      "step": 4868
    },
    {
      "epoch": 49.43,
      "learning_rate": 8.457886888405082e-05,
      "loss": 0.0046,
      "step": 4869
    },
    {
      "epoch": 49.44,
      "learning_rate": 8.457029202164023e-05,
      "loss": 0.0028,
      "step": 4870
    },
    {
      "epoch": 49.45,
      "learning_rate": 8.456171320990978e-05,
      "loss": 0.0071,
      "step": 4871
    },
    {
      "epoch": 49.46,
      "learning_rate": 8.455313244934324e-05,
      "loss": 0.0097,
      "step": 4872
    },
    {
      "epoch": 49.47,
      "learning_rate": 8.454454974042443e-05,
      "loss": 0.0196,
      "step": 4873
    },
    {
      "epoch": 49.48,
      "learning_rate": 8.453596508363732e-05,
      "loss": 0.0054,
      "step": 4874
    },
    {
      "epoch": 49.49,
      "learning_rate": 8.452737847946596e-05,
      "loss": 0.0066,
      "step": 4875
    },
    {
      "epoch": 49.5,
      "learning_rate": 8.451878992839454e-05,
      "loss": 0.0046,
      "step": 4876
    },
    {
      "epoch": 49.51,
      "learning_rate": 8.451019943090732e-05,
      "loss": 0.0062,
      "step": 4877
    },
    {
      "epoch": 49.52,
      "learning_rate": 8.450160698748872e-05,
      "loss": 0.0042,
      "step": 4878
    },
    {
      "epoch": 49.53,
      "learning_rate": 8.449301259862323e-05,
      "loss": 0.0083,
      "step": 4879
    },
    {
      "epoch": 49.54,
      "learning_rate": 8.448441626479546e-05,
      "loss": 0.0051,
      "step": 4880
    },
    {
      "epoch": 49.55,
      "learning_rate": 8.447581798649014e-05,
      "loss": 0.0334,
      "step": 4881
    },
    {
      "epoch": 49.56,
      "learning_rate": 8.446721776419211e-05,
      "loss": 0.0009,
      "step": 4882
    },
    {
      "epoch": 49.57,
      "learning_rate": 8.44586155983863e-05,
      "loss": 0.0014,
      "step": 4883
    },
    {
      "epoch": 49.58,
      "learning_rate": 8.445001148955775e-05,
      "loss": 0.0214,
      "step": 4884
    },
    {
      "epoch": 49.59,
      "learning_rate": 8.444140543819165e-05,
      "loss": 0.0027,
      "step": 4885
    },
    {
      "epoch": 49.6,
      "learning_rate": 8.443279744477324e-05,
      "loss": 0.0017,
      "step": 4886
    },
    {
      "epoch": 49.61,
      "learning_rate": 8.442418750978793e-05,
      "loss": 0.0214,
      "step": 4887
    },
    {
      "epoch": 49.62,
      "learning_rate": 8.44155756337212e-05,
      "loss": 0.0023,
      "step": 4888
    },
    {
      "epoch": 49.63,
      "learning_rate": 8.440696181705863e-05,
      "loss": 0.0062,
      "step": 4889
    },
    {
      "epoch": 49.64,
      "learning_rate": 8.439834606028594e-05,
      "loss": 0.0063,
      "step": 4890
    },
    {
      "epoch": 49.65,
      "learning_rate": 8.438972836388896e-05,
      "loss": 0.0007,
      "step": 4891
    },
    {
      "epoch": 49.66,
      "learning_rate": 8.438110872835361e-05,
      "loss": 0.0162,
      "step": 4892
    },
    {
      "epoch": 49.68,
      "learning_rate": 8.437248715416591e-05,
      "loss": 0.0021,
      "step": 4893
    },
    {
      "epoch": 49.69,
      "learning_rate": 8.436386364181203e-05,
      "loss": 0.0059,
      "step": 4894
    },
    {
      "epoch": 49.7,
      "learning_rate": 8.435523819177822e-05,
      "loss": 0.0006,
      "step": 4895
    },
    {
      "epoch": 49.71,
      "learning_rate": 8.434661080455081e-05,
      "loss": 0.024,
      "step": 4896
    },
    {
      "epoch": 49.72,
      "learning_rate": 8.433798148061633e-05,
      "loss": 0.001,
      "step": 4897
    },
    {
      "epoch": 49.73,
      "learning_rate": 8.432935022046134e-05,
      "loss": 0.0069,
      "step": 4898
    },
    {
      "epoch": 49.74,
      "learning_rate": 8.432071702457252e-05,
      "loss": 0.005,
      "step": 4899
    },
    {
      "epoch": 49.75,
      "learning_rate": 8.43120818934367e-05,
      "loss": 0.0035,
      "step": 4900
    },
    {
      "epoch": 49.76,
      "learning_rate": 8.430344482754074e-05,
      "loss": 0.0041,
      "step": 4901
    },
    {
      "epoch": 49.77,
      "learning_rate": 8.42948058273717e-05,
      "loss": 0.0006,
      "step": 4902
    },
    {
      "epoch": 49.78,
      "learning_rate": 8.42861648934167e-05,
      "loss": 0.0005,
      "step": 4903
    },
    {
      "epoch": 49.79,
      "learning_rate": 8.427752202616297e-05,
      "loss": 0.0009,
      "step": 4904
    },
    {
      "epoch": 49.8,
      "learning_rate": 8.426887722609786e-05,
      "loss": 0.0041,
      "step": 4905
    },
    {
      "epoch": 49.81,
      "learning_rate": 8.426023049370883e-05,
      "loss": 0.0021,
      "step": 4906
    },
    {
      "epoch": 49.82,
      "learning_rate": 8.425158182948345e-05,
      "loss": 0.0018,
      "step": 4907
    },
    {
      "epoch": 49.83,
      "learning_rate": 8.424293123390939e-05,
      "loss": 0.0037,
      "step": 4908
    },
    {
      "epoch": 49.84,
      "learning_rate": 8.423427870747441e-05,
      "loss": 0.0117,
      "step": 4909
    },
    {
      "epoch": 49.85,
      "learning_rate": 8.422562425066642e-05,
      "loss": 0.0115,
      "step": 4910
    },
    {
      "epoch": 49.86,
      "learning_rate": 8.421696786397342e-05,
      "loss": 0.0009,
      "step": 4911
    },
    {
      "epoch": 49.87,
      "learning_rate": 8.420830954788353e-05,
      "loss": 0.0022,
      "step": 4912
    },
    {
      "epoch": 49.88,
      "learning_rate": 8.419964930288495e-05,
      "loss": 0.0007,
      "step": 4913
    },
    {
      "epoch": 49.89,
      "learning_rate": 8.419098712946601e-05,
      "loss": 0.0013,
      "step": 4914
    },
    {
      "epoch": 49.9,
      "learning_rate": 8.418232302811515e-05,
      "loss": 0.0154,
      "step": 4915
    },
    {
      "epoch": 49.91,
      "learning_rate": 8.417365699932091e-05,
      "loss": 0.0007,
      "step": 4916
    },
    {
      "epoch": 49.92,
      "learning_rate": 8.416498904357195e-05,
      "loss": 0.0038,
      "step": 4917
    },
    {
      "epoch": 49.93,
      "learning_rate": 8.4156319161357e-05,
      "loss": 0.0016,
      "step": 4918
    },
    {
      "epoch": 49.94,
      "learning_rate": 8.414764735316498e-05,
      "loss": 0.0155,
      "step": 4919
    },
    {
      "epoch": 49.95,
      "learning_rate": 8.413897361948484e-05,
      "loss": 0.0003,
      "step": 4920
    },
    {
      "epoch": 49.96,
      "learning_rate": 8.413029796080567e-05,
      "loss": 0.0086,
      "step": 4921
    },
    {
      "epoch": 49.97,
      "learning_rate": 8.412162037761665e-05,
      "loss": 0.0043,
      "step": 4922
    },
    {
      "epoch": 49.98,
      "learning_rate": 8.411294087040711e-05,
      "loss": 0.0014,
      "step": 4923
    },
    {
      "epoch": 49.99,
      "learning_rate": 8.410425943966645e-05,
      "loss": 0.0004,
      "step": 4924
    },
    {
      "epoch": 50.0,
      "learning_rate": 8.409557608588421e-05,
      "loss": 0.0033,
      "step": 4925
    },
    {
      "epoch": 50.0,
      "eval_loss": 0.021519649773836136,
      "eval_runtime": 31.8112,
      "eval_samples_per_second": 99.022,
      "eval_steps_per_second": 6.193,
      "eval_wer": 0.005217669654289373,
      "step": 4925
    },
    {
      "epoch": 50.01,
      "learning_rate": 8.408689080954998e-05,
      "loss": 0.0003,
      "step": 4926
    },
    {
      "epoch": 50.02,
      "learning_rate": 8.407820361115352e-05,
      "loss": 0.0024,
      "step": 4927
    },
    {
      "epoch": 50.03,
      "learning_rate": 8.406951449118469e-05,
      "loss": 0.0071,
      "step": 4928
    },
    {
      "epoch": 50.04,
      "learning_rate": 8.406082345013344e-05,
      "loss": 0.0048,
      "step": 4929
    },
    {
      "epoch": 50.05,
      "learning_rate": 8.40521304884898e-05,
      "loss": 0.0156,
      "step": 4930
    },
    {
      "epoch": 50.06,
      "learning_rate": 8.404343560674399e-05,
      "loss": 0.0078,
      "step": 4931
    },
    {
      "epoch": 50.07,
      "learning_rate": 8.403473880538626e-05,
      "loss": 0.001,
      "step": 4932
    },
    {
      "epoch": 50.08,
      "learning_rate": 8.4026040084907e-05,
      "loss": 0.0005,
      "step": 4933
    },
    {
      "epoch": 50.09,
      "learning_rate": 8.40173394457967e-05,
      "loss": 0.0012,
      "step": 4934
    },
    {
      "epoch": 50.1,
      "learning_rate": 8.400863688854597e-05,
      "loss": 0.0028,
      "step": 4935
    },
    {
      "epoch": 50.11,
      "learning_rate": 8.399993241364554e-05,
      "loss": 0.0009,
      "step": 4936
    },
    {
      "epoch": 50.12,
      "learning_rate": 8.399122602158622e-05,
      "loss": 0.005,
      "step": 4937
    },
    {
      "epoch": 50.13,
      "learning_rate": 8.398251771285892e-05,
      "loss": 0.0042,
      "step": 4938
    },
    {
      "epoch": 50.14,
      "learning_rate": 8.397380748795469e-05,
      "loss": 0.0003,
      "step": 4939
    },
    {
      "epoch": 50.15,
      "learning_rate": 8.396509534736467e-05,
      "loss": 0.0184,
      "step": 4940
    },
    {
      "epoch": 50.16,
      "learning_rate": 8.395638129158014e-05,
      "loss": 0.0163,
      "step": 4941
    },
    {
      "epoch": 50.17,
      "learning_rate": 8.394766532109242e-05,
      "loss": 0.0074,
      "step": 4942
    },
    {
      "epoch": 50.18,
      "learning_rate": 8.3938947436393e-05,
      "loss": 0.002,
      "step": 4943
    },
    {
      "epoch": 50.19,
      "learning_rate": 8.393022763797347e-05,
      "loss": 0.001,
      "step": 4944
    },
    {
      "epoch": 50.2,
      "learning_rate": 8.392150592632549e-05,
      "loss": 0.0066,
      "step": 4945
    },
    {
      "epoch": 50.21,
      "learning_rate": 8.391278230194086e-05,
      "loss": 0.0008,
      "step": 4946
    },
    {
      "epoch": 50.22,
      "learning_rate": 8.390405676531147e-05,
      "loss": 0.0003,
      "step": 4947
    },
    {
      "epoch": 50.23,
      "learning_rate": 8.389532931692937e-05,
      "loss": 0.0008,
      "step": 4948
    },
    {
      "epoch": 50.24,
      "learning_rate": 8.388659995728663e-05,
      "loss": 0.0028,
      "step": 4949
    },
    {
      "epoch": 50.25,
      "learning_rate": 8.387786868687548e-05,
      "loss": 0.0069,
      "step": 4950
    },
    {
      "epoch": 50.26,
      "learning_rate": 8.386913550618825e-05,
      "loss": 0.0102,
      "step": 4951
    },
    {
      "epoch": 50.27,
      "learning_rate": 8.386040041571742e-05,
      "loss": 0.001,
      "step": 4952
    },
    {
      "epoch": 50.28,
      "learning_rate": 8.385166341595548e-05,
      "loss": 0.0004,
      "step": 4953
    },
    {
      "epoch": 50.29,
      "learning_rate": 8.384292450739512e-05,
      "loss": 0.001,
      "step": 4954
    },
    {
      "epoch": 50.3,
      "learning_rate": 8.38341836905291e-05,
      "loss": 0.0016,
      "step": 4955
    },
    {
      "epoch": 50.31,
      "learning_rate": 8.382544096585027e-05,
      "loss": 0.0066,
      "step": 4956
    },
    {
      "epoch": 50.32,
      "learning_rate": 8.381669633385162e-05,
      "loss": 0.0039,
      "step": 4957
    },
    {
      "epoch": 50.34,
      "learning_rate": 8.380794979502624e-05,
      "loss": 0.009,
      "step": 4958
    },
    {
      "epoch": 50.35,
      "learning_rate": 8.379920134986731e-05,
      "loss": 0.0022,
      "step": 4959
    },
    {
      "epoch": 50.36,
      "learning_rate": 8.379045099886813e-05,
      "loss": 0.0037,
      "step": 4960
    },
    {
      "epoch": 50.37,
      "learning_rate": 8.378169874252212e-05,
      "loss": 0.0061,
      "step": 4961
    },
    {
      "epoch": 50.38,
      "learning_rate": 8.377294458132281e-05,
      "loss": 0.0022,
      "step": 4962
    },
    {
      "epoch": 50.39,
      "learning_rate": 8.376418851576377e-05,
      "loss": 0.0008,
      "step": 4963
    },
    {
      "epoch": 50.4,
      "learning_rate": 8.375543054633877e-05,
      "loss": 0.0013,
      "step": 4964
    },
    {
      "epoch": 50.41,
      "learning_rate": 8.374667067354164e-05,
      "loss": 0.003,
      "step": 4965
    },
    {
      "epoch": 50.42,
      "learning_rate": 8.373790889786633e-05,
      "loss": 0.0047,
      "step": 4966
    },
    {
      "epoch": 50.43,
      "learning_rate": 8.372914521980685e-05,
      "loss": 0.0265,
      "step": 4967
    },
    {
      "epoch": 50.44,
      "learning_rate": 8.372037963985741e-05,
      "loss": 0.0033,
      "step": 4968
    },
    {
      "epoch": 50.45,
      "learning_rate": 8.371161215851226e-05,
      "loss": 0.0004,
      "step": 4969
    },
    {
      "epoch": 50.46,
      "learning_rate": 8.370284277626577e-05,
      "loss": 0.0232,
      "step": 4970
    },
    {
      "epoch": 50.47,
      "learning_rate": 8.369407149361241e-05,
      "loss": 0.0022,
      "step": 4971
    },
    {
      "epoch": 50.48,
      "learning_rate": 8.368529831104679e-05,
      "loss": 0.0052,
      "step": 4972
    },
    {
      "epoch": 50.49,
      "learning_rate": 8.367652322906358e-05,
      "loss": 0.0092,
      "step": 4973
    },
    {
      "epoch": 50.5,
      "learning_rate": 8.366774624815763e-05,
      "loss": 0.0035,
      "step": 4974
    },
    {
      "epoch": 50.51,
      "learning_rate": 8.365896736882378e-05,
      "loss": 0.0012,
      "step": 4975
    },
    {
      "epoch": 50.52,
      "learning_rate": 8.365018659155708e-05,
      "loss": 0.0086,
      "step": 4976
    },
    {
      "epoch": 50.53,
      "learning_rate": 8.364140391685265e-05,
      "loss": 0.0007,
      "step": 4977
    },
    {
      "epoch": 50.54,
      "learning_rate": 8.363261934520574e-05,
      "loss": 0.0063,
      "step": 4978
    },
    {
      "epoch": 50.55,
      "learning_rate": 8.362383287711165e-05,
      "loss": 0.0011,
      "step": 4979
    },
    {
      "epoch": 50.56,
      "learning_rate": 8.361504451306585e-05,
      "loss": 0.0042,
      "step": 4980
    },
    {
      "epoch": 50.57,
      "learning_rate": 8.360625425356388e-05,
      "loss": 0.0258,
      "step": 4981
    },
    {
      "epoch": 50.58,
      "learning_rate": 8.35974620991014e-05,
      "loss": 0.0006,
      "step": 4982
    },
    {
      "epoch": 50.59,
      "learning_rate": 8.358866805017418e-05,
      "loss": 0.0108,
      "step": 4983
    },
    {
      "epoch": 50.6,
      "learning_rate": 8.357987210727808e-05,
      "loss": 0.0054,
      "step": 4984
    },
    {
      "epoch": 50.61,
      "learning_rate": 8.357107427090909e-05,
      "loss": 0.0031,
      "step": 4985
    },
    {
      "epoch": 50.62,
      "learning_rate": 8.35622745415633e-05,
      "loss": 0.0233,
      "step": 4986
    },
    {
      "epoch": 50.63,
      "learning_rate": 8.355347291973688e-05,
      "loss": 0.0077,
      "step": 4987
    },
    {
      "epoch": 50.64,
      "learning_rate": 8.354466940592613e-05,
      "loss": 0.0054,
      "step": 4988
    },
    {
      "epoch": 50.65,
      "learning_rate": 8.353586400062748e-05,
      "loss": 0.0012,
      "step": 4989
    },
    {
      "epoch": 50.66,
      "learning_rate": 8.352705670433741e-05,
      "loss": 0.0025,
      "step": 4990
    },
    {
      "epoch": 50.67,
      "learning_rate": 8.351824751755257e-05,
      "loss": 0.0096,
      "step": 4991
    },
    {
      "epoch": 50.68,
      "learning_rate": 8.350943644076965e-05,
      "loss": 0.0077,
      "step": 4992
    },
    {
      "epoch": 50.69,
      "learning_rate": 8.350062347448551e-05,
      "loss": 0.0015,
      "step": 4993
    },
    {
      "epoch": 50.7,
      "learning_rate": 8.349180861919708e-05,
      "loss": 0.0017,
      "step": 4994
    },
    {
      "epoch": 50.71,
      "learning_rate": 8.34829918754014e-05,
      "loss": 0.013,
      "step": 4995
    },
    {
      "epoch": 50.72,
      "learning_rate": 8.347417324359561e-05,
      "loss": 0.0115,
      "step": 4996
    },
    {
      "epoch": 50.73,
      "learning_rate": 8.3465352724277e-05,
      "loss": 0.0145,
      "step": 4997
    },
    {
      "epoch": 50.74,
      "learning_rate": 8.345653031794292e-05,
      "loss": 0.0021,
      "step": 4998
    },
    {
      "epoch": 50.75,
      "learning_rate": 8.344770602509082e-05,
      "loss": 0.0005,
      "step": 4999
    },
    {
      "epoch": 50.76,
      "learning_rate": 8.34388798462183e-05,
      "loss": 0.0013,
      "step": 5000
    },
    {
      "epoch": 50.77,
      "learning_rate": 8.343005178182303e-05,
      "loss": 0.0064,
      "step": 5001
    },
    {
      "epoch": 50.78,
      "learning_rate": 8.34212218324028e-05,
      "loss": 0.0021,
      "step": 5002
    },
    {
      "epoch": 50.79,
      "learning_rate": 8.341238999845552e-05,
      "loss": 0.0096,
      "step": 5003
    },
    {
      "epoch": 50.8,
      "learning_rate": 8.340355628047917e-05,
      "loss": 0.0138,
      "step": 5004
    },
    {
      "epoch": 50.81,
      "learning_rate": 8.339472067897187e-05,
      "loss": 0.0413,
      "step": 5005
    },
    {
      "epoch": 50.82,
      "learning_rate": 8.338588319443184e-05,
      "loss": 0.0021,
      "step": 5006
    },
    {
      "epoch": 50.83,
      "learning_rate": 8.33770438273574e-05,
      "loss": 0.0016,
      "step": 5007
    },
    {
      "epoch": 50.84,
      "learning_rate": 8.336820257824696e-05,
      "loss": 0.0162,
      "step": 5008
    },
    {
      "epoch": 50.85,
      "learning_rate": 8.335935944759907e-05,
      "loss": 0.0094,
      "step": 5009
    },
    {
      "epoch": 50.86,
      "learning_rate": 8.335051443591235e-05,
      "loss": 0.0123,
      "step": 5010
    },
    {
      "epoch": 50.87,
      "learning_rate": 8.334166754368557e-05,
      "loss": 0.0249,
      "step": 5011
    },
    {
      "epoch": 50.88,
      "learning_rate": 8.333281877141758e-05,
      "loss": 0.01,
      "step": 5012
    },
    {
      "epoch": 50.89,
      "learning_rate": 8.33239681196073e-05,
      "loss": 0.0135,
      "step": 5013
    },
    {
      "epoch": 50.9,
      "learning_rate": 8.331511558875382e-05,
      "loss": 0.0078,
      "step": 5014
    },
    {
      "epoch": 50.91,
      "learning_rate": 8.330626117935633e-05,
      "loss": 0.0037,
      "step": 5015
    },
    {
      "epoch": 50.92,
      "learning_rate": 8.329740489191406e-05,
      "loss": 0.0047,
      "step": 5016
    },
    {
      "epoch": 50.93,
      "learning_rate": 8.328854672692642e-05,
      "loss": 0.0177,
      "step": 5017
    },
    {
      "epoch": 50.94,
      "learning_rate": 8.32796866848929e-05,
      "loss": 0.0238,
      "step": 5018
    },
    {
      "epoch": 50.95,
      "learning_rate": 8.327082476631306e-05,
      "loss": 0.0246,
      "step": 5019
    },
    {
      "epoch": 50.96,
      "learning_rate": 8.326196097168664e-05,
      "loss": 0.0024,
      "step": 5020
    },
    {
      "epoch": 50.97,
      "learning_rate": 8.32530953015134e-05,
      "loss": 0.0178,
      "step": 5021
    },
    {
      "epoch": 50.98,
      "learning_rate": 8.324422775629328e-05,
      "loss": 0.001,
      "step": 5022
    },
    {
      "epoch": 50.99,
      "learning_rate": 8.32353583365263e-05,
      "loss": 0.0009,
      "step": 5023
    },
    {
      "epoch": 50.99,
      "eval_loss": 0.020422838628292084,
      "eval_runtime": 32.769,
      "eval_samples_per_second": 96.128,
      "eval_steps_per_second": 6.012,
      "eval_wer": 0.004577464788732394,
      "step": 5023
    },
    {
      "epoch": 51.01,
      "learning_rate": 8.322648704271256e-05,
      "loss": 0.0062,
      "step": 5024
    },
    {
      "epoch": 51.02,
      "learning_rate": 8.321761387535231e-05,
      "loss": 0.0024,
      "step": 5025
    },
    {
      "epoch": 51.03,
      "learning_rate": 8.320873883494585e-05,
      "loss": 0.0184,
      "step": 5026
    },
    {
      "epoch": 51.04,
      "learning_rate": 8.319986192199364e-05,
      "loss": 0.0001,
      "step": 5027
    },
    {
      "epoch": 51.05,
      "learning_rate": 8.319098313699625e-05,
      "loss": 0.0118,
      "step": 5028
    },
    {
      "epoch": 51.06,
      "learning_rate": 8.318210248045429e-05,
      "loss": 0.0085,
      "step": 5029
    },
    {
      "epoch": 51.07,
      "learning_rate": 8.317321995286851e-05,
      "loss": 0.0082,
      "step": 5030
    },
    {
      "epoch": 51.08,
      "learning_rate": 8.316433555473979e-05,
      "loss": 0.0064,
      "step": 5031
    },
    {
      "epoch": 51.09,
      "learning_rate": 8.315544928656909e-05,
      "loss": 0.0001,
      "step": 5032
    },
    {
      "epoch": 51.1,
      "learning_rate": 8.314656114885748e-05,
      "loss": 0.0038,
      "step": 5033
    },
    {
      "epoch": 51.11,
      "learning_rate": 8.313767114210615e-05,
      "loss": 0.0029,
      "step": 5034
    },
    {
      "epoch": 51.12,
      "learning_rate": 8.312877926681637e-05,
      "loss": 0.0068,
      "step": 5035
    },
    {
      "epoch": 51.13,
      "learning_rate": 8.311988552348953e-05,
      "loss": 0.0012,
      "step": 5036
    },
    {
      "epoch": 51.14,
      "learning_rate": 8.311098991262711e-05,
      "loss": 0.0047,
      "step": 5037
    },
    {
      "epoch": 51.15,
      "learning_rate": 8.310209243473073e-05,
      "loss": 0.0028,
      "step": 5038
    },
    {
      "epoch": 51.16,
      "learning_rate": 8.309319309030207e-05,
      "loss": 0.0074,
      "step": 5039
    },
    {
      "epoch": 51.17,
      "learning_rate": 8.308429187984297e-05,
      "loss": 0.0037,
      "step": 5040
    },
    {
      "epoch": 51.18,
      "learning_rate": 8.307538880385532e-05,
      "loss": 0.001,
      "step": 5041
    },
    {
      "epoch": 51.19,
      "learning_rate": 8.306648386284115e-05,
      "loss": 0.0016,
      "step": 5042
    },
    {
      "epoch": 51.2,
      "learning_rate": 8.305757705730258e-05,
      "loss": 0.0122,
      "step": 5043
    },
    {
      "epoch": 51.21,
      "learning_rate": 8.304866838774181e-05,
      "loss": 0.0005,
      "step": 5044
    },
    {
      "epoch": 51.22,
      "learning_rate": 8.303975785466123e-05,
      "loss": 0.0178,
      "step": 5045
    },
    {
      "epoch": 51.23,
      "learning_rate": 8.303084545856324e-05,
      "loss": 0.0311,
      "step": 5046
    },
    {
      "epoch": 51.24,
      "learning_rate": 8.302193119995039e-05,
      "loss": 0.0172,
      "step": 5047
    },
    {
      "epoch": 51.25,
      "learning_rate": 8.301301507932535e-05,
      "loss": 0.0119,
      "step": 5048
    },
    {
      "epoch": 51.26,
      "learning_rate": 8.300409709719086e-05,
      "loss": 0.0011,
      "step": 5049
    },
    {
      "epoch": 51.27,
      "learning_rate": 8.299517725404975e-05,
      "loss": 0.0002,
      "step": 5050
    },
    {
      "epoch": 51.28,
      "learning_rate": 8.298625555040505e-05,
      "loss": 0.0104,
      "step": 5051
    },
    {
      "epoch": 51.29,
      "learning_rate": 8.297733198675978e-05,
      "loss": 0.0006,
      "step": 5052
    },
    {
      "epoch": 51.3,
      "learning_rate": 8.296840656361713e-05,
      "loss": 0.0082,
      "step": 5053
    },
    {
      "epoch": 51.31,
      "learning_rate": 8.295947928148036e-05,
      "loss": 0.0176,
      "step": 5054
    },
    {
      "epoch": 51.32,
      "learning_rate": 8.295055014085289e-05,
      "loss": 0.0122,
      "step": 5055
    },
    {
      "epoch": 51.33,
      "learning_rate": 8.294161914223819e-05,
      "loss": 0.0004,
      "step": 5056
    },
    {
      "epoch": 51.34,
      "learning_rate": 8.293268628613985e-05,
      "loss": 0.0002,
      "step": 5057
    },
    {
      "epoch": 51.35,
      "learning_rate": 8.292375157306156e-05,
      "loss": 0.0009,
      "step": 5058
    },
    {
      "epoch": 51.36,
      "learning_rate": 8.291481500350715e-05,
      "loss": 0.0085,
      "step": 5059
    },
    {
      "epoch": 51.37,
      "learning_rate": 8.29058765779805e-05,
      "loss": 0.0034,
      "step": 5060
    },
    {
      "epoch": 51.38,
      "learning_rate": 8.289693629698564e-05,
      "loss": 0.0112,
      "step": 5061
    },
    {
      "epoch": 51.39,
      "learning_rate": 8.288799416102668e-05,
      "loss": 0.0005,
      "step": 5062
    },
    {
      "epoch": 51.4,
      "learning_rate": 8.287905017060783e-05,
      "loss": 0.0099,
      "step": 5063
    },
    {
      "epoch": 51.41,
      "learning_rate": 8.287010432623344e-05,
      "loss": 0.0009,
      "step": 5064
    },
    {
      "epoch": 51.42,
      "learning_rate": 8.286115662840792e-05,
      "loss": 0.0325,
      "step": 5065
    },
    {
      "epoch": 51.43,
      "learning_rate": 8.285220707763583e-05,
      "loss": 0.0195,
      "step": 5066
    },
    {
      "epoch": 51.44,
      "learning_rate": 8.284325567442177e-05,
      "loss": 0.0068,
      "step": 5067
    },
    {
      "epoch": 51.45,
      "learning_rate": 8.283430241927052e-05,
      "loss": 0.0247,
      "step": 5068
    },
    {
      "epoch": 51.46,
      "learning_rate": 8.282534731268692e-05,
      "loss": 0.0008,
      "step": 5069
    },
    {
      "epoch": 51.47,
      "learning_rate": 8.28163903551759e-05,
      "loss": 0.0095,
      "step": 5070
    },
    {
      "epoch": 51.48,
      "learning_rate": 8.280743154724257e-05,
      "loss": 0.0029,
      "step": 5071
    },
    {
      "epoch": 51.49,
      "learning_rate": 8.279847088939203e-05,
      "loss": 0.0102,
      "step": 5072
    },
    {
      "epoch": 51.5,
      "learning_rate": 8.278950838212958e-05,
      "loss": 0.0004,
      "step": 5073
    },
    {
      "epoch": 51.51,
      "learning_rate": 8.278054402596058e-05,
      "loss": 0.0004,
      "step": 5074
    },
    {
      "epoch": 51.52,
      "learning_rate": 8.27715778213905e-05,
      "loss": 0.0023,
      "step": 5075
    },
    {
      "epoch": 51.53,
      "learning_rate": 8.276260976892496e-05,
      "loss": 0.0018,
      "step": 5076
    },
    {
      "epoch": 51.54,
      "learning_rate": 8.275363986906958e-05,
      "loss": 0.0008,
      "step": 5077
    },
    {
      "epoch": 51.55,
      "learning_rate": 8.274466812233017e-05,
      "loss": 0.0016,
      "step": 5078
    },
    {
      "epoch": 51.56,
      "learning_rate": 8.273569452921264e-05,
      "loss": 0.0045,
      "step": 5079
    },
    {
      "epoch": 51.57,
      "learning_rate": 8.272671909022298e-05,
      "loss": 0.0097,
      "step": 5080
    },
    {
      "epoch": 51.58,
      "learning_rate": 8.271774180586726e-05,
      "loss": 0.0089,
      "step": 5081
    },
    {
      "epoch": 51.59,
      "learning_rate": 8.270876267665173e-05,
      "loss": 0.0006,
      "step": 5082
    },
    {
      "epoch": 51.6,
      "learning_rate": 8.269978170308265e-05,
      "loss": 0.0026,
      "step": 5083
    },
    {
      "epoch": 51.61,
      "learning_rate": 8.269079888566648e-05,
      "loss": 0.0002,
      "step": 5084
    },
    {
      "epoch": 51.62,
      "learning_rate": 8.268181422490968e-05,
      "loss": 0.0034,
      "step": 5085
    },
    {
      "epoch": 51.63,
      "learning_rate": 8.267282772131892e-05,
      "loss": 0.0343,
      "step": 5086
    },
    {
      "epoch": 51.64,
      "learning_rate": 8.26638393754009e-05,
      "loss": 0.0246,
      "step": 5087
    },
    {
      "epoch": 51.65,
      "learning_rate": 8.265484918766243e-05,
      "loss": 0.007,
      "step": 5088
    },
    {
      "epoch": 51.66,
      "learning_rate": 8.264585715861048e-05,
      "loss": 0.0038,
      "step": 5089
    },
    {
      "epoch": 51.68,
      "learning_rate": 8.263686328875206e-05,
      "loss": 0.0168,
      "step": 5090
    },
    {
      "epoch": 51.69,
      "learning_rate": 8.26278675785943e-05,
      "loss": 0.0211,
      "step": 5091
    },
    {
      "epoch": 51.7,
      "learning_rate": 8.261887002864447e-05,
      "loss": 0.0004,
      "step": 5092
    },
    {
      "epoch": 51.71,
      "learning_rate": 8.26098706394099e-05,
      "loss": 0.015,
      "step": 5093
    },
    {
      "epoch": 51.72,
      "learning_rate": 8.260086941139805e-05,
      "loss": 0.0117,
      "step": 5094
    },
    {
      "epoch": 51.73,
      "learning_rate": 8.259186634511644e-05,
      "loss": 0.0053,
      "step": 5095
    },
    {
      "epoch": 51.74,
      "learning_rate": 8.258286144107276e-05,
      "loss": 0.0195,
      "step": 5096
    },
    {
      "epoch": 51.75,
      "learning_rate": 8.257385469977478e-05,
      "loss": 0.0037,
      "step": 5097
    },
    {
      "epoch": 51.76,
      "learning_rate": 8.256484612173033e-05,
      "loss": 0.001,
      "step": 5098
    },
    {
      "epoch": 51.77,
      "learning_rate": 8.25558357074474e-05,
      "loss": 0.0039,
      "step": 5099
    },
    {
      "epoch": 51.78,
      "learning_rate": 8.254682345743405e-05,
      "loss": 0.003,
      "step": 5100
    },
    {
      "epoch": 51.79,
      "learning_rate": 8.253780937219848e-05,
      "loss": 0.0033,
      "step": 5101
    },
    {
      "epoch": 51.8,
      "learning_rate": 8.252879345224894e-05,
      "loss": 0.0048,
      "step": 5102
    },
    {
      "epoch": 51.81,
      "learning_rate": 8.251977569809381e-05,
      "loss": 0.0006,
      "step": 5103
    },
    {
      "epoch": 51.82,
      "learning_rate": 8.251075611024162e-05,
      "loss": 0.0042,
      "step": 5104
    },
    {
      "epoch": 51.83,
      "learning_rate": 8.250173468920089e-05,
      "loss": 0.0036,
      "step": 5105
    },
    {
      "epoch": 51.84,
      "learning_rate": 8.249271143548036e-05,
      "loss": 0.0039,
      "step": 5106
    },
    {
      "epoch": 51.85,
      "learning_rate": 8.248368634958883e-05,
      "loss": 0.0057,
      "step": 5107
    },
    {
      "epoch": 51.86,
      "learning_rate": 8.247465943203516e-05,
      "loss": 0.0252,
      "step": 5108
    },
    {
      "epoch": 51.87,
      "learning_rate": 8.246563068332839e-05,
      "loss": 0.0006,
      "step": 5109
    },
    {
      "epoch": 51.88,
      "learning_rate": 8.24566001039776e-05,
      "loss": 0.0009,
      "step": 5110
    },
    {
      "epoch": 51.89,
      "learning_rate": 8.2447567694492e-05,
      "loss": 0.0015,
      "step": 5111
    },
    {
      "epoch": 51.9,
      "learning_rate": 8.243853345538093e-05,
      "loss": 0.0076,
      "step": 5112
    },
    {
      "epoch": 51.91,
      "learning_rate": 8.242949738715378e-05,
      "loss": 0.0015,
      "step": 5113
    },
    {
      "epoch": 51.92,
      "learning_rate": 8.242045949032007e-05,
      "loss": 0.0006,
      "step": 5114
    },
    {
      "epoch": 51.93,
      "learning_rate": 8.241141976538943e-05,
      "loss": 0.0103,
      "step": 5115
    },
    {
      "epoch": 51.94,
      "learning_rate": 8.240237821287157e-05,
      "loss": 0.0073,
      "step": 5116
    },
    {
      "epoch": 51.95,
      "learning_rate": 8.239333483327632e-05,
      "loss": 0.0021,
      "step": 5117
    },
    {
      "epoch": 51.96,
      "learning_rate": 8.238428962711364e-05,
      "loss": 0.0011,
      "step": 5118
    },
    {
      "epoch": 51.97,
      "learning_rate": 8.237524259489351e-05,
      "loss": 0.0022,
      "step": 5119
    },
    {
      "epoch": 51.98,
      "learning_rate": 8.23661937371261e-05,
      "loss": 0.0008,
      "step": 5120
    },
    {
      "epoch": 51.99,
      "learning_rate": 8.235714305432167e-05,
      "loss": 0.0023,
      "step": 5121
    },
    {
      "epoch": 52.0,
      "learning_rate": 8.234809054699052e-05,
      "loss": 0.0018,
      "step": 5122
    },
    {
      "epoch": 52.0,
      "eval_loss": 0.020378554239869118,
      "eval_runtime": 32.103,
      "eval_samples_per_second": 98.122,
      "eval_steps_per_second": 6.136,
      "eval_wer": 0.004801536491677336,
      "step": 5122
    },
    {
      "epoch": 52.01,
      "learning_rate": 8.233903621564311e-05,
      "loss": 0.002,
      "step": 5123
    },
    {
      "epoch": 52.02,
      "learning_rate": 8.232998006078997e-05,
      "loss": 0.0005,
      "step": 5124
    },
    {
      "epoch": 52.03,
      "learning_rate": 8.23209220829418e-05,
      "loss": 0.0003,
      "step": 5125
    },
    {
      "epoch": 52.04,
      "learning_rate": 8.231186228260933e-05,
      "loss": 0.0006,
      "step": 5126
    },
    {
      "epoch": 52.05,
      "learning_rate": 8.23028006603034e-05,
      "loss": 0.0029,
      "step": 5127
    },
    {
      "epoch": 52.06,
      "learning_rate": 8.229373721653498e-05,
      "loss": 0.0026,
      "step": 5128
    },
    {
      "epoch": 52.07,
      "learning_rate": 8.228467195181511e-05,
      "loss": 0.0009,
      "step": 5129
    },
    {
      "epoch": 52.08,
      "learning_rate": 8.2275604866655e-05,
      "loss": 0.0042,
      "step": 5130
    },
    {
      "epoch": 52.09,
      "learning_rate": 8.226653596156587e-05,
      "loss": 0.0011,
      "step": 5131
    },
    {
      "epoch": 52.1,
      "learning_rate": 8.225746523705912e-05,
      "loss": 0.0195,
      "step": 5132
    },
    {
      "epoch": 52.11,
      "learning_rate": 8.224839269364621e-05,
      "loss": 0.0007,
      "step": 5133
    },
    {
      "epoch": 52.12,
      "learning_rate": 8.223931833183874e-05,
      "loss": 0.0086,
      "step": 5134
    },
    {
      "epoch": 52.13,
      "learning_rate": 8.223024215214834e-05,
      "loss": 0.0066,
      "step": 5135
    },
    {
      "epoch": 52.14,
      "learning_rate": 8.222116415508683e-05,
      "loss": 0.0005,
      "step": 5136
    },
    {
      "epoch": 52.15,
      "learning_rate": 8.221208434116607e-05,
      "loss": 0.0013,
      "step": 5137
    },
    {
      "epoch": 52.16,
      "learning_rate": 8.220300271089807e-05,
      "loss": 0.0076,
      "step": 5138
    },
    {
      "epoch": 52.17,
      "learning_rate": 8.219391926479488e-05,
      "loss": 0.0156,
      "step": 5139
    },
    {
      "epoch": 52.18,
      "learning_rate": 8.218483400336871e-05,
      "loss": 0.006,
      "step": 5140
    },
    {
      "epoch": 52.19,
      "learning_rate": 8.217574692713186e-05,
      "loss": 0.0215,
      "step": 5141
    },
    {
      "epoch": 52.2,
      "learning_rate": 8.216665803659671e-05,
      "loss": 0.0061,
      "step": 5142
    },
    {
      "epoch": 52.21,
      "learning_rate": 8.215756733227577e-05,
      "loss": 0.0019,
      "step": 5143
    },
    {
      "epoch": 52.22,
      "learning_rate": 8.214847481468162e-05,
      "loss": 0.0008,
      "step": 5144
    },
    {
      "epoch": 52.23,
      "learning_rate": 8.213938048432697e-05,
      "loss": 0.0037,
      "step": 5145
    },
    {
      "epoch": 52.24,
      "learning_rate": 8.213028434172463e-05,
      "loss": 0.0327,
      "step": 5146
    },
    {
      "epoch": 52.25,
      "learning_rate": 8.212118638738751e-05,
      "loss": 0.0002,
      "step": 5147
    },
    {
      "epoch": 52.26,
      "learning_rate": 8.211208662182858e-05,
      "loss": 0.0002,
      "step": 5148
    },
    {
      "epoch": 52.27,
      "learning_rate": 8.210298504556101e-05,
      "loss": 0.0096,
      "step": 5149
    },
    {
      "epoch": 52.28,
      "learning_rate": 8.209388165909796e-05,
      "loss": 0.0101,
      "step": 5150
    },
    {
      "epoch": 52.29,
      "learning_rate": 8.208477646295277e-05,
      "loss": 0.0067,
      "step": 5151
    },
    {
      "epoch": 52.3,
      "learning_rate": 8.207566945763885e-05,
      "loss": 0.0004,
      "step": 5152
    },
    {
      "epoch": 52.31,
      "learning_rate": 8.206656064366971e-05,
      "loss": 0.001,
      "step": 5153
    },
    {
      "epoch": 52.32,
      "learning_rate": 8.205745002155899e-05,
      "loss": 0.0009,
      "step": 5154
    },
    {
      "epoch": 52.34,
      "learning_rate": 8.20483375918204e-05,
      "loss": 0.0027,
      "step": 5155
    },
    {
      "epoch": 52.35,
      "learning_rate": 8.203922335496776e-05,
      "loss": 0.0018,
      "step": 5156
    },
    {
      "epoch": 52.36,
      "learning_rate": 8.203010731151499e-05,
      "loss": 0.0007,
      "step": 5157
    },
    {
      "epoch": 52.37,
      "learning_rate": 8.202098946197613e-05,
      "loss": 0.0006,
      "step": 5158
    },
    {
      "epoch": 52.38,
      "learning_rate": 8.20118698068653e-05,
      "loss": 0.0068,
      "step": 5159
    },
    {
      "epoch": 52.39,
      "learning_rate": 8.200274834669675e-05,
      "loss": 0.0093,
      "step": 5160
    },
    {
      "epoch": 52.4,
      "learning_rate": 8.199362508198479e-05,
      "loss": 0.0071,
      "step": 5161
    },
    {
      "epoch": 52.41,
      "learning_rate": 8.198450001324387e-05,
      "loss": 0.0061,
      "step": 5162
    },
    {
      "epoch": 52.42,
      "learning_rate": 8.197537314098853e-05,
      "loss": 0.0052,
      "step": 5163
    },
    {
      "epoch": 52.43,
      "learning_rate": 8.19662444657334e-05,
      "loss": 0.0017,
      "step": 5164
    },
    {
      "epoch": 52.44,
      "learning_rate": 8.19571139879932e-05,
      "loss": 0.0001,
      "step": 5165
    },
    {
      "epoch": 52.45,
      "learning_rate": 8.19479817082828e-05,
      "loss": 0.0028,
      "step": 5166
    },
    {
      "epoch": 52.46,
      "learning_rate": 8.193884762711714e-05,
      "loss": 0.0022,
      "step": 5167
    },
    {
      "epoch": 52.47,
      "learning_rate": 8.192971174501126e-05,
      "loss": 0.004,
      "step": 5168
    },
    {
      "epoch": 52.48,
      "learning_rate": 8.192057406248028e-05,
      "loss": 0.0051,
      "step": 5169
    },
    {
      "epoch": 52.49,
      "learning_rate": 8.19114345800395e-05,
      "loss": 0.0057,
      "step": 5170
    },
    {
      "epoch": 52.5,
      "learning_rate": 8.190229329820424e-05,
      "loss": 0.0055,
      "step": 5171
    },
    {
      "epoch": 52.51,
      "learning_rate": 8.189315021748995e-05,
      "loss": 0.0032,
      "step": 5172
    },
    {
      "epoch": 52.52,
      "learning_rate": 8.188400533841217e-05,
      "loss": 0.0002,
      "step": 5173
    },
    {
      "epoch": 52.53,
      "learning_rate": 8.187485866148658e-05,
      "loss": 0.0003,
      "step": 5174
    },
    {
      "epoch": 52.54,
      "learning_rate": 8.186571018722893e-05,
      "loss": 0.0024,
      "step": 5175
    },
    {
      "epoch": 52.55,
      "learning_rate": 8.185655991615508e-05,
      "loss": 0.0025,
      "step": 5176
    },
    {
      "epoch": 52.56,
      "learning_rate": 8.184740784878096e-05,
      "loss": 0.0073,
      "step": 5177
    },
    {
      "epoch": 52.57,
      "learning_rate": 8.183825398562264e-05,
      "loss": 0.0005,
      "step": 5178
    },
    {
      "epoch": 52.58,
      "learning_rate": 8.18290983271963e-05,
      "loss": 0.0125,
      "step": 5179
    },
    {
      "epoch": 52.59,
      "learning_rate": 8.181994087401819e-05,
      "loss": 0.0024,
      "step": 5180
    },
    {
      "epoch": 52.6,
      "learning_rate": 8.181078162660464e-05,
      "loss": 0.0076,
      "step": 5181
    },
    {
      "epoch": 52.61,
      "learning_rate": 8.180162058547218e-05,
      "loss": 0.0017,
      "step": 5182
    },
    {
      "epoch": 52.62,
      "learning_rate": 8.179245775113733e-05,
      "loss": 0.0027,
      "step": 5183
    },
    {
      "epoch": 52.63,
      "learning_rate": 8.178329312411676e-05,
      "loss": 0.0026,
      "step": 5184
    },
    {
      "epoch": 52.64,
      "learning_rate": 8.177412670492725e-05,
      "loss": 0.0016,
      "step": 5185
    },
    {
      "epoch": 52.65,
      "learning_rate": 8.176495849408565e-05,
      "loss": 0.0237,
      "step": 5186
    },
    {
      "epoch": 52.66,
      "learning_rate": 8.175578849210895e-05,
      "loss": 0.0024,
      "step": 5187
    },
    {
      "epoch": 52.67,
      "learning_rate": 8.17466166995142e-05,
      "loss": 0.0011,
      "step": 5188
    },
    {
      "epoch": 52.68,
      "learning_rate": 8.17374431168186e-05,
      "loss": 0.0007,
      "step": 5189
    },
    {
      "epoch": 52.69,
      "learning_rate": 8.172826774453936e-05,
      "loss": 0.0059,
      "step": 5190
    },
    {
      "epoch": 52.7,
      "learning_rate": 8.171909058319394e-05,
      "loss": 0.0134,
      "step": 5191
    },
    {
      "epoch": 52.71,
      "learning_rate": 8.170991163329975e-05,
      "loss": 0.0122,
      "step": 5192
    },
    {
      "epoch": 52.72,
      "learning_rate": 8.170073089537438e-05,
      "loss": 0.0089,
      "step": 5193
    },
    {
      "epoch": 52.73,
      "learning_rate": 8.169154836993551e-05,
      "loss": 0.0009,
      "step": 5194
    },
    {
      "epoch": 52.74,
      "learning_rate": 8.168236405750094e-05,
      "loss": 0.002,
      "step": 5195
    },
    {
      "epoch": 52.75,
      "learning_rate": 8.167317795858851e-05,
      "loss": 0.0021,
      "step": 5196
    },
    {
      "epoch": 52.76,
      "learning_rate": 8.16639900737162e-05,
      "loss": 0.0017,
      "step": 5197
    },
    {
      "epoch": 52.77,
      "learning_rate": 8.16548004034021e-05,
      "loss": 0.0007,
      "step": 5198
    },
    {
      "epoch": 52.78,
      "learning_rate": 8.16456089481644e-05,
      "loss": 0.0018,
      "step": 5199
    },
    {
      "epoch": 52.79,
      "learning_rate": 8.163641570852137e-05,
      "loss": 0.0003,
      "step": 5200
    },
    {
      "epoch": 52.8,
      "learning_rate": 8.16272206849914e-05,
      "loss": 0.0001,
      "step": 5201
    },
    {
      "epoch": 52.81,
      "learning_rate": 8.161802387809293e-05,
      "loss": 0.0029,
      "step": 5202
    },
    {
      "epoch": 52.82,
      "learning_rate": 8.160882528834459e-05,
      "loss": 0.0002,
      "step": 5203
    },
    {
      "epoch": 52.83,
      "learning_rate": 8.159962491626505e-05,
      "loss": 0.0073,
      "step": 5204
    },
    {
      "epoch": 52.84,
      "learning_rate": 8.159042276237308e-05,
      "loss": 0.0027,
      "step": 5205
    },
    {
      "epoch": 52.85,
      "learning_rate": 8.158121882718756e-05,
      "loss": 0.0035,
      "step": 5206
    },
    {
      "epoch": 52.86,
      "learning_rate": 8.157201311122749e-05,
      "loss": 0.0006,
      "step": 5207
    },
    {
      "epoch": 52.87,
      "learning_rate": 8.156280561501195e-05,
      "loss": 0.0032,
      "step": 5208
    },
    {
      "epoch": 52.88,
      "learning_rate": 8.155359633906012e-05,
      "loss": 0.0011,
      "step": 5209
    },
    {
      "epoch": 52.89,
      "learning_rate": 8.15443852838913e-05,
      "loss": 0.001,
      "step": 5210
    },
    {
      "epoch": 52.9,
      "learning_rate": 8.153517245002484e-05,
      "loss": 0.0025,
      "step": 5211
    },
    {
      "epoch": 52.91,
      "learning_rate": 8.152595783798027e-05,
      "loss": 0.0173,
      "step": 5212
    },
    {
      "epoch": 52.92,
      "learning_rate": 8.151674144827713e-05,
      "loss": 0.0071,
      "step": 5213
    },
    {
      "epoch": 52.93,
      "learning_rate": 8.150752328143514e-05,
      "loss": 0.0217,
      "step": 5214
    },
    {
      "epoch": 52.94,
      "learning_rate": 8.149830333797407e-05,
      "loss": 0.0022,
      "step": 5215
    },
    {
      "epoch": 52.95,
      "learning_rate": 8.148908161841382e-05,
      "loss": 0.0036,
      "step": 5216
    },
    {
      "epoch": 52.96,
      "learning_rate": 8.147985812327435e-05,
      "loss": 0.0023,
      "step": 5217
    },
    {
      "epoch": 52.97,
      "learning_rate": 8.147063285307576e-05,
      "loss": 0.0142,
      "step": 5218
    },
    {
      "epoch": 52.98,
      "learning_rate": 8.146140580833828e-05,
      "loss": 0.0019,
      "step": 5219
    },
    {
      "epoch": 52.99,
      "learning_rate": 8.145217698958212e-05,
      "loss": 0.0012,
      "step": 5220
    },
    {
      "epoch": 52.99,
      "eval_loss": 0.017850583419203758,
      "eval_runtime": 31.8709,
      "eval_samples_per_second": 98.836,
      "eval_steps_per_second": 6.181,
      "eval_wer": 0.0048655569782330346,
      "step": 5220
    },
    {
      "epoch": 53.01,
      "learning_rate": 8.144294639732772e-05,
      "loss": 0.0003,
      "step": 5221
    },
    {
      "epoch": 53.02,
      "learning_rate": 8.143371403209554e-05,
      "loss": 0.0021,
      "step": 5222
    },
    {
      "epoch": 53.03,
      "learning_rate": 8.142447989440618e-05,
      "loss": 0.0004,
      "step": 5223
    },
    {
      "epoch": 53.04,
      "learning_rate": 8.141524398478033e-05,
      "loss": 0.0012,
      "step": 5224
    },
    {
      "epoch": 53.05,
      "learning_rate": 8.140600630373877e-05,
      "loss": 0.02,
      "step": 5225
    },
    {
      "epoch": 53.06,
      "learning_rate": 8.139676685180237e-05,
      "loss": 0.0019,
      "step": 5226
    },
    {
      "epoch": 53.07,
      "learning_rate": 8.138752562949215e-05,
      "loss": 0.0015,
      "step": 5227
    },
    {
      "epoch": 53.08,
      "learning_rate": 8.137828263732917e-05,
      "loss": 0.0064,
      "step": 5228
    },
    {
      "epoch": 53.09,
      "learning_rate": 8.136903787583463e-05,
      "loss": 0.0005,
      "step": 5229
    },
    {
      "epoch": 53.1,
      "learning_rate": 8.13597913455298e-05,
      "loss": 0.0024,
      "step": 5230
    },
    {
      "epoch": 53.11,
      "learning_rate": 8.135054304693609e-05,
      "loss": 0.0012,
      "step": 5231
    },
    {
      "epoch": 53.12,
      "learning_rate": 8.134129298057496e-05,
      "loss": 0.0005,
      "step": 5232
    },
    {
      "epoch": 53.13,
      "learning_rate": 8.133204114696802e-05,
      "loss": 0.0228,
      "step": 5233
    },
    {
      "epoch": 53.14,
      "learning_rate": 8.132278754663692e-05,
      "loss": 0.0016,
      "step": 5234
    },
    {
      "epoch": 53.15,
      "learning_rate": 8.131353218010346e-05,
      "loss": 0.0005,
      "step": 5235
    },
    {
      "epoch": 53.16,
      "learning_rate": 8.130427504788955e-05,
      "loss": 0.0124,
      "step": 5236
    },
    {
      "epoch": 53.17,
      "learning_rate": 8.129501615051715e-05,
      "loss": 0.0002,
      "step": 5237
    },
    {
      "epoch": 53.18,
      "learning_rate": 8.128575548850833e-05,
      "loss": 0.0035,
      "step": 5238
    },
    {
      "epoch": 53.19,
      "learning_rate": 8.12764930623853e-05,
      "loss": 0.0209,
      "step": 5239
    },
    {
      "epoch": 53.2,
      "learning_rate": 8.126722887267031e-05,
      "loss": 0.0038,
      "step": 5240
    },
    {
      "epoch": 53.21,
      "learning_rate": 8.125796291988577e-05,
      "loss": 0.0001,
      "step": 5241
    },
    {
      "epoch": 53.22,
      "learning_rate": 8.124869520455414e-05,
      "loss": 0.0016,
      "step": 5242
    },
    {
      "epoch": 53.23,
      "learning_rate": 8.1239425727198e-05,
      "loss": 0.0006,
      "step": 5243
    },
    {
      "epoch": 53.24,
      "learning_rate": 8.123015448834006e-05,
      "loss": 0.0006,
      "step": 5244
    },
    {
      "epoch": 53.25,
      "learning_rate": 8.122088148850309e-05,
      "loss": 0.0011,
      "step": 5245
    },
    {
      "epoch": 53.26,
      "learning_rate": 8.121160672820993e-05,
      "loss": 0.0016,
      "step": 5246
    },
    {
      "epoch": 53.27,
      "learning_rate": 8.120233020798358e-05,
      "loss": 0.001,
      "step": 5247
    },
    {
      "epoch": 53.28,
      "learning_rate": 8.119305192834711e-05,
      "loss": 0.0002,
      "step": 5248
    },
    {
      "epoch": 53.29,
      "learning_rate": 8.118377188982373e-05,
      "loss": 0.0006,
      "step": 5249
    },
    {
      "epoch": 53.3,
      "learning_rate": 8.117449009293668e-05,
      "loss": 0.0035,
      "step": 5250
    },
    {
      "epoch": 53.31,
      "learning_rate": 8.116520653820933e-05,
      "loss": 0.0078,
      "step": 5251
    },
    {
      "epoch": 53.32,
      "learning_rate": 8.11559212261652e-05,
      "loss": 0.0011,
      "step": 5252
    },
    {
      "epoch": 53.33,
      "learning_rate": 8.114663415732779e-05,
      "loss": 0.0024,
      "step": 5253
    },
    {
      "epoch": 53.34,
      "learning_rate": 8.113734533222083e-05,
      "loss": 0.0007,
      "step": 5254
    },
    {
      "epoch": 53.35,
      "learning_rate": 8.112805475136807e-05,
      "loss": 0.0014,
      "step": 5255
    },
    {
      "epoch": 53.36,
      "learning_rate": 8.111876241529337e-05,
      "loss": 0.0034,
      "step": 5256
    },
    {
      "epoch": 53.37,
      "learning_rate": 8.110946832452071e-05,
      "loss": 0.0019,
      "step": 5257
    },
    {
      "epoch": 53.38,
      "learning_rate": 8.110017247957415e-05,
      "loss": 0.0015,
      "step": 5258
    },
    {
      "epoch": 53.39,
      "learning_rate": 8.109087488097787e-05,
      "loss": 0.0092,
      "step": 5259
    },
    {
      "epoch": 53.4,
      "learning_rate": 8.108157552925612e-05,
      "loss": 0.0005,
      "step": 5260
    },
    {
      "epoch": 53.41,
      "learning_rate": 8.107227442493328e-05,
      "loss": 0.006,
      "step": 5261
    },
    {
      "epoch": 53.42,
      "learning_rate": 8.10629715685338e-05,
      "loss": 0.0163,
      "step": 5262
    },
    {
      "epoch": 53.43,
      "learning_rate": 8.105366696058223e-05,
      "loss": 0.0042,
      "step": 5263
    },
    {
      "epoch": 53.44,
      "learning_rate": 8.104436060160324e-05,
      "loss": 0.0017,
      "step": 5264
    },
    {
      "epoch": 53.45,
      "learning_rate": 8.10350524921216e-05,
      "loss": 0.0039,
      "step": 5265
    },
    {
      "epoch": 53.46,
      "learning_rate": 8.102574263266217e-05,
      "loss": 0.0009,
      "step": 5266
    },
    {
      "epoch": 53.47,
      "learning_rate": 8.101643102374989e-05,
      "loss": 0.0007,
      "step": 5267
    },
    {
      "epoch": 53.48,
      "learning_rate": 8.100711766590983e-05,
      "loss": 0.0007,
      "step": 5268
    },
    {
      "epoch": 53.49,
      "learning_rate": 8.099780255966712e-05,
      "loss": 0.0192,
      "step": 5269
    },
    {
      "epoch": 53.5,
      "learning_rate": 8.098848570554703e-05,
      "loss": 0.0004,
      "step": 5270
    },
    {
      "epoch": 53.51,
      "learning_rate": 8.097916710407492e-05,
      "loss": 0.0064,
      "step": 5271
    },
    {
      "epoch": 53.52,
      "learning_rate": 8.096984675577622e-05,
      "loss": 0.002,
      "step": 5272
    },
    {
      "epoch": 53.53,
      "learning_rate": 8.096052466117647e-05,
      "loss": 0.0043,
      "step": 5273
    },
    {
      "epoch": 53.54,
      "learning_rate": 8.095120082080134e-05,
      "loss": 0.0002,
      "step": 5274
    },
    {
      "epoch": 53.55,
      "learning_rate": 8.094187523517658e-05,
      "loss": 0.0022,
      "step": 5275
    },
    {
      "epoch": 53.56,
      "learning_rate": 8.093254790482801e-05,
      "loss": 0.0146,
      "step": 5276
    },
    {
      "epoch": 53.57,
      "learning_rate": 8.092321883028158e-05,
      "loss": 0.0092,
      "step": 5277
    },
    {
      "epoch": 53.58,
      "learning_rate": 8.091388801206333e-05,
      "loss": 0.0068,
      "step": 5278
    },
    {
      "epoch": 53.59,
      "learning_rate": 8.090455545069942e-05,
      "loss": 0.0184,
      "step": 5279
    },
    {
      "epoch": 53.6,
      "learning_rate": 8.089522114671603e-05,
      "loss": 0.004,
      "step": 5280
    },
    {
      "epoch": 53.61,
      "learning_rate": 8.088588510063955e-05,
      "loss": 0.0013,
      "step": 5281
    },
    {
      "epoch": 53.62,
      "learning_rate": 8.087654731299639e-05,
      "loss": 0.0019,
      "step": 5282
    },
    {
      "epoch": 53.63,
      "learning_rate": 8.086720778431307e-05,
      "loss": 0.0182,
      "step": 5283
    },
    {
      "epoch": 53.64,
      "learning_rate": 8.085786651511624e-05,
      "loss": 0.0076,
      "step": 5284
    },
    {
      "epoch": 53.65,
      "learning_rate": 8.084852350593264e-05,
      "loss": 0.0042,
      "step": 5285
    },
    {
      "epoch": 53.66,
      "learning_rate": 8.083917875728906e-05,
      "loss": 0.0013,
      "step": 5286
    },
    {
      "epoch": 53.68,
      "learning_rate": 8.082983226971244e-05,
      "loss": 0.0096,
      "step": 5287
    },
    {
      "epoch": 53.69,
      "learning_rate": 8.08204840437298e-05,
      "loss": 0.0165,
      "step": 5288
    },
    {
      "epoch": 53.7,
      "learning_rate": 8.081113407986826e-05,
      "loss": 0.0119,
      "step": 5289
    },
    {
      "epoch": 53.71,
      "learning_rate": 8.080178237865503e-05,
      "loss": 0.0003,
      "step": 5290
    },
    {
      "epoch": 53.72,
      "learning_rate": 8.079242894061745e-05,
      "loss": 0.0028,
      "step": 5291
    },
    {
      "epoch": 53.73,
      "learning_rate": 8.07830737662829e-05,
      "loss": 0.0012,
      "step": 5292
    },
    {
      "epoch": 53.74,
      "learning_rate": 8.077371685617894e-05,
      "loss": 0.0046,
      "step": 5293
    },
    {
      "epoch": 53.75,
      "learning_rate": 8.076435821083314e-05,
      "loss": 0.0154,
      "step": 5294
    },
    {
      "epoch": 53.76,
      "learning_rate": 8.07549978307732e-05,
      "loss": 0.0056,
      "step": 5295
    },
    {
      "epoch": 53.77,
      "learning_rate": 8.074563571652696e-05,
      "loss": 0.001,
      "step": 5296
    },
    {
      "epoch": 53.78,
      "learning_rate": 8.073627186862228e-05,
      "loss": 0.0006,
      "step": 5297
    },
    {
      "epoch": 53.79,
      "learning_rate": 8.072690628758721e-05,
      "loss": 0.0004,
      "step": 5298
    },
    {
      "epoch": 53.8,
      "learning_rate": 8.07175389739498e-05,
      "loss": 0.0136,
      "step": 5299
    },
    {
      "epoch": 53.81,
      "learning_rate": 8.070816992823828e-05,
      "loss": 0.0003,
      "step": 5300
    },
    {
      "epoch": 53.82,
      "learning_rate": 8.069879915098092e-05,
      "loss": 0.0016,
      "step": 5301
    },
    {
      "epoch": 53.83,
      "learning_rate": 8.068942664270616e-05,
      "loss": 0.0042,
      "step": 5302
    },
    {
      "epoch": 53.84,
      "learning_rate": 8.068005240394243e-05,
      "loss": 0.0082,
      "step": 5303
    },
    {
      "epoch": 53.85,
      "learning_rate": 8.067067643521834e-05,
      "loss": 0.0003,
      "step": 5304
    },
    {
      "epoch": 53.86,
      "learning_rate": 8.066129873706256e-05,
      "loss": 0.0111,
      "step": 5305
    },
    {
      "epoch": 53.87,
      "learning_rate": 8.06519193100039e-05,
      "loss": 0.0041,
      "step": 5306
    },
    {
      "epoch": 53.88,
      "learning_rate": 8.064253815457123e-05,
      "loss": 0.014,
      "step": 5307
    },
    {
      "epoch": 53.89,
      "learning_rate": 8.063315527129352e-05,
      "loss": 0.0006,
      "step": 5308
    },
    {
      "epoch": 53.9,
      "learning_rate": 8.062377066069981e-05,
      "loss": 0.0293,
      "step": 5309
    },
    {
      "epoch": 53.91,
      "learning_rate": 8.061438432331934e-05,
      "loss": 0.005,
      "step": 5310
    },
    {
      "epoch": 53.92,
      "learning_rate": 8.060499625968135e-05,
      "loss": 0.0151,
      "step": 5311
    },
    {
      "epoch": 53.93,
      "learning_rate": 8.05956064703152e-05,
      "loss": 0.0135,
      "step": 5312
    },
    {
      "epoch": 53.94,
      "learning_rate": 8.058621495575032e-05,
      "loss": 0.0074,
      "step": 5313
    },
    {
      "epoch": 53.95,
      "learning_rate": 8.057682171651633e-05,
      "loss": 0.0006,
      "step": 5314
    },
    {
      "epoch": 53.96,
      "learning_rate": 8.056742675314286e-05,
      "loss": 0.0022,
      "step": 5315
    },
    {
      "epoch": 53.97,
      "learning_rate": 8.055803006615966e-05,
      "loss": 0.0025,
      "step": 5316
    },
    {
      "epoch": 53.98,
      "learning_rate": 8.05486316560966e-05,
      "loss": 0.0004,
      "step": 5317
    },
    {
      "epoch": 53.99,
      "learning_rate": 8.053923152348362e-05,
      "loss": 0.0018,
      "step": 5318
    },
    {
      "epoch": 54.0,
      "learning_rate": 8.052982966885075e-05,
      "loss": 0.02,
      "step": 5319
    },
    {
      "epoch": 54.0,
      "eval_loss": 0.02344537153840065,
      "eval_runtime": 32.331,
      "eval_samples_per_second": 97.43,
      "eval_steps_per_second": 6.093,
      "eval_wer": 0.004257362355953905,
      "step": 5319
    },
    {
      "epoch": 54.01,
      "learning_rate": 8.052042609272817e-05,
      "loss": 0.0009,
      "step": 5320
    },
    {
      "epoch": 54.02,
      "learning_rate": 8.051102079564608e-05,
      "loss": 0.0007,
      "step": 5321
    },
    {
      "epoch": 54.03,
      "learning_rate": 8.050161377813485e-05,
      "loss": 0.0004,
      "step": 5322
    },
    {
      "epoch": 54.04,
      "learning_rate": 8.04922050407249e-05,
      "loss": 0.0233,
      "step": 5323
    },
    {
      "epoch": 54.05,
      "learning_rate": 8.048279458394677e-05,
      "loss": 0.0001,
      "step": 5324
    },
    {
      "epoch": 54.06,
      "learning_rate": 8.047338240833106e-05,
      "loss": 0.001,
      "step": 5325
    },
    {
      "epoch": 54.07,
      "learning_rate": 8.046396851440856e-05,
      "loss": 0.0269,
      "step": 5326
    },
    {
      "epoch": 54.08,
      "learning_rate": 8.045455290271002e-05,
      "loss": 0.0018,
      "step": 5327
    },
    {
      "epoch": 54.09,
      "learning_rate": 8.044513557376641e-05,
      "loss": 0.001,
      "step": 5328
    },
    {
      "epoch": 54.1,
      "learning_rate": 8.043571652810872e-05,
      "loss": 0.0011,
      "step": 5329
    },
    {
      "epoch": 54.11,
      "learning_rate": 8.042629576626805e-05,
      "loss": 0.001,
      "step": 5330
    },
    {
      "epoch": 54.12,
      "learning_rate": 8.041687328877567e-05,
      "loss": 0.0004,
      "step": 5331
    },
    {
      "epoch": 54.13,
      "learning_rate": 8.040744909616282e-05,
      "loss": 0.0002,
      "step": 5332
    },
    {
      "epoch": 54.14,
      "learning_rate": 8.039802318896092e-05,
      "loss": 0.0007,
      "step": 5333
    },
    {
      "epoch": 54.15,
      "learning_rate": 8.038859556770151e-05,
      "loss": 0.0199,
      "step": 5334
    },
    {
      "epoch": 54.16,
      "learning_rate": 8.037916623291613e-05,
      "loss": 0.0073,
      "step": 5335
    },
    {
      "epoch": 54.17,
      "learning_rate": 8.036973518513651e-05,
      "loss": 0.0014,
      "step": 5336
    },
    {
      "epoch": 54.18,
      "learning_rate": 8.036030242489442e-05,
      "loss": 0.0004,
      "step": 5337
    },
    {
      "epoch": 54.19,
      "learning_rate": 8.035086795272178e-05,
      "loss": 0.0025,
      "step": 5338
    },
    {
      "epoch": 54.2,
      "learning_rate": 8.034143176915053e-05,
      "loss": 0.0157,
      "step": 5339
    },
    {
      "epoch": 54.21,
      "learning_rate": 8.033199387471277e-05,
      "loss": 0.0032,
      "step": 5340
    },
    {
      "epoch": 54.22,
      "learning_rate": 8.032255426994069e-05,
      "loss": 0.0001,
      "step": 5341
    },
    {
      "epoch": 54.23,
      "learning_rate": 8.031311295536652e-05,
      "loss": 0.0022,
      "step": 5342
    },
    {
      "epoch": 54.24,
      "learning_rate": 8.030366993152266e-05,
      "loss": 0.0185,
      "step": 5343
    },
    {
      "epoch": 54.25,
      "learning_rate": 8.029422519894158e-05,
      "loss": 0.0029,
      "step": 5344
    },
    {
      "epoch": 54.26,
      "learning_rate": 8.028477875815583e-05,
      "loss": 0.0009,
      "step": 5345
    },
    {
      "epoch": 54.27,
      "learning_rate": 8.027533060969807e-05,
      "loss": 0.0021,
      "step": 5346
    },
    {
      "epoch": 54.28,
      "learning_rate": 8.026588075410104e-05,
      "loss": 0.0021,
      "step": 5347
    },
    {
      "epoch": 54.29,
      "learning_rate": 8.025642919189762e-05,
      "loss": 0.0006,
      "step": 5348
    },
    {
      "epoch": 54.3,
      "learning_rate": 8.024697592362074e-05,
      "loss": 0.0009,
      "step": 5349
    },
    {
      "epoch": 54.31,
      "learning_rate": 8.023752094980342e-05,
      "loss": 0.0073,
      "step": 5350
    },
    {
      "epoch": 54.32,
      "learning_rate": 8.022806427097884e-05,
      "loss": 0.0033,
      "step": 5351
    },
    {
      "epoch": 54.34,
      "learning_rate": 8.021860588768022e-05,
      "loss": 0.0039,
      "step": 5352
    },
    {
      "epoch": 54.35,
      "learning_rate": 8.020914580044087e-05,
      "loss": 0.0256,
      "step": 5353
    },
    {
      "epoch": 54.36,
      "learning_rate": 8.019968400979425e-05,
      "loss": 0.0006,
      "step": 5354
    },
    {
      "epoch": 54.37,
      "learning_rate": 8.019022051627388e-05,
      "loss": 0.0002,
      "step": 5355
    },
    {
      "epoch": 54.38,
      "learning_rate": 8.018075532041335e-05,
      "loss": 0.0008,
      "step": 5356
    },
    {
      "epoch": 54.39,
      "learning_rate": 8.01712884227464e-05,
      "loss": 0.0327,
      "step": 5357
    },
    {
      "epoch": 54.4,
      "learning_rate": 8.016181982380682e-05,
      "loss": 0.004,
      "step": 5358
    },
    {
      "epoch": 54.41,
      "learning_rate": 8.015234952412854e-05,
      "loss": 0.0002,
      "step": 5359
    },
    {
      "epoch": 54.42,
      "learning_rate": 8.014287752424556e-05,
      "loss": 0.0055,
      "step": 5360
    },
    {
      "epoch": 54.43,
      "learning_rate": 8.013340382469197e-05,
      "loss": 0.0007,
      "step": 5361
    },
    {
      "epoch": 54.44,
      "learning_rate": 8.012392842600198e-05,
      "loss": 0.0011,
      "step": 5362
    },
    {
      "epoch": 54.45,
      "learning_rate": 8.011445132870985e-05,
      "loss": 0.0002,
      "step": 5363
    },
    {
      "epoch": 54.46,
      "learning_rate": 8.010497253335e-05,
      "loss": 0.0003,
      "step": 5364
    },
    {
      "epoch": 54.47,
      "learning_rate": 8.009549204045689e-05,
      "loss": 0.0003,
      "step": 5365
    },
    {
      "epoch": 54.48,
      "learning_rate": 8.008600985056511e-05,
      "loss": 0.0039,
      "step": 5366
    },
    {
      "epoch": 54.49,
      "learning_rate": 8.007652596420932e-05,
      "loss": 0.0206,
      "step": 5367
    },
    {
      "epoch": 54.5,
      "learning_rate": 8.00670403819243e-05,
      "loss": 0.0148,
      "step": 5368
    },
    {
      "epoch": 54.51,
      "learning_rate": 8.005755310424494e-05,
      "loss": 0.0057,
      "step": 5369
    },
    {
      "epoch": 54.52,
      "learning_rate": 8.004806413170613e-05,
      "loss": 0.0055,
      "step": 5370
    },
    {
      "epoch": 54.53,
      "learning_rate": 8.0038573464843e-05,
      "loss": 0.0215,
      "step": 5371
    },
    {
      "epoch": 54.54,
      "learning_rate": 8.002908110419067e-05,
      "loss": 0.0004,
      "step": 5372
    },
    {
      "epoch": 54.55,
      "learning_rate": 8.001958705028437e-05,
      "loss": 0.0057,
      "step": 5373
    },
    {
      "epoch": 54.56,
      "learning_rate": 8.001009130365947e-05,
      "loss": 0.0038,
      "step": 5374
    },
    {
      "epoch": 54.57,
      "learning_rate": 8.00005938648514e-05,
      "loss": 0.0011,
      "step": 5375
    },
    {
      "epoch": 54.58,
      "learning_rate": 7.999109473439569e-05,
      "loss": 0.0093,
      "step": 5376
    },
    {
      "epoch": 54.59,
      "learning_rate": 7.998159391282798e-05,
      "loss": 0.0122,
      "step": 5377
    },
    {
      "epoch": 54.6,
      "learning_rate": 7.997209140068396e-05,
      "loss": 0.003,
      "step": 5378
    },
    {
      "epoch": 54.61,
      "learning_rate": 7.996258719849949e-05,
      "loss": 0.0113,
      "step": 5379
    },
    {
      "epoch": 54.62,
      "learning_rate": 7.995308130681047e-05,
      "loss": 0.0021,
      "step": 5380
    },
    {
      "epoch": 54.63,
      "learning_rate": 7.994357372615292e-05,
      "loss": 0.0189,
      "step": 5381
    },
    {
      "epoch": 54.64,
      "learning_rate": 7.993406445706293e-05,
      "loss": 0.0002,
      "step": 5382
    },
    {
      "epoch": 54.65,
      "learning_rate": 7.992455350007668e-05,
      "loss": 0.0053,
      "step": 5383
    },
    {
      "epoch": 54.66,
      "learning_rate": 7.991504085573051e-05,
      "loss": 0.0063,
      "step": 5384
    },
    {
      "epoch": 54.67,
      "learning_rate": 7.990552652456081e-05,
      "loss": 0.0006,
      "step": 5385
    },
    {
      "epoch": 54.68,
      "learning_rate": 7.989601050710403e-05,
      "loss": 0.0019,
      "step": 5386
    },
    {
      "epoch": 54.69,
      "learning_rate": 7.988649280389676e-05,
      "loss": 0.0003,
      "step": 5387
    },
    {
      "epoch": 54.7,
      "learning_rate": 7.987697341547569e-05,
      "loss": 0.015,
      "step": 5388
    },
    {
      "epoch": 54.71,
      "learning_rate": 7.986745234237758e-05,
      "loss": 0.0032,
      "step": 5389
    },
    {
      "epoch": 54.72,
      "learning_rate": 7.985792958513931e-05,
      "loss": 0.0017,
      "step": 5390
    },
    {
      "epoch": 54.73,
      "learning_rate": 7.984840514429783e-05,
      "loss": 0.011,
      "step": 5391
    },
    {
      "epoch": 54.74,
      "learning_rate": 7.98388790203902e-05,
      "loss": 0.0124,
      "step": 5392
    },
    {
      "epoch": 54.75,
      "learning_rate": 7.982935121395357e-05,
      "loss": 0.0002,
      "step": 5393
    },
    {
      "epoch": 54.76,
      "learning_rate": 7.981982172552518e-05,
      "loss": 0.0223,
      "step": 5394
    },
    {
      "epoch": 54.77,
      "learning_rate": 7.981029055564238e-05,
      "loss": 0.001,
      "step": 5395
    },
    {
      "epoch": 54.78,
      "learning_rate": 7.980075770484261e-05,
      "loss": 0.0037,
      "step": 5396
    },
    {
      "epoch": 54.79,
      "learning_rate": 7.979122317366337e-05,
      "loss": 0.0075,
      "step": 5397
    },
    {
      "epoch": 54.8,
      "learning_rate": 7.978168696264232e-05,
      "loss": 0.0125,
      "step": 5398
    },
    {
      "epoch": 54.81,
      "learning_rate": 7.977214907231716e-05,
      "loss": 0.0113,
      "step": 5399
    },
    {
      "epoch": 54.82,
      "learning_rate": 7.976260950322572e-05,
      "loss": 0.0009,
      "step": 5400
    },
    {
      "epoch": 54.83,
      "learning_rate": 7.97530682559059e-05,
      "loss": 0.0204,
      "step": 5401
    },
    {
      "epoch": 54.84,
      "learning_rate": 7.974352533089569e-05,
      "loss": 0.0037,
      "step": 5402
    },
    {
      "epoch": 54.85,
      "learning_rate": 7.97339807287332e-05,
      "loss": 0.0319,
      "step": 5403
    },
    {
      "epoch": 54.86,
      "learning_rate": 7.972443444995663e-05,
      "loss": 0.0089,
      "step": 5404
    },
    {
      "epoch": 54.87,
      "learning_rate": 7.971488649510426e-05,
      "loss": 0.0011,
      "step": 5405
    },
    {
      "epoch": 54.88,
      "learning_rate": 7.970533686471449e-05,
      "loss": 0.0147,
      "step": 5406
    },
    {
      "epoch": 54.89,
      "learning_rate": 7.969578555932575e-05,
      "loss": 0.0122,
      "step": 5407
    },
    {
      "epoch": 54.9,
      "learning_rate": 7.968623257947666e-05,
      "loss": 0.0027,
      "step": 5408
    },
    {
      "epoch": 54.91,
      "learning_rate": 7.967667792570586e-05,
      "loss": 0.0077,
      "step": 5409
    },
    {
      "epoch": 54.92,
      "learning_rate": 7.966712159855212e-05,
      "loss": 0.0187,
      "step": 5410
    },
    {
      "epoch": 54.93,
      "learning_rate": 7.965756359855427e-05,
      "loss": 0.0002,
      "step": 5411
    },
    {
      "epoch": 54.94,
      "learning_rate": 7.964800392625129e-05,
      "loss": 0.0002,
      "step": 5412
    },
    {
      "epoch": 54.95,
      "learning_rate": 7.96384425821822e-05,
      "loss": 0.005,
      "step": 5413
    },
    {
      "epoch": 54.96,
      "learning_rate": 7.962887956688617e-05,
      "loss": 0.0003,
      "step": 5414
    },
    {
      "epoch": 54.97,
      "learning_rate": 7.96193148809024e-05,
      "loss": 0.021,
      "step": 5415
    },
    {
      "epoch": 54.98,
      "learning_rate": 7.96097485247702e-05,
      "loss": 0.0207,
      "step": 5416
    },
    {
      "epoch": 54.99,
      "learning_rate": 7.960018049902904e-05,
      "loss": 0.0058,
      "step": 5417
    },
    {
      "epoch": 54.99,
      "eval_loss": 0.021346382796764374,
      "eval_runtime": 33.0894,
      "eval_samples_per_second": 95.197,
      "eval_steps_per_second": 5.954,
      "eval_wer": 0.004449423815620999,
      "step": 5417
    },
    {
      "epoch": 55.01,
      "learning_rate": 7.959061080421839e-05,
      "loss": 0.0018,
      "step": 5418
    },
    {
      "epoch": 55.02,
      "learning_rate": 7.958103944087789e-05,
      "loss": 0.0005,
      "step": 5419
    },
    {
      "epoch": 55.03,
      "learning_rate": 7.95714664095472e-05,
      "loss": 0.0068,
      "step": 5420
    },
    {
      "epoch": 55.04,
      "learning_rate": 7.956189171076616e-05,
      "loss": 0.0251,
      "step": 5421
    },
    {
      "epoch": 55.05,
      "learning_rate": 7.955231534507464e-05,
      "loss": 0.006,
      "step": 5422
    },
    {
      "epoch": 55.06,
      "learning_rate": 7.954273731301262e-05,
      "loss": 0.0002,
      "step": 5423
    },
    {
      "epoch": 55.07,
      "learning_rate": 7.953315761512017e-05,
      "loss": 0.0014,
      "step": 5424
    },
    {
      "epoch": 55.08,
      "learning_rate": 7.952357625193749e-05,
      "loss": 0.0018,
      "step": 5425
    },
    {
      "epoch": 55.09,
      "learning_rate": 7.951399322400484e-05,
      "loss": 0.0081,
      "step": 5426
    },
    {
      "epoch": 55.1,
      "learning_rate": 7.950440853186256e-05,
      "loss": 0.0016,
      "step": 5427
    },
    {
      "epoch": 55.11,
      "learning_rate": 7.949482217605111e-05,
      "loss": 0.0025,
      "step": 5428
    },
    {
      "epoch": 55.12,
      "learning_rate": 7.948523415711105e-05,
      "loss": 0.0003,
      "step": 5429
    },
    {
      "epoch": 55.13,
      "learning_rate": 7.9475644475583e-05,
      "loss": 0.0183,
      "step": 5430
    },
    {
      "epoch": 55.14,
      "learning_rate": 7.94660531320077e-05,
      "loss": 0.0035,
      "step": 5431
    },
    {
      "epoch": 55.15,
      "learning_rate": 7.9456460126926e-05,
      "loss": 0.0087,
      "step": 5432
    },
    {
      "epoch": 55.16,
      "learning_rate": 7.94468654608788e-05,
      "loss": 0.0002,
      "step": 5433
    },
    {
      "epoch": 55.17,
      "learning_rate": 7.943726913440712e-05,
      "loss": 0.0034,
      "step": 5434
    },
    {
      "epoch": 55.18,
      "learning_rate": 7.942767114805207e-05,
      "loss": 0.018,
      "step": 5435
    },
    {
      "epoch": 55.19,
      "learning_rate": 7.941807150235485e-05,
      "loss": 0.0063,
      "step": 5436
    },
    {
      "epoch": 55.2,
      "learning_rate": 7.940847019785677e-05,
      "loss": 0.0001,
      "step": 5437
    },
    {
      "epoch": 55.21,
      "learning_rate": 7.939886723509922e-05,
      "loss": 0.0006,
      "step": 5438
    },
    {
      "epoch": 55.22,
      "learning_rate": 7.938926261462366e-05,
      "loss": 0.0001,
      "step": 5439
    },
    {
      "epoch": 55.23,
      "learning_rate": 7.937965633697168e-05,
      "loss": 0.0002,
      "step": 5440
    },
    {
      "epoch": 55.24,
      "learning_rate": 7.937004840268496e-05,
      "loss": 0.0296,
      "step": 5441
    },
    {
      "epoch": 55.25,
      "learning_rate": 7.936043881230526e-05,
      "loss": 0.0401,
      "step": 5442
    },
    {
      "epoch": 55.26,
      "learning_rate": 7.935082756637443e-05,
      "loss": 0.0009,
      "step": 5443
    },
    {
      "epoch": 55.27,
      "learning_rate": 7.934121466543443e-05,
      "loss": 0.0064,
      "step": 5444
    },
    {
      "epoch": 55.28,
      "learning_rate": 7.933160011002728e-05,
      "loss": 0.0003,
      "step": 5445
    },
    {
      "epoch": 55.29,
      "learning_rate": 7.932198390069515e-05,
      "loss": 0.0013,
      "step": 5446
    },
    {
      "epoch": 55.3,
      "learning_rate": 7.931236603798026e-05,
      "loss": 0.0146,
      "step": 5447
    },
    {
      "epoch": 55.31,
      "learning_rate": 7.930274652242493e-05,
      "loss": 0.0003,
      "step": 5448
    },
    {
      "epoch": 55.32,
      "learning_rate": 7.929312535457155e-05,
      "loss": 0.0021,
      "step": 5449
    },
    {
      "epoch": 55.33,
      "learning_rate": 7.928350253496268e-05,
      "loss": 0.0056,
      "step": 5450
    },
    {
      "epoch": 55.34,
      "learning_rate": 7.92738780641409e-05,
      "loss": 0.001,
      "step": 5451
    },
    {
      "epoch": 55.35,
      "learning_rate": 7.92642519426489e-05,
      "loss": 0.0011,
      "step": 5452
    },
    {
      "epoch": 55.36,
      "learning_rate": 7.925462417102947e-05,
      "loss": 0.005,
      "step": 5453
    },
    {
      "epoch": 55.37,
      "learning_rate": 7.924499474982552e-05,
      "loss": 0.0061,
      "step": 5454
    },
    {
      "epoch": 55.38,
      "learning_rate": 7.923536367957999e-05,
      "loss": 0.0033,
      "step": 5455
    },
    {
      "epoch": 55.39,
      "learning_rate": 7.922573096083597e-05,
      "loss": 0.0099,
      "step": 5456
    },
    {
      "epoch": 55.4,
      "learning_rate": 7.92160965941366e-05,
      "loss": 0.0004,
      "step": 5457
    },
    {
      "epoch": 55.41,
      "learning_rate": 7.920646058002516e-05,
      "loss": 0.0018,
      "step": 5458
    },
    {
      "epoch": 55.42,
      "learning_rate": 7.919682291904498e-05,
      "loss": 0.0098,
      "step": 5459
    },
    {
      "epoch": 55.43,
      "learning_rate": 7.91871836117395e-05,
      "loss": 0.0086,
      "step": 5460
    },
    {
      "epoch": 55.44,
      "learning_rate": 7.917754265865227e-05,
      "loss": 0.0038,
      "step": 5461
    },
    {
      "epoch": 55.45,
      "learning_rate": 7.916790006032688e-05,
      "loss": 0.0002,
      "step": 5462
    },
    {
      "epoch": 55.46,
      "learning_rate": 7.91582558173071e-05,
      "loss": 0.0001,
      "step": 5463
    },
    {
      "epoch": 55.47,
      "learning_rate": 7.91486099301367e-05,
      "loss": 0.0004,
      "step": 5464
    },
    {
      "epoch": 55.48,
      "learning_rate": 7.91389623993596e-05,
      "loss": 0.0089,
      "step": 5465
    },
    {
      "epoch": 55.49,
      "learning_rate": 7.91293132255198e-05,
      "loss": 0.0014,
      "step": 5466
    },
    {
      "epoch": 55.5,
      "learning_rate": 7.91196624091614e-05,
      "loss": 0.0001,
      "step": 5467
    },
    {
      "epoch": 55.51,
      "learning_rate": 7.911000995082854e-05,
      "loss": 0.0039,
      "step": 5468
    },
    {
      "epoch": 55.52,
      "learning_rate": 7.910035585106555e-05,
      "loss": 0.0022,
      "step": 5469
    },
    {
      "epoch": 55.53,
      "learning_rate": 7.909070011041673e-05,
      "loss": 0.0003,
      "step": 5470
    },
    {
      "epoch": 55.54,
      "learning_rate": 7.908104272942659e-05,
      "loss": 0.0005,
      "step": 5471
    },
    {
      "epoch": 55.55,
      "learning_rate": 7.907138370863968e-05,
      "loss": 0.0022,
      "step": 5472
    },
    {
      "epoch": 55.56,
      "learning_rate": 7.906172304860063e-05,
      "loss": 0.0105,
      "step": 5473
    },
    {
      "epoch": 55.57,
      "learning_rate": 7.905206074985416e-05,
      "loss": 0.0018,
      "step": 5474
    },
    {
      "epoch": 55.58,
      "learning_rate": 7.904239681294514e-05,
      "loss": 0.0062,
      "step": 5475
    },
    {
      "epoch": 55.59,
      "learning_rate": 7.903273123841847e-05,
      "loss": 0.001,
      "step": 5476
    },
    {
      "epoch": 55.6,
      "learning_rate": 7.902306402681917e-05,
      "loss": 0.0003,
      "step": 5477
    },
    {
      "epoch": 55.61,
      "learning_rate": 7.901339517869232e-05,
      "loss": 0.0121,
      "step": 5478
    },
    {
      "epoch": 55.62,
      "learning_rate": 7.900372469458317e-05,
      "loss": 0.0037,
      "step": 5479
    },
    {
      "epoch": 55.63,
      "learning_rate": 7.899405257503699e-05,
      "loss": 0.0007,
      "step": 5480
    },
    {
      "epoch": 55.64,
      "learning_rate": 7.898437882059913e-05,
      "loss": 0.0182,
      "step": 5481
    },
    {
      "epoch": 55.65,
      "learning_rate": 7.897470343181508e-05,
      "loss": 0.0065,
      "step": 5482
    },
    {
      "epoch": 55.66,
      "learning_rate": 7.896502640923043e-05,
      "loss": 0.003,
      "step": 5483
    },
    {
      "epoch": 55.68,
      "learning_rate": 7.895534775339084e-05,
      "loss": 0.0002,
      "step": 5484
    },
    {
      "epoch": 55.69,
      "learning_rate": 7.894566746484205e-05,
      "loss": 0.0045,
      "step": 5485
    },
    {
      "epoch": 55.7,
      "learning_rate": 7.893598554412987e-05,
      "loss": 0.0123,
      "step": 5486
    },
    {
      "epoch": 55.71,
      "learning_rate": 7.89263019918003e-05,
      "loss": 0.0006,
      "step": 5487
    },
    {
      "epoch": 55.72,
      "learning_rate": 7.891661680839932e-05,
      "loss": 0.0028,
      "step": 5488
    },
    {
      "epoch": 55.73,
      "learning_rate": 7.89069299944731e-05,
      "loss": 0.0022,
      "step": 5489
    },
    {
      "epoch": 55.74,
      "learning_rate": 7.889724155056777e-05,
      "loss": 0.0017,
      "step": 5490
    },
    {
      "epoch": 55.75,
      "learning_rate": 7.88875514772297e-05,
      "loss": 0.0001,
      "step": 5491
    },
    {
      "epoch": 55.76,
      "learning_rate": 7.887785977500528e-05,
      "loss": 0.0016,
      "step": 5492
    },
    {
      "epoch": 55.77,
      "learning_rate": 7.886816644444098e-05,
      "loss": 0.002,
      "step": 5493
    },
    {
      "epoch": 55.78,
      "learning_rate": 7.885847148608338e-05,
      "loss": 0.0002,
      "step": 5494
    },
    {
      "epoch": 55.79,
      "learning_rate": 7.884877490047915e-05,
      "loss": 0.0055,
      "step": 5495
    },
    {
      "epoch": 55.8,
      "learning_rate": 7.883907668817508e-05,
      "loss": 0.0124,
      "step": 5496
    },
    {
      "epoch": 55.81,
      "learning_rate": 7.882937684971796e-05,
      "loss": 0.003,
      "step": 5497
    },
    {
      "epoch": 55.82,
      "learning_rate": 7.88196753856548e-05,
      "loss": 0.0012,
      "step": 5498
    },
    {
      "epoch": 55.83,
      "learning_rate": 7.880997229653262e-05,
      "loss": 0.0007,
      "step": 5499
    },
    {
      "epoch": 55.84,
      "learning_rate": 7.880026758289855e-05,
      "loss": 0.0012,
      "step": 5500
    },
    {
      "epoch": 55.85,
      "learning_rate": 7.87905612452998e-05,
      "loss": 0.0037,
      "step": 5501
    },
    {
      "epoch": 55.86,
      "learning_rate": 7.878085328428369e-05,
      "loss": 0.005,
      "step": 5502
    },
    {
      "epoch": 55.87,
      "learning_rate": 7.87711437003976e-05,
      "loss": 0.002,
      "step": 5503
    },
    {
      "epoch": 55.88,
      "learning_rate": 7.876143249418908e-05,
      "loss": 0.0012,
      "step": 5504
    },
    {
      "epoch": 55.89,
      "learning_rate": 7.875171966620568e-05,
      "loss": 0.0033,
      "step": 5505
    },
    {
      "epoch": 55.9,
      "learning_rate": 7.874200521699509e-05,
      "loss": 0.0071,
      "step": 5506
    },
    {
      "epoch": 55.91,
      "learning_rate": 7.873228914710504e-05,
      "loss": 0.0027,
      "step": 5507
    },
    {
      "epoch": 55.92,
      "learning_rate": 7.872257145708346e-05,
      "loss": 0.0029,
      "step": 5508
    },
    {
      "epoch": 55.93,
      "learning_rate": 7.871285214747826e-05,
      "loss": 0.0025,
      "step": 5509
    },
    {
      "epoch": 55.94,
      "learning_rate": 7.870313121883748e-05,
      "loss": 0.0009,
      "step": 5510
    },
    {
      "epoch": 55.95,
      "learning_rate": 7.869340867170928e-05,
      "loss": 0.0005,
      "step": 5511
    },
    {
      "epoch": 55.96,
      "learning_rate": 7.868368450664187e-05,
      "loss": 0.0002,
      "step": 5512
    },
    {
      "epoch": 55.97,
      "learning_rate": 7.867395872418358e-05,
      "loss": 0.0003,
      "step": 5513
    },
    {
      "epoch": 55.98,
      "learning_rate": 7.866423132488281e-05,
      "loss": 0.0008,
      "step": 5514
    },
    {
      "epoch": 55.99,
      "learning_rate": 7.865450230928805e-05,
      "loss": 0.0029,
      "step": 5515
    },
    {
      "epoch": 56.0,
      "learning_rate": 7.86447716779479e-05,
      "loss": 0.0142,
      "step": 5516
    },
    {
      "epoch": 56.0,
      "eval_loss": 0.026599012315273285,
      "eval_runtime": 31.7567,
      "eval_samples_per_second": 99.192,
      "eval_steps_per_second": 6.203,
      "eval_wer": 0.006850192061459667,
      "step": 5516
    },
    {
      "epoch": 56.01,
      "learning_rate": 7.863503943141107e-05,
      "loss": 0.0008,
      "step": 5517
    },
    {
      "epoch": 56.02,
      "learning_rate": 7.86253055702263e-05,
      "loss": 0.0025,
      "step": 5518
    },
    {
      "epoch": 56.03,
      "learning_rate": 7.861557009494245e-05,
      "loss": 0.0007,
      "step": 5519
    },
    {
      "epoch": 56.04,
      "learning_rate": 7.860583300610849e-05,
      "loss": 0.0002,
      "step": 5520
    },
    {
      "epoch": 56.05,
      "learning_rate": 7.859609430427347e-05,
      "loss": 0.0028,
      "step": 5521
    },
    {
      "epoch": 56.06,
      "learning_rate": 7.858635398998653e-05,
      "loss": 0.009,
      "step": 5522
    },
    {
      "epoch": 56.07,
      "learning_rate": 7.857661206379688e-05,
      "loss": 0.0006,
      "step": 5523
    },
    {
      "epoch": 56.08,
      "learning_rate": 7.856686852625385e-05,
      "loss": 0.0016,
      "step": 5524
    },
    {
      "epoch": 56.09,
      "learning_rate": 7.855712337790686e-05,
      "loss": 0.0023,
      "step": 5525
    },
    {
      "epoch": 56.1,
      "learning_rate": 7.85473766193054e-05,
      "loss": 0.0066,
      "step": 5526
    },
    {
      "epoch": 56.11,
      "learning_rate": 7.853762825099906e-05,
      "loss": 0.0013,
      "step": 5527
    },
    {
      "epoch": 56.12,
      "learning_rate": 7.852787827353753e-05,
      "loss": 0.0008,
      "step": 5528
    },
    {
      "epoch": 56.13,
      "learning_rate": 7.85181266874706e-05,
      "loss": 0.0002,
      "step": 5529
    },
    {
      "epoch": 56.14,
      "learning_rate": 7.85083734933481e-05,
      "loss": 0.0191,
      "step": 5530
    },
    {
      "epoch": 56.15,
      "learning_rate": 7.849861869171997e-05,
      "loss": 0.0006,
      "step": 5531
    },
    {
      "epoch": 56.16,
      "learning_rate": 7.848886228313632e-05,
      "loss": 0.0093,
      "step": 5532
    },
    {
      "epoch": 56.17,
      "learning_rate": 7.847910426814724e-05,
      "loss": 0.0402,
      "step": 5533
    },
    {
      "epoch": 56.18,
      "learning_rate": 7.846934464730296e-05,
      "loss": 0.0068,
      "step": 5534
    },
    {
      "epoch": 56.19,
      "learning_rate": 7.84595834211538e-05,
      "loss": 0.011,
      "step": 5535
    },
    {
      "epoch": 56.2,
      "learning_rate": 7.844982059025019e-05,
      "loss": 0.0044,
      "step": 5536
    },
    {
      "epoch": 56.21,
      "learning_rate": 7.844005615514259e-05,
      "loss": 0.0026,
      "step": 5537
    },
    {
      "epoch": 56.22,
      "learning_rate": 7.843029011638162e-05,
      "loss": 0.0015,
      "step": 5538
    },
    {
      "epoch": 56.23,
      "learning_rate": 7.842052247451794e-05,
      "loss": 0.0053,
      "step": 5539
    },
    {
      "epoch": 56.24,
      "learning_rate": 7.841075323010233e-05,
      "loss": 0.0009,
      "step": 5540
    },
    {
      "epoch": 56.25,
      "learning_rate": 7.840098238368565e-05,
      "loss": 0.0059,
      "step": 5541
    },
    {
      "epoch": 56.26,
      "learning_rate": 7.839120993581883e-05,
      "loss": 0.0037,
      "step": 5542
    },
    {
      "epoch": 56.27,
      "learning_rate": 7.838143588705294e-05,
      "loss": 0.0007,
      "step": 5543
    },
    {
      "epoch": 56.28,
      "learning_rate": 7.83716602379391e-05,
      "loss": 0.0004,
      "step": 5544
    },
    {
      "epoch": 56.29,
      "learning_rate": 7.836188298902851e-05,
      "loss": 0.0072,
      "step": 5545
    },
    {
      "epoch": 56.3,
      "learning_rate": 7.835210414087253e-05,
      "loss": 0.0123,
      "step": 5546
    },
    {
      "epoch": 56.31,
      "learning_rate": 7.83423236940225e-05,
      "loss": 0.0122,
      "step": 5547
    },
    {
      "epoch": 56.32,
      "learning_rate": 7.833254164902994e-05,
      "loss": 0.0006,
      "step": 5548
    },
    {
      "epoch": 56.34,
      "learning_rate": 7.832275800644646e-05,
      "loss": 0.0169,
      "step": 5549
    },
    {
      "epoch": 56.35,
      "learning_rate": 7.83129727668237e-05,
      "loss": 0.0194,
      "step": 5550
    },
    {
      "epoch": 56.36,
      "learning_rate": 7.830318593071341e-05,
      "loss": 0.0017,
      "step": 5551
    },
    {
      "epoch": 56.37,
      "learning_rate": 7.829339749866746e-05,
      "loss": 0.001,
      "step": 5552
    },
    {
      "epoch": 56.38,
      "learning_rate": 7.828360747123779e-05,
      "loss": 0.0041,
      "step": 5553
    },
    {
      "epoch": 56.39,
      "learning_rate": 7.827381584897644e-05,
      "loss": 0.0012,
      "step": 5554
    },
    {
      "epoch": 56.4,
      "learning_rate": 7.826402263243553e-05,
      "loss": 0.0038,
      "step": 5555
    },
    {
      "epoch": 56.41,
      "learning_rate": 7.825422782216725e-05,
      "loss": 0.0016,
      "step": 5556
    },
    {
      "epoch": 56.42,
      "learning_rate": 7.824443141872391e-05,
      "loss": 0.0005,
      "step": 5557
    },
    {
      "epoch": 56.43,
      "learning_rate": 7.823463342265792e-05,
      "loss": 0.0021,
      "step": 5558
    },
    {
      "epoch": 56.44,
      "learning_rate": 7.822483383452175e-05,
      "loss": 0.0209,
      "step": 5559
    },
    {
      "epoch": 56.45,
      "learning_rate": 7.821503265486795e-05,
      "loss": 0.0182,
      "step": 5560
    },
    {
      "epoch": 56.46,
      "learning_rate": 7.820522988424922e-05,
      "loss": 0.0005,
      "step": 5561
    },
    {
      "epoch": 56.47,
      "learning_rate": 7.819542552321828e-05,
      "loss": 0.0003,
      "step": 5562
    },
    {
      "epoch": 56.48,
      "learning_rate": 7.818561957232798e-05,
      "loss": 0.011,
      "step": 5563
    },
    {
      "epoch": 56.49,
      "learning_rate": 7.817581203213125e-05,
      "loss": 0.0105,
      "step": 5564
    },
    {
      "epoch": 56.5,
      "learning_rate": 7.81660029031811e-05,
      "loss": 0.0027,
      "step": 5565
    },
    {
      "epoch": 56.51,
      "learning_rate": 7.815619218603065e-05,
      "loss": 0.0014,
      "step": 5566
    },
    {
      "epoch": 56.52,
      "learning_rate": 7.814637988123311e-05,
      "loss": 0.0006,
      "step": 5567
    },
    {
      "epoch": 56.53,
      "learning_rate": 7.813656598934174e-05,
      "loss": 0.0002,
      "step": 5568
    },
    {
      "epoch": 56.54,
      "learning_rate": 7.812675051090992e-05,
      "loss": 0.0007,
      "step": 5569
    },
    {
      "epoch": 56.55,
      "learning_rate": 7.811693344649115e-05,
      "loss": 0.0073,
      "step": 5570
    },
    {
      "epoch": 56.56,
      "learning_rate": 7.810711479663895e-05,
      "loss": 0.0045,
      "step": 5571
    },
    {
      "epoch": 56.57,
      "learning_rate": 7.809729456190698e-05,
      "loss": 0.012,
      "step": 5572
    },
    {
      "epoch": 56.58,
      "learning_rate": 7.808747274284895e-05,
      "loss": 0.0042,
      "step": 5573
    },
    {
      "epoch": 56.59,
      "learning_rate": 7.807764934001874e-05,
      "loss": 0.0009,
      "step": 5574
    },
    {
      "epoch": 56.6,
      "learning_rate": 7.806782435397021e-05,
      "loss": 0.0071,
      "step": 5575
    },
    {
      "epoch": 56.61,
      "learning_rate": 7.805799778525741e-05,
      "loss": 0.0213,
      "step": 5576
    },
    {
      "epoch": 56.62,
      "learning_rate": 7.804816963443437e-05,
      "loss": 0.0007,
      "step": 5577
    },
    {
      "epoch": 56.63,
      "learning_rate": 7.803833990205534e-05,
      "loss": 0.0039,
      "step": 5578
    },
    {
      "epoch": 56.64,
      "learning_rate": 7.802850858867454e-05,
      "loss": 0.0016,
      "step": 5579
    },
    {
      "epoch": 56.65,
      "learning_rate": 7.801867569484636e-05,
      "loss": 0.0007,
      "step": 5580
    },
    {
      "epoch": 56.66,
      "learning_rate": 7.800884122112522e-05,
      "loss": 0.0022,
      "step": 5581
    },
    {
      "epoch": 56.67,
      "learning_rate": 7.799900516806569e-05,
      "loss": 0.0019,
      "step": 5582
    },
    {
      "epoch": 56.68,
      "learning_rate": 7.798916753622236e-05,
      "loss": 0.0016,
      "step": 5583
    },
    {
      "epoch": 56.69,
      "learning_rate": 7.797932832614999e-05,
      "loss": 0.004,
      "step": 5584
    },
    {
      "epoch": 56.7,
      "learning_rate": 7.796948753840334e-05,
      "loss": 0.0012,
      "step": 5585
    },
    {
      "epoch": 56.71,
      "learning_rate": 7.795964517353735e-05,
      "loss": 0.0055,
      "step": 5586
    },
    {
      "epoch": 56.72,
      "learning_rate": 7.794980123210696e-05,
      "loss": 0.0002,
      "step": 5587
    },
    {
      "epoch": 56.73,
      "learning_rate": 7.793995571466726e-05,
      "loss": 0.0028,
      "step": 5588
    },
    {
      "epoch": 56.74,
      "learning_rate": 7.793010862177341e-05,
      "loss": 0.0077,
      "step": 5589
    },
    {
      "epoch": 56.75,
      "learning_rate": 7.792025995398068e-05,
      "loss": 0.0187,
      "step": 5590
    },
    {
      "epoch": 56.76,
      "learning_rate": 7.791040971184438e-05,
      "loss": 0.0002,
      "step": 5591
    },
    {
      "epoch": 56.77,
      "learning_rate": 7.790055789591993e-05,
      "loss": 0.0003,
      "step": 5592
    },
    {
      "epoch": 56.78,
      "learning_rate": 7.789070450676287e-05,
      "loss": 0.0008,
      "step": 5593
    },
    {
      "epoch": 56.79,
      "learning_rate": 7.78808495449288e-05,
      "loss": 0.0106,
      "step": 5594
    },
    {
      "epoch": 56.8,
      "learning_rate": 7.78709930109734e-05,
      "loss": 0.0128,
      "step": 5595
    },
    {
      "epoch": 56.81,
      "learning_rate": 7.786113490545246e-05,
      "loss": 0.0027,
      "step": 5596
    },
    {
      "epoch": 56.82,
      "learning_rate": 7.785127522892186e-05,
      "loss": 0.0004,
      "step": 5597
    },
    {
      "epoch": 56.83,
      "learning_rate": 7.784141398193753e-05,
      "loss": 0.0003,
      "step": 5598
    },
    {
      "epoch": 56.84,
      "learning_rate": 7.783155116505557e-05,
      "loss": 0.0004,
      "step": 5599
    },
    {
      "epoch": 56.85,
      "learning_rate": 7.782168677883206e-05,
      "loss": 0.0001,
      "step": 5600
    },
    {
      "epoch": 56.86,
      "learning_rate": 7.781182082382325e-05,
      "loss": 0.0017,
      "step": 5601
    },
    {
      "epoch": 56.87,
      "learning_rate": 7.780195330058544e-05,
      "loss": 0.0005,
      "step": 5602
    },
    {
      "epoch": 56.88,
      "learning_rate": 7.779208420967506e-05,
      "loss": 0.011,
      "step": 5603
    },
    {
      "epoch": 56.89,
      "learning_rate": 7.778221355164858e-05,
      "loss": 0.0035,
      "step": 5604
    },
    {
      "epoch": 56.9,
      "learning_rate": 7.777234132706257e-05,
      "loss": 0.0001,
      "step": 5605
    },
    {
      "epoch": 56.91,
      "learning_rate": 7.776246753647371e-05,
      "loss": 0.0014,
      "step": 5606
    },
    {
      "epoch": 56.92,
      "learning_rate": 7.775259218043876e-05,
      "loss": 0.0001,
      "step": 5607
    },
    {
      "epoch": 56.93,
      "learning_rate": 7.774271525951453e-05,
      "loss": 0.0001,
      "step": 5608
    },
    {
      "epoch": 56.94,
      "learning_rate": 7.7732836774258e-05,
      "loss": 0.0153,
      "step": 5609
    },
    {
      "epoch": 56.95,
      "learning_rate": 7.772295672522615e-05,
      "loss": 0.0002,
      "step": 5610
    },
    {
      "epoch": 56.96,
      "learning_rate": 7.771307511297611e-05,
      "loss": 0.0024,
      "step": 5611
    },
    {
      "epoch": 56.97,
      "learning_rate": 7.770319193806506e-05,
      "loss": 0.0079,
      "step": 5612
    },
    {
      "epoch": 56.98,
      "learning_rate": 7.76933072010503e-05,
      "loss": 0.0036,
      "step": 5613
    },
    {
      "epoch": 56.99,
      "learning_rate": 7.76834209024892e-05,
      "loss": 0.0004,
      "step": 5614
    },
    {
      "epoch": 56.99,
      "eval_loss": 0.0206503514200449,
      "eval_runtime": 31.8224,
      "eval_samples_per_second": 98.987,
      "eval_steps_per_second": 6.191,
      "eval_wer": 0.004449423815620999,
      "step": 5614
    },
    {
      "epoch": 57.01,
      "learning_rate": 7.76735330429392e-05,
      "loss": 0.0004,
      "step": 5615
    },
    {
      "epoch": 57.02,
      "learning_rate": 7.766364362295789e-05,
      "loss": 0.0003,
      "step": 5616
    },
    {
      "epoch": 57.03,
      "learning_rate": 7.765375264310285e-05,
      "loss": 0.0005,
      "step": 5617
    },
    {
      "epoch": 57.04,
      "learning_rate": 7.764386010393183e-05,
      "loss": 0.0012,
      "step": 5618
    },
    {
      "epoch": 57.05,
      "learning_rate": 7.763396600600267e-05,
      "loss": 0.0023,
      "step": 5619
    },
    {
      "epoch": 57.06,
      "learning_rate": 7.762407034987323e-05,
      "loss": 0.0003,
      "step": 5620
    },
    {
      "epoch": 57.07,
      "learning_rate": 7.76141731361015e-05,
      "loss": 0.0156,
      "step": 5621
    },
    {
      "epoch": 57.08,
      "learning_rate": 7.76042743652456e-05,
      "loss": 0.0018,
      "step": 5622
    },
    {
      "epoch": 57.09,
      "learning_rate": 7.759437403786363e-05,
      "loss": 0.0178,
      "step": 5623
    },
    {
      "epoch": 57.1,
      "learning_rate": 7.75844721545139e-05,
      "loss": 0.007,
      "step": 5624
    },
    {
      "epoch": 57.11,
      "learning_rate": 7.75745687157547e-05,
      "loss": 0.0005,
      "step": 5625
    },
    {
      "epoch": 57.12,
      "learning_rate": 7.756466372214448e-05,
      "loss": 0.0006,
      "step": 5626
    },
    {
      "epoch": 57.13,
      "learning_rate": 7.755475717424176e-05,
      "loss": 0.0041,
      "step": 5627
    },
    {
      "epoch": 57.14,
      "learning_rate": 7.754484907260513e-05,
      "loss": 0.0019,
      "step": 5628
    },
    {
      "epoch": 57.15,
      "learning_rate": 7.753493941779329e-05,
      "loss": 0.005,
      "step": 5629
    },
    {
      "epoch": 57.16,
      "learning_rate": 7.752502821036501e-05,
      "loss": 0.0005,
      "step": 5630
    },
    {
      "epoch": 57.17,
      "learning_rate": 7.751511545087914e-05,
      "loss": 0.0008,
      "step": 5631
    },
    {
      "epoch": 57.18,
      "learning_rate": 7.750520113989465e-05,
      "loss": 0.0176,
      "step": 5632
    },
    {
      "epoch": 57.19,
      "learning_rate": 7.74952852779706e-05,
      "loss": 0.0007,
      "step": 5633
    },
    {
      "epoch": 57.2,
      "learning_rate": 7.748536786566606e-05,
      "loss": 0.0005,
      "step": 5634
    },
    {
      "epoch": 57.21,
      "learning_rate": 7.74754489035403e-05,
      "loss": 0.0008,
      "step": 5635
    },
    {
      "epoch": 57.22,
      "learning_rate": 7.74655283921526e-05,
      "loss": 0.0061,
      "step": 5636
    },
    {
      "epoch": 57.23,
      "learning_rate": 7.745560633206234e-05,
      "loss": 0.0016,
      "step": 5637
    },
    {
      "epoch": 57.24,
      "learning_rate": 7.744568272382901e-05,
      "loss": 0.0006,
      "step": 5638
    },
    {
      "epoch": 57.25,
      "learning_rate": 7.743575756801218e-05,
      "loss": 0.0003,
      "step": 5639
    },
    {
      "epoch": 57.26,
      "learning_rate": 7.74258308651715e-05,
      "loss": 0.0007,
      "step": 5640
    },
    {
      "epoch": 57.27,
      "learning_rate": 7.741590261586667e-05,
      "loss": 0.0031,
      "step": 5641
    },
    {
      "epoch": 57.28,
      "learning_rate": 7.740597282065756e-05,
      "loss": 0.0001,
      "step": 5642
    },
    {
      "epoch": 57.29,
      "learning_rate": 7.739604148010406e-05,
      "loss": 0.0006,
      "step": 5643
    },
    {
      "epoch": 57.3,
      "learning_rate": 7.738610859476619e-05,
      "loss": 0.013,
      "step": 5644
    },
    {
      "epoch": 57.31,
      "learning_rate": 7.737617416520403e-05,
      "loss": 0.0046,
      "step": 5645
    },
    {
      "epoch": 57.32,
      "learning_rate": 7.736623819197773e-05,
      "loss": 0.0161,
      "step": 5646
    },
    {
      "epoch": 57.33,
      "learning_rate": 7.735630067564758e-05,
      "loss": 0.0022,
      "step": 5647
    },
    {
      "epoch": 57.34,
      "learning_rate": 7.734636161677392e-05,
      "loss": 0.0006,
      "step": 5648
    },
    {
      "epoch": 57.35,
      "learning_rate": 7.733642101591718e-05,
      "loss": 0.0022,
      "step": 5649
    },
    {
      "epoch": 57.36,
      "learning_rate": 7.732647887363789e-05,
      "loss": 0.0035,
      "step": 5650
    },
    {
      "epoch": 57.37,
      "learning_rate": 7.731653519049665e-05,
      "loss": 0.0007,
      "step": 5651
    },
    {
      "epoch": 57.38,
      "learning_rate": 7.730658996705415e-05,
      "loss": 0.0294,
      "step": 5652
    },
    {
      "epoch": 57.39,
      "learning_rate": 7.72966432038712e-05,
      "loss": 0.0014,
      "step": 5653
    },
    {
      "epoch": 57.4,
      "learning_rate": 7.728669490150864e-05,
      "loss": 0.0018,
      "step": 5654
    },
    {
      "epoch": 57.41,
      "learning_rate": 7.727674506052743e-05,
      "loss": 0.001,
      "step": 5655
    },
    {
      "epoch": 57.42,
      "learning_rate": 7.726679368148864e-05,
      "loss": 0.0016,
      "step": 5656
    },
    {
      "epoch": 57.43,
      "learning_rate": 7.725684076495339e-05,
      "loss": 0.0209,
      "step": 5657
    },
    {
      "epoch": 57.44,
      "learning_rate": 7.724688631148286e-05,
      "loss": 0.003,
      "step": 5658
    },
    {
      "epoch": 57.45,
      "learning_rate": 7.723693032163839e-05,
      "loss": 0.0064,
      "step": 5659
    },
    {
      "epoch": 57.46,
      "learning_rate": 7.722697279598136e-05,
      "loss": 0.0017,
      "step": 5660
    },
    {
      "epoch": 57.47,
      "learning_rate": 7.721701373507326e-05,
      "loss": 0.0048,
      "step": 5661
    },
    {
      "epoch": 57.48,
      "learning_rate": 7.720705313947563e-05,
      "loss": 0.0004,
      "step": 5662
    },
    {
      "epoch": 57.49,
      "learning_rate": 7.719709100975012e-05,
      "loss": 0.0013,
      "step": 5663
    },
    {
      "epoch": 57.5,
      "learning_rate": 7.71871273464585e-05,
      "loss": 0.0001,
      "step": 5664
    },
    {
      "epoch": 57.51,
      "learning_rate": 7.717716215016256e-05,
      "loss": 0.0004,
      "step": 5665
    },
    {
      "epoch": 57.52,
      "learning_rate": 7.716719542142422e-05,
      "loss": 0.0002,
      "step": 5666
    },
    {
      "epoch": 57.53,
      "learning_rate": 7.715722716080545e-05,
      "loss": 0.0033,
      "step": 5667
    },
    {
      "epoch": 57.54,
      "learning_rate": 7.714725736886836e-05,
      "loss": 0.0047,
      "step": 5668
    },
    {
      "epoch": 57.55,
      "learning_rate": 7.713728604617511e-05,
      "loss": 0.0035,
      "step": 5669
    },
    {
      "epoch": 57.56,
      "learning_rate": 7.712731319328798e-05,
      "loss": 0.0034,
      "step": 5670
    },
    {
      "epoch": 57.57,
      "learning_rate": 7.711733881076926e-05,
      "loss": 0.0038,
      "step": 5671
    },
    {
      "epoch": 57.58,
      "learning_rate": 7.710736289918143e-05,
      "loss": 0.0024,
      "step": 5672
    },
    {
      "epoch": 57.59,
      "learning_rate": 7.709738545908696e-05,
      "loss": 0.0227,
      "step": 5673
    },
    {
      "epoch": 57.6,
      "learning_rate": 7.708740649104847e-05,
      "loss": 0.0002,
      "step": 5674
    },
    {
      "epoch": 57.61,
      "learning_rate": 7.707742599562863e-05,
      "loss": 0.0026,
      "step": 5675
    },
    {
      "epoch": 57.62,
      "learning_rate": 7.706744397339022e-05,
      "loss": 0.0104,
      "step": 5676
    },
    {
      "epoch": 57.63,
      "learning_rate": 7.705746042489613e-05,
      "loss": 0.0045,
      "step": 5677
    },
    {
      "epoch": 57.64,
      "learning_rate": 7.704747535070926e-05,
      "loss": 0.0024,
      "step": 5678
    },
    {
      "epoch": 57.65,
      "learning_rate": 7.703748875139264e-05,
      "loss": 0.0014,
      "step": 5679
    },
    {
      "epoch": 57.66,
      "learning_rate": 7.702750062750942e-05,
      "loss": 0.0007,
      "step": 5680
    },
    {
      "epoch": 57.68,
      "learning_rate": 7.701751097962279e-05,
      "loss": 0.0053,
      "step": 5681
    },
    {
      "epoch": 57.69,
      "learning_rate": 7.700751980829602e-05,
      "loss": 0.0019,
      "step": 5682
    },
    {
      "epoch": 57.7,
      "learning_rate": 7.699752711409248e-05,
      "loss": 0.0057,
      "step": 5683
    },
    {
      "epoch": 57.71,
      "learning_rate": 7.698753289757565e-05,
      "loss": 0.01,
      "step": 5684
    },
    {
      "epoch": 57.72,
      "learning_rate": 7.697753715930906e-05,
      "loss": 0.0063,
      "step": 5685
    },
    {
      "epoch": 57.73,
      "learning_rate": 7.696753989985637e-05,
      "loss": 0.0011,
      "step": 5686
    },
    {
      "epoch": 57.74,
      "learning_rate": 7.695754111978127e-05,
      "loss": 0.0037,
      "step": 5687
    },
    {
      "epoch": 57.75,
      "learning_rate": 7.694754081964755e-05,
      "loss": 0.0075,
      "step": 5688
    },
    {
      "epoch": 57.76,
      "learning_rate": 7.693753900001912e-05,
      "loss": 0.0128,
      "step": 5689
    },
    {
      "epoch": 57.77,
      "learning_rate": 7.692753566145998e-05,
      "loss": 0.0048,
      "step": 5690
    },
    {
      "epoch": 57.78,
      "learning_rate": 7.691753080453412e-05,
      "loss": 0.0021,
      "step": 5691
    },
    {
      "epoch": 57.79,
      "learning_rate": 7.690752442980576e-05,
      "loss": 0.0003,
      "step": 5692
    },
    {
      "epoch": 57.8,
      "learning_rate": 7.689751653783906e-05,
      "loss": 0.0015,
      "step": 5693
    },
    {
      "epoch": 57.81,
      "learning_rate": 7.688750712919839e-05,
      "loss": 0.0127,
      "step": 5694
    },
    {
      "epoch": 57.82,
      "learning_rate": 7.687749620444815e-05,
      "loss": 0.0006,
      "step": 5695
    },
    {
      "epoch": 57.83,
      "learning_rate": 7.686748376415281e-05,
      "loss": 0.0037,
      "step": 5696
    },
    {
      "epoch": 57.84,
      "learning_rate": 7.685746980887691e-05,
      "loss": 0.0006,
      "step": 5697
    },
    {
      "epoch": 57.85,
      "learning_rate": 7.684745433918518e-05,
      "loss": 0.0009,
      "step": 5698
    },
    {
      "epoch": 57.86,
      "learning_rate": 7.683743735564231e-05,
      "loss": 0.0076,
      "step": 5699
    },
    {
      "epoch": 57.87,
      "learning_rate": 7.682741885881315e-05,
      "loss": 0.0081,
      "step": 5700
    },
    {
      "epoch": 57.88,
      "learning_rate": 7.681739884926261e-05,
      "loss": 0.0043,
      "step": 5701
    },
    {
      "epoch": 57.89,
      "learning_rate": 7.68073773275557e-05,
      "loss": 0.003,
      "step": 5702
    },
    {
      "epoch": 57.9,
      "learning_rate": 7.679735429425748e-05,
      "loss": 0.0062,
      "step": 5703
    },
    {
      "epoch": 57.91,
      "learning_rate": 7.678732974993314e-05,
      "loss": 0.0004,
      "step": 5704
    },
    {
      "epoch": 57.92,
      "learning_rate": 7.677730369514793e-05,
      "loss": 0.0011,
      "step": 5705
    },
    {
      "epoch": 57.93,
      "learning_rate": 7.67672761304672e-05,
      "loss": 0.0005,
      "step": 5706
    },
    {
      "epoch": 57.94,
      "learning_rate": 7.675724705645634e-05,
      "loss": 0.0011,
      "step": 5707
    },
    {
      "epoch": 57.95,
      "learning_rate": 7.67472164736809e-05,
      "loss": 0.0105,
      "step": 5708
    },
    {
      "epoch": 57.96,
      "learning_rate": 7.673718438270648e-05,
      "loss": 0.0021,
      "step": 5709
    },
    {
      "epoch": 57.97,
      "learning_rate": 7.672715078409873e-05,
      "loss": 0.0109,
      "step": 5710
    },
    {
      "epoch": 57.98,
      "learning_rate": 7.671711567842344e-05,
      "loss": 0.0075,
      "step": 5711
    },
    {
      "epoch": 57.99,
      "learning_rate": 7.670707906624644e-05,
      "loss": 0.0124,
      "step": 5712
    },
    {
      "epoch": 58.0,
      "learning_rate": 7.669704094813368e-05,
      "loss": 0.006,
      "step": 5713
    },
    {
      "epoch": 58.0,
      "eval_loss": 0.019720369949936867,
      "eval_runtime": 31.8687,
      "eval_samples_per_second": 98.843,
      "eval_steps_per_second": 6.182,
      "eval_wer": 0.004737516005121639,
      "step": 5713
    },
    {
      "epoch": 58.01,
      "learning_rate": 7.668700132465118e-05,
      "loss": 0.0003,
      "step": 5714
    },
    {
      "epoch": 58.02,
      "learning_rate": 7.667696019636503e-05,
      "loss": 0.0024,
      "step": 5715
    },
    {
      "epoch": 58.03,
      "learning_rate": 7.666691756384145e-05,
      "loss": 0.0064,
      "step": 5716
    },
    {
      "epoch": 58.04,
      "learning_rate": 7.66568734276467e-05,
      "loss": 0.0006,
      "step": 5717
    },
    {
      "epoch": 58.05,
      "learning_rate": 7.664682778834713e-05,
      "loss": 0.0011,
      "step": 5718
    },
    {
      "epoch": 58.06,
      "learning_rate": 7.66367806465092e-05,
      "loss": 0.0004,
      "step": 5719
    },
    {
      "epoch": 58.07,
      "learning_rate": 7.662673200269943e-05,
      "loss": 0.0066,
      "step": 5720
    },
    {
      "epoch": 58.08,
      "learning_rate": 7.661668185748443e-05,
      "loss": 0.006,
      "step": 5721
    },
    {
      "epoch": 58.09,
      "learning_rate": 7.660663021143092e-05,
      "loss": 0.0087,
      "step": 5722
    },
    {
      "epoch": 58.1,
      "learning_rate": 7.659657706510566e-05,
      "loss": 0.0013,
      "step": 5723
    },
    {
      "epoch": 58.11,
      "learning_rate": 7.658652241907554e-05,
      "loss": 0.0003,
      "step": 5724
    },
    {
      "epoch": 58.12,
      "learning_rate": 7.657646627390749e-05,
      "loss": 0.0009,
      "step": 5725
    },
    {
      "epoch": 58.13,
      "learning_rate": 7.656640863016857e-05,
      "loss": 0.0039,
      "step": 5726
    },
    {
      "epoch": 58.14,
      "learning_rate": 7.655634948842587e-05,
      "loss": 0.0004,
      "step": 5727
    },
    {
      "epoch": 58.15,
      "learning_rate": 7.654628884924664e-05,
      "loss": 0.0241,
      "step": 5728
    },
    {
      "epoch": 58.16,
      "learning_rate": 7.653622671319813e-05,
      "loss": 0.0154,
      "step": 5729
    },
    {
      "epoch": 58.17,
      "learning_rate": 7.652616308084774e-05,
      "loss": 0.0008,
      "step": 5730
    },
    {
      "epoch": 58.18,
      "learning_rate": 7.651609795276292e-05,
      "loss": 0.0005,
      "step": 5731
    },
    {
      "epoch": 58.19,
      "learning_rate": 7.650603132951121e-05,
      "loss": 0.0012,
      "step": 5732
    },
    {
      "epoch": 58.2,
      "learning_rate": 7.649596321166024e-05,
      "loss": 0.0105,
      "step": 5733
    },
    {
      "epoch": 58.21,
      "learning_rate": 7.648589359977775e-05,
      "loss": 0.0004,
      "step": 5734
    },
    {
      "epoch": 58.22,
      "learning_rate": 7.647582249443149e-05,
      "loss": 0.0028,
      "step": 5735
    },
    {
      "epoch": 58.23,
      "learning_rate": 7.646574989618938e-05,
      "loss": 0.019,
      "step": 5736
    },
    {
      "epoch": 58.24,
      "learning_rate": 7.645567580561934e-05,
      "loss": 0.0003,
      "step": 5737
    },
    {
      "epoch": 58.25,
      "learning_rate": 7.644560022328946e-05,
      "loss": 0.0001,
      "step": 5738
    },
    {
      "epoch": 58.26,
      "learning_rate": 7.643552314976787e-05,
      "loss": 0.001,
      "step": 5739
    },
    {
      "epoch": 58.27,
      "learning_rate": 7.642544458562278e-05,
      "loss": 0.0007,
      "step": 5740
    },
    {
      "epoch": 58.28,
      "learning_rate": 7.641536453142248e-05,
      "loss": 0.0112,
      "step": 5741
    },
    {
      "epoch": 58.29,
      "learning_rate": 7.640528298773536e-05,
      "loss": 0.0006,
      "step": 5742
    },
    {
      "epoch": 58.3,
      "learning_rate": 7.639519995512992e-05,
      "loss": 0.0004,
      "step": 5743
    },
    {
      "epoch": 58.31,
      "learning_rate": 7.638511543417466e-05,
      "loss": 0.0056,
      "step": 5744
    },
    {
      "epoch": 58.32,
      "learning_rate": 7.637502942543824e-05,
      "loss": 0.0014,
      "step": 5745
    },
    {
      "epoch": 58.34,
      "learning_rate": 7.636494192948939e-05,
      "loss": 0.0021,
      "step": 5746
    },
    {
      "epoch": 58.35,
      "learning_rate": 7.635485294689694e-05,
      "loss": 0.0017,
      "step": 5747
    },
    {
      "epoch": 58.36,
      "learning_rate": 7.634476247822972e-05,
      "loss": 0.0003,
      "step": 5748
    },
    {
      "epoch": 58.37,
      "learning_rate": 7.633467052405673e-05,
      "loss": 0.0079,
      "step": 5749
    },
    {
      "epoch": 58.38,
      "learning_rate": 7.632457708494705e-05,
      "loss": 0.0016,
      "step": 5750
    },
    {
      "epoch": 58.39,
      "learning_rate": 7.63144821614698e-05,
      "loss": 0.0166,
      "step": 5751
    },
    {
      "epoch": 58.4,
      "learning_rate": 7.630438575419418e-05,
      "loss": 0.0024,
      "step": 5752
    },
    {
      "epoch": 58.41,
      "learning_rate": 7.629428786368954e-05,
      "loss": 0.0013,
      "step": 5753
    },
    {
      "epoch": 58.42,
      "learning_rate": 7.628418849052523e-05,
      "loss": 0.0022,
      "step": 5754
    },
    {
      "epoch": 58.43,
      "learning_rate": 7.627408763527078e-05,
      "loss": 0.0021,
      "step": 5755
    },
    {
      "epoch": 58.44,
      "learning_rate": 7.626398529849568e-05,
      "loss": 0.0189,
      "step": 5756
    },
    {
      "epoch": 58.45,
      "learning_rate": 7.625388148076962e-05,
      "loss": 0.0138,
      "step": 5757
    },
    {
      "epoch": 58.46,
      "learning_rate": 7.624377618266231e-05,
      "loss": 0.0196,
      "step": 5758
    },
    {
      "epoch": 58.47,
      "learning_rate": 7.623366940474356e-05,
      "loss": 0.0039,
      "step": 5759
    },
    {
      "epoch": 58.48,
      "learning_rate": 7.622356114758328e-05,
      "loss": 0.0039,
      "step": 5760
    },
    {
      "epoch": 58.49,
      "learning_rate": 7.62134514117514e-05,
      "loss": 0.0013,
      "step": 5761
    },
    {
      "epoch": 58.5,
      "learning_rate": 7.620334019781802e-05,
      "loss": 0.0005,
      "step": 5762
    },
    {
      "epoch": 58.51,
      "learning_rate": 7.619322750635327e-05,
      "loss": 0.0083,
      "step": 5763
    },
    {
      "epoch": 58.52,
      "learning_rate": 7.61831133379274e-05,
      "loss": 0.0008,
      "step": 5764
    },
    {
      "epoch": 58.53,
      "learning_rate": 7.617299769311066e-05,
      "loss": 0.0006,
      "step": 5765
    },
    {
      "epoch": 58.54,
      "learning_rate": 7.616288057247349e-05,
      "loss": 0.0216,
      "step": 5766
    },
    {
      "epoch": 58.55,
      "learning_rate": 7.615276197658635e-05,
      "loss": 0.0012,
      "step": 5767
    },
    {
      "epoch": 58.56,
      "learning_rate": 7.614264190601981e-05,
      "loss": 0.0098,
      "step": 5768
    },
    {
      "epoch": 58.57,
      "learning_rate": 7.613252036134449e-05,
      "loss": 0.0037,
      "step": 5769
    },
    {
      "epoch": 58.58,
      "learning_rate": 7.612239734313114e-05,
      "loss": 0.0043,
      "step": 5770
    },
    {
      "epoch": 58.59,
      "learning_rate": 7.611227285195054e-05,
      "loss": 0.0211,
      "step": 5771
    },
    {
      "epoch": 58.6,
      "learning_rate": 7.610214688837361e-05,
      "loss": 0.0195,
      "step": 5772
    },
    {
      "epoch": 58.61,
      "learning_rate": 7.609201945297131e-05,
      "loss": 0.0003,
      "step": 5773
    },
    {
      "epoch": 58.62,
      "learning_rate": 7.608189054631469e-05,
      "loss": 0.0005,
      "step": 5774
    },
    {
      "epoch": 58.63,
      "learning_rate": 7.60717601689749e-05,
      "loss": 0.0013,
      "step": 5775
    },
    {
      "epoch": 58.64,
      "learning_rate": 7.606162832152318e-05,
      "loss": 0.0001,
      "step": 5776
    },
    {
      "epoch": 58.65,
      "learning_rate": 7.605149500453081e-05,
      "loss": 0.0012,
      "step": 5777
    },
    {
      "epoch": 58.66,
      "learning_rate": 7.604136021856917e-05,
      "loss": 0.014,
      "step": 5778
    },
    {
      "epoch": 58.67,
      "learning_rate": 7.603122396420976e-05,
      "loss": 0.0004,
      "step": 5779
    },
    {
      "epoch": 58.68,
      "learning_rate": 7.602108624202411e-05,
      "loss": 0.0448,
      "step": 5780
    },
    {
      "epoch": 58.69,
      "learning_rate": 7.60109470525839e-05,
      "loss": 0.0006,
      "step": 5781
    },
    {
      "epoch": 58.7,
      "learning_rate": 7.600080639646077e-05,
      "loss": 0.0003,
      "step": 5782
    },
    {
      "epoch": 58.71,
      "learning_rate": 7.59906642742266e-05,
      "loss": 0.0259,
      "step": 5783
    },
    {
      "epoch": 58.72,
      "learning_rate": 7.598052068645325e-05,
      "loss": 0.0064,
      "step": 5784
    },
    {
      "epoch": 58.73,
      "learning_rate": 7.597037563371269e-05,
      "loss": 0.0019,
      "step": 5785
    },
    {
      "epoch": 58.74,
      "learning_rate": 7.596022911657695e-05,
      "loss": 0.0,
      "step": 5786
    },
    {
      "epoch": 58.75,
      "learning_rate": 7.595008113561818e-05,
      "loss": 0.0003,
      "step": 5787
    },
    {
      "epoch": 58.76,
      "learning_rate": 7.59399316914086e-05,
      "loss": 0.0061,
      "step": 5788
    },
    {
      "epoch": 58.77,
      "learning_rate": 7.59297807845205e-05,
      "loss": 0.0004,
      "step": 5789
    },
    {
      "epoch": 58.78,
      "learning_rate": 7.591962841552627e-05,
      "loss": 0.0002,
      "step": 5790
    },
    {
      "epoch": 58.79,
      "learning_rate": 7.590947458499836e-05,
      "loss": 0.0006,
      "step": 5791
    },
    {
      "epoch": 58.8,
      "learning_rate": 7.58993192935093e-05,
      "loss": 0.0005,
      "step": 5792
    },
    {
      "epoch": 58.81,
      "learning_rate": 7.588916254163177e-05,
      "loss": 0.0131,
      "step": 5793
    },
    {
      "epoch": 58.82,
      "learning_rate": 7.587900432993844e-05,
      "loss": 0.0013,
      "step": 5794
    },
    {
      "epoch": 58.83,
      "learning_rate": 7.58688446590021e-05,
      "loss": 0.0002,
      "step": 5795
    },
    {
      "epoch": 58.84,
      "learning_rate": 7.585868352939563e-05,
      "loss": 0.0002,
      "step": 5796
    },
    {
      "epoch": 58.85,
      "learning_rate": 7.584852094169202e-05,
      "loss": 0.0056,
      "step": 5797
    },
    {
      "epoch": 58.86,
      "learning_rate": 7.583835689646427e-05,
      "loss": 0.0002,
      "step": 5798
    },
    {
      "epoch": 58.87,
      "learning_rate": 7.58281913942855e-05,
      "loss": 0.0046,
      "step": 5799
    },
    {
      "epoch": 58.88,
      "learning_rate": 7.581802443572894e-05,
      "loss": 0.0045,
      "step": 5800
    },
    {
      "epoch": 58.89,
      "learning_rate": 7.580785602136786e-05,
      "loss": 0.0014,
      "step": 5801
    },
    {
      "epoch": 58.9,
      "learning_rate": 7.579768615177565e-05,
      "loss": 0.001,
      "step": 5802
    },
    {
      "epoch": 58.91,
      "learning_rate": 7.578751482752571e-05,
      "loss": 0.0026,
      "step": 5803
    },
    {
      "epoch": 58.92,
      "learning_rate": 7.577734204919164e-05,
      "loss": 0.0014,
      "step": 5804
    },
    {
      "epoch": 58.93,
      "learning_rate": 7.576716781734698e-05,
      "loss": 0.009,
      "step": 5805
    },
    {
      "epoch": 58.94,
      "learning_rate": 7.575699213256549e-05,
      "loss": 0.0076,
      "step": 5806
    },
    {
      "epoch": 58.95,
      "learning_rate": 7.57468149954209e-05,
      "loss": 0.0096,
      "step": 5807
    },
    {
      "epoch": 58.96,
      "learning_rate": 7.57366364064871e-05,
      "loss": 0.0006,
      "step": 5808
    },
    {
      "epoch": 58.97,
      "learning_rate": 7.572645636633802e-05,
      "loss": 0.0154,
      "step": 5809
    },
    {
      "epoch": 58.98,
      "learning_rate": 7.571627487554769e-05,
      "loss": 0.0002,
      "step": 5810
    },
    {
      "epoch": 58.99,
      "learning_rate": 7.570609193469019e-05,
      "loss": 0.0015,
      "step": 5811
    },
    {
      "epoch": 58.99,
      "eval_loss": 0.018801668658852577,
      "eval_runtime": 32.7669,
      "eval_samples_per_second": 96.134,
      "eval_steps_per_second": 6.012,
      "eval_wer": 0.004353393085787452,
      "step": 5811
    },
    {
      "epoch": 59.01,
      "learning_rate": 7.569590754433975e-05,
      "loss": 0.0022,
      "step": 5812
    },
    {
      "epoch": 59.02,
      "learning_rate": 7.56857217050706e-05,
      "loss": 0.0005,
      "step": 5813
    },
    {
      "epoch": 59.03,
      "learning_rate": 7.567553441745712e-05,
      "loss": 0.0004,
      "step": 5814
    },
    {
      "epoch": 59.04,
      "learning_rate": 7.56653456820737e-05,
      "loss": 0.0025,
      "step": 5815
    },
    {
      "epoch": 59.05,
      "learning_rate": 7.56551554994949e-05,
      "loss": 0.0003,
      "step": 5816
    },
    {
      "epoch": 59.06,
      "learning_rate": 7.564496387029532e-05,
      "loss": 0.0042,
      "step": 5817
    },
    {
      "epoch": 59.07,
      "learning_rate": 7.563477079504959e-05,
      "loss": 0.0003,
      "step": 5818
    },
    {
      "epoch": 59.08,
      "learning_rate": 7.562457627433249e-05,
      "loss": 0.0006,
      "step": 5819
    },
    {
      "epoch": 59.09,
      "learning_rate": 7.561438030871885e-05,
      "loss": 0.0038,
      "step": 5820
    },
    {
      "epoch": 59.1,
      "learning_rate": 7.560418289878363e-05,
      "loss": 0.0163,
      "step": 5821
    },
    {
      "epoch": 59.11,
      "learning_rate": 7.559398404510178e-05,
      "loss": 0.0008,
      "step": 5822
    },
    {
      "epoch": 59.12,
      "learning_rate": 7.558378374824844e-05,
      "loss": 0.0038,
      "step": 5823
    },
    {
      "epoch": 59.13,
      "learning_rate": 7.55735820087987e-05,
      "loss": 0.0016,
      "step": 5824
    },
    {
      "epoch": 59.14,
      "learning_rate": 7.556337882732789e-05,
      "loss": 0.0005,
      "step": 5825
    },
    {
      "epoch": 59.15,
      "learning_rate": 7.555317420441129e-05,
      "loss": 0.0025,
      "step": 5826
    },
    {
      "epoch": 59.16,
      "learning_rate": 7.554296814062433e-05,
      "loss": 0.0001,
      "step": 5827
    },
    {
      "epoch": 59.17,
      "learning_rate": 7.553276063654246e-05,
      "loss": 0.0107,
      "step": 5828
    },
    {
      "epoch": 59.18,
      "learning_rate": 7.552255169274132e-05,
      "loss": 0.0194,
      "step": 5829
    },
    {
      "epoch": 59.19,
      "learning_rate": 7.55123413097965e-05,
      "loss": 0.0155,
      "step": 5830
    },
    {
      "epoch": 59.2,
      "learning_rate": 7.550212948828377e-05,
      "loss": 0.003,
      "step": 5831
    },
    {
      "epoch": 59.21,
      "learning_rate": 7.549191622877892e-05,
      "loss": 0.0151,
      "step": 5832
    },
    {
      "epoch": 59.22,
      "learning_rate": 7.548170153185789e-05,
      "loss": 0.0005,
      "step": 5833
    },
    {
      "epoch": 59.23,
      "learning_rate": 7.54714853980966e-05,
      "loss": 0.0005,
      "step": 5834
    },
    {
      "epoch": 59.24,
      "learning_rate": 7.546126782807116e-05,
      "loss": 0.0093,
      "step": 5835
    },
    {
      "epoch": 59.25,
      "learning_rate": 7.545104882235768e-05,
      "loss": 0.0099,
      "step": 5836
    },
    {
      "epoch": 59.26,
      "learning_rate": 7.544082838153239e-05,
      "loss": 0.0001,
      "step": 5837
    },
    {
      "epoch": 59.27,
      "learning_rate": 7.543060650617158e-05,
      "loss": 0.0071,
      "step": 5838
    },
    {
      "epoch": 59.28,
      "learning_rate": 7.542038319685166e-05,
      "loss": 0.0003,
      "step": 5839
    },
    {
      "epoch": 59.29,
      "learning_rate": 7.541015845414905e-05,
      "loss": 0.0003,
      "step": 5840
    },
    {
      "epoch": 59.3,
      "learning_rate": 7.539993227864033e-05,
      "loss": 0.0004,
      "step": 5841
    },
    {
      "epoch": 59.31,
      "learning_rate": 7.538970467090213e-05,
      "loss": 0.0007,
      "step": 5842
    },
    {
      "epoch": 59.32,
      "learning_rate": 7.537947563151112e-05,
      "loss": 0.0006,
      "step": 5843
    },
    {
      "epoch": 59.33,
      "learning_rate": 7.536924516104411e-05,
      "loss": 0.0029,
      "step": 5844
    },
    {
      "epoch": 59.34,
      "learning_rate": 7.535901326007795e-05,
      "loss": 0.0253,
      "step": 5845
    },
    {
      "epoch": 59.35,
      "learning_rate": 7.534877992918963e-05,
      "loss": 0.0009,
      "step": 5846
    },
    {
      "epoch": 59.36,
      "learning_rate": 7.533854516895614e-05,
      "loss": 0.0063,
      "step": 5847
    },
    {
      "epoch": 59.37,
      "learning_rate": 7.532830897995457e-05,
      "loss": 0.0036,
      "step": 5848
    },
    {
      "epoch": 59.38,
      "learning_rate": 7.531807136276216e-05,
      "loss": 0.0166,
      "step": 5849
    },
    {
      "epoch": 59.39,
      "learning_rate": 7.530783231795615e-05,
      "loss": 0.0048,
      "step": 5850
    },
    {
      "epoch": 59.4,
      "learning_rate": 7.52975918461139e-05,
      "loss": 0.0065,
      "step": 5851
    },
    {
      "epoch": 59.41,
      "learning_rate": 7.528734994781283e-05,
      "loss": 0.0005,
      "step": 5852
    },
    {
      "epoch": 59.42,
      "learning_rate": 7.527710662363046e-05,
      "loss": 0.0094,
      "step": 5853
    },
    {
      "epoch": 59.43,
      "learning_rate": 7.52668618741444e-05,
      "loss": 0.0002,
      "step": 5854
    },
    {
      "epoch": 59.44,
      "learning_rate": 7.525661569993228e-05,
      "loss": 0.0012,
      "step": 5855
    },
    {
      "epoch": 59.45,
      "learning_rate": 7.524636810157188e-05,
      "loss": 0.0009,
      "step": 5856
    },
    {
      "epoch": 59.46,
      "learning_rate": 7.523611907964103e-05,
      "loss": 0.0001,
      "step": 5857
    },
    {
      "epoch": 59.47,
      "learning_rate": 7.522586863471766e-05,
      "loss": 0.0004,
      "step": 5858
    },
    {
      "epoch": 59.48,
      "learning_rate": 7.521561676737971e-05,
      "loss": 0.0207,
      "step": 5859
    },
    {
      "epoch": 59.49,
      "learning_rate": 7.520536347820531e-05,
      "loss": 0.0127,
      "step": 5860
    },
    {
      "epoch": 59.5,
      "learning_rate": 7.519510876777258e-05,
      "loss": 0.0002,
      "step": 5861
    },
    {
      "epoch": 59.51,
      "learning_rate": 7.518485263665978e-05,
      "loss": 0.0012,
      "step": 5862
    },
    {
      "epoch": 59.52,
      "learning_rate": 7.51745950854452e-05,
      "loss": 0.0017,
      "step": 5863
    },
    {
      "epoch": 59.53,
      "learning_rate": 7.516433611470723e-05,
      "loss": 0.0031,
      "step": 5864
    },
    {
      "epoch": 59.54,
      "learning_rate": 7.515407572502437e-05,
      "loss": 0.0012,
      "step": 5865
    },
    {
      "epoch": 59.55,
      "learning_rate": 7.514381391697517e-05,
      "loss": 0.0001,
      "step": 5866
    },
    {
      "epoch": 59.56,
      "learning_rate": 7.513355069113825e-05,
      "loss": 0.0008,
      "step": 5867
    },
    {
      "epoch": 59.57,
      "learning_rate": 7.512328604809232e-05,
      "loss": 0.0004,
      "step": 5868
    },
    {
      "epoch": 59.58,
      "learning_rate": 7.511301998841619e-05,
      "loss": 0.0003,
      "step": 5869
    },
    {
      "epoch": 59.59,
      "learning_rate": 7.510275251268872e-05,
      "loss": 0.0015,
      "step": 5870
    },
    {
      "epoch": 59.6,
      "learning_rate": 7.509248362148889e-05,
      "loss": 0.0157,
      "step": 5871
    },
    {
      "epoch": 59.61,
      "learning_rate": 7.508221331539569e-05,
      "loss": 0.007,
      "step": 5872
    },
    {
      "epoch": 59.62,
      "learning_rate": 7.507194159498827e-05,
      "loss": 0.0166,
      "step": 5873
    },
    {
      "epoch": 59.63,
      "learning_rate": 7.506166846084579e-05,
      "loss": 0.0007,
      "step": 5874
    },
    {
      "epoch": 59.64,
      "learning_rate": 7.505139391354757e-05,
      "loss": 0.0015,
      "step": 5875
    },
    {
      "epoch": 59.65,
      "learning_rate": 7.504111795367293e-05,
      "loss": 0.0031,
      "step": 5876
    },
    {
      "epoch": 59.66,
      "learning_rate": 7.503084058180129e-05,
      "loss": 0.0087,
      "step": 5877
    },
    {
      "epoch": 59.68,
      "learning_rate": 7.502056179851218e-05,
      "loss": 0.0033,
      "step": 5878
    },
    {
      "epoch": 59.69,
      "learning_rate": 7.501028160438521e-05,
      "loss": 0.0001,
      "step": 5879
    },
    {
      "epoch": 59.7,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0003,
      "step": 5880
    },
    {
      "epoch": 59.71,
      "learning_rate": 7.498971698593636e-05,
      "loss": 0.0026,
      "step": 5881
    },
    {
      "epoch": 59.72,
      "learning_rate": 7.497943256277407e-05,
      "loss": 0.0113,
      "step": 5882
    },
    {
      "epoch": 59.73,
      "learning_rate": 7.496914673109305e-05,
      "loss": 0.0134,
      "step": 5883
    },
    {
      "epoch": 59.74,
      "learning_rate": 7.495885949147334e-05,
      "loss": 0.0018,
      "step": 5884
    },
    {
      "epoch": 59.75,
      "learning_rate": 7.494857084449491e-05,
      "loss": 0.0002,
      "step": 5885
    },
    {
      "epoch": 59.76,
      "learning_rate": 7.493828079073801e-05,
      "loss": 0.0003,
      "step": 5886
    },
    {
      "epoch": 59.77,
      "learning_rate": 7.492798933078279e-05,
      "loss": 0.0222,
      "step": 5887
    },
    {
      "epoch": 59.78,
      "learning_rate": 7.49176964652096e-05,
      "loss": 0.0022,
      "step": 5888
    },
    {
      "epoch": 59.79,
      "learning_rate": 7.490740219459881e-05,
      "loss": 0.0043,
      "step": 5889
    },
    {
      "epoch": 59.8,
      "learning_rate": 7.489710651953089e-05,
      "loss": 0.0014,
      "step": 5890
    },
    {
      "epoch": 59.81,
      "learning_rate": 7.488680944058636e-05,
      "loss": 0.0036,
      "step": 5891
    },
    {
      "epoch": 59.82,
      "learning_rate": 7.487651095834588e-05,
      "loss": 0.0048,
      "step": 5892
    },
    {
      "epoch": 59.83,
      "learning_rate": 7.486621107339014e-05,
      "loss": 0.0146,
      "step": 5893
    },
    {
      "epoch": 59.84,
      "learning_rate": 7.48559097862999e-05,
      "loss": 0.0045,
      "step": 5894
    },
    {
      "epoch": 59.85,
      "learning_rate": 7.484560709765605e-05,
      "loss": 0.0053,
      "step": 5895
    },
    {
      "epoch": 59.86,
      "learning_rate": 7.483530300803951e-05,
      "loss": 0.0004,
      "step": 5896
    },
    {
      "epoch": 59.87,
      "learning_rate": 7.48249975180313e-05,
      "loss": 0.0089,
      "step": 5897
    },
    {
      "epoch": 59.88,
      "learning_rate": 7.481469062821252e-05,
      "loss": 0.0031,
      "step": 5898
    },
    {
      "epoch": 59.89,
      "learning_rate": 7.480438233916433e-05,
      "loss": 0.0045,
      "step": 5899
    },
    {
      "epoch": 59.9,
      "learning_rate": 7.4794072651468e-05,
      "loss": 0.0031,
      "step": 5900
    },
    {
      "epoch": 59.91,
      "learning_rate": 7.478376156570489e-05,
      "loss": 0.0041,
      "step": 5901
    },
    {
      "epoch": 59.92,
      "learning_rate": 7.477344908245637e-05,
      "loss": 0.0022,
      "step": 5902
    },
    {
      "epoch": 59.93,
      "learning_rate": 7.476313520230396e-05,
      "loss": 0.0075,
      "step": 5903
    },
    {
      "epoch": 59.94,
      "learning_rate": 7.47528199258292e-05,
      "loss": 0.0002,
      "step": 5904
    },
    {
      "epoch": 59.95,
      "learning_rate": 7.474250325361377e-05,
      "loss": 0.0035,
      "step": 5905
    },
    {
      "epoch": 59.96,
      "learning_rate": 7.473218518623936e-05,
      "loss": 0.006,
      "step": 5906
    },
    {
      "epoch": 59.97,
      "learning_rate": 7.472186572428785e-05,
      "loss": 0.0024,
      "step": 5907
    },
    {
      "epoch": 59.98,
      "learning_rate": 7.471154486834105e-05,
      "loss": 0.0092,
      "step": 5908
    },
    {
      "epoch": 59.99,
      "learning_rate": 7.470122261898095e-05,
      "loss": 0.0026,
      "step": 5909
    },
    {
      "epoch": 60.0,
      "learning_rate": 7.469089897678958e-05,
      "loss": 0.0216,
      "step": 5910
    },
    {
      "epoch": 60.0,
      "eval_loss": 0.017538543790578842,
      "eval_runtime": 31.9884,
      "eval_samples_per_second": 98.473,
      "eval_steps_per_second": 6.158,
      "eval_wer": 0.003649167733674776,
      "step": 5910
    },
    {
      "epoch": 60.01,
      "learning_rate": 7.468057394234909e-05,
      "loss": 0.0017,
      "step": 5911
    },
    {
      "epoch": 60.02,
      "learning_rate": 7.467024751624165e-05,
      "loss": 0.0031,
      "step": 5912
    },
    {
      "epoch": 60.03,
      "learning_rate": 7.465991969904956e-05,
      "loss": 0.0009,
      "step": 5913
    },
    {
      "epoch": 60.04,
      "learning_rate": 7.464959049135516e-05,
      "loss": 0.0003,
      "step": 5914
    },
    {
      "epoch": 60.05,
      "learning_rate": 7.463925989374089e-05,
      "loss": 0.0021,
      "step": 5915
    },
    {
      "epoch": 60.06,
      "learning_rate": 7.462892790678927e-05,
      "loss": 0.0004,
      "step": 5916
    },
    {
      "epoch": 60.07,
      "learning_rate": 7.461859453108288e-05,
      "loss": 0.0006,
      "step": 5917
    },
    {
      "epoch": 60.08,
      "learning_rate": 7.460825976720437e-05,
      "loss": 0.0187,
      "step": 5918
    },
    {
      "epoch": 60.09,
      "learning_rate": 7.459792361573654e-05,
      "loss": 0.0098,
      "step": 5919
    },
    {
      "epoch": 60.1,
      "learning_rate": 7.458758607726217e-05,
      "loss": 0.0075,
      "step": 5920
    },
    {
      "epoch": 60.11,
      "learning_rate": 7.45772471523642e-05,
      "loss": 0.001,
      "step": 5921
    },
    {
      "epoch": 60.12,
      "learning_rate": 7.456690684162557e-05,
      "loss": 0.0024,
      "step": 5922
    },
    {
      "epoch": 60.13,
      "learning_rate": 7.455656514562939e-05,
      "loss": 0.0104,
      "step": 5923
    },
    {
      "epoch": 60.14,
      "learning_rate": 7.454622206495875e-05,
      "loss": 0.0005,
      "step": 5924
    },
    {
      "epoch": 60.15,
      "learning_rate": 7.45358776001969e-05,
      "loss": 0.0003,
      "step": 5925
    },
    {
      "epoch": 60.16,
      "learning_rate": 7.452553175192711e-05,
      "loss": 0.0012,
      "step": 5926
    },
    {
      "epoch": 60.17,
      "learning_rate": 7.451518452073279e-05,
      "loss": 0.0041,
      "step": 5927
    },
    {
      "epoch": 60.18,
      "learning_rate": 7.450483590719737e-05,
      "loss": 0.0183,
      "step": 5928
    },
    {
      "epoch": 60.19,
      "learning_rate": 7.449448591190435e-05,
      "loss": 0.0013,
      "step": 5929
    },
    {
      "epoch": 60.2,
      "learning_rate": 7.448413453543738e-05,
      "loss": 0.0002,
      "step": 5930
    },
    {
      "epoch": 60.21,
      "learning_rate": 7.447378177838013e-05,
      "loss": 0.0038,
      "step": 5931
    },
    {
      "epoch": 60.22,
      "learning_rate": 7.446342764131636e-05,
      "loss": 0.0006,
      "step": 5932
    },
    {
      "epoch": 60.23,
      "learning_rate": 7.44530721248299e-05,
      "loss": 0.008,
      "step": 5933
    },
    {
      "epoch": 60.24,
      "learning_rate": 7.44427152295047e-05,
      "loss": 0.0017,
      "step": 5934
    },
    {
      "epoch": 60.25,
      "learning_rate": 7.443235695592469e-05,
      "loss": 0.0001,
      "step": 5935
    },
    {
      "epoch": 60.26,
      "learning_rate": 7.442199730467402e-05,
      "loss": 0.0183,
      "step": 5936
    },
    {
      "epoch": 60.27,
      "learning_rate": 7.441163627633681e-05,
      "loss": 0.0037,
      "step": 5937
    },
    {
      "epoch": 60.28,
      "learning_rate": 7.440127387149729e-05,
      "loss": 0.0003,
      "step": 5938
    },
    {
      "epoch": 60.29,
      "learning_rate": 7.439091009073975e-05,
      "loss": 0.0023,
      "step": 5939
    },
    {
      "epoch": 60.3,
      "learning_rate": 7.438054493464858e-05,
      "loss": 0.0004,
      "step": 5940
    },
    {
      "epoch": 60.31,
      "learning_rate": 7.437017840380827e-05,
      "loss": 0.0015,
      "step": 5941
    },
    {
      "epoch": 60.32,
      "learning_rate": 7.435981049880332e-05,
      "loss": 0.0007,
      "step": 5942
    },
    {
      "epoch": 60.34,
      "learning_rate": 7.434944122021836e-05,
      "loss": 0.0159,
      "step": 5943
    },
    {
      "epoch": 60.35,
      "learning_rate": 7.43390705686381e-05,
      "loss": 0.0008,
      "step": 5944
    },
    {
      "epoch": 60.36,
      "learning_rate": 7.432869854464731e-05,
      "loss": 0.0005,
      "step": 5945
    },
    {
      "epoch": 60.37,
      "learning_rate": 7.431832514883081e-05,
      "loss": 0.0003,
      "step": 5946
    },
    {
      "epoch": 60.38,
      "learning_rate": 7.430795038177356e-05,
      "loss": 0.0015,
      "step": 5947
    },
    {
      "epoch": 60.39,
      "learning_rate": 7.429757424406053e-05,
      "loss": 0.0017,
      "step": 5948
    },
    {
      "epoch": 60.4,
      "learning_rate": 7.428719673627685e-05,
      "loss": 0.001,
      "step": 5949
    },
    {
      "epoch": 60.41,
      "learning_rate": 7.427681785900761e-05,
      "loss": 0.0011,
      "step": 5950
    },
    {
      "epoch": 60.42,
      "learning_rate": 7.42664376128381e-05,
      "loss": 0.0256,
      "step": 5951
    },
    {
      "epoch": 60.43,
      "learning_rate": 7.425605599835361e-05,
      "loss": 0.0197,
      "step": 5952
    },
    {
      "epoch": 60.44,
      "learning_rate": 7.424567301613954e-05,
      "loss": 0.0045,
      "step": 5953
    },
    {
      "epoch": 60.45,
      "learning_rate": 7.423528866678134e-05,
      "loss": 0.0199,
      "step": 5954
    },
    {
      "epoch": 60.46,
      "learning_rate": 7.422490295086458e-05,
      "loss": 0.0007,
      "step": 5955
    },
    {
      "epoch": 60.47,
      "learning_rate": 7.421451586897483e-05,
      "loss": 0.0006,
      "step": 5956
    },
    {
      "epoch": 60.48,
      "learning_rate": 7.420412742169786e-05,
      "loss": 0.0075,
      "step": 5957
    },
    {
      "epoch": 60.49,
      "learning_rate": 7.419373760961939e-05,
      "loss": 0.0035,
      "step": 5958
    },
    {
      "epoch": 60.5,
      "learning_rate": 7.41833464333253e-05,
      "loss": 0.0208,
      "step": 5959
    },
    {
      "epoch": 60.51,
      "learning_rate": 7.41729538934015e-05,
      "loss": 0.0007,
      "step": 5960
    },
    {
      "epoch": 60.52,
      "learning_rate": 7.416255999043401e-05,
      "loss": 0.0186,
      "step": 5961
    },
    {
      "epoch": 60.53,
      "learning_rate": 7.415216472500889e-05,
      "loss": 0.0086,
      "step": 5962
    },
    {
      "epoch": 60.54,
      "learning_rate": 7.414176809771233e-05,
      "loss": 0.0186,
      "step": 5963
    },
    {
      "epoch": 60.55,
      "learning_rate": 7.413137010913054e-05,
      "loss": 0.0045,
      "step": 5964
    },
    {
      "epoch": 60.56,
      "learning_rate": 7.412097075984985e-05,
      "loss": 0.0144,
      "step": 5965
    },
    {
      "epoch": 60.57,
      "learning_rate": 7.411057005045666e-05,
      "loss": 0.0542,
      "step": 5966
    },
    {
      "epoch": 60.58,
      "learning_rate": 7.410016798153741e-05,
      "loss": 0.0205,
      "step": 5967
    },
    {
      "epoch": 60.59,
      "learning_rate": 7.408976455367864e-05,
      "loss": 0.0004,
      "step": 5968
    },
    {
      "epoch": 60.6,
      "learning_rate": 7.407935976746698e-05,
      "loss": 0.0008,
      "step": 5969
    },
    {
      "epoch": 60.61,
      "learning_rate": 7.406895362348916e-05,
      "loss": 0.0102,
      "step": 5970
    },
    {
      "epoch": 60.62,
      "learning_rate": 7.40585461223319e-05,
      "loss": 0.0006,
      "step": 5971
    },
    {
      "epoch": 60.63,
      "learning_rate": 7.404813726458206e-05,
      "loss": 0.0227,
      "step": 5972
    },
    {
      "epoch": 60.64,
      "learning_rate": 7.403772705082659e-05,
      "loss": 0.0066,
      "step": 5973
    },
    {
      "epoch": 60.65,
      "learning_rate": 7.402731548165248e-05,
      "loss": 0.0005,
      "step": 5974
    },
    {
      "epoch": 60.66,
      "learning_rate": 7.401690255764679e-05,
      "loss": 0.015,
      "step": 5975
    },
    {
      "epoch": 60.67,
      "learning_rate": 7.400648827939672e-05,
      "loss": 0.0019,
      "step": 5976
    },
    {
      "epoch": 60.68,
      "learning_rate": 7.399607264748944e-05,
      "loss": 0.0068,
      "step": 5977
    },
    {
      "epoch": 60.69,
      "learning_rate": 7.398565566251232e-05,
      "loss": 0.001,
      "step": 5978
    },
    {
      "epoch": 60.7,
      "learning_rate": 7.39752373250527e-05,
      "loss": 0.0083,
      "step": 5979
    },
    {
      "epoch": 60.71,
      "learning_rate": 7.396481763569806e-05,
      "loss": 0.0078,
      "step": 5980
    },
    {
      "epoch": 60.72,
      "learning_rate": 7.395439659503592e-05,
      "loss": 0.0009,
      "step": 5981
    },
    {
      "epoch": 60.73,
      "learning_rate": 7.394397420365394e-05,
      "loss": 0.0008,
      "step": 5982
    },
    {
      "epoch": 60.74,
      "learning_rate": 7.393355046213974e-05,
      "loss": 0.0114,
      "step": 5983
    },
    {
      "epoch": 60.75,
      "learning_rate": 7.392312537108111e-05,
      "loss": 0.01,
      "step": 5984
    },
    {
      "epoch": 60.76,
      "learning_rate": 7.391269893106592e-05,
      "loss": 0.0041,
      "step": 5985
    },
    {
      "epoch": 60.77,
      "learning_rate": 7.390227114268206e-05,
      "loss": 0.0002,
      "step": 5986
    },
    {
      "epoch": 60.78,
      "learning_rate": 7.389184200651753e-05,
      "loss": 0.0081,
      "step": 5987
    },
    {
      "epoch": 60.79,
      "learning_rate": 7.388141152316038e-05,
      "loss": 0.0025,
      "step": 5988
    },
    {
      "epoch": 60.8,
      "learning_rate": 7.387097969319881e-05,
      "loss": 0.0084,
      "step": 5989
    },
    {
      "epoch": 60.81,
      "learning_rate": 7.386054651722098e-05,
      "loss": 0.0008,
      "step": 5990
    },
    {
      "epoch": 60.82,
      "learning_rate": 7.385011199581522e-05,
      "loss": 0.0168,
      "step": 5991
    },
    {
      "epoch": 60.83,
      "learning_rate": 7.383967612956988e-05,
      "loss": 0.0247,
      "step": 5992
    },
    {
      "epoch": 60.84,
      "learning_rate": 7.382923891907344e-05,
      "loss": 0.0045,
      "step": 5993
    },
    {
      "epoch": 60.85,
      "learning_rate": 7.38188003649144e-05,
      "loss": 0.0067,
      "step": 5994
    },
    {
      "epoch": 60.86,
      "learning_rate": 7.380836046768137e-05,
      "loss": 0.0027,
      "step": 5995
    },
    {
      "epoch": 60.87,
      "learning_rate": 7.379791922796302e-05,
      "loss": 0.0131,
      "step": 5996
    },
    {
      "epoch": 60.88,
      "learning_rate": 7.378747664634811e-05,
      "loss": 0.0051,
      "step": 5997
    },
    {
      "epoch": 60.89,
      "learning_rate": 7.377703272342546e-05,
      "loss": 0.0073,
      "step": 5998
    },
    {
      "epoch": 60.9,
      "learning_rate": 7.376658745978398e-05,
      "loss": 0.0069,
      "step": 5999
    },
    {
      "epoch": 60.91,
      "learning_rate": 7.375614085601265e-05,
      "loss": 0.0003,
      "step": 6000
    },
    {
      "epoch": 60.92,
      "learning_rate": 7.37456929127005e-05,
      "loss": 0.0015,
      "step": 6001
    },
    {
      "epoch": 60.93,
      "learning_rate": 7.373524363043669e-05,
      "loss": 0.003,
      "step": 6002
    },
    {
      "epoch": 60.94,
      "learning_rate": 7.37247930098104e-05,
      "loss": 0.0072,
      "step": 6003
    },
    {
      "epoch": 60.95,
      "learning_rate": 7.371434105141094e-05,
      "loss": 0.0023,
      "step": 6004
    },
    {
      "epoch": 60.96,
      "learning_rate": 7.370388775582764e-05,
      "loss": 0.0008,
      "step": 6005
    },
    {
      "epoch": 60.97,
      "learning_rate": 7.369343312364993e-05,
      "loss": 0.0008,
      "step": 6006
    },
    {
      "epoch": 60.98,
      "learning_rate": 7.368297715546734e-05,
      "loss": 0.0007,
      "step": 6007
    },
    {
      "epoch": 60.99,
      "learning_rate": 7.367251985186945e-05,
      "loss": 0.001,
      "step": 6008
    },
    {
      "epoch": 60.99,
      "eval_loss": 0.018080249428749084,
      "eval_runtime": 31.7512,
      "eval_samples_per_second": 99.209,
      "eval_steps_per_second": 6.204,
      "eval_wer": 0.0034571062740076826,
      "step": 6008
    },
    {
      "epoch": 61.01,
      "learning_rate": 7.366206121344589e-05,
      "loss": 0.007,
      "step": 6009
    },
    {
      "epoch": 61.02,
      "learning_rate": 7.365160124078642e-05,
      "loss": 0.0047,
      "step": 6010
    },
    {
      "epoch": 61.03,
      "learning_rate": 7.364113993448083e-05,
      "loss": 0.0039,
      "step": 6011
    },
    {
      "epoch": 61.04,
      "learning_rate": 7.363067729511902e-05,
      "loss": 0.0226,
      "step": 6012
    },
    {
      "epoch": 61.05,
      "learning_rate": 7.362021332329092e-05,
      "loss": 0.0356,
      "step": 6013
    },
    {
      "epoch": 61.06,
      "learning_rate": 7.360974801958661e-05,
      "loss": 0.0002,
      "step": 6014
    },
    {
      "epoch": 61.07,
      "learning_rate": 7.359928138459615e-05,
      "loss": 0.0063,
      "step": 6015
    },
    {
      "epoch": 61.08,
      "learning_rate": 7.358881341890976e-05,
      "loss": 0.0361,
      "step": 6016
    },
    {
      "epoch": 61.09,
      "learning_rate": 7.357834412311768e-05,
      "loss": 0.0009,
      "step": 6017
    },
    {
      "epoch": 61.1,
      "learning_rate": 7.356787349781024e-05,
      "loss": 0.0025,
      "step": 6018
    },
    {
      "epoch": 61.11,
      "learning_rate": 7.355740154357785e-05,
      "loss": 0.0028,
      "step": 6019
    },
    {
      "epoch": 61.12,
      "learning_rate": 7.354692826101102e-05,
      "loss": 0.0011,
      "step": 6020
    },
    {
      "epoch": 61.13,
      "learning_rate": 7.353645365070025e-05,
      "loss": 0.0004,
      "step": 6021
    },
    {
      "epoch": 61.14,
      "learning_rate": 7.352597771323626e-05,
      "loss": 0.0011,
      "step": 6022
    },
    {
      "epoch": 61.15,
      "learning_rate": 7.351550044920968e-05,
      "loss": 0.0006,
      "step": 6023
    },
    {
      "epoch": 61.16,
      "learning_rate": 7.350502185921132e-05,
      "loss": 0.0005,
      "step": 6024
    },
    {
      "epoch": 61.17,
      "learning_rate": 7.349454194383204e-05,
      "loss": 0.0006,
      "step": 6025
    },
    {
      "epoch": 61.18,
      "learning_rate": 7.348406070366279e-05,
      "loss": 0.0064,
      "step": 6026
    },
    {
      "epoch": 61.19,
      "learning_rate": 7.347357813929454e-05,
      "loss": 0.0011,
      "step": 6027
    },
    {
      "epoch": 61.2,
      "learning_rate": 7.34630942513184e-05,
      "loss": 0.0435,
      "step": 6028
    },
    {
      "epoch": 61.21,
      "learning_rate": 7.345260904032551e-05,
      "loss": 0.0201,
      "step": 6029
    },
    {
      "epoch": 61.22,
      "learning_rate": 7.344212250690712e-05,
      "loss": 0.002,
      "step": 6030
    },
    {
      "epoch": 61.23,
      "learning_rate": 7.343163465165452e-05,
      "loss": 0.0005,
      "step": 6031
    },
    {
      "epoch": 61.24,
      "learning_rate": 7.342114547515909e-05,
      "loss": 0.0003,
      "step": 6032
    },
    {
      "epoch": 61.25,
      "learning_rate": 7.34106549780123e-05,
      "loss": 0.0012,
      "step": 6033
    },
    {
      "epoch": 61.26,
      "learning_rate": 7.340016316080565e-05,
      "loss": 0.0029,
      "step": 6034
    },
    {
      "epoch": 61.27,
      "learning_rate": 7.338967002413078e-05,
      "loss": 0.0006,
      "step": 6035
    },
    {
      "epoch": 61.28,
      "learning_rate": 7.337917556857934e-05,
      "loss": 0.0181,
      "step": 6036
    },
    {
      "epoch": 61.29,
      "learning_rate": 7.33686797947431e-05,
      "loss": 0.0033,
      "step": 6037
    },
    {
      "epoch": 61.3,
      "learning_rate": 7.335818270321386e-05,
      "loss": 0.0009,
      "step": 6038
    },
    {
      "epoch": 61.31,
      "learning_rate": 7.334768429458355e-05,
      "loss": 0.0002,
      "step": 6039
    },
    {
      "epoch": 61.32,
      "learning_rate": 7.333718456944414e-05,
      "loss": 0.0007,
      "step": 6040
    },
    {
      "epoch": 61.33,
      "learning_rate": 7.332668352838767e-05,
      "loss": 0.0229,
      "step": 6041
    },
    {
      "epoch": 61.34,
      "learning_rate": 7.331618117200626e-05,
      "loss": 0.0063,
      "step": 6042
    },
    {
      "epoch": 61.35,
      "learning_rate": 7.330567750089213e-05,
      "loss": 0.0006,
      "step": 6043
    },
    {
      "epoch": 61.36,
      "learning_rate": 7.329517251563753e-05,
      "loss": 0.0003,
      "step": 6044
    },
    {
      "epoch": 61.37,
      "learning_rate": 7.32846662168348e-05,
      "loss": 0.0001,
      "step": 6045
    },
    {
      "epoch": 61.38,
      "learning_rate": 7.32741586050764e-05,
      "loss": 0.0008,
      "step": 6046
    },
    {
      "epoch": 61.39,
      "learning_rate": 7.326364968095477e-05,
      "loss": 0.0015,
      "step": 6047
    },
    {
      "epoch": 61.4,
      "learning_rate": 7.325313944506254e-05,
      "loss": 0.0105,
      "step": 6048
    },
    {
      "epoch": 61.41,
      "learning_rate": 7.324262789799228e-05,
      "loss": 0.0004,
      "step": 6049
    },
    {
      "epoch": 61.42,
      "learning_rate": 7.323211504033677e-05,
      "loss": 0.0054,
      "step": 6050
    },
    {
      "epoch": 61.43,
      "learning_rate": 7.322160087268877e-05,
      "loss": 0.0008,
      "step": 6051
    },
    {
      "epoch": 61.44,
      "learning_rate": 7.321108539564115e-05,
      "loss": 0.0084,
      "step": 6052
    },
    {
      "epoch": 61.45,
      "learning_rate": 7.320056860978684e-05,
      "loss": 0.0004,
      "step": 6053
    },
    {
      "epoch": 61.46,
      "learning_rate": 7.319005051571885e-05,
      "loss": 0.0371,
      "step": 6054
    },
    {
      "epoch": 61.47,
      "learning_rate": 7.317953111403029e-05,
      "loss": 0.0008,
      "step": 6055
    },
    {
      "epoch": 61.48,
      "learning_rate": 7.31690104053143e-05,
      "loss": 0.0008,
      "step": 6056
    },
    {
      "epoch": 61.49,
      "learning_rate": 7.31584883901641e-05,
      "loss": 0.008,
      "step": 6057
    },
    {
      "epoch": 61.5,
      "learning_rate": 7.314796506917301e-05,
      "loss": 0.0014,
      "step": 6058
    },
    {
      "epoch": 61.51,
      "learning_rate": 7.313744044293442e-05,
      "loss": 0.0001,
      "step": 6059
    },
    {
      "epoch": 61.52,
      "learning_rate": 7.312691451204178e-05,
      "loss": 0.0028,
      "step": 6060
    },
    {
      "epoch": 61.53,
      "learning_rate": 7.31163872770886e-05,
      "loss": 0.0024,
      "step": 6061
    },
    {
      "epoch": 61.54,
      "learning_rate": 7.310585873866848e-05,
      "loss": 0.0045,
      "step": 6062
    },
    {
      "epoch": 61.55,
      "learning_rate": 7.309532889737512e-05,
      "loss": 0.0002,
      "step": 6063
    },
    {
      "epoch": 61.56,
      "learning_rate": 7.308479775380226e-05,
      "loss": 0.0025,
      "step": 6064
    },
    {
      "epoch": 61.57,
      "learning_rate": 7.307426530854371e-05,
      "loss": 0.0015,
      "step": 6065
    },
    {
      "epoch": 61.58,
      "learning_rate": 7.306373156219337e-05,
      "loss": 0.0075,
      "step": 6066
    },
    {
      "epoch": 61.59,
      "learning_rate": 7.30531965153452e-05,
      "loss": 0.001,
      "step": 6067
    },
    {
      "epoch": 61.6,
      "learning_rate": 7.304266016859324e-05,
      "loss": 0.0013,
      "step": 6068
    },
    {
      "epoch": 61.61,
      "learning_rate": 7.303212252253162e-05,
      "loss": 0.0037,
      "step": 6069
    },
    {
      "epoch": 61.62,
      "learning_rate": 7.302158357775452e-05,
      "loss": 0.0028,
      "step": 6070
    },
    {
      "epoch": 61.63,
      "learning_rate": 7.30110433348562e-05,
      "loss": 0.0002,
      "step": 6071
    },
    {
      "epoch": 61.64,
      "learning_rate": 7.3000501794431e-05,
      "loss": 0.0002,
      "step": 6072
    },
    {
      "epoch": 61.65,
      "learning_rate": 7.298995895707332e-05,
      "loss": 0.0041,
      "step": 6073
    },
    {
      "epoch": 61.66,
      "learning_rate": 7.297941482337764e-05,
      "loss": 0.001,
      "step": 6074
    },
    {
      "epoch": 61.68,
      "learning_rate": 7.296886939393852e-05,
      "loss": 0.0005,
      "step": 6075
    },
    {
      "epoch": 61.69,
      "learning_rate": 7.295832266935059e-05,
      "loss": 0.0005,
      "step": 6076
    },
    {
      "epoch": 61.7,
      "learning_rate": 7.294777465020854e-05,
      "loss": 0.0234,
      "step": 6077
    },
    {
      "epoch": 61.71,
      "learning_rate": 7.293722533710714e-05,
      "loss": 0.0,
      "step": 6078
    },
    {
      "epoch": 61.72,
      "learning_rate": 7.292667473064123e-05,
      "loss": 0.0172,
      "step": 6079
    },
    {
      "epoch": 61.73,
      "learning_rate": 7.291612283140575e-05,
      "loss": 0.0035,
      "step": 6080
    },
    {
      "epoch": 61.74,
      "learning_rate": 7.290556963999569e-05,
      "loss": 0.0001,
      "step": 6081
    },
    {
      "epoch": 61.75,
      "learning_rate": 7.28950151570061e-05,
      "loss": 0.0002,
      "step": 6082
    },
    {
      "epoch": 61.76,
      "learning_rate": 7.28844593830321e-05,
      "loss": 0.0003,
      "step": 6083
    },
    {
      "epoch": 61.77,
      "learning_rate": 7.287390231866894e-05,
      "loss": 0.0004,
      "step": 6084
    },
    {
      "epoch": 61.78,
      "learning_rate": 7.286334396451189e-05,
      "loss": 0.0029,
      "step": 6085
    },
    {
      "epoch": 61.79,
      "learning_rate": 7.28527843211563e-05,
      "loss": 0.0144,
      "step": 6086
    },
    {
      "epoch": 61.8,
      "learning_rate": 7.284222338919758e-05,
      "loss": 0.0005,
      "step": 6087
    },
    {
      "epoch": 61.81,
      "learning_rate": 7.283166116923126e-05,
      "loss": 0.0009,
      "step": 6088
    },
    {
      "epoch": 61.82,
      "learning_rate": 7.28210976618529e-05,
      "loss": 0.0325,
      "step": 6089
    },
    {
      "epoch": 61.83,
      "learning_rate": 7.281053286765815e-05,
      "loss": 0.0036,
      "step": 6090
    },
    {
      "epoch": 61.84,
      "learning_rate": 7.279996678724273e-05,
      "loss": 0.0097,
      "step": 6091
    },
    {
      "epoch": 61.85,
      "learning_rate": 7.278939942120242e-05,
      "loss": 0.0019,
      "step": 6092
    },
    {
      "epoch": 61.86,
      "learning_rate": 7.27788307701331e-05,
      "loss": 0.0112,
      "step": 6093
    },
    {
      "epoch": 61.87,
      "learning_rate": 7.27682608346307e-05,
      "loss": 0.0091,
      "step": 6094
    },
    {
      "epoch": 61.88,
      "learning_rate": 7.27576896152912e-05,
      "loss": 0.0065,
      "step": 6095
    },
    {
      "epoch": 61.89,
      "learning_rate": 7.274711711271074e-05,
      "loss": 0.0005,
      "step": 6096
    },
    {
      "epoch": 61.9,
      "learning_rate": 7.273654332748541e-05,
      "loss": 0.005,
      "step": 6097
    },
    {
      "epoch": 61.91,
      "learning_rate": 7.272596826021149e-05,
      "loss": 0.0094,
      "step": 6098
    },
    {
      "epoch": 61.92,
      "learning_rate": 7.271539191148524e-05,
      "loss": 0.001,
      "step": 6099
    },
    {
      "epoch": 61.93,
      "learning_rate": 7.270481428190303e-05,
      "loss": 0.0004,
      "step": 6100
    },
    {
      "epoch": 61.94,
      "learning_rate": 7.269423537206134e-05,
      "loss": 0.0064,
      "step": 6101
    },
    {
      "epoch": 61.95,
      "learning_rate": 7.268365518255665e-05,
      "loss": 0.0127,
      "step": 6102
    },
    {
      "epoch": 61.96,
      "learning_rate": 7.267307371398555e-05,
      "loss": 0.0008,
      "step": 6103
    },
    {
      "epoch": 61.97,
      "learning_rate": 7.26624909669447e-05,
      "loss": 0.0169,
      "step": 6104
    },
    {
      "epoch": 61.98,
      "learning_rate": 7.265190694203085e-05,
      "loss": 0.0003,
      "step": 6105
    },
    {
      "epoch": 61.99,
      "learning_rate": 7.264132163984079e-05,
      "loss": 0.0031,
      "step": 6106
    },
    {
      "epoch": 62.0,
      "learning_rate": 7.263073506097139e-05,
      "loss": 0.0038,
      "step": 6107
    },
    {
      "epoch": 62.0,
      "eval_loss": 0.018031099811196327,
      "eval_runtime": 32.0501,
      "eval_samples_per_second": 98.284,
      "eval_steps_per_second": 6.147,
      "eval_wer": 0.0046094750320102434,
      "step": 6107
    },
    {
      "epoch": 62.01,
      "learning_rate": 7.26201472060196e-05,
      "loss": 0.0045,
      "step": 6108
    },
    {
      "epoch": 62.02,
      "learning_rate": 7.260955807558243e-05,
      "loss": 0.0045,
      "step": 6109
    },
    {
      "epoch": 62.03,
      "learning_rate": 7.259896767025698e-05,
      "loss": 0.0053,
      "step": 6110
    },
    {
      "epoch": 62.04,
      "learning_rate": 7.258837599064043e-05,
      "loss": 0.001,
      "step": 6111
    },
    {
      "epoch": 62.05,
      "learning_rate": 7.257778303732997e-05,
      "loss": 0.0002,
      "step": 6112
    },
    {
      "epoch": 62.06,
      "learning_rate": 7.256718881092295e-05,
      "loss": 0.0006,
      "step": 6113
    },
    {
      "epoch": 62.07,
      "learning_rate": 7.255659331201673e-05,
      "loss": 0.0125,
      "step": 6114
    },
    {
      "epoch": 62.08,
      "learning_rate": 7.254599654120877e-05,
      "loss": 0.0055,
      "step": 6115
    },
    {
      "epoch": 62.09,
      "learning_rate": 7.253539849909656e-05,
      "loss": 0.0039,
      "step": 6116
    },
    {
      "epoch": 62.1,
      "learning_rate": 7.252479918627774e-05,
      "loss": 0.0004,
      "step": 6117
    },
    {
      "epoch": 62.11,
      "learning_rate": 7.251419860334994e-05,
      "loss": 0.0004,
      "step": 6118
    },
    {
      "epoch": 62.12,
      "learning_rate": 7.250359675091091e-05,
      "loss": 0.0006,
      "step": 6119
    },
    {
      "epoch": 62.13,
      "learning_rate": 7.249299362955846e-05,
      "loss": 0.0037,
      "step": 6120
    },
    {
      "epoch": 62.14,
      "learning_rate": 7.248238923989046e-05,
      "loss": 0.0109,
      "step": 6121
    },
    {
      "epoch": 62.15,
      "learning_rate": 7.247178358250488e-05,
      "loss": 0.005,
      "step": 6122
    },
    {
      "epoch": 62.16,
      "learning_rate": 7.246117665799972e-05,
      "loss": 0.0072,
      "step": 6123
    },
    {
      "epoch": 62.17,
      "learning_rate": 7.245056846697305e-05,
      "loss": 0.0006,
      "step": 6124
    },
    {
      "epoch": 62.18,
      "learning_rate": 7.243995901002312e-05,
      "loss": 0.0006,
      "step": 6125
    },
    {
      "epoch": 62.19,
      "learning_rate": 7.242934828774808e-05,
      "loss": 0.0087,
      "step": 6126
    },
    {
      "epoch": 62.2,
      "learning_rate": 7.24187363007463e-05,
      "loss": 0.0034,
      "step": 6127
    },
    {
      "epoch": 62.21,
      "learning_rate": 7.240812304961611e-05,
      "loss": 0.0001,
      "step": 6128
    },
    {
      "epoch": 62.22,
      "learning_rate": 7.2397508534956e-05,
      "loss": 0.0026,
      "step": 6129
    },
    {
      "epoch": 62.23,
      "learning_rate": 7.238689275736449e-05,
      "loss": 0.0142,
      "step": 6130
    },
    {
      "epoch": 62.24,
      "learning_rate": 7.237627571744013e-05,
      "loss": 0.0018,
      "step": 6131
    },
    {
      "epoch": 62.25,
      "learning_rate": 7.236565741578163e-05,
      "loss": 0.0009,
      "step": 6132
    },
    {
      "epoch": 62.26,
      "learning_rate": 7.235503785298772e-05,
      "loss": 0.0012,
      "step": 6133
    },
    {
      "epoch": 62.27,
      "learning_rate": 7.234441702965718e-05,
      "loss": 0.0015,
      "step": 6134
    },
    {
      "epoch": 62.28,
      "learning_rate": 7.233379494638891e-05,
      "loss": 0.0041,
      "step": 6135
    },
    {
      "epoch": 62.29,
      "learning_rate": 7.232317160378186e-05,
      "loss": 0.0003,
      "step": 6136
    },
    {
      "epoch": 62.3,
      "learning_rate": 7.231254700243503e-05,
      "loss": 0.006,
      "step": 6137
    },
    {
      "epoch": 62.31,
      "learning_rate": 7.230192114294753e-05,
      "loss": 0.0023,
      "step": 6138
    },
    {
      "epoch": 62.32,
      "learning_rate": 7.229129402591852e-05,
      "loss": 0.0099,
      "step": 6139
    },
    {
      "epoch": 62.34,
      "learning_rate": 7.228066565194724e-05,
      "loss": 0.0129,
      "step": 6140
    },
    {
      "epoch": 62.35,
      "learning_rate": 7.227003602163295e-05,
      "loss": 0.0028,
      "step": 6141
    },
    {
      "epoch": 62.36,
      "learning_rate": 7.22594051355751e-05,
      "loss": 0.0004,
      "step": 6142
    },
    {
      "epoch": 62.37,
      "learning_rate": 7.224877299437306e-05,
      "loss": 0.0157,
      "step": 6143
    },
    {
      "epoch": 62.38,
      "learning_rate": 7.223813959862638e-05,
      "loss": 0.0009,
      "step": 6144
    },
    {
      "epoch": 62.39,
      "learning_rate": 7.222750494893466e-05,
      "loss": 0.0011,
      "step": 6145
    },
    {
      "epoch": 62.4,
      "learning_rate": 7.221686904589754e-05,
      "loss": 0.0016,
      "step": 6146
    },
    {
      "epoch": 62.41,
      "learning_rate": 7.220623189011474e-05,
      "loss": 0.0105,
      "step": 6147
    },
    {
      "epoch": 62.42,
      "learning_rate": 7.219559348218608e-05,
      "loss": 0.0003,
      "step": 6148
    },
    {
      "epoch": 62.43,
      "learning_rate": 7.21849538227114e-05,
      "loss": 0.0041,
      "step": 6149
    },
    {
      "epoch": 62.44,
      "learning_rate": 7.217431291229067e-05,
      "loss": 0.0002,
      "step": 6150
    },
    {
      "epoch": 62.45,
      "learning_rate": 7.216367075152391e-05,
      "loss": 0.0004,
      "step": 6151
    },
    {
      "epoch": 62.46,
      "learning_rate": 7.215302734101115e-05,
      "loss": 0.0001,
      "step": 6152
    },
    {
      "epoch": 62.47,
      "learning_rate": 7.214238268135258e-05,
      "loss": 0.0002,
      "step": 6153
    },
    {
      "epoch": 62.48,
      "learning_rate": 7.213173677314842e-05,
      "loss": 0.0172,
      "step": 6154
    },
    {
      "epoch": 62.49,
      "learning_rate": 7.212108961699894e-05,
      "loss": 0.0028,
      "step": 6155
    },
    {
      "epoch": 62.5,
      "learning_rate": 7.211044121350455e-05,
      "loss": 0.0003,
      "step": 6156
    },
    {
      "epoch": 62.51,
      "learning_rate": 7.209979156326563e-05,
      "loss": 0.0001,
      "step": 6157
    },
    {
      "epoch": 62.52,
      "learning_rate": 7.20891406668827e-05,
      "loss": 0.0003,
      "step": 6158
    },
    {
      "epoch": 62.53,
      "learning_rate": 7.207848852495635e-05,
      "loss": 0.0001,
      "step": 6159
    },
    {
      "epoch": 62.54,
      "learning_rate": 7.20678351380872e-05,
      "loss": 0.015,
      "step": 6160
    },
    {
      "epoch": 62.55,
      "learning_rate": 7.205718050687598e-05,
      "loss": 0.002,
      "step": 6161
    },
    {
      "epoch": 62.56,
      "learning_rate": 7.204652463192347e-05,
      "loss": 0.0002,
      "step": 6162
    },
    {
      "epoch": 62.57,
      "learning_rate": 7.203586751383054e-05,
      "loss": 0.0321,
      "step": 6163
    },
    {
      "epoch": 62.58,
      "learning_rate": 7.202520915319809e-05,
      "loss": 0.0038,
      "step": 6164
    },
    {
      "epoch": 62.59,
      "learning_rate": 7.201454955062712e-05,
      "loss": 0.0001,
      "step": 6165
    },
    {
      "epoch": 62.6,
      "learning_rate": 7.20038887067187e-05,
      "loss": 0.0144,
      "step": 6166
    },
    {
      "epoch": 62.61,
      "learning_rate": 7.199322662207396e-05,
      "loss": 0.0005,
      "step": 6167
    },
    {
      "epoch": 62.62,
      "learning_rate": 7.198256329729412e-05,
      "loss": 0.0007,
      "step": 6168
    },
    {
      "epoch": 62.63,
      "learning_rate": 7.197189873298042e-05,
      "loss": 0.0125,
      "step": 6169
    },
    {
      "epoch": 62.64,
      "learning_rate": 7.196123292973423e-05,
      "loss": 0.0009,
      "step": 6170
    },
    {
      "epoch": 62.65,
      "learning_rate": 7.195056588815696e-05,
      "loss": 0.0074,
      "step": 6171
    },
    {
      "epoch": 62.66,
      "learning_rate": 7.19398976088501e-05,
      "loss": 0.0011,
      "step": 6172
    },
    {
      "epoch": 62.67,
      "learning_rate": 7.192922809241519e-05,
      "loss": 0.0046,
      "step": 6173
    },
    {
      "epoch": 62.68,
      "learning_rate": 7.191855733945387e-05,
      "loss": 0.0017,
      "step": 6174
    },
    {
      "epoch": 62.69,
      "learning_rate": 7.190788535056783e-05,
      "loss": 0.0071,
      "step": 6175
    },
    {
      "epoch": 62.7,
      "learning_rate": 7.189721212635882e-05,
      "loss": 0.0055,
      "step": 6176
    },
    {
      "epoch": 62.71,
      "learning_rate": 7.188653766742868e-05,
      "loss": 0.0193,
      "step": 6177
    },
    {
      "epoch": 62.72,
      "learning_rate": 7.18758619743793e-05,
      "loss": 0.0281,
      "step": 6178
    },
    {
      "epoch": 62.73,
      "learning_rate": 7.186518504781266e-05,
      "loss": 0.0151,
      "step": 6179
    },
    {
      "epoch": 62.74,
      "learning_rate": 7.185450688833084e-05,
      "loss": 0.0009,
      "step": 6180
    },
    {
      "epoch": 62.75,
      "learning_rate": 7.184382749653589e-05,
      "loss": 0.0015,
      "step": 6181
    },
    {
      "epoch": 62.76,
      "learning_rate": 7.183314687303002e-05,
      "loss": 0.0007,
      "step": 6182
    },
    {
      "epoch": 62.77,
      "learning_rate": 7.182246501841546e-05,
      "loss": 0.0005,
      "step": 6183
    },
    {
      "epoch": 62.78,
      "learning_rate": 7.181178193329457e-05,
      "loss": 0.0005,
      "step": 6184
    },
    {
      "epoch": 62.79,
      "learning_rate": 7.18010976182697e-05,
      "loss": 0.016,
      "step": 6185
    },
    {
      "epoch": 62.8,
      "learning_rate": 7.179041207394333e-05,
      "loss": 0.0033,
      "step": 6186
    },
    {
      "epoch": 62.81,
      "learning_rate": 7.177972530091796e-05,
      "loss": 0.0012,
      "step": 6187
    },
    {
      "epoch": 62.82,
      "learning_rate": 7.176903729979621e-05,
      "loss": 0.0016,
      "step": 6188
    },
    {
      "epoch": 62.83,
      "learning_rate": 7.175834807118076e-05,
      "loss": 0.0189,
      "step": 6189
    },
    {
      "epoch": 62.84,
      "learning_rate": 7.174765761567432e-05,
      "loss": 0.0066,
      "step": 6190
    },
    {
      "epoch": 62.85,
      "learning_rate": 7.17369659338797e-05,
      "loss": 0.019,
      "step": 6191
    },
    {
      "epoch": 62.86,
      "learning_rate": 7.172627302639976e-05,
      "loss": 0.0096,
      "step": 6192
    },
    {
      "epoch": 62.87,
      "learning_rate": 7.171557889383748e-05,
      "loss": 0.0008,
      "step": 6193
    },
    {
      "epoch": 62.88,
      "learning_rate": 7.170488353679581e-05,
      "loss": 0.0009,
      "step": 6194
    },
    {
      "epoch": 62.89,
      "learning_rate": 7.169418695587791e-05,
      "loss": 0.0014,
      "step": 6195
    },
    {
      "epoch": 62.9,
      "learning_rate": 7.168348915168687e-05,
      "loss": 0.0016,
      "step": 6196
    },
    {
      "epoch": 62.91,
      "learning_rate": 7.167279012482593e-05,
      "loss": 0.0032,
      "step": 6197
    },
    {
      "epoch": 62.92,
      "learning_rate": 7.166208987589837e-05,
      "loss": 0.002,
      "step": 6198
    },
    {
      "epoch": 62.93,
      "learning_rate": 7.165138840550755e-05,
      "loss": 0.0014,
      "step": 6199
    },
    {
      "epoch": 62.94,
      "learning_rate": 7.16406857142569e-05,
      "loss": 0.0006,
      "step": 6200
    },
    {
      "epoch": 62.95,
      "learning_rate": 7.162998180274991e-05,
      "loss": 0.0197,
      "step": 6201
    },
    {
      "epoch": 62.96,
      "learning_rate": 7.161927667159013e-05,
      "loss": 0.001,
      "step": 6202
    },
    {
      "epoch": 62.97,
      "learning_rate": 7.160857032138122e-05,
      "loss": 0.0138,
      "step": 6203
    },
    {
      "epoch": 62.98,
      "learning_rate": 7.159786275272686e-05,
      "loss": 0.002,
      "step": 6204
    },
    {
      "epoch": 62.99,
      "learning_rate": 7.158715396623084e-05,
      "loss": 0.0036,
      "step": 6205
    },
    {
      "epoch": 62.99,
      "eval_loss": 0.017041582614183426,
      "eval_runtime": 32.8537,
      "eval_samples_per_second": 95.88,
      "eval_steps_per_second": 5.996,
      "eval_wer": 0.004161331626120359,
      "step": 6205
    },
    {
      "epoch": 63.01,
      "learning_rate": 7.157644396249694e-05,
      "loss": 0.0031,
      "step": 6206
    },
    {
      "epoch": 63.02,
      "learning_rate": 7.156573274212915e-05,
      "loss": 0.0001,
      "step": 6207
    },
    {
      "epoch": 63.03,
      "learning_rate": 7.155502030573138e-05,
      "loss": 0.0013,
      "step": 6208
    },
    {
      "epoch": 63.04,
      "learning_rate": 7.15443066539077e-05,
      "loss": 0.0101,
      "step": 6209
    },
    {
      "epoch": 63.05,
      "learning_rate": 7.153359178726223e-05,
      "loss": 0.001,
      "step": 6210
    },
    {
      "epoch": 63.06,
      "learning_rate": 7.152287570639913e-05,
      "loss": 0.0001,
      "step": 6211
    },
    {
      "epoch": 63.07,
      "learning_rate": 7.151215841192267e-05,
      "loss": 0.0014,
      "step": 6212
    },
    {
      "epoch": 63.08,
      "learning_rate": 7.150143990443714e-05,
      "loss": 0.0008,
      "step": 6213
    },
    {
      "epoch": 63.09,
      "learning_rate": 7.149072018454695e-05,
      "loss": 0.012,
      "step": 6214
    },
    {
      "epoch": 63.1,
      "learning_rate": 7.147999925285655e-05,
      "loss": 0.0119,
      "step": 6215
    },
    {
      "epoch": 63.11,
      "learning_rate": 7.146927710997047e-05,
      "loss": 0.0004,
      "step": 6216
    },
    {
      "epoch": 63.12,
      "learning_rate": 7.145855375649326e-05,
      "loss": 0.0004,
      "step": 6217
    },
    {
      "epoch": 63.13,
      "learning_rate": 7.144782919302964e-05,
      "loss": 0.0159,
      "step": 6218
    },
    {
      "epoch": 63.14,
      "learning_rate": 7.143710342018428e-05,
      "loss": 0.0005,
      "step": 6219
    },
    {
      "epoch": 63.15,
      "learning_rate": 7.142637643856202e-05,
      "loss": 0.0041,
      "step": 6220
    },
    {
      "epoch": 63.16,
      "learning_rate": 7.141564824876771e-05,
      "loss": 0.001,
      "step": 6221
    },
    {
      "epoch": 63.17,
      "learning_rate": 7.14049188514063e-05,
      "loss": 0.0008,
      "step": 6222
    },
    {
      "epoch": 63.18,
      "learning_rate": 7.139418824708272e-05,
      "loss": 0.0014,
      "step": 6223
    },
    {
      "epoch": 63.19,
      "learning_rate": 7.13834564364021e-05,
      "loss": 0.0072,
      "step": 6224
    },
    {
      "epoch": 63.2,
      "learning_rate": 7.137272341996958e-05,
      "loss": 0.0005,
      "step": 6225
    },
    {
      "epoch": 63.21,
      "learning_rate": 7.136198919839034e-05,
      "loss": 0.0231,
      "step": 6226
    },
    {
      "epoch": 63.22,
      "learning_rate": 7.135125377226965e-05,
      "loss": 0.0109,
      "step": 6227
    },
    {
      "epoch": 63.23,
      "learning_rate": 7.134051714221287e-05,
      "loss": 0.0062,
      "step": 6228
    },
    {
      "epoch": 63.24,
      "learning_rate": 7.132977930882539e-05,
      "loss": 0.0005,
      "step": 6229
    },
    {
      "epoch": 63.25,
      "learning_rate": 7.13190402727127e-05,
      "loss": 0.0002,
      "step": 6230
    },
    {
      "epoch": 63.26,
      "learning_rate": 7.130830003448032e-05,
      "loss": 0.0044,
      "step": 6231
    },
    {
      "epoch": 63.27,
      "learning_rate": 7.129755859473388e-05,
      "loss": 0.0012,
      "step": 6232
    },
    {
      "epoch": 63.28,
      "learning_rate": 7.128681595407908e-05,
      "loss": 0.0004,
      "step": 6233
    },
    {
      "epoch": 63.29,
      "learning_rate": 7.127607211312163e-05,
      "loss": 0.0038,
      "step": 6234
    },
    {
      "epoch": 63.3,
      "learning_rate": 7.126532707246735e-05,
      "loss": 0.0003,
      "step": 6235
    },
    {
      "epoch": 63.31,
      "learning_rate": 7.125458083272213e-05,
      "loss": 0.0011,
      "step": 6236
    },
    {
      "epoch": 63.32,
      "learning_rate": 7.124383339449194e-05,
      "loss": 0.0006,
      "step": 6237
    },
    {
      "epoch": 63.33,
      "learning_rate": 7.123308475838275e-05,
      "loss": 0.0123,
      "step": 6238
    },
    {
      "epoch": 63.34,
      "learning_rate": 7.122233492500067e-05,
      "loss": 0.0113,
      "step": 6239
    },
    {
      "epoch": 63.35,
      "learning_rate": 7.121158389495186e-05,
      "loss": 0.0009,
      "step": 6240
    },
    {
      "epoch": 63.36,
      "learning_rate": 7.120083166884255e-05,
      "loss": 0.0004,
      "step": 6241
    },
    {
      "epoch": 63.37,
      "learning_rate": 7.1190078247279e-05,
      "loss": 0.0033,
      "step": 6242
    },
    {
      "epoch": 63.38,
      "learning_rate": 7.117932363086757e-05,
      "loss": 0.0002,
      "step": 6243
    },
    {
      "epoch": 63.39,
      "learning_rate": 7.116856782021468e-05,
      "loss": 0.0004,
      "step": 6244
    },
    {
      "epoch": 63.4,
      "learning_rate": 7.115781081592685e-05,
      "loss": 0.0006,
      "step": 6245
    },
    {
      "epoch": 63.41,
      "learning_rate": 7.114705261861062e-05,
      "loss": 0.001,
      "step": 6246
    },
    {
      "epoch": 63.42,
      "learning_rate": 7.113629322887257e-05,
      "loss": 0.0297,
      "step": 6247
    },
    {
      "epoch": 63.43,
      "learning_rate": 7.112553264731945e-05,
      "loss": 0.0109,
      "step": 6248
    },
    {
      "epoch": 63.44,
      "learning_rate": 7.1114770874558e-05,
      "loss": 0.0001,
      "step": 6249
    },
    {
      "epoch": 63.45,
      "learning_rate": 7.110400791119503e-05,
      "loss": 0.0012,
      "step": 6250
    },
    {
      "epoch": 63.46,
      "learning_rate": 7.109324375783746e-05,
      "loss": 0.0016,
      "step": 6251
    },
    {
      "epoch": 63.47,
      "learning_rate": 7.108247841509222e-05,
      "loss": 0.0016,
      "step": 6252
    },
    {
      "epoch": 63.48,
      "learning_rate": 7.107171188356636e-05,
      "loss": 0.0002,
      "step": 6253
    },
    {
      "epoch": 63.49,
      "learning_rate": 7.106094416386698e-05,
      "loss": 0.0014,
      "step": 6254
    },
    {
      "epoch": 63.5,
      "learning_rate": 7.10501752566012e-05,
      "loss": 0.0037,
      "step": 6255
    },
    {
      "epoch": 63.51,
      "learning_rate": 7.103940516237629e-05,
      "loss": 0.0261,
      "step": 6256
    },
    {
      "epoch": 63.52,
      "learning_rate": 7.102863388179952e-05,
      "loss": 0.0004,
      "step": 6257
    },
    {
      "epoch": 63.53,
      "learning_rate": 7.101786141547828e-05,
      "loss": 0.0061,
      "step": 6258
    },
    {
      "epoch": 63.54,
      "learning_rate": 7.100708776401996e-05,
      "loss": 0.0116,
      "step": 6259
    },
    {
      "epoch": 63.55,
      "learning_rate": 7.099631292803209e-05,
      "loss": 0.0003,
      "step": 6260
    },
    {
      "epoch": 63.56,
      "learning_rate": 7.098553690812221e-05,
      "loss": 0.0042,
      "step": 6261
    },
    {
      "epoch": 63.57,
      "learning_rate": 7.097475970489796e-05,
      "loss": 0.0011,
      "step": 6262
    },
    {
      "epoch": 63.58,
      "learning_rate": 7.096398131896704e-05,
      "loss": 0.0001,
      "step": 6263
    },
    {
      "epoch": 63.59,
      "learning_rate": 7.095320175093719e-05,
      "loss": 0.0003,
      "step": 6264
    },
    {
      "epoch": 63.6,
      "learning_rate": 7.094242100141625e-05,
      "loss": 0.0005,
      "step": 6265
    },
    {
      "epoch": 63.61,
      "learning_rate": 7.093163907101212e-05,
      "loss": 0.004,
      "step": 6266
    },
    {
      "epoch": 63.62,
      "learning_rate": 7.092085596033278e-05,
      "loss": 0.0002,
      "step": 6267
    },
    {
      "epoch": 63.63,
      "learning_rate": 7.091007166998623e-05,
      "loss": 0.0162,
      "step": 6268
    },
    {
      "epoch": 63.64,
      "learning_rate": 7.089928620058056e-05,
      "loss": 0.0001,
      "step": 6269
    },
    {
      "epoch": 63.65,
      "learning_rate": 7.088849955272396e-05,
      "loss": 0.0043,
      "step": 6270
    },
    {
      "epoch": 63.66,
      "learning_rate": 7.087771172702464e-05,
      "loss": 0.0004,
      "step": 6271
    },
    {
      "epoch": 63.68,
      "learning_rate": 7.08669227240909e-05,
      "loss": 0.0004,
      "step": 6272
    },
    {
      "epoch": 63.69,
      "learning_rate": 7.08561325445311e-05,
      "loss": 0.0005,
      "step": 6273
    },
    {
      "epoch": 63.7,
      "learning_rate": 7.084534118895367e-05,
      "loss": 0.0115,
      "step": 6274
    },
    {
      "epoch": 63.71,
      "learning_rate": 7.083454865796711e-05,
      "loss": 0.005,
      "step": 6275
    },
    {
      "epoch": 63.72,
      "learning_rate": 7.082375495217995e-05,
      "loss": 0.0002,
      "step": 6276
    },
    {
      "epoch": 63.73,
      "learning_rate": 7.081296007220086e-05,
      "loss": 0.0008,
      "step": 6277
    },
    {
      "epoch": 63.74,
      "learning_rate": 7.08021640186385e-05,
      "loss": 0.0007,
      "step": 6278
    },
    {
      "epoch": 63.75,
      "learning_rate": 7.079136679210165e-05,
      "loss": 0.0005,
      "step": 6279
    },
    {
      "epoch": 63.76,
      "learning_rate": 7.078056839319911e-05,
      "loss": 0.0011,
      "step": 6280
    },
    {
      "epoch": 63.77,
      "learning_rate": 7.076976882253978e-05,
      "loss": 0.0005,
      "step": 6281
    },
    {
      "epoch": 63.78,
      "learning_rate": 7.075896808073263e-05,
      "loss": 0.0015,
      "step": 6282
    },
    {
      "epoch": 63.79,
      "learning_rate": 7.074816616838669e-05,
      "loss": 0.0046,
      "step": 6283
    },
    {
      "epoch": 63.8,
      "learning_rate": 7.0737363086111e-05,
      "loss": 0.0126,
      "step": 6284
    },
    {
      "epoch": 63.81,
      "learning_rate": 7.072655883451478e-05,
      "loss": 0.0034,
      "step": 6285
    },
    {
      "epoch": 63.82,
      "learning_rate": 7.071575341420719e-05,
      "loss": 0.0063,
      "step": 6286
    },
    {
      "epoch": 63.83,
      "learning_rate": 7.070494682579757e-05,
      "loss": 0.0002,
      "step": 6287
    },
    {
      "epoch": 63.84,
      "learning_rate": 7.069413906989523e-05,
      "loss": 0.001,
      "step": 6288
    },
    {
      "epoch": 63.85,
      "learning_rate": 7.068333014710962e-05,
      "loss": 0.0004,
      "step": 6289
    },
    {
      "epoch": 63.86,
      "learning_rate": 7.067252005805019e-05,
      "loss": 0.0083,
      "step": 6290
    },
    {
      "epoch": 63.87,
      "learning_rate": 7.066170880332653e-05,
      "loss": 0.0002,
      "step": 6291
    },
    {
      "epoch": 63.88,
      "learning_rate": 7.065089638354824e-05,
      "loss": 0.0001,
      "step": 6292
    },
    {
      "epoch": 63.89,
      "learning_rate": 7.064008279932499e-05,
      "loss": 0.0005,
      "step": 6293
    },
    {
      "epoch": 63.9,
      "learning_rate": 7.062926805126653e-05,
      "loss": 0.0015,
      "step": 6294
    },
    {
      "epoch": 63.91,
      "learning_rate": 7.061845213998269e-05,
      "loss": 0.0009,
      "step": 6295
    },
    {
      "epoch": 63.92,
      "learning_rate": 7.060763506608332e-05,
      "loss": 0.0045,
      "step": 6296
    },
    {
      "epoch": 63.93,
      "learning_rate": 7.059681683017838e-05,
      "loss": 0.0006,
      "step": 6297
    },
    {
      "epoch": 63.94,
      "learning_rate": 7.05859974328779e-05,
      "loss": 0.004,
      "step": 6298
    },
    {
      "epoch": 63.95,
      "learning_rate": 7.05751768747919e-05,
      "loss": 0.0133,
      "step": 6299
    },
    {
      "epoch": 63.96,
      "learning_rate": 7.056435515653059e-05,
      "loss": 0.0038,
      "step": 6300
    },
    {
      "epoch": 63.97,
      "learning_rate": 7.055353227870412e-05,
      "loss": 0.0004,
      "step": 6301
    },
    {
      "epoch": 63.98,
      "learning_rate": 7.054270824192278e-05,
      "loss": 0.0001,
      "step": 6302
    },
    {
      "epoch": 63.99,
      "learning_rate": 7.05318830467969e-05,
      "loss": 0.0033,
      "step": 6303
    },
    {
      "epoch": 64.0,
      "learning_rate": 7.052105669393691e-05,
      "loss": 0.0013,
      "step": 6304
    },
    {
      "epoch": 64.0,
      "eval_loss": 0.01960149221122265,
      "eval_runtime": 31.9082,
      "eval_samples_per_second": 98.721,
      "eval_steps_per_second": 6.174,
      "eval_wer": 0.0038732394366197184,
      "step": 6304
    },
    {
      "epoch": 64.01,
      "learning_rate": 7.051022918395324e-05,
      "loss": 0.0053,
      "step": 6305
    },
    {
      "epoch": 64.02,
      "learning_rate": 7.049940051745646e-05,
      "loss": 0.0003,
      "step": 6306
    },
    {
      "epoch": 64.03,
      "learning_rate": 7.048857069505714e-05,
      "loss": 0.0004,
      "step": 6307
    },
    {
      "epoch": 64.04,
      "learning_rate": 7.047773971736594e-05,
      "loss": 0.0005,
      "step": 6308
    },
    {
      "epoch": 64.05,
      "learning_rate": 7.04669075849936e-05,
      "loss": 0.0029,
      "step": 6309
    },
    {
      "epoch": 64.06,
      "learning_rate": 7.04560742985509e-05,
      "loss": 0.0039,
      "step": 6310
    },
    {
      "epoch": 64.07,
      "learning_rate": 7.044523985864871e-05,
      "loss": 0.006,
      "step": 6311
    },
    {
      "epoch": 64.08,
      "learning_rate": 7.043440426589796e-05,
      "loss": 0.0008,
      "step": 6312
    },
    {
      "epoch": 64.09,
      "learning_rate": 7.042356752090962e-05,
      "loss": 0.0007,
      "step": 6313
    },
    {
      "epoch": 64.1,
      "learning_rate": 7.041272962429477e-05,
      "loss": 0.0002,
      "step": 6314
    },
    {
      "epoch": 64.11,
      "learning_rate": 7.040189057666449e-05,
      "loss": 0.0004,
      "step": 6315
    },
    {
      "epoch": 64.12,
      "learning_rate": 7.039105037862999e-05,
      "loss": 0.0004,
      "step": 6316
    },
    {
      "epoch": 64.13,
      "learning_rate": 7.038020903080251e-05,
      "loss": 0.0011,
      "step": 6317
    },
    {
      "epoch": 64.14,
      "learning_rate": 7.036936653379335e-05,
      "loss": 0.0011,
      "step": 6318
    },
    {
      "epoch": 64.15,
      "learning_rate": 7.035852288821393e-05,
      "loss": 0.0003,
      "step": 6319
    },
    {
      "epoch": 64.16,
      "learning_rate": 7.034767809467563e-05,
      "loss": 0.0222,
      "step": 6320
    },
    {
      "epoch": 64.17,
      "learning_rate": 7.033683215379002e-05,
      "loss": 0.0012,
      "step": 6321
    },
    {
      "epoch": 64.18,
      "learning_rate": 7.032598506616861e-05,
      "loss": 0.0006,
      "step": 6322
    },
    {
      "epoch": 64.19,
      "learning_rate": 7.03151368324231e-05,
      "loss": 0.0013,
      "step": 6323
    },
    {
      "epoch": 64.2,
      "learning_rate": 7.030428745316514e-05,
      "loss": 0.0079,
      "step": 6324
    },
    {
      "epoch": 64.21,
      "learning_rate": 7.029343692900651e-05,
      "loss": 0.0003,
      "step": 6325
    },
    {
      "epoch": 64.22,
      "learning_rate": 7.028258526055904e-05,
      "loss": 0.0004,
      "step": 6326
    },
    {
      "epoch": 64.23,
      "learning_rate": 7.027173244843465e-05,
      "loss": 0.0002,
      "step": 6327
    },
    {
      "epoch": 64.24,
      "learning_rate": 7.026087849324527e-05,
      "loss": 0.0005,
      "step": 6328
    },
    {
      "epoch": 64.25,
      "learning_rate": 7.025002339560292e-05,
      "loss": 0.001,
      "step": 6329
    },
    {
      "epoch": 64.26,
      "learning_rate": 7.023916715611969e-05,
      "loss": 0.0017,
      "step": 6330
    },
    {
      "epoch": 64.27,
      "learning_rate": 7.022830977540776e-05,
      "loss": 0.0003,
      "step": 6331
    },
    {
      "epoch": 64.28,
      "learning_rate": 7.021745125407932e-05,
      "loss": 0.0002,
      "step": 6332
    },
    {
      "epoch": 64.29,
      "learning_rate": 7.020659159274664e-05,
      "loss": 0.0081,
      "step": 6333
    },
    {
      "epoch": 64.3,
      "learning_rate": 7.019573079202211e-05,
      "loss": 0.0023,
      "step": 6334
    },
    {
      "epoch": 64.31,
      "learning_rate": 7.018486885251812e-05,
      "loss": 0.0078,
      "step": 6335
    },
    {
      "epoch": 64.32,
      "learning_rate": 7.017400577484712e-05,
      "loss": 0.0012,
      "step": 6336
    },
    {
      "epoch": 64.34,
      "learning_rate": 7.016314155962168e-05,
      "loss": 0.0022,
      "step": 6337
    },
    {
      "epoch": 64.35,
      "learning_rate": 7.015227620745436e-05,
      "loss": 0.0005,
      "step": 6338
    },
    {
      "epoch": 64.36,
      "learning_rate": 7.014140971895786e-05,
      "loss": 0.0074,
      "step": 6339
    },
    {
      "epoch": 64.37,
      "learning_rate": 7.013054209474491e-05,
      "loss": 0.0002,
      "step": 6340
    },
    {
      "epoch": 64.38,
      "learning_rate": 7.01196733354283e-05,
      "loss": 0.0007,
      "step": 6341
    },
    {
      "epoch": 64.39,
      "learning_rate": 7.010880344162088e-05,
      "loss": 0.0001,
      "step": 6342
    },
    {
      "epoch": 64.4,
      "learning_rate": 7.009793241393557e-05,
      "loss": 0.0003,
      "step": 6343
    },
    {
      "epoch": 64.41,
      "learning_rate": 7.008706025298538e-05,
      "loss": 0.0001,
      "step": 6344
    },
    {
      "epoch": 64.42,
      "learning_rate": 7.007618695938334e-05,
      "loss": 0.0006,
      "step": 6345
    },
    {
      "epoch": 64.43,
      "learning_rate": 7.006531253374255e-05,
      "loss": 0.0062,
      "step": 6346
    },
    {
      "epoch": 64.44,
      "learning_rate": 7.005443697667622e-05,
      "loss": 0.0015,
      "step": 6347
    },
    {
      "epoch": 64.45,
      "learning_rate": 7.00435602887976e-05,
      "loss": 0.0004,
      "step": 6348
    },
    {
      "epoch": 64.46,
      "learning_rate": 7.003268247071993e-05,
      "loss": 0.0072,
      "step": 6349
    },
    {
      "epoch": 64.47,
      "learning_rate": 7.002180352305664e-05,
      "loss": 0.0127,
      "step": 6350
    },
    {
      "epoch": 64.48,
      "learning_rate": 7.001092344642114e-05,
      "loss": 0.0041,
      "step": 6351
    },
    {
      "epoch": 64.49,
      "learning_rate": 7.000004224142694e-05,
      "loss": 0.0356,
      "step": 6352
    },
    {
      "epoch": 64.5,
      "learning_rate": 6.998915990868758e-05,
      "loss": 0.0027,
      "step": 6353
    },
    {
      "epoch": 64.51,
      "learning_rate": 6.99782764488167e-05,
      "loss": 0.0004,
      "step": 6354
    },
    {
      "epoch": 64.52,
      "learning_rate": 6.996739186242798e-05,
      "loss": 0.0001,
      "step": 6355
    },
    {
      "epoch": 64.53,
      "learning_rate": 6.995650615013516e-05,
      "loss": 0.0022,
      "step": 6356
    },
    {
      "epoch": 64.54,
      "learning_rate": 6.99456193125521e-05,
      "loss": 0.0019,
      "step": 6357
    },
    {
      "epoch": 64.55,
      "learning_rate": 6.993473135029261e-05,
      "loss": 0.0152,
      "step": 6358
    },
    {
      "epoch": 64.56,
      "learning_rate": 6.992384226397067e-05,
      "loss": 0.0088,
      "step": 6359
    },
    {
      "epoch": 64.57,
      "learning_rate": 6.991295205420028e-05,
      "loss": 0.0002,
      "step": 6360
    },
    {
      "epoch": 64.58,
      "learning_rate": 6.990206072159551e-05,
      "loss": 0.0031,
      "step": 6361
    },
    {
      "epoch": 64.59,
      "learning_rate": 6.98911682667705e-05,
      "loss": 0.0031,
      "step": 6362
    },
    {
      "epoch": 64.6,
      "learning_rate": 6.988027469033942e-05,
      "loss": 0.0005,
      "step": 6363
    },
    {
      "epoch": 64.61,
      "learning_rate": 6.986937999291655e-05,
      "loss": 0.0006,
      "step": 6364
    },
    {
      "epoch": 64.62,
      "learning_rate": 6.985848417511617e-05,
      "loss": 0.0008,
      "step": 6365
    },
    {
      "epoch": 64.63,
      "learning_rate": 6.984758723755273e-05,
      "loss": 0.0166,
      "step": 6366
    },
    {
      "epoch": 64.64,
      "learning_rate": 6.983668918084062e-05,
      "loss": 0.0038,
      "step": 6367
    },
    {
      "epoch": 64.65,
      "learning_rate": 6.982579000559438e-05,
      "loss": 0.0041,
      "step": 6368
    },
    {
      "epoch": 64.66,
      "learning_rate": 6.981488971242859e-05,
      "loss": 0.0002,
      "step": 6369
    },
    {
      "epoch": 64.67,
      "learning_rate": 6.980398830195785e-05,
      "loss": 0.0004,
      "step": 6370
    },
    {
      "epoch": 64.68,
      "learning_rate": 6.979308577479688e-05,
      "loss": 0.0006,
      "step": 6371
    },
    {
      "epoch": 64.69,
      "learning_rate": 6.978218213156045e-05,
      "loss": 0.0003,
      "step": 6372
    },
    {
      "epoch": 64.7,
      "learning_rate": 6.97712773728634e-05,
      "loss": 0.0018,
      "step": 6373
    },
    {
      "epoch": 64.71,
      "learning_rate": 6.976037149932056e-05,
      "loss": 0.0029,
      "step": 6374
    },
    {
      "epoch": 64.72,
      "learning_rate": 6.974946451154693e-05,
      "loss": 0.0023,
      "step": 6375
    },
    {
      "epoch": 64.73,
      "learning_rate": 6.973855641015752e-05,
      "loss": 0.0056,
      "step": 6376
    },
    {
      "epoch": 64.74,
      "learning_rate": 6.972764719576739e-05,
      "loss": 0.0033,
      "step": 6377
    },
    {
      "epoch": 64.75,
      "learning_rate": 6.97167368689917e-05,
      "loss": 0.001,
      "step": 6378
    },
    {
      "epoch": 64.76,
      "learning_rate": 6.970582543044562e-05,
      "loss": 0.0016,
      "step": 6379
    },
    {
      "epoch": 64.77,
      "learning_rate": 6.969491288074445e-05,
      "loss": 0.0046,
      "step": 6380
    },
    {
      "epoch": 64.78,
      "learning_rate": 6.968399922050349e-05,
      "loss": 0.0049,
      "step": 6381
    },
    {
      "epoch": 64.79,
      "learning_rate": 6.967308445033817e-05,
      "loss": 0.0037,
      "step": 6382
    },
    {
      "epoch": 64.8,
      "learning_rate": 6.966216857086388e-05,
      "loss": 0.0008,
      "step": 6383
    },
    {
      "epoch": 64.81,
      "learning_rate": 6.965125158269619e-05,
      "loss": 0.0013,
      "step": 6384
    },
    {
      "epoch": 64.82,
      "learning_rate": 6.964033348645064e-05,
      "loss": 0.002,
      "step": 6385
    },
    {
      "epoch": 64.83,
      "learning_rate": 6.962941428274291e-05,
      "loss": 0.0105,
      "step": 6386
    },
    {
      "epoch": 64.84,
      "learning_rate": 6.961849397218866e-05,
      "loss": 0.0004,
      "step": 6387
    },
    {
      "epoch": 64.85,
      "learning_rate": 6.960757255540368e-05,
      "loss": 0.0018,
      "step": 6388
    },
    {
      "epoch": 64.86,
      "learning_rate": 6.959665003300381e-05,
      "loss": 0.001,
      "step": 6389
    },
    {
      "epoch": 64.87,
      "learning_rate": 6.958572640560492e-05,
      "loss": 0.0002,
      "step": 6390
    },
    {
      "epoch": 64.88,
      "learning_rate": 6.957480167382294e-05,
      "loss": 0.0019,
      "step": 6391
    },
    {
      "epoch": 64.89,
      "learning_rate": 6.956387583827393e-05,
      "loss": 0.005,
      "step": 6392
    },
    {
      "epoch": 64.9,
      "learning_rate": 6.955294889957393e-05,
      "loss": 0.0137,
      "step": 6393
    },
    {
      "epoch": 64.91,
      "learning_rate": 6.954202085833911e-05,
      "loss": 0.0003,
      "step": 6394
    },
    {
      "epoch": 64.92,
      "learning_rate": 6.953109171518565e-05,
      "loss": 0.0081,
      "step": 6395
    },
    {
      "epoch": 64.93,
      "learning_rate": 6.952016147072981e-05,
      "loss": 0.0107,
      "step": 6396
    },
    {
      "epoch": 64.94,
      "learning_rate": 6.950923012558794e-05,
      "loss": 0.0004,
      "step": 6397
    },
    {
      "epoch": 64.95,
      "learning_rate": 6.94982976803764e-05,
      "loss": 0.0043,
      "step": 6398
    },
    {
      "epoch": 64.96,
      "learning_rate": 6.948736413571166e-05,
      "loss": 0.0188,
      "step": 6399
    },
    {
      "epoch": 64.97,
      "learning_rate": 6.94764294922102e-05,
      "loss": 0.0008,
      "step": 6400
    },
    {
      "epoch": 64.98,
      "learning_rate": 6.946549375048864e-05,
      "loss": 0.0005,
      "step": 6401
    },
    {
      "epoch": 64.99,
      "learning_rate": 6.945455691116358e-05,
      "loss": 0.0053,
      "step": 6402
    },
    {
      "epoch": 64.99,
      "eval_loss": 0.0203822273761034,
      "eval_runtime": 31.9526,
      "eval_samples_per_second": 98.584,
      "eval_steps_per_second": 6.165,
      "eval_wer": 0.004449423815620999,
      "step": 6402
    },
    {
      "epoch": 65.01,
      "learning_rate": 6.944361897485173e-05,
      "loss": 0.0132,
      "step": 6403
    },
    {
      "epoch": 65.02,
      "learning_rate": 6.943267994216984e-05,
      "loss": 0.0002,
      "step": 6404
    },
    {
      "epoch": 65.03,
      "learning_rate": 6.942173981373474e-05,
      "loss": 0.0002,
      "step": 6405
    },
    {
      "epoch": 65.04,
      "learning_rate": 6.94107985901633e-05,
      "loss": 0.0007,
      "step": 6406
    },
    {
      "epoch": 65.05,
      "learning_rate": 6.939985627207251e-05,
      "loss": 0.0004,
      "step": 6407
    },
    {
      "epoch": 65.06,
      "learning_rate": 6.93889128600793e-05,
      "loss": 0.0018,
      "step": 6408
    },
    {
      "epoch": 65.07,
      "learning_rate": 6.937796835480079e-05,
      "loss": 0.0012,
      "step": 6409
    },
    {
      "epoch": 65.08,
      "learning_rate": 6.936702275685409e-05,
      "loss": 0.0004,
      "step": 6410
    },
    {
      "epoch": 65.09,
      "learning_rate": 6.935607606685642e-05,
      "loss": 0.002,
      "step": 6411
    },
    {
      "epoch": 65.1,
      "learning_rate": 6.934512828542497e-05,
      "loss": 0.0055,
      "step": 6412
    },
    {
      "epoch": 65.11,
      "learning_rate": 6.933417941317714e-05,
      "loss": 0.0015,
      "step": 6413
    },
    {
      "epoch": 65.12,
      "learning_rate": 6.932322945073023e-05,
      "loss": 0.0111,
      "step": 6414
    },
    {
      "epoch": 65.13,
      "learning_rate": 6.931227839870172e-05,
      "loss": 0.0058,
      "step": 6415
    },
    {
      "epoch": 65.14,
      "learning_rate": 6.930132625770909e-05,
      "loss": 0.0003,
      "step": 6416
    },
    {
      "epoch": 65.15,
      "learning_rate": 6.929037302836992e-05,
      "loss": 0.0002,
      "step": 6417
    },
    {
      "epoch": 65.16,
      "learning_rate": 6.92794187113018e-05,
      "loss": 0.0003,
      "step": 6418
    },
    {
      "epoch": 65.17,
      "learning_rate": 6.926846330712242e-05,
      "loss": 0.0043,
      "step": 6419
    },
    {
      "epoch": 65.18,
      "learning_rate": 6.925750681644953e-05,
      "loss": 0.002,
      "step": 6420
    },
    {
      "epoch": 65.19,
      "learning_rate": 6.924654923990096e-05,
      "loss": 0.0002,
      "step": 6421
    },
    {
      "epoch": 65.2,
      "learning_rate": 6.923559057809455e-05,
      "loss": 0.0131,
      "step": 6422
    },
    {
      "epoch": 65.21,
      "learning_rate": 6.922463083164823e-05,
      "loss": 0.0029,
      "step": 6423
    },
    {
      "epoch": 65.22,
      "learning_rate": 6.921367000118e-05,
      "loss": 0.0007,
      "step": 6424
    },
    {
      "epoch": 65.23,
      "learning_rate": 6.920270808730788e-05,
      "loss": 0.0011,
      "step": 6425
    },
    {
      "epoch": 65.24,
      "learning_rate": 6.919174509065004e-05,
      "loss": 0.0064,
      "step": 6426
    },
    {
      "epoch": 65.25,
      "learning_rate": 6.918078101182457e-05,
      "loss": 0.0005,
      "step": 6427
    },
    {
      "epoch": 65.26,
      "learning_rate": 6.916981585144977e-05,
      "loss": 0.0001,
      "step": 6428
    },
    {
      "epoch": 65.27,
      "learning_rate": 6.91588496101439e-05,
      "loss": 0.0006,
      "step": 6429
    },
    {
      "epoch": 65.28,
      "learning_rate": 6.914788228852533e-05,
      "loss": 0.0005,
      "step": 6430
    },
    {
      "epoch": 65.29,
      "learning_rate": 6.913691388721246e-05,
      "loss": 0.0024,
      "step": 6431
    },
    {
      "epoch": 65.3,
      "learning_rate": 6.912594440682381e-05,
      "loss": 0.0188,
      "step": 6432
    },
    {
      "epoch": 65.31,
      "learning_rate": 6.911497384797785e-05,
      "loss": 0.0016,
      "step": 6433
    },
    {
      "epoch": 65.32,
      "learning_rate": 6.910400221129322e-05,
      "loss": 0.015,
      "step": 6434
    },
    {
      "epoch": 65.33,
      "learning_rate": 6.909302949738859e-05,
      "loss": 0.0025,
      "step": 6435
    },
    {
      "epoch": 65.34,
      "learning_rate": 6.908205570688267e-05,
      "loss": 0.0014,
      "step": 6436
    },
    {
      "epoch": 65.35,
      "learning_rate": 6.907108084039421e-05,
      "loss": 0.0008,
      "step": 6437
    },
    {
      "epoch": 65.36,
      "learning_rate": 6.906010489854209e-05,
      "loss": 0.0028,
      "step": 6438
    },
    {
      "epoch": 65.37,
      "learning_rate": 6.90491278819452e-05,
      "loss": 0.0006,
      "step": 6439
    },
    {
      "epoch": 65.38,
      "learning_rate": 6.903814979122249e-05,
      "loss": 0.0005,
      "step": 6440
    },
    {
      "epoch": 65.39,
      "learning_rate": 6.902717062699299e-05,
      "loss": 0.0123,
      "step": 6441
    },
    {
      "epoch": 65.4,
      "learning_rate": 6.901619038987579e-05,
      "loss": 0.0006,
      "step": 6442
    },
    {
      "epoch": 65.41,
      "learning_rate": 6.900520908049004e-05,
      "loss": 0.0036,
      "step": 6443
    },
    {
      "epoch": 65.42,
      "learning_rate": 6.899422669945493e-05,
      "loss": 0.0006,
      "step": 6444
    },
    {
      "epoch": 65.43,
      "learning_rate": 6.898324324738973e-05,
      "loss": 0.0005,
      "step": 6445
    },
    {
      "epoch": 65.44,
      "learning_rate": 6.897225872491376e-05,
      "loss": 0.0001,
      "step": 6446
    },
    {
      "epoch": 65.45,
      "learning_rate": 6.896127313264643e-05,
      "loss": 0.0006,
      "step": 6447
    },
    {
      "epoch": 65.46,
      "learning_rate": 6.895028647120716e-05,
      "loss": 0.0004,
      "step": 6448
    },
    {
      "epoch": 65.47,
      "learning_rate": 6.893929874121545e-05,
      "loss": 0.0015,
      "step": 6449
    },
    {
      "epoch": 65.48,
      "learning_rate": 6.89283099432909e-05,
      "loss": 0.005,
      "step": 6450
    },
    {
      "epoch": 65.49,
      "learning_rate": 6.891732007805311e-05,
      "loss": 0.0009,
      "step": 6451
    },
    {
      "epoch": 65.5,
      "learning_rate": 6.890632914612176e-05,
      "loss": 0.0,
      "step": 6452
    },
    {
      "epoch": 65.51,
      "learning_rate": 6.889533714811663e-05,
      "loss": 0.0003,
      "step": 6453
    },
    {
      "epoch": 65.52,
      "learning_rate": 6.888434408465751e-05,
      "loss": 0.0106,
      "step": 6454
    },
    {
      "epoch": 65.53,
      "learning_rate": 6.887334995636426e-05,
      "loss": 0.0007,
      "step": 6455
    },
    {
      "epoch": 65.54,
      "learning_rate": 6.886235476385682e-05,
      "loss": 0.0016,
      "step": 6456
    },
    {
      "epoch": 65.55,
      "learning_rate": 6.885135850775518e-05,
      "loss": 0.0072,
      "step": 6457
    },
    {
      "epoch": 65.56,
      "learning_rate": 6.884036118867935e-05,
      "loss": 0.0044,
      "step": 6458
    },
    {
      "epoch": 65.57,
      "learning_rate": 6.882936280724948e-05,
      "loss": 0.0009,
      "step": 6459
    },
    {
      "epoch": 65.58,
      "learning_rate": 6.881836336408573e-05,
      "loss": 0.0001,
      "step": 6460
    },
    {
      "epoch": 65.59,
      "learning_rate": 6.880736285980832e-05,
      "loss": 0.0115,
      "step": 6461
    },
    {
      "epoch": 65.6,
      "learning_rate": 6.879636129503753e-05,
      "loss": 0.0017,
      "step": 6462
    },
    {
      "epoch": 65.61,
      "learning_rate": 6.878535867039372e-05,
      "loss": 0.0145,
      "step": 6463
    },
    {
      "epoch": 65.62,
      "learning_rate": 6.877435498649729e-05,
      "loss": 0.0018,
      "step": 6464
    },
    {
      "epoch": 65.63,
      "learning_rate": 6.876335024396872e-05,
      "loss": 0.0013,
      "step": 6465
    },
    {
      "epoch": 65.64,
      "learning_rate": 6.875234444342851e-05,
      "loss": 0.0007,
      "step": 6466
    },
    {
      "epoch": 65.65,
      "learning_rate": 6.874133758549726e-05,
      "loss": 0.0002,
      "step": 6467
    },
    {
      "epoch": 65.66,
      "learning_rate": 6.873032967079561e-05,
      "loss": 0.0157,
      "step": 6468
    },
    {
      "epoch": 65.68,
      "learning_rate": 6.871932069994427e-05,
      "loss": 0.0109,
      "step": 6469
    },
    {
      "epoch": 65.69,
      "learning_rate": 6.8708310673564e-05,
      "loss": 0.0001,
      "step": 6470
    },
    {
      "epoch": 65.7,
      "learning_rate": 6.869729959227563e-05,
      "loss": 0.0047,
      "step": 6471
    },
    {
      "epoch": 65.71,
      "learning_rate": 6.868628745670006e-05,
      "loss": 0.0002,
      "step": 6472
    },
    {
      "epoch": 65.72,
      "learning_rate": 6.86752742674582e-05,
      "loss": 0.0006,
      "step": 6473
    },
    {
      "epoch": 65.73,
      "learning_rate": 6.866426002517105e-05,
      "loss": 0.0018,
      "step": 6474
    },
    {
      "epoch": 65.74,
      "learning_rate": 6.86532447304597e-05,
      "loss": 0.0126,
      "step": 6475
    },
    {
      "epoch": 65.75,
      "learning_rate": 6.864222838394526e-05,
      "loss": 0.0161,
      "step": 6476
    },
    {
      "epoch": 65.76,
      "learning_rate": 6.863121098624891e-05,
      "loss": 0.0001,
      "step": 6477
    },
    {
      "epoch": 65.77,
      "learning_rate": 6.862019253799187e-05,
      "loss": 0.0014,
      "step": 6478
    },
    {
      "epoch": 65.78,
      "learning_rate": 6.860917303979547e-05,
      "loss": 0.0125,
      "step": 6479
    },
    {
      "epoch": 65.79,
      "learning_rate": 6.859815249228106e-05,
      "loss": 0.0003,
      "step": 6480
    },
    {
      "epoch": 65.8,
      "learning_rate": 6.858713089607005e-05,
      "loss": 0.0043,
      "step": 6481
    },
    {
      "epoch": 65.81,
      "learning_rate": 6.85761082517839e-05,
      "loss": 0.0164,
      "step": 6482
    },
    {
      "epoch": 65.82,
      "learning_rate": 6.856508456004418e-05,
      "loss": 0.0014,
      "step": 6483
    },
    {
      "epoch": 65.83,
      "learning_rate": 6.855405982147248e-05,
      "loss": 0.0018,
      "step": 6484
    },
    {
      "epoch": 65.84,
      "learning_rate": 6.854303403669043e-05,
      "loss": 0.001,
      "step": 6485
    },
    {
      "epoch": 65.85,
      "learning_rate": 6.853200720631973e-05,
      "loss": 0.0001,
      "step": 6486
    },
    {
      "epoch": 65.86,
      "learning_rate": 6.852097933098221e-05,
      "loss": 0.001,
      "step": 6487
    },
    {
      "epoch": 65.87,
      "learning_rate": 6.850995041129965e-05,
      "loss": 0.0009,
      "step": 6488
    },
    {
      "epoch": 65.88,
      "learning_rate": 6.849892044789395e-05,
      "loss": 0.0004,
      "step": 6489
    },
    {
      "epoch": 65.89,
      "learning_rate": 6.848788944138705e-05,
      "loss": 0.0089,
      "step": 6490
    },
    {
      "epoch": 65.9,
      "learning_rate": 6.8476857392401e-05,
      "loss": 0.0009,
      "step": 6491
    },
    {
      "epoch": 65.91,
      "learning_rate": 6.846582430155783e-05,
      "loss": 0.0036,
      "step": 6492
    },
    {
      "epoch": 65.92,
      "learning_rate": 6.845479016947967e-05,
      "loss": 0.0151,
      "step": 6493
    },
    {
      "epoch": 65.93,
      "learning_rate": 6.844375499678867e-05,
      "loss": 0.0177,
      "step": 6494
    },
    {
      "epoch": 65.94,
      "learning_rate": 6.843271878410714e-05,
      "loss": 0.0005,
      "step": 6495
    },
    {
      "epoch": 65.95,
      "learning_rate": 6.842168153205734e-05,
      "loss": 0.0028,
      "step": 6496
    },
    {
      "epoch": 65.96,
      "learning_rate": 6.841064324126162e-05,
      "loss": 0.0044,
      "step": 6497
    },
    {
      "epoch": 65.97,
      "learning_rate": 6.839960391234242e-05,
      "loss": 0.0002,
      "step": 6498
    },
    {
      "epoch": 65.98,
      "learning_rate": 6.838856354592222e-05,
      "loss": 0.0012,
      "step": 6499
    },
    {
      "epoch": 65.99,
      "learning_rate": 6.837752214262352e-05,
      "loss": 0.0011,
      "step": 6500
    },
    {
      "epoch": 66.0,
      "learning_rate": 6.836647970306894e-05,
      "loss": 0.0078,
      "step": 6501
    },
    {
      "epoch": 66.0,
      "eval_loss": 0.021305164322257042,
      "eval_runtime": 32.2376,
      "eval_samples_per_second": 97.712,
      "eval_steps_per_second": 6.111,
      "eval_wer": 0.004929577464788733,
      "step": 6501
    },
    {
      "epoch": 66.01,
      "learning_rate": 6.835543622788115e-05,
      "loss": 0.0029,
      "step": 6502
    },
    {
      "epoch": 66.02,
      "learning_rate": 6.834439171768281e-05,
      "loss": 0.0004,
      "step": 6503
    },
    {
      "epoch": 66.03,
      "learning_rate": 6.833334617309672e-05,
      "loss": 0.0006,
      "step": 6504
    },
    {
      "epoch": 66.04,
      "learning_rate": 6.832229959474571e-05,
      "loss": 0.0211,
      "step": 6505
    },
    {
      "epoch": 66.05,
      "learning_rate": 6.831125198325267e-05,
      "loss": 0.0005,
      "step": 6506
    },
    {
      "epoch": 66.06,
      "learning_rate": 6.83002033392405e-05,
      "loss": 0.0007,
      "step": 6507
    },
    {
      "epoch": 66.07,
      "learning_rate": 6.828915366333226e-05,
      "loss": 0.001,
      "step": 6508
    },
    {
      "epoch": 66.08,
      "learning_rate": 6.827810295615097e-05,
      "loss": 0.0108,
      "step": 6509
    },
    {
      "epoch": 66.09,
      "learning_rate": 6.826705121831976e-05,
      "loss": 0.0132,
      "step": 6510
    },
    {
      "epoch": 66.1,
      "learning_rate": 6.82559984504618e-05,
      "loss": 0.025,
      "step": 6511
    },
    {
      "epoch": 66.11,
      "learning_rate": 6.824494465320034e-05,
      "loss": 0.0169,
      "step": 6512
    },
    {
      "epoch": 66.12,
      "learning_rate": 6.823388982715865e-05,
      "loss": 0.0003,
      "step": 6513
    },
    {
      "epoch": 66.13,
      "learning_rate": 6.822283397296009e-05,
      "loss": 0.0227,
      "step": 6514
    },
    {
      "epoch": 66.14,
      "learning_rate": 6.821177709122806e-05,
      "loss": 0.0009,
      "step": 6515
    },
    {
      "epoch": 66.15,
      "learning_rate": 6.820071918258606e-05,
      "loss": 0.0003,
      "step": 6516
    },
    {
      "epoch": 66.16,
      "learning_rate": 6.818966024765758e-05,
      "loss": 0.006,
      "step": 6517
    },
    {
      "epoch": 66.17,
      "learning_rate": 6.817860028706621e-05,
      "loss": 0.0005,
      "step": 6518
    },
    {
      "epoch": 66.18,
      "learning_rate": 6.816753930143558e-05,
      "loss": 0.0005,
      "step": 6519
    },
    {
      "epoch": 66.19,
      "learning_rate": 6.815647729138941e-05,
      "loss": 0.0001,
      "step": 6520
    },
    {
      "epoch": 66.2,
      "learning_rate": 6.814541425755143e-05,
      "loss": 0.0164,
      "step": 6521
    },
    {
      "epoch": 66.21,
      "learning_rate": 6.813435020054548e-05,
      "loss": 0.0147,
      "step": 6522
    },
    {
      "epoch": 66.22,
      "learning_rate": 6.81232851209954e-05,
      "loss": 0.002,
      "step": 6523
    },
    {
      "epoch": 66.23,
      "learning_rate": 6.811221901952513e-05,
      "loss": 0.0018,
      "step": 6524
    },
    {
      "epoch": 66.24,
      "learning_rate": 6.81011518967587e-05,
      "loss": 0.0003,
      "step": 6525
    },
    {
      "epoch": 66.25,
      "learning_rate": 6.809008375332007e-05,
      "loss": 0.0001,
      "step": 6526
    },
    {
      "epoch": 66.26,
      "learning_rate": 6.807901458983341e-05,
      "loss": 0.0026,
      "step": 6527
    },
    {
      "epoch": 66.27,
      "learning_rate": 6.806794440692282e-05,
      "loss": 0.0021,
      "step": 6528
    },
    {
      "epoch": 66.28,
      "learning_rate": 6.805687320521259e-05,
      "loss": 0.0015,
      "step": 6529
    },
    {
      "epoch": 66.29,
      "learning_rate": 6.804580098532692e-05,
      "loss": 0.0002,
      "step": 6530
    },
    {
      "epoch": 66.3,
      "learning_rate": 6.80347277478902e-05,
      "loss": 0.0081,
      "step": 6531
    },
    {
      "epoch": 66.31,
      "learning_rate": 6.802365349352676e-05,
      "loss": 0.0073,
      "step": 6532
    },
    {
      "epoch": 66.32,
      "learning_rate": 6.801257822286108e-05,
      "loss": 0.0008,
      "step": 6533
    },
    {
      "epoch": 66.34,
      "learning_rate": 6.800150193651767e-05,
      "loss": 0.0004,
      "step": 6534
    },
    {
      "epoch": 66.35,
      "learning_rate": 6.79904246351211e-05,
      "loss": 0.0174,
      "step": 6535
    },
    {
      "epoch": 66.36,
      "learning_rate": 6.797934631929592e-05,
      "loss": 0.0161,
      "step": 6536
    },
    {
      "epoch": 66.37,
      "learning_rate": 6.796826698966689e-05,
      "loss": 0.0014,
      "step": 6537
    },
    {
      "epoch": 66.38,
      "learning_rate": 6.795718664685868e-05,
      "loss": 0.0143,
      "step": 6538
    },
    {
      "epoch": 66.39,
      "learning_rate": 6.794610529149612e-05,
      "loss": 0.0004,
      "step": 6539
    },
    {
      "epoch": 66.4,
      "learning_rate": 6.793502292420402e-05,
      "loss": 0.0004,
      "step": 6540
    },
    {
      "epoch": 66.41,
      "learning_rate": 6.792393954560731e-05,
      "loss": 0.0008,
      "step": 6541
    },
    {
      "epoch": 66.42,
      "learning_rate": 6.791285515633094e-05,
      "loss": 0.0023,
      "step": 6542
    },
    {
      "epoch": 66.43,
      "learning_rate": 6.790176975699992e-05,
      "loss": 0.0173,
      "step": 6543
    },
    {
      "epoch": 66.44,
      "learning_rate": 6.789068334823934e-05,
      "loss": 0.0011,
      "step": 6544
    },
    {
      "epoch": 66.45,
      "learning_rate": 6.78795959306743e-05,
      "loss": 0.0025,
      "step": 6545
    },
    {
      "epoch": 66.46,
      "learning_rate": 6.786850750493006e-05,
      "loss": 0.0106,
      "step": 6546
    },
    {
      "epoch": 66.47,
      "learning_rate": 6.785741807163177e-05,
      "loss": 0.0033,
      "step": 6547
    },
    {
      "epoch": 66.48,
      "learning_rate": 6.78463276314048e-05,
      "loss": 0.0048,
      "step": 6548
    },
    {
      "epoch": 66.49,
      "learning_rate": 6.783523618487446e-05,
      "loss": 0.0001,
      "step": 6549
    },
    {
      "epoch": 66.5,
      "learning_rate": 6.782414373266621e-05,
      "loss": 0.0001,
      "step": 6550
    },
    {
      "epoch": 66.51,
      "learning_rate": 6.781305027540548e-05,
      "loss": 0.0244,
      "step": 6551
    },
    {
      "epoch": 66.52,
      "learning_rate": 6.780195581371784e-05,
      "loss": 0.0,
      "step": 6552
    },
    {
      "epoch": 66.53,
      "learning_rate": 6.779086034822884e-05,
      "loss": 0.0009,
      "step": 6553
    },
    {
      "epoch": 66.54,
      "learning_rate": 6.777976387956415e-05,
      "loss": 0.0002,
      "step": 6554
    },
    {
      "epoch": 66.55,
      "learning_rate": 6.776866640834945e-05,
      "loss": 0.0002,
      "step": 6555
    },
    {
      "epoch": 66.56,
      "learning_rate": 6.775756793521049e-05,
      "loss": 0.0012,
      "step": 6556
    },
    {
      "epoch": 66.57,
      "learning_rate": 6.774646846077309e-05,
      "loss": 0.0025,
      "step": 6557
    },
    {
      "epoch": 66.58,
      "learning_rate": 6.773536798566313e-05,
      "loss": 0.0003,
      "step": 6558
    },
    {
      "epoch": 66.59,
      "learning_rate": 6.772426651050651e-05,
      "loss": 0.0009,
      "step": 6559
    },
    {
      "epoch": 66.6,
      "learning_rate": 6.771316403592922e-05,
      "loss": 0.004,
      "step": 6560
    },
    {
      "epoch": 66.61,
      "learning_rate": 6.77020605625573e-05,
      "loss": 0.0017,
      "step": 6561
    },
    {
      "epoch": 66.62,
      "learning_rate": 6.769095609101683e-05,
      "loss": 0.0006,
      "step": 6562
    },
    {
      "epoch": 66.63,
      "learning_rate": 6.767985062193399e-05,
      "loss": 0.0002,
      "step": 6563
    },
    {
      "epoch": 66.64,
      "learning_rate": 6.766874415593496e-05,
      "loss": 0.0011,
      "step": 6564
    },
    {
      "epoch": 66.65,
      "learning_rate": 6.765763669364601e-05,
      "loss": 0.0,
      "step": 6565
    },
    {
      "epoch": 66.66,
      "learning_rate": 6.764652823569344e-05,
      "loss": 0.0007,
      "step": 6566
    },
    {
      "epoch": 66.67,
      "learning_rate": 6.763541878270368e-05,
      "loss": 0.005,
      "step": 6567
    },
    {
      "epoch": 66.68,
      "learning_rate": 6.762430833530308e-05,
      "loss": 0.0004,
      "step": 6568
    },
    {
      "epoch": 66.69,
      "learning_rate": 6.761319689411817e-05,
      "loss": 0.0007,
      "step": 6569
    },
    {
      "epoch": 66.7,
      "learning_rate": 6.760208445977551e-05,
      "loss": 0.0001,
      "step": 6570
    },
    {
      "epoch": 66.71,
      "learning_rate": 6.759097103290168e-05,
      "loss": 0.013,
      "step": 6571
    },
    {
      "epoch": 66.72,
      "learning_rate": 6.757985661412331e-05,
      "loss": 0.0048,
      "step": 6572
    },
    {
      "epoch": 66.73,
      "learning_rate": 6.756874120406714e-05,
      "loss": 0.0008,
      "step": 6573
    },
    {
      "epoch": 66.74,
      "learning_rate": 6.755762480335993e-05,
      "loss": 0.0018,
      "step": 6574
    },
    {
      "epoch": 66.75,
      "learning_rate": 6.754650741262851e-05,
      "loss": 0.0079,
      "step": 6575
    },
    {
      "epoch": 66.76,
      "learning_rate": 6.753538903249975e-05,
      "loss": 0.0004,
      "step": 6576
    },
    {
      "epoch": 66.77,
      "learning_rate": 6.752426966360054e-05,
      "loss": 0.0011,
      "step": 6577
    },
    {
      "epoch": 66.78,
      "learning_rate": 6.751314930655795e-05,
      "loss": 0.0004,
      "step": 6578
    },
    {
      "epoch": 66.79,
      "learning_rate": 6.750202796199899e-05,
      "loss": 0.0024,
      "step": 6579
    },
    {
      "epoch": 66.8,
      "learning_rate": 6.749090563055076e-05,
      "loss": 0.0005,
      "step": 6580
    },
    {
      "epoch": 66.81,
      "learning_rate": 6.747978231284037e-05,
      "loss": 0.0278,
      "step": 6581
    },
    {
      "epoch": 66.82,
      "learning_rate": 6.746865800949512e-05,
      "loss": 0.0149,
      "step": 6582
    },
    {
      "epoch": 66.83,
      "learning_rate": 6.745753272114221e-05,
      "loss": 0.0063,
      "step": 6583
    },
    {
      "epoch": 66.84,
      "learning_rate": 6.7446406448409e-05,
      "loss": 0.0002,
      "step": 6584
    },
    {
      "epoch": 66.85,
      "learning_rate": 6.743527919192286e-05,
      "loss": 0.0013,
      "step": 6585
    },
    {
      "epoch": 66.86,
      "learning_rate": 6.742415095231121e-05,
      "loss": 0.0032,
      "step": 6586
    },
    {
      "epoch": 66.87,
      "learning_rate": 6.741302173020154e-05,
      "loss": 0.0048,
      "step": 6587
    },
    {
      "epoch": 66.88,
      "learning_rate": 6.740189152622143e-05,
      "loss": 0.0018,
      "step": 6588
    },
    {
      "epoch": 66.89,
      "learning_rate": 6.739076034099842e-05,
      "loss": 0.0021,
      "step": 6589
    },
    {
      "epoch": 66.9,
      "learning_rate": 6.737962817516022e-05,
      "loss": 0.0025,
      "step": 6590
    },
    {
      "epoch": 66.91,
      "learning_rate": 6.736849502933452e-05,
      "loss": 0.0009,
      "step": 6591
    },
    {
      "epoch": 66.92,
      "learning_rate": 6.73573609041491e-05,
      "loss": 0.0193,
      "step": 6592
    },
    {
      "epoch": 66.93,
      "learning_rate": 6.734622580023173e-05,
      "loss": 0.0063,
      "step": 6593
    },
    {
      "epoch": 66.94,
      "learning_rate": 6.733508971821036e-05,
      "loss": 0.0077,
      "step": 6594
    },
    {
      "epoch": 66.95,
      "learning_rate": 6.732395265871288e-05,
      "loss": 0.0025,
      "step": 6595
    },
    {
      "epoch": 66.96,
      "learning_rate": 6.731281462236728e-05,
      "loss": 0.0031,
      "step": 6596
    },
    {
      "epoch": 66.97,
      "learning_rate": 6.73016756098016e-05,
      "loss": 0.0003,
      "step": 6597
    },
    {
      "epoch": 66.98,
      "learning_rate": 6.729053562164396e-05,
      "loss": 0.0125,
      "step": 6598
    },
    {
      "epoch": 66.99,
      "learning_rate": 6.727939465852247e-05,
      "loss": 0.001,
      "step": 6599
    },
    {
      "epoch": 66.99,
      "eval_loss": 0.01884419098496437,
      "eval_runtime": 32.9,
      "eval_samples_per_second": 95.745,
      "eval_steps_per_second": 5.988,
      "eval_wer": 0.004481434058898848,
      "step": 6599
    },
    {
      "epoch": 67.01,
      "learning_rate": 6.726825272106538e-05,
      "loss": 0.0,
      "step": 6600
    },
    {
      "epoch": 67.02,
      "learning_rate": 6.725710980990094e-05,
      "loss": 0.0006,
      "step": 6601
    },
    {
      "epoch": 67.03,
      "learning_rate": 6.724596592565745e-05,
      "loss": 0.0024,
      "step": 6602
    },
    {
      "epoch": 67.04,
      "learning_rate": 6.72348210689633e-05,
      "loss": 0.0007,
      "step": 6603
    },
    {
      "epoch": 67.05,
      "learning_rate": 6.722367524044691e-05,
      "loss": 0.0004,
      "step": 6604
    },
    {
      "epoch": 67.06,
      "learning_rate": 6.721252844073676e-05,
      "loss": 0.0002,
      "step": 6605
    },
    {
      "epoch": 67.07,
      "learning_rate": 6.720138067046136e-05,
      "loss": 0.0088,
      "step": 6606
    },
    {
      "epoch": 67.08,
      "learning_rate": 6.719023193024936e-05,
      "loss": 0.0176,
      "step": 6607
    },
    {
      "epoch": 67.09,
      "learning_rate": 6.717908222072935e-05,
      "loss": 0.0006,
      "step": 6608
    },
    {
      "epoch": 67.1,
      "learning_rate": 6.716793154253009e-05,
      "loss": 0.0041,
      "step": 6609
    },
    {
      "epoch": 67.11,
      "learning_rate": 6.715677989628025e-05,
      "loss": 0.0019,
      "step": 6610
    },
    {
      "epoch": 67.12,
      "learning_rate": 6.714562728260873e-05,
      "loss": 0.0179,
      "step": 6611
    },
    {
      "epoch": 67.13,
      "learning_rate": 6.713447370214432e-05,
      "loss": 0.0011,
      "step": 6612
    },
    {
      "epoch": 67.14,
      "learning_rate": 6.7123319155516e-05,
      "loss": 0.0004,
      "step": 6613
    },
    {
      "epoch": 67.15,
      "learning_rate": 6.711216364335267e-05,
      "loss": 0.0018,
      "step": 6614
    },
    {
      "epoch": 67.16,
      "learning_rate": 6.710100716628344e-05,
      "loss": 0.0014,
      "step": 6615
    },
    {
      "epoch": 67.17,
      "learning_rate": 6.708984972493735e-05,
      "loss": 0.0068,
      "step": 6616
    },
    {
      "epoch": 67.18,
      "learning_rate": 6.707869131994354e-05,
      "loss": 0.0014,
      "step": 6617
    },
    {
      "epoch": 67.19,
      "learning_rate": 6.706753195193117e-05,
      "loss": 0.0081,
      "step": 6618
    },
    {
      "epoch": 67.2,
      "learning_rate": 6.705637162152953e-05,
      "loss": 0.0003,
      "step": 6619
    },
    {
      "epoch": 67.21,
      "learning_rate": 6.70452103293679e-05,
      "loss": 0.0001,
      "step": 6620
    },
    {
      "epoch": 67.22,
      "learning_rate": 6.703404807607564e-05,
      "loss": 0.0022,
      "step": 6621
    },
    {
      "epoch": 67.23,
      "learning_rate": 6.702288486228216e-05,
      "loss": 0.0008,
      "step": 6622
    },
    {
      "epoch": 67.24,
      "learning_rate": 6.701172068861691e-05,
      "loss": 0.0239,
      "step": 6623
    },
    {
      "epoch": 67.25,
      "learning_rate": 6.700055555570942e-05,
      "loss": 0.002,
      "step": 6624
    },
    {
      "epoch": 67.26,
      "learning_rate": 6.698938946418923e-05,
      "loss": 0.0135,
      "step": 6625
    },
    {
      "epoch": 67.27,
      "learning_rate": 6.6978222414686e-05,
      "loss": 0.0001,
      "step": 6626
    },
    {
      "epoch": 67.28,
      "learning_rate": 6.696705440782938e-05,
      "loss": 0.0004,
      "step": 6627
    },
    {
      "epoch": 67.29,
      "learning_rate": 6.695588544424913e-05,
      "loss": 0.009,
      "step": 6628
    },
    {
      "epoch": 67.3,
      "learning_rate": 6.694471552457502e-05,
      "loss": 0.0001,
      "step": 6629
    },
    {
      "epoch": 67.31,
      "learning_rate": 6.693354464943688e-05,
      "loss": 0.0003,
      "step": 6630
    },
    {
      "epoch": 67.32,
      "learning_rate": 6.692237281946463e-05,
      "loss": 0.0003,
      "step": 6631
    },
    {
      "epoch": 67.33,
      "learning_rate": 6.69112000352882e-05,
      "loss": 0.0004,
      "step": 6632
    },
    {
      "epoch": 67.34,
      "learning_rate": 6.690002629753759e-05,
      "loss": 0.0003,
      "step": 6633
    },
    {
      "epoch": 67.35,
      "learning_rate": 6.688885160684285e-05,
      "loss": 0.0018,
      "step": 6634
    },
    {
      "epoch": 67.36,
      "learning_rate": 6.687767596383409e-05,
      "loss": 0.0015,
      "step": 6635
    },
    {
      "epoch": 67.37,
      "learning_rate": 6.686649936914152e-05,
      "loss": 0.004,
      "step": 6636
    },
    {
      "epoch": 67.38,
      "learning_rate": 6.685532182339528e-05,
      "loss": 0.0006,
      "step": 6637
    },
    {
      "epoch": 67.39,
      "learning_rate": 6.684414332722568e-05,
      "loss": 0.0177,
      "step": 6638
    },
    {
      "epoch": 67.4,
      "learning_rate": 6.683296388126303e-05,
      "loss": 0.0012,
      "step": 6639
    },
    {
      "epoch": 67.41,
      "learning_rate": 6.682178348613775e-05,
      "loss": 0.0003,
      "step": 6640
    },
    {
      "epoch": 67.42,
      "learning_rate": 6.681060214248021e-05,
      "loss": 0.0036,
      "step": 6641
    },
    {
      "epoch": 67.43,
      "learning_rate": 6.679941985092092e-05,
      "loss": 0.0002,
      "step": 6642
    },
    {
      "epoch": 67.44,
      "learning_rate": 6.678823661209043e-05,
      "loss": 0.0003,
      "step": 6643
    },
    {
      "epoch": 67.45,
      "learning_rate": 6.677705242661931e-05,
      "loss": 0.0001,
      "step": 6644
    },
    {
      "epoch": 67.46,
      "learning_rate": 6.676586729513823e-05,
      "loss": 0.0001,
      "step": 6645
    },
    {
      "epoch": 67.47,
      "learning_rate": 6.675468121827785e-05,
      "loss": 0.0298,
      "step": 6646
    },
    {
      "epoch": 67.48,
      "learning_rate": 6.674349419666895e-05,
      "loss": 0.0005,
      "step": 6647
    },
    {
      "epoch": 67.49,
      "learning_rate": 6.673230623094232e-05,
      "loss": 0.0237,
      "step": 6648
    },
    {
      "epoch": 67.5,
      "learning_rate": 6.672111732172883e-05,
      "loss": 0.002,
      "step": 6649
    },
    {
      "epoch": 67.51,
      "learning_rate": 6.670992746965938e-05,
      "loss": 0.0001,
      "step": 6650
    },
    {
      "epoch": 67.52,
      "learning_rate": 6.669873667536493e-05,
      "loss": 0.0015,
      "step": 6651
    },
    {
      "epoch": 67.53,
      "learning_rate": 6.668754493947653e-05,
      "loss": 0.0005,
      "step": 6652
    },
    {
      "epoch": 67.54,
      "learning_rate": 6.667635226262521e-05,
      "loss": 0.0023,
      "step": 6653
    },
    {
      "epoch": 67.55,
      "learning_rate": 6.666515864544209e-05,
      "loss": 0.001,
      "step": 6654
    },
    {
      "epoch": 67.56,
      "learning_rate": 6.665396408855838e-05,
      "loss": 0.005,
      "step": 6655
    },
    {
      "epoch": 67.57,
      "learning_rate": 6.664276859260528e-05,
      "loss": 0.0087,
      "step": 6656
    },
    {
      "epoch": 67.58,
      "learning_rate": 6.663157215821411e-05,
      "loss": 0.0016,
      "step": 6657
    },
    {
      "epoch": 67.59,
      "learning_rate": 6.662037478601616e-05,
      "loss": 0.0047,
      "step": 6658
    },
    {
      "epoch": 67.6,
      "learning_rate": 6.660917647664284e-05,
      "loss": 0.0001,
      "step": 6659
    },
    {
      "epoch": 67.61,
      "learning_rate": 6.659797723072558e-05,
      "loss": 0.0003,
      "step": 6660
    },
    {
      "epoch": 67.62,
      "learning_rate": 6.658677704889589e-05,
      "loss": 0.0016,
      "step": 6661
    },
    {
      "epoch": 67.63,
      "learning_rate": 6.657557593178531e-05,
      "loss": 0.0014,
      "step": 6662
    },
    {
      "epoch": 67.64,
      "learning_rate": 6.656437388002543e-05,
      "loss": 0.006,
      "step": 6663
    },
    {
      "epoch": 67.65,
      "learning_rate": 6.65531708942479e-05,
      "loss": 0.0018,
      "step": 6664
    },
    {
      "epoch": 67.66,
      "learning_rate": 6.654196697508445e-05,
      "loss": 0.006,
      "step": 6665
    },
    {
      "epoch": 67.68,
      "learning_rate": 6.653076212316681e-05,
      "loss": 0.0076,
      "step": 6666
    },
    {
      "epoch": 67.69,
      "learning_rate": 6.65195563391268e-05,
      "loss": 0.0076,
      "step": 6667
    },
    {
      "epoch": 67.7,
      "learning_rate": 6.650834962359628e-05,
      "loss": 0.027,
      "step": 6668
    },
    {
      "epoch": 67.71,
      "learning_rate": 6.649714197720716e-05,
      "loss": 0.0001,
      "step": 6669
    },
    {
      "epoch": 67.72,
      "learning_rate": 6.648593340059142e-05,
      "loss": 0.0038,
      "step": 6670
    },
    {
      "epoch": 67.73,
      "learning_rate": 6.647472389438107e-05,
      "loss": 0.0004,
      "step": 6671
    },
    {
      "epoch": 67.74,
      "learning_rate": 6.646351345920818e-05,
      "loss": 0.0212,
      "step": 6672
    },
    {
      "epoch": 67.75,
      "learning_rate": 6.645230209570488e-05,
      "loss": 0.0001,
      "step": 6673
    },
    {
      "epoch": 67.76,
      "learning_rate": 6.644108980450335e-05,
      "loss": 0.0002,
      "step": 6674
    },
    {
      "epoch": 67.77,
      "learning_rate": 6.64298765862358e-05,
      "loss": 0.0015,
      "step": 6675
    },
    {
      "epoch": 67.78,
      "learning_rate": 6.641866244153454e-05,
      "loss": 0.0002,
      "step": 6676
    },
    {
      "epoch": 67.79,
      "learning_rate": 6.640744737103188e-05,
      "loss": 0.0084,
      "step": 6677
    },
    {
      "epoch": 67.8,
      "learning_rate": 6.639623137536023e-05,
      "loss": 0.0052,
      "step": 6678
    },
    {
      "epoch": 67.81,
      "learning_rate": 6.6385014455152e-05,
      "loss": 0.0005,
      "step": 6679
    },
    {
      "epoch": 67.82,
      "learning_rate": 6.637379661103969e-05,
      "loss": 0.0014,
      "step": 6680
    },
    {
      "epoch": 67.83,
      "learning_rate": 6.636257784365584e-05,
      "loss": 0.0047,
      "step": 6681
    },
    {
      "epoch": 67.84,
      "learning_rate": 6.635135815363307e-05,
      "loss": 0.0159,
      "step": 6682
    },
    {
      "epoch": 67.85,
      "learning_rate": 6.634013754160398e-05,
      "loss": 0.0139,
      "step": 6683
    },
    {
      "epoch": 67.86,
      "learning_rate": 6.632891600820132e-05,
      "loss": 0.0044,
      "step": 6684
    },
    {
      "epoch": 67.87,
      "learning_rate": 6.63176935540578e-05,
      "loss": 0.0024,
      "step": 6685
    },
    {
      "epoch": 67.88,
      "learning_rate": 6.63064701798062e-05,
      "loss": 0.0151,
      "step": 6686
    },
    {
      "epoch": 67.89,
      "learning_rate": 6.629524588607947e-05,
      "loss": 0.0113,
      "step": 6687
    },
    {
      "epoch": 67.9,
      "learning_rate": 6.628402067351041e-05,
      "loss": 0.0025,
      "step": 6688
    },
    {
      "epoch": 67.91,
      "learning_rate": 6.627279454273206e-05,
      "loss": 0.0011,
      "step": 6689
    },
    {
      "epoch": 67.92,
      "learning_rate": 6.626156749437736e-05,
      "loss": 0.0005,
      "step": 6690
    },
    {
      "epoch": 67.93,
      "learning_rate": 6.625033952907942e-05,
      "loss": 0.0011,
      "step": 6691
    },
    {
      "epoch": 67.94,
      "learning_rate": 6.623911064747133e-05,
      "loss": 0.0002,
      "step": 6692
    },
    {
      "epoch": 67.95,
      "learning_rate": 6.622788085018626e-05,
      "loss": 0.0085,
      "step": 6693
    },
    {
      "epoch": 67.96,
      "learning_rate": 6.621665013785743e-05,
      "loss": 0.0048,
      "step": 6694
    },
    {
      "epoch": 67.97,
      "learning_rate": 6.620541851111812e-05,
      "loss": 0.0006,
      "step": 6695
    },
    {
      "epoch": 67.98,
      "learning_rate": 6.61941859706016e-05,
      "loss": 0.0004,
      "step": 6696
    },
    {
      "epoch": 67.99,
      "learning_rate": 6.61829525169413e-05,
      "loss": 0.0006,
      "step": 6697
    },
    {
      "epoch": 68.0,
      "learning_rate": 6.617171815077061e-05,
      "loss": 0.0006,
      "step": 6698
    },
    {
      "epoch": 68.0,
      "eval_loss": 0.017798826098442078,
      "eval_runtime": 32.5153,
      "eval_samples_per_second": 96.878,
      "eval_steps_per_second": 6.059,
      "eval_wer": 0.003905249679897567,
      "step": 6698
    },
    {
      "epoch": 68.01,
      "learning_rate": 6.616048287272301e-05,
      "loss": 0.0001,
      "step": 6699
    },
    {
      "epoch": 68.02,
      "learning_rate": 6.6149246683432e-05,
      "loss": 0.0149,
      "step": 6700
    },
    {
      "epoch": 68.03,
      "learning_rate": 6.613800958353123e-05,
      "loss": 0.0005,
      "step": 6701
    },
    {
      "epoch": 68.04,
      "learning_rate": 6.612677157365426e-05,
      "loss": 0.0003,
      "step": 6702
    },
    {
      "epoch": 68.05,
      "learning_rate": 6.611553265443479e-05,
      "loss": 0.0182,
      "step": 6703
    },
    {
      "epoch": 68.06,
      "learning_rate": 6.610429282650655e-05,
      "loss": 0.0003,
      "step": 6704
    },
    {
      "epoch": 68.07,
      "learning_rate": 6.609305209050332e-05,
      "loss": 0.0006,
      "step": 6705
    },
    {
      "epoch": 68.08,
      "learning_rate": 6.608181044705892e-05,
      "loss": 0.0003,
      "step": 6706
    },
    {
      "epoch": 68.09,
      "learning_rate": 6.607056789680727e-05,
      "loss": 0.0027,
      "step": 6707
    },
    {
      "epoch": 68.1,
      "learning_rate": 6.605932444038229e-05,
      "loss": 0.003,
      "step": 6708
    },
    {
      "epoch": 68.11,
      "learning_rate": 6.604808007841792e-05,
      "loss": 0.0003,
      "step": 6709
    },
    {
      "epoch": 68.12,
      "learning_rate": 6.603683481154829e-05,
      "loss": 0.0002,
      "step": 6710
    },
    {
      "epoch": 68.13,
      "learning_rate": 6.602558864040739e-05,
      "loss": 0.0009,
      "step": 6711
    },
    {
      "epoch": 68.14,
      "learning_rate": 6.601434156562944e-05,
      "loss": 0.0004,
      "step": 6712
    },
    {
      "epoch": 68.15,
      "learning_rate": 6.600309358784857e-05,
      "loss": 0.0045,
      "step": 6713
    },
    {
      "epoch": 68.16,
      "learning_rate": 6.599184470769908e-05,
      "loss": 0.0094,
      "step": 6714
    },
    {
      "epoch": 68.17,
      "learning_rate": 6.598059492581521e-05,
      "loss": 0.0002,
      "step": 6715
    },
    {
      "epoch": 68.18,
      "learning_rate": 6.596934424283132e-05,
      "loss": 0.0005,
      "step": 6716
    },
    {
      "epoch": 68.19,
      "learning_rate": 6.59580926593818e-05,
      "loss": 0.0001,
      "step": 6717
    },
    {
      "epoch": 68.2,
      "learning_rate": 6.59468401761011e-05,
      "loss": 0.0016,
      "step": 6718
    },
    {
      "epoch": 68.21,
      "learning_rate": 6.593558679362374e-05,
      "loss": 0.0017,
      "step": 6719
    },
    {
      "epoch": 68.22,
      "learning_rate": 6.592433251258423e-05,
      "loss": 0.0094,
      "step": 6720
    },
    {
      "epoch": 68.23,
      "learning_rate": 6.591307733361716e-05,
      "loss": 0.0035,
      "step": 6721
    },
    {
      "epoch": 68.24,
      "learning_rate": 6.590182125735724e-05,
      "loss": 0.0009,
      "step": 6722
    },
    {
      "epoch": 68.25,
      "learning_rate": 6.589056428443909e-05,
      "loss": 0.0001,
      "step": 6723
    },
    {
      "epoch": 68.26,
      "learning_rate": 6.587930641549749e-05,
      "loss": 0.0003,
      "step": 6724
    },
    {
      "epoch": 68.27,
      "learning_rate": 6.586804765116725e-05,
      "loss": 0.0007,
      "step": 6725
    },
    {
      "epoch": 68.28,
      "learning_rate": 6.58567879920832e-05,
      "loss": 0.0003,
      "step": 6726
    },
    {
      "epoch": 68.29,
      "learning_rate": 6.584552743888028e-05,
      "loss": 0.0004,
      "step": 6727
    },
    {
      "epoch": 68.3,
      "learning_rate": 6.583426599219339e-05,
      "loss": 0.0001,
      "step": 6728
    },
    {
      "epoch": 68.31,
      "learning_rate": 6.582300365265756e-05,
      "loss": 0.0013,
      "step": 6729
    },
    {
      "epoch": 68.32,
      "learning_rate": 6.581174042090782e-05,
      "loss": 0.0002,
      "step": 6730
    },
    {
      "epoch": 68.34,
      "learning_rate": 6.58004762975793e-05,
      "loss": 0.0001,
      "step": 6731
    },
    {
      "epoch": 68.35,
      "learning_rate": 6.578921128330714e-05,
      "loss": 0.0073,
      "step": 6732
    },
    {
      "epoch": 68.36,
      "learning_rate": 6.577794537872652e-05,
      "loss": 0.0019,
      "step": 6733
    },
    {
      "epoch": 68.37,
      "learning_rate": 6.576667858447272e-05,
      "loss": 0.0124,
      "step": 6734
    },
    {
      "epoch": 68.38,
      "learning_rate": 6.575541090118105e-05,
      "loss": 0.0056,
      "step": 6735
    },
    {
      "epoch": 68.39,
      "learning_rate": 6.574414232948682e-05,
      "loss": 0.0023,
      "step": 6736
    },
    {
      "epoch": 68.4,
      "learning_rate": 6.573287287002546e-05,
      "loss": 0.0193,
      "step": 6737
    },
    {
      "epoch": 68.41,
      "learning_rate": 6.572160252343242e-05,
      "loss": 0.0085,
      "step": 6738
    },
    {
      "epoch": 68.42,
      "learning_rate": 6.571033129034321e-05,
      "loss": 0.0011,
      "step": 6739
    },
    {
      "epoch": 68.43,
      "learning_rate": 6.569905917139338e-05,
      "loss": 0.0059,
      "step": 6740
    },
    {
      "epoch": 68.44,
      "learning_rate": 6.568778616721853e-05,
      "loss": 0.0129,
      "step": 6741
    },
    {
      "epoch": 68.45,
      "learning_rate": 6.567651227845429e-05,
      "loss": 0.0034,
      "step": 6742
    },
    {
      "epoch": 68.46,
      "learning_rate": 6.566523750573641e-05,
      "loss": 0.0003,
      "step": 6743
    },
    {
      "epoch": 68.47,
      "learning_rate": 6.56539618497006e-05,
      "loss": 0.0001,
      "step": 6744
    },
    {
      "epoch": 68.48,
      "learning_rate": 6.564268531098268e-05,
      "loss": 0.0013,
      "step": 6745
    },
    {
      "epoch": 68.49,
      "learning_rate": 6.563140789021849e-05,
      "loss": 0.0003,
      "step": 6746
    },
    {
      "epoch": 68.5,
      "learning_rate": 6.562012958804393e-05,
      "loss": 0.0005,
      "step": 6747
    },
    {
      "epoch": 68.51,
      "learning_rate": 6.560885040509499e-05,
      "loss": 0.0003,
      "step": 6748
    },
    {
      "epoch": 68.52,
      "learning_rate": 6.559757034200763e-05,
      "loss": 0.0006,
      "step": 6749
    },
    {
      "epoch": 68.53,
      "learning_rate": 6.558628939941791e-05,
      "loss": 0.0136,
      "step": 6750
    },
    {
      "epoch": 68.54,
      "learning_rate": 6.557500757796193e-05,
      "loss": 0.0013,
      "step": 6751
    },
    {
      "epoch": 68.55,
      "learning_rate": 6.556372487827586e-05,
      "loss": 0.0003,
      "step": 6752
    },
    {
      "epoch": 68.56,
      "learning_rate": 6.555244130099585e-05,
      "loss": 0.0002,
      "step": 6753
    },
    {
      "epoch": 68.57,
      "learning_rate": 6.554115684675821e-05,
      "loss": 0.0007,
      "step": 6754
    },
    {
      "epoch": 68.58,
      "learning_rate": 6.552987151619919e-05,
      "loss": 0.0021,
      "step": 6755
    },
    {
      "epoch": 68.59,
      "learning_rate": 6.551858530995517e-05,
      "loss": 0.0009,
      "step": 6756
    },
    {
      "epoch": 68.6,
      "learning_rate": 6.550729822866253e-05,
      "loss": 0.0002,
      "step": 6757
    },
    {
      "epoch": 68.61,
      "learning_rate": 6.549601027295771e-05,
      "loss": 0.0035,
      "step": 6758
    },
    {
      "epoch": 68.62,
      "learning_rate": 6.548472144347721e-05,
      "loss": 0.0004,
      "step": 6759
    },
    {
      "epoch": 68.63,
      "learning_rate": 6.54734317408576e-05,
      "loss": 0.0019,
      "step": 6760
    },
    {
      "epoch": 68.64,
      "learning_rate": 6.546214116573544e-05,
      "loss": 0.0025,
      "step": 6761
    },
    {
      "epoch": 68.65,
      "learning_rate": 6.545084971874738e-05,
      "loss": 0.0004,
      "step": 6762
    },
    {
      "epoch": 68.66,
      "learning_rate": 6.543955740053012e-05,
      "loss": 0.0071,
      "step": 6763
    },
    {
      "epoch": 68.67,
      "learning_rate": 6.542826421172041e-05,
      "loss": 0.0002,
      "step": 6764
    },
    {
      "epoch": 68.68,
      "learning_rate": 6.541697015295503e-05,
      "loss": 0.0005,
      "step": 6765
    },
    {
      "epoch": 68.69,
      "learning_rate": 6.540567522487081e-05,
      "loss": 0.0001,
      "step": 6766
    },
    {
      "epoch": 68.7,
      "learning_rate": 6.539437942810466e-05,
      "loss": 0.0005,
      "step": 6767
    },
    {
      "epoch": 68.71,
      "learning_rate": 6.538308276329349e-05,
      "loss": 0.0006,
      "step": 6768
    },
    {
      "epoch": 68.72,
      "learning_rate": 6.537178523107432e-05,
      "loss": 0.0001,
      "step": 6769
    },
    {
      "epoch": 68.73,
      "learning_rate": 6.536048683208416e-05,
      "loss": 0.0003,
      "step": 6770
    },
    {
      "epoch": 68.74,
      "learning_rate": 6.53491875669601e-05,
      "loss": 0.0042,
      "step": 6771
    },
    {
      "epoch": 68.75,
      "learning_rate": 6.53378874363393e-05,
      "loss": 0.0004,
      "step": 6772
    },
    {
      "epoch": 68.76,
      "learning_rate": 6.53265864408589e-05,
      "loss": 0.0006,
      "step": 6773
    },
    {
      "epoch": 68.77,
      "learning_rate": 6.531528458115615e-05,
      "loss": 0.0147,
      "step": 6774
    },
    {
      "epoch": 68.78,
      "learning_rate": 6.530398185786833e-05,
      "loss": 0.0143,
      "step": 6775
    },
    {
      "epoch": 68.79,
      "learning_rate": 6.529267827163277e-05,
      "loss": 0.0006,
      "step": 6776
    },
    {
      "epoch": 68.8,
      "learning_rate": 6.528137382308685e-05,
      "loss": 0.0008,
      "step": 6777
    },
    {
      "epoch": 68.81,
      "learning_rate": 6.527006851286799e-05,
      "loss": 0.0015,
      "step": 6778
    },
    {
      "epoch": 68.82,
      "learning_rate": 6.525876234161364e-05,
      "loss": 0.0039,
      "step": 6779
    },
    {
      "epoch": 68.83,
      "learning_rate": 6.524745530996137e-05,
      "loss": 0.0009,
      "step": 6780
    },
    {
      "epoch": 68.84,
      "learning_rate": 6.523614741854872e-05,
      "loss": 0.0006,
      "step": 6781
    },
    {
      "epoch": 68.85,
      "learning_rate": 6.522483866801332e-05,
      "loss": 0.0028,
      "step": 6782
    },
    {
      "epoch": 68.86,
      "learning_rate": 6.521352905899282e-05,
      "loss": 0.0006,
      "step": 6783
    },
    {
      "epoch": 68.87,
      "learning_rate": 6.520221859212497e-05,
      "loss": 0.0003,
      "step": 6784
    },
    {
      "epoch": 68.88,
      "learning_rate": 6.51909072680475e-05,
      "loss": 0.0176,
      "step": 6785
    },
    {
      "epoch": 68.89,
      "learning_rate": 6.517959508739826e-05,
      "loss": 0.0012,
      "step": 6786
    },
    {
      "epoch": 68.9,
      "learning_rate": 6.516828205081507e-05,
      "loss": 0.0097,
      "step": 6787
    },
    {
      "epoch": 68.91,
      "learning_rate": 6.515696815893587e-05,
      "loss": 0.0007,
      "step": 6788
    },
    {
      "epoch": 68.92,
      "learning_rate": 6.514565341239861e-05,
      "loss": 0.0003,
      "step": 6789
    },
    {
      "epoch": 68.93,
      "learning_rate": 6.51343378118413e-05,
      "loss": 0.0003,
      "step": 6790
    },
    {
      "epoch": 68.94,
      "learning_rate": 6.512302135790199e-05,
      "loss": 0.0251,
      "step": 6791
    },
    {
      "epoch": 68.95,
      "learning_rate": 6.511170405121877e-05,
      "loss": 0.005,
      "step": 6792
    },
    {
      "epoch": 68.96,
      "learning_rate": 6.510038589242981e-05,
      "loss": 0.0052,
      "step": 6793
    },
    {
      "epoch": 68.97,
      "learning_rate": 6.50890668821733e-05,
      "loss": 0.0059,
      "step": 6794
    },
    {
      "epoch": 68.98,
      "learning_rate": 6.507774702108747e-05,
      "loss": 0.012,
      "step": 6795
    },
    {
      "epoch": 68.99,
      "learning_rate": 6.506642630981067e-05,
      "loss": 0.0006,
      "step": 6796
    },
    {
      "epoch": 68.99,
      "eval_loss": 0.022348394617438316,
      "eval_runtime": 31.8607,
      "eval_samples_per_second": 98.868,
      "eval_steps_per_second": 6.183,
      "eval_wer": 0.004513444302176696,
      "step": 6796
    },
    {
      "epoch": 69.01,
      "learning_rate": 6.505510474898118e-05,
      "loss": 0.0009,
      "step": 6797
    },
    {
      "epoch": 69.02,
      "learning_rate": 6.504378233923743e-05,
      "loss": 0.0046,
      "step": 6798
    },
    {
      "epoch": 69.03,
      "learning_rate": 6.503245908121781e-05,
      "loss": 0.0018,
      "step": 6799
    },
    {
      "epoch": 69.04,
      "learning_rate": 6.502113497556087e-05,
      "loss": 0.0004,
      "step": 6800
    },
    {
      "epoch": 69.05,
      "learning_rate": 6.50098100229051e-05,
      "loss": 0.0015,
      "step": 6801
    },
    {
      "epoch": 69.06,
      "learning_rate": 6.499848422388911e-05,
      "loss": 0.0001,
      "step": 6802
    },
    {
      "epoch": 69.07,
      "learning_rate": 6.498715757915149e-05,
      "loss": 0.0002,
      "step": 6803
    },
    {
      "epoch": 69.08,
      "learning_rate": 6.497583008933097e-05,
      "loss": 0.0052,
      "step": 6804
    },
    {
      "epoch": 69.09,
      "learning_rate": 6.496450175506623e-05,
      "loss": 0.0003,
      "step": 6805
    },
    {
      "epoch": 69.1,
      "learning_rate": 6.495317257699606e-05,
      "loss": 0.0001,
      "step": 6806
    },
    {
      "epoch": 69.11,
      "learning_rate": 6.494184255575928e-05,
      "loss": 0.0017,
      "step": 6807
    },
    {
      "epoch": 69.12,
      "learning_rate": 6.493051169199476e-05,
      "loss": 0.0002,
      "step": 6808
    },
    {
      "epoch": 69.13,
      "learning_rate": 6.49191799863414e-05,
      "loss": 0.0011,
      "step": 6809
    },
    {
      "epoch": 69.14,
      "learning_rate": 6.490784743943818e-05,
      "loss": 0.0008,
      "step": 6810
    },
    {
      "epoch": 69.15,
      "learning_rate": 6.48965140519241e-05,
      "loss": 0.0002,
      "step": 6811
    },
    {
      "epoch": 69.16,
      "learning_rate": 6.488517982443823e-05,
      "loss": 0.0002,
      "step": 6812
    },
    {
      "epoch": 69.17,
      "learning_rate": 6.487384475761966e-05,
      "loss": 0.0002,
      "step": 6813
    },
    {
      "epoch": 69.18,
      "learning_rate": 6.486250885210753e-05,
      "loss": 0.0003,
      "step": 6814
    },
    {
      "epoch": 69.19,
      "learning_rate": 6.48511721085411e-05,
      "loss": 0.0042,
      "step": 6815
    },
    {
      "epoch": 69.2,
      "learning_rate": 6.483983452755953e-05,
      "loss": 0.0101,
      "step": 6816
    },
    {
      "epoch": 69.21,
      "learning_rate": 6.482849610980219e-05,
      "loss": 0.0002,
      "step": 6817
    },
    {
      "epoch": 69.22,
      "learning_rate": 6.481715685590836e-05,
      "loss": 0.0001,
      "step": 6818
    },
    {
      "epoch": 69.23,
      "learning_rate": 6.480581676651747e-05,
      "loss": 0.0177,
      "step": 6819
    },
    {
      "epoch": 69.24,
      "learning_rate": 6.479447584226892e-05,
      "loss": 0.0029,
      "step": 6820
    },
    {
      "epoch": 69.25,
      "learning_rate": 6.478313408380225e-05,
      "loss": 0.001,
      "step": 6821
    },
    {
      "epoch": 69.26,
      "learning_rate": 6.477179149175692e-05,
      "loss": 0.0043,
      "step": 6822
    },
    {
      "epoch": 69.27,
      "learning_rate": 6.476044806677258e-05,
      "loss": 0.0001,
      "step": 6823
    },
    {
      "epoch": 69.28,
      "learning_rate": 6.474910380948877e-05,
      "loss": 0.0005,
      "step": 6824
    },
    {
      "epoch": 69.29,
      "learning_rate": 6.473775872054521e-05,
      "loss": 0.0035,
      "step": 6825
    },
    {
      "epoch": 69.3,
      "learning_rate": 6.472641280058163e-05,
      "loss": 0.0001,
      "step": 6826
    },
    {
      "epoch": 69.31,
      "learning_rate": 6.471506605023775e-05,
      "loss": 0.0003,
      "step": 6827
    },
    {
      "epoch": 69.32,
      "learning_rate": 6.470371847015341e-05,
      "loss": 0.0018,
      "step": 6828
    },
    {
      "epoch": 69.33,
      "learning_rate": 6.469237006096848e-05,
      "loss": 0.0005,
      "step": 6829
    },
    {
      "epoch": 69.34,
      "learning_rate": 6.468102082332283e-05,
      "loss": 0.0001,
      "step": 6830
    },
    {
      "epoch": 69.35,
      "learning_rate": 6.466967075785643e-05,
      "loss": 0.0002,
      "step": 6831
    },
    {
      "epoch": 69.36,
      "learning_rate": 6.465831986520927e-05,
      "loss": 0.0004,
      "step": 6832
    },
    {
      "epoch": 69.37,
      "learning_rate": 6.46469681460214e-05,
      "loss": 0.0006,
      "step": 6833
    },
    {
      "epoch": 69.38,
      "learning_rate": 6.463561560093292e-05,
      "loss": 0.0001,
      "step": 6834
    },
    {
      "epoch": 69.39,
      "learning_rate": 6.462426223058395e-05,
      "loss": 0.0,
      "step": 6835
    },
    {
      "epoch": 69.4,
      "learning_rate": 6.461290803561469e-05,
      "loss": 0.0003,
      "step": 6836
    },
    {
      "epoch": 69.41,
      "learning_rate": 6.460155301666535e-05,
      "loss": 0.0135,
      "step": 6837
    },
    {
      "epoch": 69.42,
      "learning_rate": 6.459019717437624e-05,
      "loss": 0.0003,
      "step": 6838
    },
    {
      "epoch": 69.43,
      "learning_rate": 6.457884050938763e-05,
      "loss": 0.0146,
      "step": 6839
    },
    {
      "epoch": 69.44,
      "learning_rate": 6.456748302233995e-05,
      "loss": 0.0069,
      "step": 6840
    },
    {
      "epoch": 69.45,
      "learning_rate": 6.455612471387357e-05,
      "loss": 0.0009,
      "step": 6841
    },
    {
      "epoch": 69.46,
      "learning_rate": 6.454476558462899e-05,
      "loss": 0.0004,
      "step": 6842
    },
    {
      "epoch": 69.47,
      "learning_rate": 6.453340563524669e-05,
      "loss": 0.0172,
      "step": 6843
    },
    {
      "epoch": 69.48,
      "learning_rate": 6.452204486636724e-05,
      "loss": 0.0077,
      "step": 6844
    },
    {
      "epoch": 69.49,
      "learning_rate": 6.451068327863123e-05,
      "loss": 0.0006,
      "step": 6845
    },
    {
      "epoch": 69.5,
      "learning_rate": 6.449932087267932e-05,
      "loss": 0.0034,
      "step": 6846
    },
    {
      "epoch": 69.51,
      "learning_rate": 6.448795764915219e-05,
      "loss": 0.0132,
      "step": 6847
    },
    {
      "epoch": 69.52,
      "learning_rate": 6.447659360869059e-05,
      "loss": 0.0001,
      "step": 6848
    },
    {
      "epoch": 69.53,
      "learning_rate": 6.446522875193531e-05,
      "loss": 0.0012,
      "step": 6849
    },
    {
      "epoch": 69.54,
      "learning_rate": 6.445386307952716e-05,
      "loss": 0.0002,
      "step": 6850
    },
    {
      "epoch": 69.55,
      "learning_rate": 6.444249659210704e-05,
      "loss": 0.0015,
      "step": 6851
    },
    {
      "epoch": 69.56,
      "learning_rate": 6.443112929031587e-05,
      "loss": 0.0071,
      "step": 6852
    },
    {
      "epoch": 69.57,
      "learning_rate": 6.44197611747946e-05,
      "loss": 0.0098,
      "step": 6853
    },
    {
      "epoch": 69.58,
      "learning_rate": 6.440839224618427e-05,
      "loss": 0.001,
      "step": 6854
    },
    {
      "epoch": 69.59,
      "learning_rate": 6.439702250512596e-05,
      "loss": 0.0224,
      "step": 6855
    },
    {
      "epoch": 69.6,
      "learning_rate": 6.438565195226072e-05,
      "loss": 0.0106,
      "step": 6856
    },
    {
      "epoch": 69.61,
      "learning_rate": 6.437428058822972e-05,
      "loss": 0.0091,
      "step": 6857
    },
    {
      "epoch": 69.62,
      "learning_rate": 6.43629084136742e-05,
      "loss": 0.0271,
      "step": 6858
    },
    {
      "epoch": 69.63,
      "learning_rate": 6.435153542923538e-05,
      "loss": 0.0021,
      "step": 6859
    },
    {
      "epoch": 69.64,
      "learning_rate": 6.434016163555452e-05,
      "loss": 0.0003,
      "step": 6860
    },
    {
      "epoch": 69.65,
      "learning_rate": 6.432878703327298e-05,
      "loss": 0.0016,
      "step": 6861
    },
    {
      "epoch": 69.66,
      "learning_rate": 6.431741162303217e-05,
      "loss": 0.0019,
      "step": 6862
    },
    {
      "epoch": 69.68,
      "learning_rate": 6.430603540547348e-05,
      "loss": 0.0006,
      "step": 6863
    },
    {
      "epoch": 69.69,
      "learning_rate": 6.429465838123838e-05,
      "loss": 0.0002,
      "step": 6864
    },
    {
      "epoch": 69.7,
      "learning_rate": 6.42832805509684e-05,
      "loss": 0.0142,
      "step": 6865
    },
    {
      "epoch": 69.71,
      "learning_rate": 6.427190191530512e-05,
      "loss": 0.0009,
      "step": 6866
    },
    {
      "epoch": 69.72,
      "learning_rate": 6.426052247489012e-05,
      "loss": 0.0035,
      "step": 6867
    },
    {
      "epoch": 69.73,
      "learning_rate": 6.424914223036506e-05,
      "loss": 0.0137,
      "step": 6868
    },
    {
      "epoch": 69.74,
      "learning_rate": 6.423776118237165e-05,
      "loss": 0.0008,
      "step": 6869
    },
    {
      "epoch": 69.75,
      "learning_rate": 6.422637933155162e-05,
      "loss": 0.0,
      "step": 6870
    },
    {
      "epoch": 69.76,
      "learning_rate": 6.421499667854677e-05,
      "loss": 0.0005,
      "step": 6871
    },
    {
      "epoch": 69.77,
      "learning_rate": 6.420361322399897e-05,
      "loss": 0.0001,
      "step": 6872
    },
    {
      "epoch": 69.78,
      "learning_rate": 6.419222896855004e-05,
      "loss": 0.0005,
      "step": 6873
    },
    {
      "epoch": 69.79,
      "learning_rate": 6.418084391284192e-05,
      "loss": 0.0005,
      "step": 6874
    },
    {
      "epoch": 69.8,
      "learning_rate": 6.41694580575166e-05,
      "loss": 0.003,
      "step": 6875
    },
    {
      "epoch": 69.81,
      "learning_rate": 6.415807140321611e-05,
      "loss": 0.0063,
      "step": 6876
    },
    {
      "epoch": 69.82,
      "learning_rate": 6.414668395058245e-05,
      "loss": 0.0008,
      "step": 6877
    },
    {
      "epoch": 69.83,
      "learning_rate": 6.41352957002578e-05,
      "loss": 0.0013,
      "step": 6878
    },
    {
      "epoch": 69.84,
      "learning_rate": 6.412390665288426e-05,
      "loss": 0.0003,
      "step": 6879
    },
    {
      "epoch": 69.85,
      "learning_rate": 6.411251680910406e-05,
      "loss": 0.001,
      "step": 6880
    },
    {
      "epoch": 69.86,
      "learning_rate": 6.410112616955938e-05,
      "loss": 0.0058,
      "step": 6881
    },
    {
      "epoch": 69.87,
      "learning_rate": 6.408973473489257e-05,
      "loss": 0.0094,
      "step": 6882
    },
    {
      "epoch": 69.88,
      "learning_rate": 6.407834250574594e-05,
      "loss": 0.0073,
      "step": 6883
    },
    {
      "epoch": 69.89,
      "learning_rate": 6.406694948276186e-05,
      "loss": 0.0015,
      "step": 6884
    },
    {
      "epoch": 69.9,
      "learning_rate": 6.405555566658276e-05,
      "loss": 0.0004,
      "step": 6885
    },
    {
      "epoch": 69.91,
      "learning_rate": 6.40441610578511e-05,
      "loss": 0.0004,
      "step": 6886
    },
    {
      "epoch": 69.92,
      "learning_rate": 6.403276565720937e-05,
      "loss": 0.0,
      "step": 6887
    },
    {
      "epoch": 69.93,
      "learning_rate": 6.402136946530014e-05,
      "loss": 0.0067,
      "step": 6888
    },
    {
      "epoch": 69.94,
      "learning_rate": 6.400997248276602e-05,
      "loss": 0.0003,
      "step": 6889
    },
    {
      "epoch": 69.95,
      "learning_rate": 6.399857471024965e-05,
      "loss": 0.011,
      "step": 6890
    },
    {
      "epoch": 69.96,
      "learning_rate": 6.398717614839369e-05,
      "loss": 0.0017,
      "step": 6891
    },
    {
      "epoch": 69.97,
      "learning_rate": 6.39757767978409e-05,
      "loss": 0.0135,
      "step": 6892
    },
    {
      "epoch": 69.98,
      "learning_rate": 6.396437665923408e-05,
      "loss": 0.0006,
      "step": 6893
    },
    {
      "epoch": 69.99,
      "learning_rate": 6.395297573321597e-05,
      "loss": 0.0009,
      "step": 6894
    },
    {
      "epoch": 70.0,
      "learning_rate": 6.394157402042951e-05,
      "loss": 0.0027,
      "step": 6895
    },
    {
      "epoch": 70.0,
      "eval_loss": 0.02012988179922104,
      "eval_runtime": 32.2031,
      "eval_samples_per_second": 97.817,
      "eval_steps_per_second": 6.117,
      "eval_wer": 0.003745198463508323,
      "step": 6895
    },
    {
      "epoch": 70.01,
      "learning_rate": 6.393017152151759e-05,
      "loss": 0.0001,
      "step": 6896
    },
    {
      "epoch": 70.02,
      "learning_rate": 6.391876823712317e-05,
      "loss": 0.0002,
      "step": 6897
    },
    {
      "epoch": 70.03,
      "learning_rate": 6.390736416788921e-05,
      "loss": 0.0001,
      "step": 6898
    },
    {
      "epoch": 70.04,
      "learning_rate": 6.389595931445881e-05,
      "loss": 0.0005,
      "step": 6899
    },
    {
      "epoch": 70.05,
      "learning_rate": 6.388455367747502e-05,
      "loss": 0.0016,
      "step": 6900
    },
    {
      "epoch": 70.06,
      "learning_rate": 6.387314725758098e-05,
      "loss": 0.0009,
      "step": 6901
    },
    {
      "epoch": 70.07,
      "learning_rate": 6.386174005541986e-05,
      "loss": 0.0136,
      "step": 6902
    },
    {
      "epoch": 70.08,
      "learning_rate": 6.38503320716349e-05,
      "loss": 0.0001,
      "step": 6903
    },
    {
      "epoch": 70.09,
      "learning_rate": 6.383892330686934e-05,
      "loss": 0.0018,
      "step": 6904
    },
    {
      "epoch": 70.1,
      "learning_rate": 6.38275137617665e-05,
      "loss": 0.0086,
      "step": 6905
    },
    {
      "epoch": 70.11,
      "learning_rate": 6.381610343696971e-05,
      "loss": 0.0014,
      "step": 6906
    },
    {
      "epoch": 70.12,
      "learning_rate": 6.38046923331224e-05,
      "loss": 0.0022,
      "step": 6907
    },
    {
      "epoch": 70.13,
      "learning_rate": 6.379328045086799e-05,
      "loss": 0.0006,
      "step": 6908
    },
    {
      "epoch": 70.14,
      "learning_rate": 6.378186779084995e-05,
      "loss": 0.0009,
      "step": 6909
    },
    {
      "epoch": 70.15,
      "learning_rate": 6.377045435371185e-05,
      "loss": 0.0004,
      "step": 6910
    },
    {
      "epoch": 70.16,
      "learning_rate": 6.375904014009724e-05,
      "loss": 0.0003,
      "step": 6911
    },
    {
      "epoch": 70.17,
      "learning_rate": 6.374762515064971e-05,
      "loss": 0.0005,
      "step": 6912
    },
    {
      "epoch": 70.18,
      "learning_rate": 6.373620938601294e-05,
      "loss": 0.0033,
      "step": 6913
    },
    {
      "epoch": 70.19,
      "learning_rate": 6.372479284683062e-05,
      "loss": 0.0255,
      "step": 6914
    },
    {
      "epoch": 70.2,
      "learning_rate": 6.371337553374652e-05,
      "loss": 0.0133,
      "step": 6915
    },
    {
      "epoch": 70.21,
      "learning_rate": 6.370195744740442e-05,
      "loss": 0.0003,
      "step": 6916
    },
    {
      "epoch": 70.22,
      "learning_rate": 6.369053858844814e-05,
      "loss": 0.0035,
      "step": 6917
    },
    {
      "epoch": 70.23,
      "learning_rate": 6.367911895752159e-05,
      "loss": 0.0002,
      "step": 6918
    },
    {
      "epoch": 70.24,
      "learning_rate": 6.366769855526863e-05,
      "loss": 0.0243,
      "step": 6919
    },
    {
      "epoch": 70.25,
      "learning_rate": 6.365627738233329e-05,
      "loss": 0.0086,
      "step": 6920
    },
    {
      "epoch": 70.26,
      "learning_rate": 6.364485543935951e-05,
      "loss": 0.0002,
      "step": 6921
    },
    {
      "epoch": 70.27,
      "learning_rate": 6.363343272699142e-05,
      "loss": 0.0003,
      "step": 6922
    },
    {
      "epoch": 70.28,
      "learning_rate": 6.362200924587305e-05,
      "loss": 0.0003,
      "step": 6923
    },
    {
      "epoch": 70.29,
      "learning_rate": 6.361058499664856e-05,
      "loss": 0.0139,
      "step": 6924
    },
    {
      "epoch": 70.3,
      "learning_rate": 6.359915997996212e-05,
      "loss": 0.0036,
      "step": 6925
    },
    {
      "epoch": 70.31,
      "learning_rate": 6.358773419645801e-05,
      "loss": 0.0015,
      "step": 6926
    },
    {
      "epoch": 70.32,
      "learning_rate": 6.35763076467804e-05,
      "loss": 0.0203,
      "step": 6927
    },
    {
      "epoch": 70.34,
      "learning_rate": 6.356488033157369e-05,
      "loss": 0.0002,
      "step": 6928
    },
    {
      "epoch": 70.35,
      "learning_rate": 6.355345225148216e-05,
      "loss": 0.0009,
      "step": 6929
    },
    {
      "epoch": 70.36,
      "learning_rate": 6.354202340715026e-05,
      "loss": 0.0042,
      "step": 6930
    },
    {
      "epoch": 70.37,
      "learning_rate": 6.353059379922242e-05,
      "loss": 0.0007,
      "step": 6931
    },
    {
      "epoch": 70.38,
      "learning_rate": 6.35191634283431e-05,
      "loss": 0.0044,
      "step": 6932
    },
    {
      "epoch": 70.39,
      "learning_rate": 6.350773229515685e-05,
      "loss": 0.001,
      "step": 6933
    },
    {
      "epoch": 70.4,
      "learning_rate": 6.349630040030823e-05,
      "loss": 0.0004,
      "step": 6934
    },
    {
      "epoch": 70.41,
      "learning_rate": 6.348486774444184e-05,
      "loss": 0.002,
      "step": 6935
    },
    {
      "epoch": 70.42,
      "learning_rate": 6.347343432820236e-05,
      "loss": 0.0024,
      "step": 6936
    },
    {
      "epoch": 70.43,
      "learning_rate": 6.346200015223446e-05,
      "loss": 0.0204,
      "step": 6937
    },
    {
      "epoch": 70.44,
      "learning_rate": 6.345056521718291e-05,
      "loss": 0.0021,
      "step": 6938
    },
    {
      "epoch": 70.45,
      "learning_rate": 6.343912952369246e-05,
      "loss": 0.0009,
      "step": 6939
    },
    {
      "epoch": 70.46,
      "learning_rate": 6.342769307240796e-05,
      "loss": 0.0057,
      "step": 6940
    },
    {
      "epoch": 70.47,
      "learning_rate": 6.34162558639743e-05,
      "loss": 0.0,
      "step": 6941
    },
    {
      "epoch": 70.48,
      "learning_rate": 6.340481789903634e-05,
      "loss": 0.0001,
      "step": 6942
    },
    {
      "epoch": 70.49,
      "learning_rate": 6.339337917823905e-05,
      "loss": 0.0131,
      "step": 6943
    },
    {
      "epoch": 70.5,
      "learning_rate": 6.338193970222744e-05,
      "loss": 0.0003,
      "step": 6944
    },
    {
      "epoch": 70.51,
      "learning_rate": 6.337049947164656e-05,
      "loss": 0.0081,
      "step": 6945
    },
    {
      "epoch": 70.52,
      "learning_rate": 6.335905848714147e-05,
      "loss": 0.005,
      "step": 6946
    },
    {
      "epoch": 70.53,
      "learning_rate": 6.334761674935729e-05,
      "loss": 0.0103,
      "step": 6947
    },
    {
      "epoch": 70.54,
      "learning_rate": 6.333617425893919e-05,
      "loss": 0.0007,
      "step": 6948
    },
    {
      "epoch": 70.55,
      "learning_rate": 6.332473101653241e-05,
      "loss": 0.0165,
      "step": 6949
    },
    {
      "epoch": 70.56,
      "learning_rate": 6.331328702278216e-05,
      "loss": 0.0002,
      "step": 6950
    },
    {
      "epoch": 70.57,
      "learning_rate": 6.330184227833376e-05,
      "loss": 0.0003,
      "step": 6951
    },
    {
      "epoch": 70.58,
      "learning_rate": 6.329039678383254e-05,
      "loss": 0.0006,
      "step": 6952
    },
    {
      "epoch": 70.59,
      "learning_rate": 6.327895053992387e-05,
      "loss": 0.0054,
      "step": 6953
    },
    {
      "epoch": 70.6,
      "learning_rate": 6.326750354725319e-05,
      "loss": 0.0171,
      "step": 6954
    },
    {
      "epoch": 70.61,
      "learning_rate": 6.325605580646594e-05,
      "loss": 0.0002,
      "step": 6955
    },
    {
      "epoch": 70.62,
      "learning_rate": 6.324460731820764e-05,
      "loss": 0.0002,
      "step": 6956
    },
    {
      "epoch": 70.63,
      "learning_rate": 6.323315808312383e-05,
      "loss": 0.0053,
      "step": 6957
    },
    {
      "epoch": 70.64,
      "learning_rate": 6.322170810186012e-05,
      "loss": 0.0148,
      "step": 6958
    },
    {
      "epoch": 70.65,
      "learning_rate": 6.321025737506211e-05,
      "loss": 0.0027,
      "step": 6959
    },
    {
      "epoch": 70.66,
      "learning_rate": 6.319880590337549e-05,
      "loss": 0.0003,
      "step": 6960
    },
    {
      "epoch": 70.67,
      "learning_rate": 6.318735368744598e-05,
      "loss": 0.0042,
      "step": 6961
    },
    {
      "epoch": 70.68,
      "learning_rate": 6.317590072791935e-05,
      "loss": 0.0261,
      "step": 6962
    },
    {
      "epoch": 70.69,
      "learning_rate": 6.316444702544136e-05,
      "loss": 0.0001,
      "step": 6963
    },
    {
      "epoch": 70.7,
      "learning_rate": 6.315299258065786e-05,
      "loss": 0.0001,
      "step": 6964
    },
    {
      "epoch": 70.71,
      "learning_rate": 6.314153739421476e-05,
      "loss": 0.0008,
      "step": 6965
    },
    {
      "epoch": 70.72,
      "learning_rate": 6.3130081466758e-05,
      "loss": 0.0013,
      "step": 6966
    },
    {
      "epoch": 70.73,
      "learning_rate": 6.311862479893348e-05,
      "loss": 0.0004,
      "step": 6967
    },
    {
      "epoch": 70.74,
      "learning_rate": 6.310716739138727e-05,
      "loss": 0.0155,
      "step": 6968
    },
    {
      "epoch": 70.75,
      "learning_rate": 6.30957092447654e-05,
      "loss": 0.019,
      "step": 6969
    },
    {
      "epoch": 70.76,
      "learning_rate": 6.308425035971395e-05,
      "loss": 0.0001,
      "step": 6970
    },
    {
      "epoch": 70.77,
      "learning_rate": 6.307279073687907e-05,
      "loss": 0.0001,
      "step": 6971
    },
    {
      "epoch": 70.78,
      "learning_rate": 6.306133037690693e-05,
      "loss": 0.0079,
      "step": 6972
    },
    {
      "epoch": 70.79,
      "learning_rate": 6.304986928044374e-05,
      "loss": 0.0013,
      "step": 6973
    },
    {
      "epoch": 70.8,
      "learning_rate": 6.303840744813577e-05,
      "loss": 0.0086,
      "step": 6974
    },
    {
      "epoch": 70.81,
      "learning_rate": 6.302694488062931e-05,
      "loss": 0.0075,
      "step": 6975
    },
    {
      "epoch": 70.82,
      "learning_rate": 6.30154815785707e-05,
      "loss": 0.0071,
      "step": 6976
    },
    {
      "epoch": 70.83,
      "learning_rate": 6.300401754260635e-05,
      "loss": 0.0003,
      "step": 6977
    },
    {
      "epoch": 70.84,
      "learning_rate": 6.299255277338265e-05,
      "loss": 0.0083,
      "step": 6978
    },
    {
      "epoch": 70.85,
      "learning_rate": 6.298108727154608e-05,
      "loss": 0.0196,
      "step": 6979
    },
    {
      "epoch": 70.86,
      "learning_rate": 6.296962103774315e-05,
      "loss": 0.0005,
      "step": 6980
    },
    {
      "epoch": 70.87,
      "learning_rate": 6.29581540726204e-05,
      "loss": 0.0003,
      "step": 6981
    },
    {
      "epoch": 70.88,
      "learning_rate": 6.294668637682441e-05,
      "loss": 0.0001,
      "step": 6982
    },
    {
      "epoch": 70.89,
      "learning_rate": 6.293521795100186e-05,
      "loss": 0.0004,
      "step": 6983
    },
    {
      "epoch": 70.9,
      "learning_rate": 6.292374879579934e-05,
      "loss": 0.0071,
      "step": 6984
    },
    {
      "epoch": 70.91,
      "learning_rate": 6.291227891186364e-05,
      "loss": 0.0004,
      "step": 6985
    },
    {
      "epoch": 70.92,
      "learning_rate": 6.290080829984147e-05,
      "loss": 0.0011,
      "step": 6986
    },
    {
      "epoch": 70.93,
      "learning_rate": 6.288933696037966e-05,
      "loss": 0.0176,
      "step": 6987
    },
    {
      "epoch": 70.94,
      "learning_rate": 6.287786489412499e-05,
      "loss": 0.0205,
      "step": 6988
    },
    {
      "epoch": 70.95,
      "learning_rate": 6.286639210172438e-05,
      "loss": 0.0009,
      "step": 6989
    },
    {
      "epoch": 70.96,
      "learning_rate": 6.285491858382475e-05,
      "loss": 0.0009,
      "step": 6990
    },
    {
      "epoch": 70.97,
      "learning_rate": 6.284344434107302e-05,
      "loss": 0.0057,
      "step": 6991
    },
    {
      "epoch": 70.98,
      "learning_rate": 6.283196937411624e-05,
      "loss": 0.0004,
      "step": 6992
    },
    {
      "epoch": 70.99,
      "learning_rate": 6.282049368360142e-05,
      "loss": 0.0008,
      "step": 6993
    },
    {
      "epoch": 70.99,
      "eval_loss": 0.019043903797864914,
      "eval_runtime": 33.1297,
      "eval_samples_per_second": 95.081,
      "eval_steps_per_second": 5.946,
      "eval_wer": 0.0038092189500640206,
      "step": 6993
    },
    {
      "epoch": 71.01,
      "learning_rate": 6.280901727017565e-05,
      "loss": 0.0001,
      "step": 6994
    },
    {
      "epoch": 71.02,
      "learning_rate": 6.279754013448605e-05,
      "loss": 0.0003,
      "step": 6995
    },
    {
      "epoch": 71.03,
      "learning_rate": 6.27860622771798e-05,
      "loss": 0.003,
      "step": 6996
    },
    {
      "epoch": 71.04,
      "learning_rate": 6.277458369890405e-05,
      "loss": 0.0007,
      "step": 6997
    },
    {
      "epoch": 71.05,
      "learning_rate": 6.27631044003061e-05,
      "loss": 0.0033,
      "step": 6998
    },
    {
      "epoch": 71.06,
      "learning_rate": 6.275162438203323e-05,
      "loss": 0.0001,
      "step": 6999
    },
    {
      "epoch": 71.07,
      "learning_rate": 6.274014364473274e-05,
      "loss": 0.0014,
      "step": 7000
    },
    {
      "epoch": 71.08,
      "learning_rate": 6.2728662189052e-05,
      "loss": 0.0001,
      "step": 7001
    },
    {
      "epoch": 71.09,
      "learning_rate": 6.271718001563844e-05,
      "loss": 0.0007,
      "step": 7002
    },
    {
      "epoch": 71.1,
      "learning_rate": 6.270569712513948e-05,
      "loss": 0.0078,
      "step": 7003
    },
    {
      "epoch": 71.11,
      "learning_rate": 6.269421351820261e-05,
      "loss": 0.0041,
      "step": 7004
    },
    {
      "epoch": 71.12,
      "learning_rate": 6.268272919547537e-05,
      "loss": 0.0004,
      "step": 7005
    },
    {
      "epoch": 71.13,
      "learning_rate": 6.267124415760533e-05,
      "loss": 0.0002,
      "step": 7006
    },
    {
      "epoch": 71.14,
      "learning_rate": 6.26597584052401e-05,
      "loss": 0.0043,
      "step": 7007
    },
    {
      "epoch": 71.15,
      "learning_rate": 6.264827193902731e-05,
      "loss": 0.0002,
      "step": 7008
    },
    {
      "epoch": 71.16,
      "learning_rate": 6.263678475961465e-05,
      "loss": 0.0257,
      "step": 7009
    },
    {
      "epoch": 71.17,
      "learning_rate": 6.262529686764988e-05,
      "loss": 0.0001,
      "step": 7010
    },
    {
      "epoch": 71.18,
      "learning_rate": 6.261380826378074e-05,
      "loss": 0.004,
      "step": 7011
    },
    {
      "epoch": 71.19,
      "learning_rate": 6.260231894865504e-05,
      "loss": 0.0004,
      "step": 7012
    },
    {
      "epoch": 71.2,
      "learning_rate": 6.259082892292063e-05,
      "loss": 0.0004,
      "step": 7013
    },
    {
      "epoch": 71.21,
      "learning_rate": 6.257933818722543e-05,
      "loss": 0.0001,
      "step": 7014
    },
    {
      "epoch": 71.22,
      "learning_rate": 6.256784674221734e-05,
      "loss": 0.0222,
      "step": 7015
    },
    {
      "epoch": 71.23,
      "learning_rate": 6.255635458854433e-05,
      "loss": 0.0101,
      "step": 7016
    },
    {
      "epoch": 71.24,
      "learning_rate": 6.254486172685443e-05,
      "loss": 0.0072,
      "step": 7017
    },
    {
      "epoch": 71.25,
      "learning_rate": 6.253336815779565e-05,
      "loss": 0.0001,
      "step": 7018
    },
    {
      "epoch": 71.26,
      "learning_rate": 6.252187388201613e-05,
      "loss": 0.0001,
      "step": 7019
    },
    {
      "epoch": 71.27,
      "learning_rate": 6.251037890016395e-05,
      "loss": 0.0023,
      "step": 7020
    },
    {
      "epoch": 71.28,
      "learning_rate": 6.249888321288733e-05,
      "loss": 0.0001,
      "step": 7021
    },
    {
      "epoch": 71.29,
      "learning_rate": 6.248738682083444e-05,
      "loss": 0.0069,
      "step": 7022
    },
    {
      "epoch": 71.3,
      "learning_rate": 6.247588972465354e-05,
      "loss": 0.0001,
      "step": 7023
    },
    {
      "epoch": 71.31,
      "learning_rate": 6.246439192499292e-05,
      "loss": 0.0002,
      "step": 7024
    },
    {
      "epoch": 71.32,
      "learning_rate": 6.245289342250093e-05,
      "loss": 0.0003,
      "step": 7025
    },
    {
      "epoch": 71.33,
      "learning_rate": 6.244139421782587e-05,
      "loss": 0.0045,
      "step": 7026
    },
    {
      "epoch": 71.34,
      "learning_rate": 6.242989431161624e-05,
      "loss": 0.004,
      "step": 7027
    },
    {
      "epoch": 71.35,
      "learning_rate": 6.241839370452041e-05,
      "loss": 0.0002,
      "step": 7028
    },
    {
      "epoch": 71.36,
      "learning_rate": 6.240689239718691e-05,
      "loss": 0.002,
      "step": 7029
    },
    {
      "epoch": 71.37,
      "learning_rate": 6.239539039026423e-05,
      "loss": 0.0002,
      "step": 7030
    },
    {
      "epoch": 71.38,
      "learning_rate": 6.238388768440098e-05,
      "loss": 0.0033,
      "step": 7031
    },
    {
      "epoch": 71.39,
      "learning_rate": 6.237238428024572e-05,
      "loss": 0.0075,
      "step": 7032
    },
    {
      "epoch": 71.4,
      "learning_rate": 6.236088017844713e-05,
      "loss": 0.0023,
      "step": 7033
    },
    {
      "epoch": 71.41,
      "learning_rate": 6.234937537965387e-05,
      "loss": 0.0001,
      "step": 7034
    },
    {
      "epoch": 71.42,
      "learning_rate": 6.233786988451468e-05,
      "loss": 0.0003,
      "step": 7035
    },
    {
      "epoch": 71.43,
      "learning_rate": 6.232636369367832e-05,
      "loss": 0.0038,
      "step": 7036
    },
    {
      "epoch": 71.44,
      "learning_rate": 6.231485680779358e-05,
      "loss": 0.0002,
      "step": 7037
    },
    {
      "epoch": 71.45,
      "learning_rate": 6.230334922750929e-05,
      "loss": 0.0075,
      "step": 7038
    },
    {
      "epoch": 71.46,
      "learning_rate": 6.229184095347435e-05,
      "loss": 0.0008,
      "step": 7039
    },
    {
      "epoch": 71.47,
      "learning_rate": 6.228033198633769e-05,
      "loss": 0.0025,
      "step": 7040
    },
    {
      "epoch": 71.48,
      "learning_rate": 6.226882232674825e-05,
      "loss": 0.019,
      "step": 7041
    },
    {
      "epoch": 71.49,
      "learning_rate": 6.2257311975355e-05,
      "loss": 0.0004,
      "step": 7042
    },
    {
      "epoch": 71.5,
      "learning_rate": 6.224580093280701e-05,
      "loss": 0.0027,
      "step": 7043
    },
    {
      "epoch": 71.51,
      "learning_rate": 6.223428919975338e-05,
      "loss": 0.0002,
      "step": 7044
    },
    {
      "epoch": 71.52,
      "learning_rate": 6.222277677684317e-05,
      "loss": 0.0002,
      "step": 7045
    },
    {
      "epoch": 71.53,
      "learning_rate": 6.221126366472556e-05,
      "loss": 0.0161,
      "step": 7046
    },
    {
      "epoch": 71.54,
      "learning_rate": 6.219974986404971e-05,
      "loss": 0.0003,
      "step": 7047
    },
    {
      "epoch": 71.55,
      "learning_rate": 6.218823537546491e-05,
      "loss": 0.0,
      "step": 7048
    },
    {
      "epoch": 71.56,
      "learning_rate": 6.217672019962038e-05,
      "loss": 0.0002,
      "step": 7049
    },
    {
      "epoch": 71.57,
      "learning_rate": 6.216520433716545e-05,
      "loss": 0.0028,
      "step": 7050
    },
    {
      "epoch": 71.58,
      "learning_rate": 6.215368778874944e-05,
      "loss": 0.0001,
      "step": 7051
    },
    {
      "epoch": 71.59,
      "learning_rate": 6.214217055502178e-05,
      "loss": 0.0012,
      "step": 7052
    },
    {
      "epoch": 71.6,
      "learning_rate": 6.213065263663185e-05,
      "loss": 0.0078,
      "step": 7053
    },
    {
      "epoch": 71.61,
      "learning_rate": 6.211913403422914e-05,
      "loss": 0.0003,
      "step": 7054
    },
    {
      "epoch": 71.62,
      "learning_rate": 6.210761474846313e-05,
      "loss": 0.0041,
      "step": 7055
    },
    {
      "epoch": 71.63,
      "learning_rate": 6.209609477998338e-05,
      "loss": 0.0008,
      "step": 7056
    },
    {
      "epoch": 71.64,
      "learning_rate": 6.208457412943948e-05,
      "loss": 0.0001,
      "step": 7057
    },
    {
      "epoch": 71.65,
      "learning_rate": 6.2073052797481e-05,
      "loss": 0.005,
      "step": 7058
    },
    {
      "epoch": 71.66,
      "learning_rate": 6.206153078475763e-05,
      "loss": 0.001,
      "step": 7059
    },
    {
      "epoch": 71.68,
      "learning_rate": 6.205000809191905e-05,
      "loss": 0.0,
      "step": 7060
    },
    {
      "epoch": 71.69,
      "learning_rate": 6.203848471961501e-05,
      "loss": 0.0035,
      "step": 7061
    },
    {
      "epoch": 71.7,
      "learning_rate": 6.202696066849525e-05,
      "loss": 0.0106,
      "step": 7062
    },
    {
      "epoch": 71.71,
      "learning_rate": 6.20154359392096e-05,
      "loss": 0.0092,
      "step": 7063
    },
    {
      "epoch": 71.72,
      "learning_rate": 6.200391053240789e-05,
      "loss": 0.0003,
      "step": 7064
    },
    {
      "epoch": 71.73,
      "learning_rate": 6.199238444874005e-05,
      "loss": 0.0002,
      "step": 7065
    },
    {
      "epoch": 71.74,
      "learning_rate": 6.198085768885593e-05,
      "loss": 0.0124,
      "step": 7066
    },
    {
      "epoch": 71.75,
      "learning_rate": 6.196933025340554e-05,
      "loss": 0.0004,
      "step": 7067
    },
    {
      "epoch": 71.76,
      "learning_rate": 6.195780214303888e-05,
      "loss": 0.0026,
      "step": 7068
    },
    {
      "epoch": 71.77,
      "learning_rate": 6.194627335840599e-05,
      "loss": 0.0034,
      "step": 7069
    },
    {
      "epoch": 71.78,
      "learning_rate": 6.19347439001569e-05,
      "loss": 0.0003,
      "step": 7070
    },
    {
      "epoch": 71.79,
      "learning_rate": 6.192321376894175e-05,
      "loss": 0.0002,
      "step": 7071
    },
    {
      "epoch": 71.8,
      "learning_rate": 6.191168296541072e-05,
      "loss": 0.0005,
      "step": 7072
    },
    {
      "epoch": 71.81,
      "learning_rate": 6.190015149021397e-05,
      "loss": 0.0002,
      "step": 7073
    },
    {
      "epoch": 71.82,
      "learning_rate": 6.188861934400172e-05,
      "loss": 0.0005,
      "step": 7074
    },
    {
      "epoch": 71.83,
      "learning_rate": 6.187708652742424e-05,
      "loss": 0.0005,
      "step": 7075
    },
    {
      "epoch": 71.84,
      "learning_rate": 6.186555304113186e-05,
      "loss": 0.0023,
      "step": 7076
    },
    {
      "epoch": 71.85,
      "learning_rate": 6.185401888577488e-05,
      "loss": 0.0001,
      "step": 7077
    },
    {
      "epoch": 71.86,
      "learning_rate": 6.184248406200372e-05,
      "loss": 0.002,
      "step": 7078
    },
    {
      "epoch": 71.87,
      "learning_rate": 6.183094857046874e-05,
      "loss": 0.0002,
      "step": 7079
    },
    {
      "epoch": 71.88,
      "learning_rate": 6.181941241182045e-05,
      "loss": 0.0004,
      "step": 7080
    },
    {
      "epoch": 71.89,
      "learning_rate": 6.18078755867093e-05,
      "loss": 0.002,
      "step": 7081
    },
    {
      "epoch": 71.9,
      "learning_rate": 6.179633809578585e-05,
      "loss": 0.0002,
      "step": 7082
    },
    {
      "epoch": 71.91,
      "learning_rate": 6.178479993970064e-05,
      "loss": 0.0301,
      "step": 7083
    },
    {
      "epoch": 71.92,
      "learning_rate": 6.177326111910429e-05,
      "loss": 0.001,
      "step": 7084
    },
    {
      "epoch": 71.93,
      "learning_rate": 6.176172163464744e-05,
      "loss": 0.0063,
      "step": 7085
    },
    {
      "epoch": 71.94,
      "learning_rate": 6.175018148698077e-05,
      "loss": 0.0001,
      "step": 7086
    },
    {
      "epoch": 71.95,
      "learning_rate": 6.173864067675497e-05,
      "loss": 0.0002,
      "step": 7087
    },
    {
      "epoch": 71.96,
      "learning_rate": 6.172709920462084e-05,
      "loss": 0.0105,
      "step": 7088
    },
    {
      "epoch": 71.97,
      "learning_rate": 6.171555707122911e-05,
      "loss": 0.0,
      "step": 7089
    },
    {
      "epoch": 71.98,
      "learning_rate": 6.170401427723067e-05,
      "loss": 0.0002,
      "step": 7090
    },
    {
      "epoch": 71.99,
      "learning_rate": 6.169247082327634e-05,
      "loss": 0.0076,
      "step": 7091
    },
    {
      "epoch": 72.0,
      "learning_rate": 6.168092671001705e-05,
      "loss": 0.0137,
      "step": 7092
    },
    {
      "epoch": 72.0,
      "eval_loss": 0.023862158879637718,
      "eval_runtime": 32.0651,
      "eval_samples_per_second": 98.238,
      "eval_steps_per_second": 6.144,
      "eval_wer": 0.0038732394366197184,
      "step": 7092
    },
    {
      "epoch": 72.01,
      "learning_rate": 6.166938193810374e-05,
      "loss": 0.018,
      "step": 7093
    },
    {
      "epoch": 72.02,
      "learning_rate": 6.165783650818735e-05,
      "loss": 0.0001,
      "step": 7094
    },
    {
      "epoch": 72.03,
      "learning_rate": 6.164629042091893e-05,
      "loss": 0.0,
      "step": 7095
    },
    {
      "epoch": 72.04,
      "learning_rate": 6.163474367694953e-05,
      "loss": 0.0036,
      "step": 7096
    },
    {
      "epoch": 72.05,
      "learning_rate": 6.162319627693022e-05,
      "loss": 0.0044,
      "step": 7097
    },
    {
      "epoch": 72.06,
      "learning_rate": 6.161164822151213e-05,
      "loss": 0.0007,
      "step": 7098
    },
    {
      "epoch": 72.07,
      "learning_rate": 6.160009951134645e-05,
      "loss": 0.0003,
      "step": 7099
    },
    {
      "epoch": 72.08,
      "learning_rate": 6.158855014708431e-05,
      "loss": 0.0049,
      "step": 7100
    },
    {
      "epoch": 72.09,
      "learning_rate": 6.157700012937702e-05,
      "loss": 0.0132,
      "step": 7101
    },
    {
      "epoch": 72.1,
      "learning_rate": 6.156544945887581e-05,
      "loss": 0.0005,
      "step": 7102
    },
    {
      "epoch": 72.11,
      "learning_rate": 6.155389813623201e-05,
      "loss": 0.0128,
      "step": 7103
    },
    {
      "epoch": 72.12,
      "learning_rate": 6.154234616209693e-05,
      "loss": 0.0001,
      "step": 7104
    },
    {
      "epoch": 72.13,
      "learning_rate": 6.153079353712201e-05,
      "loss": 0.0006,
      "step": 7105
    },
    {
      "epoch": 72.14,
      "learning_rate": 6.151924026195864e-05,
      "loss": 0.0003,
      "step": 7106
    },
    {
      "epoch": 72.15,
      "learning_rate": 6.150768633725826e-05,
      "loss": 0.0011,
      "step": 7107
    },
    {
      "epoch": 72.16,
      "learning_rate": 6.149613176367237e-05,
      "loss": 0.0005,
      "step": 7108
    },
    {
      "epoch": 72.17,
      "learning_rate": 6.148457654185253e-05,
      "loss": 0.0022,
      "step": 7109
    },
    {
      "epoch": 72.18,
      "learning_rate": 6.147302067245028e-05,
      "loss": 0.0086,
      "step": 7110
    },
    {
      "epoch": 72.19,
      "learning_rate": 6.146146415611723e-05,
      "loss": 0.0102,
      "step": 7111
    },
    {
      "epoch": 72.2,
      "learning_rate": 6.144990699350497e-05,
      "loss": 0.0005,
      "step": 7112
    },
    {
      "epoch": 72.21,
      "learning_rate": 6.143834918526527e-05,
      "loss": 0.0003,
      "step": 7113
    },
    {
      "epoch": 72.22,
      "learning_rate": 6.142679073204978e-05,
      "loss": 0.0001,
      "step": 7114
    },
    {
      "epoch": 72.23,
      "learning_rate": 6.141523163451025e-05,
      "loss": 0.0014,
      "step": 7115
    },
    {
      "epoch": 72.24,
      "learning_rate": 6.140367189329848e-05,
      "loss": 0.0069,
      "step": 7116
    },
    {
      "epoch": 72.25,
      "learning_rate": 6.139211150906629e-05,
      "loss": 0.0002,
      "step": 7117
    },
    {
      "epoch": 72.26,
      "learning_rate": 6.138055048246552e-05,
      "loss": 0.0,
      "step": 7118
    },
    {
      "epoch": 72.27,
      "learning_rate": 6.136898881414807e-05,
      "loss": 0.0185,
      "step": 7119
    },
    {
      "epoch": 72.28,
      "learning_rate": 6.135742650476589e-05,
      "loss": 0.0006,
      "step": 7120
    },
    {
      "epoch": 72.29,
      "learning_rate": 6.134586355497092e-05,
      "loss": 0.0,
      "step": 7121
    },
    {
      "epoch": 72.3,
      "learning_rate": 6.133429996541518e-05,
      "loss": 0.0167,
      "step": 7122
    },
    {
      "epoch": 72.31,
      "learning_rate": 6.13227357367507e-05,
      "loss": 0.0001,
      "step": 7123
    },
    {
      "epoch": 72.32,
      "learning_rate": 6.131117086962954e-05,
      "loss": 0.0089,
      "step": 7124
    },
    {
      "epoch": 72.34,
      "learning_rate": 6.129960536470382e-05,
      "loss": 0.0001,
      "step": 7125
    },
    {
      "epoch": 72.35,
      "learning_rate": 6.128803922262573e-05,
      "loss": 0.011,
      "step": 7126
    },
    {
      "epoch": 72.36,
      "learning_rate": 6.127647244404737e-05,
      "loss": 0.0155,
      "step": 7127
    },
    {
      "epoch": 72.37,
      "learning_rate": 6.1264905029621e-05,
      "loss": 0.0011,
      "step": 7128
    },
    {
      "epoch": 72.38,
      "learning_rate": 6.125333697999888e-05,
      "loss": 0.0007,
      "step": 7129
    },
    {
      "epoch": 72.39,
      "learning_rate": 6.12417682958333e-05,
      "loss": 0.0023,
      "step": 7130
    },
    {
      "epoch": 72.4,
      "learning_rate": 6.123019897777657e-05,
      "loss": 0.0002,
      "step": 7131
    },
    {
      "epoch": 72.41,
      "learning_rate": 6.121862902648106e-05,
      "loss": 0.0055,
      "step": 7132
    },
    {
      "epoch": 72.42,
      "learning_rate": 6.120705844259913e-05,
      "loss": 0.0143,
      "step": 7133
    },
    {
      "epoch": 72.43,
      "learning_rate": 6.119548722678328e-05,
      "loss": 0.0012,
      "step": 7134
    },
    {
      "epoch": 72.44,
      "learning_rate": 6.118391537968592e-05,
      "loss": 0.0003,
      "step": 7135
    },
    {
      "epoch": 72.45,
      "learning_rate": 6.117234290195958e-05,
      "loss": 0.0025,
      "step": 7136
    },
    {
      "epoch": 72.46,
      "learning_rate": 6.116076979425681e-05,
      "loss": 0.0002,
      "step": 7137
    },
    {
      "epoch": 72.47,
      "learning_rate": 6.114919605723015e-05,
      "loss": 0.0002,
      "step": 7138
    },
    {
      "epoch": 72.48,
      "learning_rate": 6.113762169153226e-05,
      "loss": 0.0001,
      "step": 7139
    },
    {
      "epoch": 72.49,
      "learning_rate": 6.112604669781572e-05,
      "loss": 0.0017,
      "step": 7140
    },
    {
      "epoch": 72.5,
      "learning_rate": 6.111447107673326e-05,
      "loss": 0.0117,
      "step": 7141
    },
    {
      "epoch": 72.51,
      "learning_rate": 6.110289482893759e-05,
      "loss": 0.0118,
      "step": 7142
    },
    {
      "epoch": 72.52,
      "learning_rate": 6.109131795508144e-05,
      "loss": 0.0009,
      "step": 7143
    },
    {
      "epoch": 72.53,
      "learning_rate": 6.107974045581761e-05,
      "loss": 0.0005,
      "step": 7144
    },
    {
      "epoch": 72.54,
      "learning_rate": 6.106816233179893e-05,
      "loss": 0.0086,
      "step": 7145
    },
    {
      "epoch": 72.55,
      "learning_rate": 6.105658358367823e-05,
      "loss": 0.0101,
      "step": 7146
    },
    {
      "epoch": 72.56,
      "learning_rate": 6.104500421210844e-05,
      "loss": 0.0272,
      "step": 7147
    },
    {
      "epoch": 72.57,
      "learning_rate": 6.103342421774246e-05,
      "loss": 0.016,
      "step": 7148
    },
    {
      "epoch": 72.58,
      "learning_rate": 6.1021843601233266e-05,
      "loss": 0.0003,
      "step": 7149
    },
    {
      "epoch": 72.59,
      "learning_rate": 6.101026236323385e-05,
      "loss": 0.0005,
      "step": 7150
    },
    {
      "epoch": 72.6,
      "learning_rate": 6.099868050439725e-05,
      "loss": 0.0007,
      "step": 7151
    },
    {
      "epoch": 72.61,
      "learning_rate": 6.098709802537653e-05,
      "loss": 0.0026,
      "step": 7152
    },
    {
      "epoch": 72.62,
      "learning_rate": 6.097551492682478e-05,
      "loss": 0.0141,
      "step": 7153
    },
    {
      "epoch": 72.63,
      "learning_rate": 6.096393120939516e-05,
      "loss": 0.0001,
      "step": 7154
    },
    {
      "epoch": 72.64,
      "learning_rate": 6.095234687374085e-05,
      "loss": 0.0043,
      "step": 7155
    },
    {
      "epoch": 72.65,
      "learning_rate": 6.094076192051502e-05,
      "loss": 0.0001,
      "step": 7156
    },
    {
      "epoch": 72.66,
      "learning_rate": 6.0929176350370944e-05,
      "loss": 0.0007,
      "step": 7157
    },
    {
      "epoch": 72.67,
      "learning_rate": 6.091759016396188e-05,
      "loss": 0.0029,
      "step": 7158
    },
    {
      "epoch": 72.68,
      "learning_rate": 6.0906003361941153e-05,
      "loss": 0.0001,
      "step": 7159
    },
    {
      "epoch": 72.69,
      "learning_rate": 6.089441594496211e-05,
      "loss": 0.0001,
      "step": 7160
    },
    {
      "epoch": 72.7,
      "learning_rate": 6.088282791367812e-05,
      "loss": 0.0096,
      "step": 7161
    },
    {
      "epoch": 72.71,
      "learning_rate": 6.087123926874261e-05,
      "loss": 0.0013,
      "step": 7162
    },
    {
      "epoch": 72.72,
      "learning_rate": 6.085965001080902e-05,
      "loss": 0.0112,
      "step": 7163
    },
    {
      "epoch": 72.73,
      "learning_rate": 6.084806014053086e-05,
      "loss": 0.0016,
      "step": 7164
    },
    {
      "epoch": 72.74,
      "learning_rate": 6.08364696585616e-05,
      "loss": 0.0004,
      "step": 7165
    },
    {
      "epoch": 72.75,
      "learning_rate": 6.0824878565554853e-05,
      "loss": 0.0023,
      "step": 7166
    },
    {
      "epoch": 72.76,
      "learning_rate": 6.081328686216418e-05,
      "loss": 0.0005,
      "step": 7167
    },
    {
      "epoch": 72.77,
      "learning_rate": 6.08016945490432e-05,
      "loss": 0.0003,
      "step": 7168
    },
    {
      "epoch": 72.78,
      "learning_rate": 6.0790101626845576e-05,
      "loss": 0.0018,
      "step": 7169
    },
    {
      "epoch": 72.79,
      "learning_rate": 6.0778508096224985e-05,
      "loss": 0.0116,
      "step": 7170
    },
    {
      "epoch": 72.8,
      "learning_rate": 6.076691395783517e-05,
      "loss": 0.0097,
      "step": 7171
    },
    {
      "epoch": 72.81,
      "learning_rate": 6.0755319212329906e-05,
      "loss": 0.0002,
      "step": 7172
    },
    {
      "epoch": 72.82,
      "learning_rate": 6.074372386036296e-05,
      "loss": 0.0439,
      "step": 7173
    },
    {
      "epoch": 72.83,
      "learning_rate": 6.073212790258815e-05,
      "loss": 0.0058,
      "step": 7174
    },
    {
      "epoch": 72.84,
      "learning_rate": 6.072053133965938e-05,
      "loss": 0.0002,
      "step": 7175
    },
    {
      "epoch": 72.85,
      "learning_rate": 6.0708934172230527e-05,
      "loss": 0.0002,
      "step": 7176
    },
    {
      "epoch": 72.86,
      "learning_rate": 6.0697336400955505e-05,
      "loss": 0.0005,
      "step": 7177
    },
    {
      "epoch": 72.87,
      "learning_rate": 6.0685738026488304e-05,
      "loss": 0.0021,
      "step": 7178
    },
    {
      "epoch": 72.88,
      "learning_rate": 6.0674139049482915e-05,
      "loss": 0.0029,
      "step": 7179
    },
    {
      "epoch": 72.89,
      "learning_rate": 6.066253947059337e-05,
      "loss": 0.0007,
      "step": 7180
    },
    {
      "epoch": 72.9,
      "learning_rate": 6.065093929047374e-05,
      "loss": 0.0013,
      "step": 7181
    },
    {
      "epoch": 72.91,
      "learning_rate": 6.063933850977811e-05,
      "loss": 0.002,
      "step": 7182
    },
    {
      "epoch": 72.92,
      "learning_rate": 6.0627737129160636e-05,
      "loss": 0.0107,
      "step": 7183
    },
    {
      "epoch": 72.93,
      "learning_rate": 6.0616135149275476e-05,
      "loss": 0.0001,
      "step": 7184
    },
    {
      "epoch": 72.94,
      "learning_rate": 6.060453257077685e-05,
      "loss": 0.0003,
      "step": 7185
    },
    {
      "epoch": 72.95,
      "learning_rate": 6.059292939431894e-05,
      "loss": 0.0027,
      "step": 7186
    },
    {
      "epoch": 72.96,
      "learning_rate": 6.0581325620556094e-05,
      "loss": 0.0003,
      "step": 7187
    },
    {
      "epoch": 72.97,
      "learning_rate": 6.056972125014255e-05,
      "loss": 0.0024,
      "step": 7188
    },
    {
      "epoch": 72.98,
      "learning_rate": 6.055811628373269e-05,
      "loss": 0.0049,
      "step": 7189
    },
    {
      "epoch": 72.99,
      "learning_rate": 6.054651072198085e-05,
      "loss": 0.0003,
      "step": 7190
    },
    {
      "epoch": 72.99,
      "eval_loss": 0.016231747344136238,
      "eval_runtime": 32.1169,
      "eval_samples_per_second": 98.079,
      "eval_steps_per_second": 6.134,
      "eval_wer": 0.0030089628681177977,
      "step": 7190
    },
    {
      "epoch": 73.01,
      "learning_rate": 6.053490456554146e-05,
      "loss": 0.0029,
      "step": 7191
    },
    {
      "epoch": 73.02,
      "learning_rate": 6.052329781506895e-05,
      "loss": 0.0001,
      "step": 7192
    },
    {
      "epoch": 73.03,
      "learning_rate": 6.051169047121778e-05,
      "loss": 0.0015,
      "step": 7193
    },
    {
      "epoch": 73.04,
      "learning_rate": 6.0500082534642464e-05,
      "loss": 0.003,
      "step": 7194
    },
    {
      "epoch": 73.05,
      "learning_rate": 6.048847400599757e-05,
      "loss": 0.0082,
      "step": 7195
    },
    {
      "epoch": 73.06,
      "learning_rate": 6.04768648859376e-05,
      "loss": 0.0008,
      "step": 7196
    },
    {
      "epoch": 73.07,
      "learning_rate": 6.046525517511722e-05,
      "loss": 0.0006,
      "step": 7197
    },
    {
      "epoch": 73.08,
      "learning_rate": 6.045364487419104e-05,
      "loss": 0.0012,
      "step": 7198
    },
    {
      "epoch": 73.09,
      "learning_rate": 6.0442033983813764e-05,
      "loss": 0.0003,
      "step": 7199
    },
    {
      "epoch": 73.1,
      "learning_rate": 6.043042250464005e-05,
      "loss": 0.0001,
      "step": 7200
    },
    {
      "epoch": 73.11,
      "learning_rate": 6.0418810437324655e-05,
      "loss": 0.0015,
      "step": 7201
    },
    {
      "epoch": 73.12,
      "learning_rate": 6.0407197782522374e-05,
      "loss": 0.0016,
      "step": 7202
    },
    {
      "epoch": 73.13,
      "learning_rate": 6.0395584540887963e-05,
      "loss": 0.0002,
      "step": 7203
    },
    {
      "epoch": 73.14,
      "learning_rate": 6.038397071307631e-05,
      "loss": 0.0028,
      "step": 7204
    },
    {
      "epoch": 73.15,
      "learning_rate": 6.0372356299742264e-05,
      "loss": 0.0003,
      "step": 7205
    },
    {
      "epoch": 73.16,
      "learning_rate": 6.0360741301540726e-05,
      "loss": 0.0107,
      "step": 7206
    },
    {
      "epoch": 73.17,
      "learning_rate": 6.034912571912662e-05,
      "loss": 0.0122,
      "step": 7207
    },
    {
      "epoch": 73.18,
      "learning_rate": 6.033750955315495e-05,
      "loss": 0.0003,
      "step": 7208
    },
    {
      "epoch": 73.19,
      "learning_rate": 6.032589280428068e-05,
      "loss": 0.0143,
      "step": 7209
    },
    {
      "epoch": 73.2,
      "learning_rate": 6.031427547315889e-05,
      "loss": 0.0189,
      "step": 7210
    },
    {
      "epoch": 73.21,
      "learning_rate": 6.0302657560444584e-05,
      "loss": 0.0,
      "step": 7211
    },
    {
      "epoch": 73.22,
      "learning_rate": 6.0291039066792935e-05,
      "loss": 0.0037,
      "step": 7212
    },
    {
      "epoch": 73.23,
      "learning_rate": 6.027941999285902e-05,
      "loss": 0.0001,
      "step": 7213
    },
    {
      "epoch": 73.24,
      "learning_rate": 6.026780033929804e-05,
      "loss": 0.0005,
      "step": 7214
    },
    {
      "epoch": 73.25,
      "learning_rate": 6.025618010676516e-05,
      "loss": 0.0007,
      "step": 7215
    },
    {
      "epoch": 73.26,
      "learning_rate": 6.024455929591566e-05,
      "loss": 0.0042,
      "step": 7216
    },
    {
      "epoch": 73.27,
      "learning_rate": 6.0232937907404765e-05,
      "loss": 0.0044,
      "step": 7217
    },
    {
      "epoch": 73.28,
      "learning_rate": 6.0221315941887776e-05,
      "loss": 0.0018,
      "step": 7218
    },
    {
      "epoch": 73.29,
      "learning_rate": 6.020969340002004e-05,
      "loss": 0.0002,
      "step": 7219
    },
    {
      "epoch": 73.3,
      "learning_rate": 6.019807028245692e-05,
      "loss": 0.0005,
      "step": 7220
    },
    {
      "epoch": 73.31,
      "learning_rate": 6.0186446589853784e-05,
      "loss": 0.0004,
      "step": 7221
    },
    {
      "epoch": 73.32,
      "learning_rate": 6.0174822322866075e-05,
      "loss": 0.0001,
      "step": 7222
    },
    {
      "epoch": 73.33,
      "learning_rate": 6.0163197482149245e-05,
      "loss": 0.0015,
      "step": 7223
    },
    {
      "epoch": 73.34,
      "learning_rate": 6.015157206835881e-05,
      "loss": 0.0002,
      "step": 7224
    },
    {
      "epoch": 73.35,
      "learning_rate": 6.013994608215028e-05,
      "loss": 0.0097,
      "step": 7225
    },
    {
      "epoch": 73.36,
      "learning_rate": 6.012831952417919e-05,
      "loss": 0.001,
      "step": 7226
    },
    {
      "epoch": 73.37,
      "learning_rate": 6.0116692395101145e-05,
      "loss": 0.0005,
      "step": 7227
    },
    {
      "epoch": 73.38,
      "learning_rate": 6.0105064695571764e-05,
      "loss": 0.0008,
      "step": 7228
    },
    {
      "epoch": 73.39,
      "learning_rate": 6.009343642624672e-05,
      "loss": 0.0139,
      "step": 7229
    },
    {
      "epoch": 73.4,
      "learning_rate": 6.008180758778167e-05,
      "loss": 0.0013,
      "step": 7230
    },
    {
      "epoch": 73.41,
      "learning_rate": 6.007017818083234e-05,
      "loss": 0.0015,
      "step": 7231
    },
    {
      "epoch": 73.42,
      "learning_rate": 6.005854820605448e-05,
      "loss": 0.0198,
      "step": 7232
    },
    {
      "epoch": 73.43,
      "learning_rate": 6.004691766410387e-05,
      "loss": 0.0001,
      "step": 7233
    },
    {
      "epoch": 73.44,
      "learning_rate": 6.003528655563632e-05,
      "loss": 0.0069,
      "step": 7234
    },
    {
      "epoch": 73.45,
      "learning_rate": 6.002365488130768e-05,
      "loss": 0.0001,
      "step": 7235
    },
    {
      "epoch": 73.46,
      "learning_rate": 6.0012022641773826e-05,
      "loss": 0.0005,
      "step": 7236
    },
    {
      "epoch": 73.47,
      "learning_rate": 6.0000389837690674e-05,
      "loss": 0.0001,
      "step": 7237
    },
    {
      "epoch": 73.48,
      "learning_rate": 5.9988756469714135e-05,
      "loss": 0.0003,
      "step": 7238
    },
    {
      "epoch": 73.49,
      "learning_rate": 5.997712253850022e-05,
      "loss": 0.0001,
      "step": 7239
    },
    {
      "epoch": 73.5,
      "learning_rate": 5.996548804470491e-05,
      "loss": 0.0001,
      "step": 7240
    },
    {
      "epoch": 73.51,
      "learning_rate": 5.9953852988984235e-05,
      "loss": 0.016,
      "step": 7241
    },
    {
      "epoch": 73.52,
      "learning_rate": 5.99422173719943e-05,
      "loss": 0.0001,
      "step": 7242
    },
    {
      "epoch": 73.53,
      "learning_rate": 5.993058119439117e-05,
      "loss": 0.0003,
      "step": 7243
    },
    {
      "epoch": 73.54,
      "learning_rate": 5.991894445683097e-05,
      "loss": 0.0005,
      "step": 7244
    },
    {
      "epoch": 73.55,
      "learning_rate": 5.9907307159969884e-05,
      "loss": 0.0001,
      "step": 7245
    },
    {
      "epoch": 73.56,
      "learning_rate": 5.989566930446411e-05,
      "loss": 0.0003,
      "step": 7246
    },
    {
      "epoch": 73.57,
      "learning_rate": 5.988403089096985e-05,
      "loss": 0.0002,
      "step": 7247
    },
    {
      "epoch": 73.58,
      "learning_rate": 5.987239192014336e-05,
      "loss": 0.0007,
      "step": 7248
    },
    {
      "epoch": 73.59,
      "learning_rate": 5.9860752392640954e-05,
      "loss": 0.0026,
      "step": 7249
    },
    {
      "epoch": 73.6,
      "learning_rate": 5.984911230911894e-05,
      "loss": 0.0007,
      "step": 7250
    },
    {
      "epoch": 73.61,
      "learning_rate": 5.983747167023367e-05,
      "loss": 0.0002,
      "step": 7251
    },
    {
      "epoch": 73.62,
      "learning_rate": 5.982583047664151e-05,
      "loss": 0.0015,
      "step": 7252
    },
    {
      "epoch": 73.63,
      "learning_rate": 5.981418872899889e-05,
      "loss": 0.0038,
      "step": 7253
    },
    {
      "epoch": 73.64,
      "learning_rate": 5.9802546427962266e-05,
      "loss": 0.0003,
      "step": 7254
    },
    {
      "epoch": 73.65,
      "learning_rate": 5.9790903574188096e-05,
      "loss": 0.0053,
      "step": 7255
    },
    {
      "epoch": 73.66,
      "learning_rate": 5.9779260168332886e-05,
      "loss": 0.0021,
      "step": 7256
    },
    {
      "epoch": 73.68,
      "learning_rate": 5.976761621105317e-05,
      "loss": 0.0142,
      "step": 7257
    },
    {
      "epoch": 73.69,
      "learning_rate": 5.9755971703005554e-05,
      "loss": 0.0043,
      "step": 7258
    },
    {
      "epoch": 73.7,
      "learning_rate": 5.9744326644846584e-05,
      "loss": 0.0096,
      "step": 7259
    },
    {
      "epoch": 73.71,
      "learning_rate": 5.973268103723293e-05,
      "loss": 0.0061,
      "step": 7260
    },
    {
      "epoch": 73.72,
      "learning_rate": 5.972103488082123e-05,
      "loss": 0.0004,
      "step": 7261
    },
    {
      "epoch": 73.73,
      "learning_rate": 5.970938817626821e-05,
      "loss": 0.0113,
      "step": 7262
    },
    {
      "epoch": 73.74,
      "learning_rate": 5.969774092423057e-05,
      "loss": 0.0003,
      "step": 7263
    },
    {
      "epoch": 73.75,
      "learning_rate": 5.968609312536507e-05,
      "loss": 0.0001,
      "step": 7264
    },
    {
      "epoch": 73.76,
      "learning_rate": 5.96744447803285e-05,
      "loss": 0.0046,
      "step": 7265
    },
    {
      "epoch": 73.77,
      "learning_rate": 5.9662795889777666e-05,
      "loss": 0.001,
      "step": 7266
    },
    {
      "epoch": 73.78,
      "learning_rate": 5.965114645436943e-05,
      "loss": 0.0112,
      "step": 7267
    },
    {
      "epoch": 73.79,
      "learning_rate": 5.9639496474760645e-05,
      "loss": 0.0033,
      "step": 7268
    },
    {
      "epoch": 73.8,
      "learning_rate": 5.962784595160826e-05,
      "loss": 0.0006,
      "step": 7269
    },
    {
      "epoch": 73.81,
      "learning_rate": 5.961619488556919e-05,
      "loss": 0.0013,
      "step": 7270
    },
    {
      "epoch": 73.82,
      "learning_rate": 5.9604543277300405e-05,
      "loss": 0.0009,
      "step": 7271
    },
    {
      "epoch": 73.83,
      "learning_rate": 5.9592891127458914e-05,
      "loss": 0.0001,
      "step": 7272
    },
    {
      "epoch": 73.84,
      "learning_rate": 5.9581238436701736e-05,
      "loss": 0.0045,
      "step": 7273
    },
    {
      "epoch": 73.85,
      "learning_rate": 5.956958520568594e-05,
      "loss": 0.0003,
      "step": 7274
    },
    {
      "epoch": 73.86,
      "learning_rate": 5.955793143506863e-05,
      "loss": 0.0024,
      "step": 7275
    },
    {
      "epoch": 73.87,
      "learning_rate": 5.95462771255069e-05,
      "loss": 0.0001,
      "step": 7276
    },
    {
      "epoch": 73.88,
      "learning_rate": 5.9534622277657926e-05,
      "loss": 0.0026,
      "step": 7277
    },
    {
      "epoch": 73.89,
      "learning_rate": 5.952296689217889e-05,
      "loss": 0.0001,
      "step": 7278
    },
    {
      "epoch": 73.9,
      "learning_rate": 5.9511310969727006e-05,
      "loss": 0.0002,
      "step": 7279
    },
    {
      "epoch": 73.91,
      "learning_rate": 5.949965451095951e-05,
      "loss": 0.0003,
      "step": 7280
    },
    {
      "epoch": 73.92,
      "learning_rate": 5.948799751653368e-05,
      "loss": 0.0016,
      "step": 7281
    },
    {
      "epoch": 73.93,
      "learning_rate": 5.947633998710681e-05,
      "loss": 0.0001,
      "step": 7282
    },
    {
      "epoch": 73.94,
      "learning_rate": 5.946468192333625e-05,
      "loss": 0.002,
      "step": 7283
    },
    {
      "epoch": 73.95,
      "learning_rate": 5.945302332587939e-05,
      "loss": 0.0005,
      "step": 7284
    },
    {
      "epoch": 73.96,
      "learning_rate": 5.944136419539356e-05,
      "loss": 0.0014,
      "step": 7285
    },
    {
      "epoch": 73.97,
      "learning_rate": 5.9429704532536237e-05,
      "loss": 0.0,
      "step": 7286
    },
    {
      "epoch": 73.98,
      "learning_rate": 5.941804433796485e-05,
      "loss": 0.0049,
      "step": 7287
    },
    {
      "epoch": 73.99,
      "learning_rate": 5.9406383612336904e-05,
      "loss": 0.0036,
      "step": 7288
    },
    {
      "epoch": 74.0,
      "learning_rate": 5.939472235630989e-05,
      "loss": 0.0,
      "step": 7289
    },
    {
      "epoch": 74.0,
      "eval_loss": 0.020261794328689575,
      "eval_runtime": 32.0739,
      "eval_samples_per_second": 98.211,
      "eval_steps_per_second": 6.142,
      "eval_wer": 0.0033290653008962866,
      "step": 7289
    },
    {
      "epoch": 74.01,
      "learning_rate": 5.9383060570541384e-05,
      "loss": 0.0001,
      "step": 7290
    },
    {
      "epoch": 74.02,
      "learning_rate": 5.937139825568892e-05,
      "loss": 0.0221,
      "step": 7291
    },
    {
      "epoch": 74.03,
      "learning_rate": 5.935973541241015e-05,
      "loss": 0.0017,
      "step": 7292
    },
    {
      "epoch": 74.04,
      "learning_rate": 5.934807204136267e-05,
      "loss": 0.0016,
      "step": 7293
    },
    {
      "epoch": 74.05,
      "learning_rate": 5.933640814320417e-05,
      "loss": 0.0002,
      "step": 7294
    },
    {
      "epoch": 74.06,
      "learning_rate": 5.932474371859232e-05,
      "loss": 0.0015,
      "step": 7295
    },
    {
      "epoch": 74.07,
      "learning_rate": 5.931307876818487e-05,
      "loss": 0.0006,
      "step": 7296
    },
    {
      "epoch": 74.08,
      "learning_rate": 5.930141329263953e-05,
      "loss": 0.0137,
      "step": 7297
    },
    {
      "epoch": 74.09,
      "learning_rate": 5.9289747292614136e-05,
      "loss": 0.0057,
      "step": 7298
    },
    {
      "epoch": 74.1,
      "learning_rate": 5.927808076876646e-05,
      "loss": 0.0004,
      "step": 7299
    },
    {
      "epoch": 74.11,
      "learning_rate": 5.926641372175438e-05,
      "loss": 0.0098,
      "step": 7300
    },
    {
      "epoch": 74.12,
      "learning_rate": 5.925474615223573e-05,
      "loss": 0.0103,
      "step": 7301
    },
    {
      "epoch": 74.13,
      "learning_rate": 5.924307806086844e-05,
      "loss": 0.0003,
      "step": 7302
    },
    {
      "epoch": 74.14,
      "learning_rate": 5.9231409448310424e-05,
      "loss": 0.01,
      "step": 7303
    },
    {
      "epoch": 74.15,
      "learning_rate": 5.921974031521964e-05,
      "loss": 0.0012,
      "step": 7304
    },
    {
      "epoch": 74.16,
      "learning_rate": 5.920807066225409e-05,
      "loss": 0.004,
      "step": 7305
    },
    {
      "epoch": 74.17,
      "learning_rate": 5.919640049007178e-05,
      "loss": 0.0008,
      "step": 7306
    },
    {
      "epoch": 74.18,
      "learning_rate": 5.918472979933077e-05,
      "loss": 0.0001,
      "step": 7307
    },
    {
      "epoch": 74.19,
      "learning_rate": 5.917305859068912e-05,
      "loss": 0.0001,
      "step": 7308
    },
    {
      "epoch": 74.2,
      "learning_rate": 5.916138686480496e-05,
      "loss": 0.0002,
      "step": 7309
    },
    {
      "epoch": 74.21,
      "learning_rate": 5.9149714622336396e-05,
      "loss": 0.0001,
      "step": 7310
    },
    {
      "epoch": 74.22,
      "learning_rate": 5.9138041863941616e-05,
      "loss": 0.0002,
      "step": 7311
    },
    {
      "epoch": 74.23,
      "learning_rate": 5.9126368590278805e-05,
      "loss": 0.0001,
      "step": 7312
    },
    {
      "epoch": 74.24,
      "learning_rate": 5.911469480200619e-05,
      "loss": 0.0292,
      "step": 7313
    },
    {
      "epoch": 74.25,
      "learning_rate": 5.910302049978199e-05,
      "loss": 0.0004,
      "step": 7314
    },
    {
      "epoch": 74.26,
      "learning_rate": 5.9091345684264546e-05,
      "loss": 0.0048,
      "step": 7315
    },
    {
      "epoch": 74.27,
      "learning_rate": 5.907967035611211e-05,
      "loss": 0.0001,
      "step": 7316
    },
    {
      "epoch": 74.28,
      "learning_rate": 5.906799451598307e-05,
      "loss": 0.004,
      "step": 7317
    },
    {
      "epoch": 74.29,
      "learning_rate": 5.905631816453575e-05,
      "loss": 0.001,
      "step": 7318
    },
    {
      "epoch": 74.3,
      "learning_rate": 5.904464130242857e-05,
      "loss": 0.0004,
      "step": 7319
    },
    {
      "epoch": 74.31,
      "learning_rate": 5.903296393031995e-05,
      "loss": 0.0003,
      "step": 7320
    },
    {
      "epoch": 74.32,
      "learning_rate": 5.902128604886834e-05,
      "loss": 0.0001,
      "step": 7321
    },
    {
      "epoch": 74.34,
      "learning_rate": 5.900960765873222e-05,
      "loss": 0.0003,
      "step": 7322
    },
    {
      "epoch": 74.35,
      "learning_rate": 5.899792876057013e-05,
      "loss": 0.0006,
      "step": 7323
    },
    {
      "epoch": 74.36,
      "learning_rate": 5.898624935504057e-05,
      "loss": 0.0025,
      "step": 7324
    },
    {
      "epoch": 74.37,
      "learning_rate": 5.897456944280212e-05,
      "loss": 0.0004,
      "step": 7325
    },
    {
      "epoch": 74.38,
      "learning_rate": 5.896288902451338e-05,
      "loss": 0.0002,
      "step": 7326
    },
    {
      "epoch": 74.39,
      "learning_rate": 5.895120810083298e-05,
      "loss": 0.0005,
      "step": 7327
    },
    {
      "epoch": 74.4,
      "learning_rate": 5.893952667241958e-05,
      "loss": 0.0019,
      "step": 7328
    },
    {
      "epoch": 74.41,
      "learning_rate": 5.8927844739931834e-05,
      "loss": 0.0008,
      "step": 7329
    },
    {
      "epoch": 74.42,
      "learning_rate": 5.8916162304028476e-05,
      "loss": 0.0043,
      "step": 7330
    },
    {
      "epoch": 74.43,
      "learning_rate": 5.8904479365368245e-05,
      "loss": 0.0046,
      "step": 7331
    },
    {
      "epoch": 74.44,
      "learning_rate": 5.889279592460991e-05,
      "loss": 0.0077,
      "step": 7332
    },
    {
      "epoch": 74.45,
      "learning_rate": 5.888111198241225e-05,
      "loss": 0.0049,
      "step": 7333
    },
    {
      "epoch": 74.46,
      "learning_rate": 5.886942753943411e-05,
      "loss": 0.0197,
      "step": 7334
    },
    {
      "epoch": 74.47,
      "learning_rate": 5.885774259633432e-05,
      "loss": 0.0079,
      "step": 7335
    },
    {
      "epoch": 74.48,
      "learning_rate": 5.8846057153771786e-05,
      "loss": 0.0133,
      "step": 7336
    },
    {
      "epoch": 74.49,
      "learning_rate": 5.883437121240539e-05,
      "loss": 0.0006,
      "step": 7337
    },
    {
      "epoch": 74.5,
      "learning_rate": 5.882268477289409e-05,
      "loss": 0.0034,
      "step": 7338
    },
    {
      "epoch": 74.51,
      "learning_rate": 5.881099783589683e-05,
      "loss": 0.0002,
      "step": 7339
    },
    {
      "epoch": 74.52,
      "learning_rate": 5.879931040207264e-05,
      "loss": 0.0,
      "step": 7340
    },
    {
      "epoch": 74.53,
      "learning_rate": 5.87876224720805e-05,
      "loss": 0.0001,
      "step": 7341
    },
    {
      "epoch": 74.54,
      "learning_rate": 5.8775934046579474e-05,
      "loss": 0.0004,
      "step": 7342
    },
    {
      "epoch": 74.55,
      "learning_rate": 5.8764245126228636e-05,
      "loss": 0.0004,
      "step": 7343
    },
    {
      "epoch": 74.56,
      "learning_rate": 5.87525557116871e-05,
      "loss": 0.0002,
      "step": 7344
    },
    {
      "epoch": 74.57,
      "learning_rate": 5.874086580361401e-05,
      "loss": 0.0003,
      "step": 7345
    },
    {
      "epoch": 74.58,
      "learning_rate": 5.872917540266849e-05,
      "loss": 0.002,
      "step": 7346
    },
    {
      "epoch": 74.59,
      "learning_rate": 5.8717484509509757e-05,
      "loss": 0.0003,
      "step": 7347
    },
    {
      "epoch": 74.6,
      "learning_rate": 5.8705793124797014e-05,
      "loss": 0.0016,
      "step": 7348
    },
    {
      "epoch": 74.61,
      "learning_rate": 5.869410124918952e-05,
      "loss": 0.0001,
      "step": 7349
    },
    {
      "epoch": 74.62,
      "learning_rate": 5.868240888334653e-05,
      "loss": 0.0002,
      "step": 7350
    },
    {
      "epoch": 74.63,
      "learning_rate": 5.8670716027927345e-05,
      "loss": 0.0046,
      "step": 7351
    },
    {
      "epoch": 74.64,
      "learning_rate": 5.8659022683591295e-05,
      "loss": 0.0003,
      "step": 7352
    },
    {
      "epoch": 74.65,
      "learning_rate": 5.864732885099774e-05,
      "loss": 0.0001,
      "step": 7353
    },
    {
      "epoch": 74.66,
      "learning_rate": 5.863563453080605e-05,
      "loss": 0.0109,
      "step": 7354
    },
    {
      "epoch": 74.67,
      "learning_rate": 5.8623939723675636e-05,
      "loss": 0.0108,
      "step": 7355
    },
    {
      "epoch": 74.68,
      "learning_rate": 5.861224443026595e-05,
      "loss": 0.0089,
      "step": 7356
    },
    {
      "epoch": 74.69,
      "learning_rate": 5.860054865123645e-05,
      "loss": 0.0192,
      "step": 7357
    },
    {
      "epoch": 74.7,
      "learning_rate": 5.858885238724662e-05,
      "loss": 0.0072,
      "step": 7358
    },
    {
      "epoch": 74.71,
      "learning_rate": 5.857715563895597e-05,
      "loss": 0.0016,
      "step": 7359
    },
    {
      "epoch": 74.72,
      "learning_rate": 5.856545840702406e-05,
      "loss": 0.0002,
      "step": 7360
    },
    {
      "epoch": 74.73,
      "learning_rate": 5.8553760692110485e-05,
      "loss": 0.0001,
      "step": 7361
    },
    {
      "epoch": 74.74,
      "learning_rate": 5.85420624948748e-05,
      "loss": 0.0,
      "step": 7362
    },
    {
      "epoch": 74.75,
      "learning_rate": 5.853036381597665e-05,
      "loss": 0.0014,
      "step": 7363
    },
    {
      "epoch": 74.76,
      "learning_rate": 5.8518664656075706e-05,
      "loss": 0.0023,
      "step": 7364
    },
    {
      "epoch": 74.77,
      "learning_rate": 5.850696501583164e-05,
      "loss": 0.0007,
      "step": 7365
    },
    {
      "epoch": 74.78,
      "learning_rate": 5.849526489590416e-05,
      "loss": 0.0037,
      "step": 7366
    },
    {
      "epoch": 74.79,
      "learning_rate": 5.8483564296953e-05,
      "loss": 0.0005,
      "step": 7367
    },
    {
      "epoch": 74.8,
      "learning_rate": 5.8471863219637924e-05,
      "loss": 0.012,
      "step": 7368
    },
    {
      "epoch": 74.81,
      "learning_rate": 5.8460161664618717e-05,
      "loss": 0.0167,
      "step": 7369
    },
    {
      "epoch": 74.82,
      "learning_rate": 5.844845963255523e-05,
      "loss": 0.0063,
      "step": 7370
    },
    {
      "epoch": 74.83,
      "learning_rate": 5.8436757124107245e-05,
      "loss": 0.0012,
      "step": 7371
    },
    {
      "epoch": 74.84,
      "learning_rate": 5.84250541399347e-05,
      "loss": 0.0003,
      "step": 7372
    },
    {
      "epoch": 74.85,
      "learning_rate": 5.8413350680697444e-05,
      "loss": 0.0005,
      "step": 7373
    },
    {
      "epoch": 74.86,
      "learning_rate": 5.8401646747055425e-05,
      "loss": 0.0007,
      "step": 7374
    },
    {
      "epoch": 74.87,
      "learning_rate": 5.838994233966858e-05,
      "loss": 0.0007,
      "step": 7375
    },
    {
      "epoch": 74.88,
      "learning_rate": 5.837823745919691e-05,
      "loss": 0.0003,
      "step": 7376
    },
    {
      "epoch": 74.89,
      "learning_rate": 5.8366532106300384e-05,
      "loss": 0.0004,
      "step": 7377
    },
    {
      "epoch": 74.9,
      "learning_rate": 5.835482628163909e-05,
      "loss": 0.0005,
      "step": 7378
    },
    {
      "epoch": 74.91,
      "learning_rate": 5.834311998587302e-05,
      "loss": 0.0096,
      "step": 7379
    },
    {
      "epoch": 74.92,
      "learning_rate": 5.833141321966229e-05,
      "loss": 0.0004,
      "step": 7380
    },
    {
      "epoch": 74.93,
      "learning_rate": 5.8319705983667016e-05,
      "loss": 0.0029,
      "step": 7381
    },
    {
      "epoch": 74.94,
      "learning_rate": 5.830799827854734e-05,
      "loss": 0.0001,
      "step": 7382
    },
    {
      "epoch": 74.95,
      "learning_rate": 5.82962901049634e-05,
      "loss": 0.011,
      "step": 7383
    },
    {
      "epoch": 74.96,
      "learning_rate": 5.828458146357541e-05,
      "loss": 0.0027,
      "step": 7384
    },
    {
      "epoch": 74.97,
      "learning_rate": 5.827287235504356e-05,
      "loss": 0.0038,
      "step": 7385
    },
    {
      "epoch": 74.98,
      "learning_rate": 5.8261162780028135e-05,
      "loss": 0.0091,
      "step": 7386
    },
    {
      "epoch": 74.99,
      "learning_rate": 5.8249452739189384e-05,
      "loss": 0.0003,
      "step": 7387
    },
    {
      "epoch": 74.99,
      "eval_loss": 0.01795065589249134,
      "eval_runtime": 32.6501,
      "eval_samples_per_second": 96.478,
      "eval_steps_per_second": 6.034,
      "eval_wer": 0.0034571062740076826,
      "step": 7387
    },
    {
      "epoch": 75.01,
      "learning_rate": 5.823774223318756e-05,
      "loss": 0.0001,
      "step": 7388
    },
    {
      "epoch": 75.02,
      "learning_rate": 5.822603126268307e-05,
      "loss": 0.0001,
      "step": 7389
    },
    {
      "epoch": 75.03,
      "learning_rate": 5.8214319828336194e-05,
      "loss": 0.0002,
      "step": 7390
    },
    {
      "epoch": 75.04,
      "learning_rate": 5.820260793080734e-05,
      "loss": 0.0002,
      "step": 7391
    },
    {
      "epoch": 75.05,
      "learning_rate": 5.819089557075689e-05,
      "loss": 0.0003,
      "step": 7392
    },
    {
      "epoch": 75.06,
      "learning_rate": 5.8179182748845285e-05,
      "loss": 0.0006,
      "step": 7393
    },
    {
      "epoch": 75.07,
      "learning_rate": 5.816746946573296e-05,
      "loss": 0.0015,
      "step": 7394
    },
    {
      "epoch": 75.08,
      "learning_rate": 5.8155755722080415e-05,
      "loss": 0.0009,
      "step": 7395
    },
    {
      "epoch": 75.09,
      "learning_rate": 5.814404151854813e-05,
      "loss": 0.0023,
      "step": 7396
    },
    {
      "epoch": 75.1,
      "learning_rate": 5.813232685579666e-05,
      "loss": 0.0017,
      "step": 7397
    },
    {
      "epoch": 75.11,
      "learning_rate": 5.812061173448655e-05,
      "loss": 0.0002,
      "step": 7398
    },
    {
      "epoch": 75.12,
      "learning_rate": 5.810889615527838e-05,
      "loss": 0.0001,
      "step": 7399
    },
    {
      "epoch": 75.13,
      "learning_rate": 5.809718011883275e-05,
      "loss": 0.0002,
      "step": 7400
    },
    {
      "epoch": 75.14,
      "learning_rate": 5.808546362581032e-05,
      "loss": 0.0005,
      "step": 7401
    },
    {
      "epoch": 75.15,
      "learning_rate": 5.807374667687173e-05,
      "loss": 0.0006,
      "step": 7402
    },
    {
      "epoch": 75.16,
      "learning_rate": 5.8062029272677666e-05,
      "loss": 0.0001,
      "step": 7403
    },
    {
      "epoch": 75.17,
      "learning_rate": 5.805031141388884e-05,
      "loss": 0.0003,
      "step": 7404
    },
    {
      "epoch": 75.18,
      "learning_rate": 5.8038593101165994e-05,
      "loss": 0.0068,
      "step": 7405
    },
    {
      "epoch": 75.19,
      "learning_rate": 5.802687433516989e-05,
      "loss": 0.0,
      "step": 7406
    },
    {
      "epoch": 75.2,
      "learning_rate": 5.8015155116561305e-05,
      "loss": 0.0001,
      "step": 7407
    },
    {
      "epoch": 75.21,
      "learning_rate": 5.8003435446001055e-05,
      "loss": 0.0002,
      "step": 7408
    },
    {
      "epoch": 75.22,
      "learning_rate": 5.7991715324149985e-05,
      "loss": 0.0001,
      "step": 7409
    },
    {
      "epoch": 75.23,
      "learning_rate": 5.7979994751668964e-05,
      "loss": 0.0014,
      "step": 7410
    },
    {
      "epoch": 75.24,
      "learning_rate": 5.796827372921887e-05,
      "loss": 0.0001,
      "step": 7411
    },
    {
      "epoch": 75.25,
      "learning_rate": 5.795655225746063e-05,
      "loss": 0.0003,
      "step": 7412
    },
    {
      "epoch": 75.26,
      "learning_rate": 5.794483033705517e-05,
      "loss": 0.0001,
      "step": 7413
    },
    {
      "epoch": 75.27,
      "learning_rate": 5.793310796866347e-05,
      "loss": 0.0012,
      "step": 7414
    },
    {
      "epoch": 75.28,
      "learning_rate": 5.792138515294649e-05,
      "loss": 0.0,
      "step": 7415
    },
    {
      "epoch": 75.29,
      "learning_rate": 5.79096618905653e-05,
      "loss": 0.0024,
      "step": 7416
    },
    {
      "epoch": 75.3,
      "learning_rate": 5.789793818218089e-05,
      "loss": 0.0173,
      "step": 7417
    },
    {
      "epoch": 75.31,
      "learning_rate": 5.788621402845436e-05,
      "loss": 0.0031,
      "step": 7418
    },
    {
      "epoch": 75.32,
      "learning_rate": 5.787448943004677e-05,
      "loss": 0.0002,
      "step": 7419
    },
    {
      "epoch": 75.33,
      "learning_rate": 5.786276438761927e-05,
      "loss": 0.0001,
      "step": 7420
    },
    {
      "epoch": 75.34,
      "learning_rate": 5.785103890183298e-05,
      "loss": 0.0001,
      "step": 7421
    },
    {
      "epoch": 75.35,
      "learning_rate": 5.783931297334908e-05,
      "loss": 0.0004,
      "step": 7422
    },
    {
      "epoch": 75.36,
      "learning_rate": 5.7827586602828744e-05,
      "loss": 0.0043,
      "step": 7423
    },
    {
      "epoch": 75.37,
      "learning_rate": 5.78158597909332e-05,
      "loss": 0.0001,
      "step": 7424
    },
    {
      "epoch": 75.38,
      "learning_rate": 5.78041325383237e-05,
      "loss": 0.0002,
      "step": 7425
    },
    {
      "epoch": 75.39,
      "learning_rate": 5.7792404845661496e-05,
      "loss": 0.0003,
      "step": 7426
    },
    {
      "epoch": 75.4,
      "learning_rate": 5.778067671360787e-05,
      "loss": 0.0115,
      "step": 7427
    },
    {
      "epoch": 75.41,
      "learning_rate": 5.7768948142824154e-05,
      "loss": 0.0012,
      "step": 7428
    },
    {
      "epoch": 75.42,
      "learning_rate": 5.7757219133971686e-05,
      "loss": 0.002,
      "step": 7429
    },
    {
      "epoch": 75.43,
      "learning_rate": 5.774548968771183e-05,
      "loss": 0.0001,
      "step": 7430
    },
    {
      "epoch": 75.44,
      "learning_rate": 5.773375980470598e-05,
      "loss": 0.0004,
      "step": 7431
    },
    {
      "epoch": 75.45,
      "learning_rate": 5.7722029485615535e-05,
      "loss": 0.0136,
      "step": 7432
    },
    {
      "epoch": 75.46,
      "learning_rate": 5.771029873110195e-05,
      "loss": 0.0001,
      "step": 7433
    },
    {
      "epoch": 75.47,
      "learning_rate": 5.7698567541826675e-05,
      "loss": 0.0,
      "step": 7434
    },
    {
      "epoch": 75.48,
      "learning_rate": 5.768683591845123e-05,
      "loss": 0.0023,
      "step": 7435
    },
    {
      "epoch": 75.49,
      "learning_rate": 5.7675103861637084e-05,
      "loss": 0.0012,
      "step": 7436
    },
    {
      "epoch": 75.5,
      "learning_rate": 5.766337137204579e-05,
      "loss": 0.0088,
      "step": 7437
    },
    {
      "epoch": 75.51,
      "learning_rate": 5.765163845033893e-05,
      "loss": 0.0001,
      "step": 7438
    },
    {
      "epoch": 75.52,
      "learning_rate": 5.763990509717807e-05,
      "loss": 0.0018,
      "step": 7439
    },
    {
      "epoch": 75.53,
      "learning_rate": 5.762817131322482e-05,
      "loss": 0.001,
      "step": 7440
    },
    {
      "epoch": 75.54,
      "learning_rate": 5.7616437099140816e-05,
      "loss": 0.0002,
      "step": 7441
    },
    {
      "epoch": 75.55,
      "learning_rate": 5.760470245558772e-05,
      "loss": 0.0053,
      "step": 7442
    },
    {
      "epoch": 75.56,
      "learning_rate": 5.7592967383227235e-05,
      "loss": 0.0003,
      "step": 7443
    },
    {
      "epoch": 75.57,
      "learning_rate": 5.758123188272102e-05,
      "loss": 0.0036,
      "step": 7444
    },
    {
      "epoch": 75.58,
      "learning_rate": 5.756949595473085e-05,
      "loss": 0.0001,
      "step": 7445
    },
    {
      "epoch": 75.59,
      "learning_rate": 5.755775959991845e-05,
      "loss": 0.0056,
      "step": 7446
    },
    {
      "epoch": 75.6,
      "learning_rate": 5.754602281894562e-05,
      "loss": 0.0034,
      "step": 7447
    },
    {
      "epoch": 75.61,
      "learning_rate": 5.753428561247416e-05,
      "loss": 0.0101,
      "step": 7448
    },
    {
      "epoch": 75.62,
      "learning_rate": 5.75225479811659e-05,
      "loss": 0.0007,
      "step": 7449
    },
    {
      "epoch": 75.63,
      "learning_rate": 5.751080992568268e-05,
      "loss": 0.0053,
      "step": 7450
    },
    {
      "epoch": 75.64,
      "learning_rate": 5.749907144668637e-05,
      "loss": 0.0029,
      "step": 7451
    },
    {
      "epoch": 75.65,
      "learning_rate": 5.74873325448389e-05,
      "loss": 0.0008,
      "step": 7452
    },
    {
      "epoch": 75.66,
      "learning_rate": 5.747559322080216e-05,
      "loss": 0.0137,
      "step": 7453
    },
    {
      "epoch": 75.68,
      "learning_rate": 5.74638534752381e-05,
      "loss": 0.0283,
      "step": 7454
    },
    {
      "epoch": 75.69,
      "learning_rate": 5.745211330880872e-05,
      "loss": 0.0002,
      "step": 7455
    },
    {
      "epoch": 75.7,
      "learning_rate": 5.7440372722176005e-05,
      "loss": 0.003,
      "step": 7456
    },
    {
      "epoch": 75.71,
      "learning_rate": 5.7428631716001944e-05,
      "loss": 0.0003,
      "step": 7457
    },
    {
      "epoch": 75.72,
      "learning_rate": 5.741689029094861e-05,
      "loss": 0.005,
      "step": 7458
    },
    {
      "epoch": 75.73,
      "learning_rate": 5.740514844767805e-05,
      "loss": 0.0001,
      "step": 7459
    },
    {
      "epoch": 75.74,
      "learning_rate": 5.739340618685236e-05,
      "loss": 0.0209,
      "step": 7460
    },
    {
      "epoch": 75.75,
      "learning_rate": 5.7381663509133655e-05,
      "loss": 0.0031,
      "step": 7461
    },
    {
      "epoch": 75.76,
      "learning_rate": 5.7369920415184064e-05,
      "loss": 0.0002,
      "step": 7462
    },
    {
      "epoch": 75.77,
      "learning_rate": 5.735817690566575e-05,
      "loss": 0.0001,
      "step": 7463
    },
    {
      "epoch": 75.78,
      "learning_rate": 5.7346432981240904e-05,
      "loss": 0.0006,
      "step": 7464
    },
    {
      "epoch": 75.79,
      "learning_rate": 5.733468864257172e-05,
      "loss": 0.0011,
      "step": 7465
    },
    {
      "epoch": 75.8,
      "learning_rate": 5.732294389032042e-05,
      "loss": 0.001,
      "step": 7466
    },
    {
      "epoch": 75.81,
      "learning_rate": 5.731119872514929e-05,
      "loss": 0.014,
      "step": 7467
    },
    {
      "epoch": 75.82,
      "learning_rate": 5.7299453147720575e-05,
      "loss": 0.0005,
      "step": 7468
    },
    {
      "epoch": 75.83,
      "learning_rate": 5.72877071586966e-05,
      "loss": 0.0067,
      "step": 7469
    },
    {
      "epoch": 75.84,
      "learning_rate": 5.727596075873966e-05,
      "loss": 0.0001,
      "step": 7470
    },
    {
      "epoch": 75.85,
      "learning_rate": 5.726421394851211e-05,
      "loss": 0.0002,
      "step": 7471
    },
    {
      "epoch": 75.86,
      "learning_rate": 5.7252466728676324e-05,
      "loss": 0.0044,
      "step": 7472
    },
    {
      "epoch": 75.87,
      "learning_rate": 5.72407190998947e-05,
      "loss": 0.0005,
      "step": 7473
    },
    {
      "epoch": 75.88,
      "learning_rate": 5.722897106282963e-05,
      "loss": 0.0005,
      "step": 7474
    },
    {
      "epoch": 75.89,
      "learning_rate": 5.7217222618143596e-05,
      "loss": 0.0003,
      "step": 7475
    },
    {
      "epoch": 75.9,
      "learning_rate": 5.7205473766499005e-05,
      "loss": 0.0009,
      "step": 7476
    },
    {
      "epoch": 75.91,
      "learning_rate": 5.719372450855839e-05,
      "loss": 0.0008,
      "step": 7477
    },
    {
      "epoch": 75.92,
      "learning_rate": 5.718197484498421e-05,
      "loss": 0.0002,
      "step": 7478
    },
    {
      "epoch": 75.93,
      "learning_rate": 5.717022477643905e-05,
      "loss": 0.014,
      "step": 7479
    },
    {
      "epoch": 75.94,
      "learning_rate": 5.7158474303585404e-05,
      "loss": 0.0005,
      "step": 7480
    },
    {
      "epoch": 75.95,
      "learning_rate": 5.7146723427085914e-05,
      "loss": 0.0022,
      "step": 7481
    },
    {
      "epoch": 75.96,
      "learning_rate": 5.7134972147603105e-05,
      "loss": 0.0046,
      "step": 7482
    },
    {
      "epoch": 75.97,
      "learning_rate": 5.712322046579966e-05,
      "loss": 0.0001,
      "step": 7483
    },
    {
      "epoch": 75.98,
      "learning_rate": 5.711146838233817e-05,
      "loss": 0.0006,
      "step": 7484
    },
    {
      "epoch": 75.99,
      "learning_rate": 5.709971589788136e-05,
      "loss": 0.0075,
      "step": 7485
    },
    {
      "epoch": 76.0,
      "learning_rate": 5.708796301309186e-05,
      "loss": 0.0014,
      "step": 7486
    },
    {
      "epoch": 76.0,
      "eval_loss": 0.0171379204839468,
      "eval_runtime": 31.9241,
      "eval_samples_per_second": 98.671,
      "eval_steps_per_second": 6.171,
      "eval_wer": 0.0034891165172855313,
      "step": 7486
    },
    {
      "epoch": 76.01,
      "learning_rate": 5.707620972863241e-05,
      "loss": 0.0011,
      "step": 7487
    },
    {
      "epoch": 76.02,
      "learning_rate": 5.706445604516575e-05,
      "loss": 0.0004,
      "step": 7488
    },
    {
      "epoch": 76.03,
      "learning_rate": 5.7052701963354626e-05,
      "loss": 0.0001,
      "step": 7489
    },
    {
      "epoch": 76.04,
      "learning_rate": 5.704094748386184e-05,
      "loss": 0.0379,
      "step": 7490
    },
    {
      "epoch": 76.05,
      "learning_rate": 5.7029192607350146e-05,
      "loss": 0.0003,
      "step": 7491
    },
    {
      "epoch": 76.06,
      "learning_rate": 5.7017437334482417e-05,
      "loss": 0.0264,
      "step": 7492
    },
    {
      "epoch": 76.07,
      "learning_rate": 5.7005681665921464e-05,
      "loss": 0.0005,
      "step": 7493
    },
    {
      "epoch": 76.08,
      "learning_rate": 5.6993925602330175e-05,
      "loss": 0.0004,
      "step": 7494
    },
    {
      "epoch": 76.09,
      "learning_rate": 5.698216914437143e-05,
      "loss": 0.0005,
      "step": 7495
    },
    {
      "epoch": 76.1,
      "learning_rate": 5.6970412292708165e-05,
      "loss": 0.0008,
      "step": 7496
    },
    {
      "epoch": 76.11,
      "learning_rate": 5.695865504800327e-05,
      "loss": 0.0005,
      "step": 7497
    },
    {
      "epoch": 76.12,
      "learning_rate": 5.6946897410919766e-05,
      "loss": 0.0011,
      "step": 7498
    },
    {
      "epoch": 76.13,
      "learning_rate": 5.6935139382120554e-05,
      "loss": 0.0004,
      "step": 7499
    },
    {
      "epoch": 76.14,
      "learning_rate": 5.69233809622687e-05,
      "loss": 0.002,
      "step": 7500
    },
    {
      "epoch": 76.15,
      "learning_rate": 5.6911622152027214e-05,
      "loss": 0.0003,
      "step": 7501
    },
    {
      "epoch": 76.16,
      "learning_rate": 5.689986295205913e-05,
      "loss": 0.0069,
      "step": 7502
    },
    {
      "epoch": 76.17,
      "learning_rate": 5.68881033630275e-05,
      "loss": 0.0024,
      "step": 7503
    },
    {
      "epoch": 76.18,
      "learning_rate": 5.6876343385595446e-05,
      "loss": 0.0003,
      "step": 7504
    },
    {
      "epoch": 76.19,
      "learning_rate": 5.686458302042607e-05,
      "loss": 0.0008,
      "step": 7505
    },
    {
      "epoch": 76.2,
      "learning_rate": 5.6852822268182495e-05,
      "loss": 0.0132,
      "step": 7506
    },
    {
      "epoch": 76.21,
      "learning_rate": 5.684106112952787e-05,
      "loss": 0.0023,
      "step": 7507
    },
    {
      "epoch": 76.22,
      "learning_rate": 5.6829299605125405e-05,
      "loss": 0.0005,
      "step": 7508
    },
    {
      "epoch": 76.23,
      "learning_rate": 5.681753769563827e-05,
      "loss": 0.0002,
      "step": 7509
    },
    {
      "epoch": 76.24,
      "learning_rate": 5.680577540172969e-05,
      "loss": 0.011,
      "step": 7510
    },
    {
      "epoch": 76.25,
      "learning_rate": 5.679401272406292e-05,
      "loss": 0.0007,
      "step": 7511
    },
    {
      "epoch": 76.26,
      "learning_rate": 5.67822496633012e-05,
      "loss": 0.0003,
      "step": 7512
    },
    {
      "epoch": 76.27,
      "learning_rate": 5.677048622010786e-05,
      "loss": 0.0158,
      "step": 7513
    },
    {
      "epoch": 76.28,
      "learning_rate": 5.6758722395146145e-05,
      "loss": 0.0052,
      "step": 7514
    },
    {
      "epoch": 76.29,
      "learning_rate": 5.674695818907943e-05,
      "loss": 0.0002,
      "step": 7515
    },
    {
      "epoch": 76.3,
      "learning_rate": 5.673519360257103e-05,
      "loss": 0.0005,
      "step": 7516
    },
    {
      "epoch": 76.31,
      "learning_rate": 5.6723428636284356e-05,
      "loss": 0.0007,
      "step": 7517
    },
    {
      "epoch": 76.32,
      "learning_rate": 5.6711663290882776e-05,
      "loss": 0.0075,
      "step": 7518
    },
    {
      "epoch": 76.34,
      "learning_rate": 5.6699897567029714e-05,
      "loss": 0.003,
      "step": 7519
    },
    {
      "epoch": 76.35,
      "learning_rate": 5.6688131465388594e-05,
      "loss": 0.0008,
      "step": 7520
    },
    {
      "epoch": 76.36,
      "learning_rate": 5.6676364986622886e-05,
      "loss": 0.0022,
      "step": 7521
    },
    {
      "epoch": 76.37,
      "learning_rate": 5.6664598131396054e-05,
      "loss": 0.0004,
      "step": 7522
    },
    {
      "epoch": 76.38,
      "learning_rate": 5.665283090037161e-05,
      "loss": 0.0027,
      "step": 7523
    },
    {
      "epoch": 76.39,
      "learning_rate": 5.664106329421306e-05,
      "loss": 0.0002,
      "step": 7524
    },
    {
      "epoch": 76.4,
      "learning_rate": 5.6629295313583974e-05,
      "loss": 0.0002,
      "step": 7525
    },
    {
      "epoch": 76.41,
      "learning_rate": 5.6617526959147884e-05,
      "loss": 0.002,
      "step": 7526
    },
    {
      "epoch": 76.42,
      "learning_rate": 5.6605758231568384e-05,
      "loss": 0.0007,
      "step": 7527
    },
    {
      "epoch": 76.43,
      "learning_rate": 5.659398913150907e-05,
      "loss": 0.0008,
      "step": 7528
    },
    {
      "epoch": 76.44,
      "learning_rate": 5.65822196596336e-05,
      "loss": 0.0001,
      "step": 7529
    },
    {
      "epoch": 76.45,
      "learning_rate": 5.6570449816605596e-05,
      "loss": 0.0151,
      "step": 7530
    },
    {
      "epoch": 76.46,
      "learning_rate": 5.655867960308871e-05,
      "loss": 0.0057,
      "step": 7531
    },
    {
      "epoch": 76.47,
      "learning_rate": 5.6546909019746666e-05,
      "loss": 0.0056,
      "step": 7532
    },
    {
      "epoch": 76.48,
      "learning_rate": 5.653513806724315e-05,
      "loss": 0.0001,
      "step": 7533
    },
    {
      "epoch": 76.49,
      "learning_rate": 5.652336674624191e-05,
      "loss": 0.0001,
      "step": 7534
    },
    {
      "epoch": 76.5,
      "learning_rate": 5.651159505740667e-05,
      "loss": 0.0013,
      "step": 7535
    },
    {
      "epoch": 76.51,
      "learning_rate": 5.649982300140123e-05,
      "loss": 0.0012,
      "step": 7536
    },
    {
      "epoch": 76.52,
      "learning_rate": 5.6488050578889376e-05,
      "loss": 0.0001,
      "step": 7537
    },
    {
      "epoch": 76.53,
      "learning_rate": 5.647627779053491e-05,
      "loss": 0.0003,
      "step": 7538
    },
    {
      "epoch": 76.54,
      "learning_rate": 5.646450463700167e-05,
      "loss": 0.0012,
      "step": 7539
    },
    {
      "epoch": 76.55,
      "learning_rate": 5.6452731118953506e-05,
      "loss": 0.0016,
      "step": 7540
    },
    {
      "epoch": 76.56,
      "learning_rate": 5.6440957237054306e-05,
      "loss": 0.0062,
      "step": 7541
    },
    {
      "epoch": 76.57,
      "learning_rate": 5.6429182991967965e-05,
      "loss": 0.0002,
      "step": 7542
    },
    {
      "epoch": 76.58,
      "learning_rate": 5.641740838435839e-05,
      "loss": 0.0006,
      "step": 7543
    },
    {
      "epoch": 76.59,
      "learning_rate": 5.6405633414889515e-05,
      "loss": 0.0001,
      "step": 7544
    },
    {
      "epoch": 76.6,
      "learning_rate": 5.6393858084225305e-05,
      "loss": 0.0001,
      "step": 7545
    },
    {
      "epoch": 76.61,
      "learning_rate": 5.6382082393029746e-05,
      "loss": 0.0073,
      "step": 7546
    },
    {
      "epoch": 76.62,
      "learning_rate": 5.6370306341966806e-05,
      "loss": 0.0001,
      "step": 7547
    },
    {
      "epoch": 76.63,
      "learning_rate": 5.635852993170052e-05,
      "loss": 0.0008,
      "step": 7548
    },
    {
      "epoch": 76.64,
      "learning_rate": 5.634675316289494e-05,
      "loss": 0.0009,
      "step": 7549
    },
    {
      "epoch": 76.65,
      "learning_rate": 5.633497603621409e-05,
      "loss": 0.0109,
      "step": 7550
    },
    {
      "epoch": 76.66,
      "learning_rate": 5.63231985523221e-05,
      "loss": 0.0022,
      "step": 7551
    },
    {
      "epoch": 76.67,
      "learning_rate": 5.6311420711883025e-05,
      "loss": 0.0001,
      "step": 7552
    },
    {
      "epoch": 76.68,
      "learning_rate": 5.629964251556099e-05,
      "loss": 0.0154,
      "step": 7553
    },
    {
      "epoch": 76.69,
      "learning_rate": 5.6287863964020136e-05,
      "loss": 0.0013,
      "step": 7554
    },
    {
      "epoch": 76.7,
      "learning_rate": 5.627608505792465e-05,
      "loss": 0.0015,
      "step": 7555
    },
    {
      "epoch": 76.71,
      "learning_rate": 5.626430579793866e-05,
      "loss": 0.0003,
      "step": 7556
    },
    {
      "epoch": 76.72,
      "learning_rate": 5.625252618472641e-05,
      "loss": 0.0006,
      "step": 7557
    },
    {
      "epoch": 76.73,
      "learning_rate": 5.624074621895209e-05,
      "loss": 0.0091,
      "step": 7558
    },
    {
      "epoch": 76.74,
      "learning_rate": 5.6228965901279964e-05,
      "loss": 0.0003,
      "step": 7559
    },
    {
      "epoch": 76.75,
      "learning_rate": 5.621718523237427e-05,
      "loss": 0.0002,
      "step": 7560
    },
    {
      "epoch": 76.76,
      "learning_rate": 5.6205404212899285e-05,
      "loss": 0.0006,
      "step": 7561
    },
    {
      "epoch": 76.77,
      "learning_rate": 5.619362284351931e-05,
      "loss": 0.0006,
      "step": 7562
    },
    {
      "epoch": 76.78,
      "learning_rate": 5.6181841124898684e-05,
      "loss": 0.0002,
      "step": 7563
    },
    {
      "epoch": 76.79,
      "learning_rate": 5.617005905770172e-05,
      "loss": 0.0035,
      "step": 7564
    },
    {
      "epoch": 76.8,
      "learning_rate": 5.615827664259278e-05,
      "loss": 0.0014,
      "step": 7565
    },
    {
      "epoch": 76.81,
      "learning_rate": 5.614649388023623e-05,
      "loss": 0.0059,
      "step": 7566
    },
    {
      "epoch": 76.82,
      "learning_rate": 5.61347107712965e-05,
      "loss": 0.0013,
      "step": 7567
    },
    {
      "epoch": 76.83,
      "learning_rate": 5.612292731643798e-05,
      "loss": 0.0033,
      "step": 7568
    },
    {
      "epoch": 76.84,
      "learning_rate": 5.611114351632509e-05,
      "loss": 0.0003,
      "step": 7569
    },
    {
      "epoch": 76.85,
      "learning_rate": 5.609935937162233e-05,
      "loss": 0.0006,
      "step": 7570
    },
    {
      "epoch": 76.86,
      "learning_rate": 5.6087574882994135e-05,
      "loss": 0.0002,
      "step": 7571
    },
    {
      "epoch": 76.87,
      "learning_rate": 5.6075790051105023e-05,
      "loss": 0.0031,
      "step": 7572
    },
    {
      "epoch": 76.88,
      "learning_rate": 5.606400487661949e-05,
      "loss": 0.0001,
      "step": 7573
    },
    {
      "epoch": 76.89,
      "learning_rate": 5.605221936020207e-05,
      "loss": 0.0045,
      "step": 7574
    },
    {
      "epoch": 76.9,
      "learning_rate": 5.604043350251733e-05,
      "loss": 0.0014,
      "step": 7575
    },
    {
      "epoch": 76.91,
      "learning_rate": 5.602864730422983e-05,
      "loss": 0.0001,
      "step": 7576
    },
    {
      "epoch": 76.92,
      "learning_rate": 5.601686076600414e-05,
      "loss": 0.0011,
      "step": 7577
    },
    {
      "epoch": 76.93,
      "learning_rate": 5.600507388850491e-05,
      "loss": 0.0025,
      "step": 7578
    },
    {
      "epoch": 76.94,
      "learning_rate": 5.5993286672396735e-05,
      "loss": 0.0007,
      "step": 7579
    },
    {
      "epoch": 76.95,
      "learning_rate": 5.59814991183443e-05,
      "loss": 0.0001,
      "step": 7580
    },
    {
      "epoch": 76.96,
      "learning_rate": 5.596971122701221e-05,
      "loss": 0.0018,
      "step": 7581
    },
    {
      "epoch": 76.97,
      "learning_rate": 5.595792299906521e-05,
      "loss": 0.0039,
      "step": 7582
    },
    {
      "epoch": 76.98,
      "learning_rate": 5.5946134435167984e-05,
      "loss": 0.0161,
      "step": 7583
    },
    {
      "epoch": 76.99,
      "learning_rate": 5.593434553598526e-05,
      "loss": 0.0196,
      "step": 7584
    },
    {
      "epoch": 76.99,
      "eval_loss": 0.020533548668026924,
      "eval_runtime": 32.2741,
      "eval_samples_per_second": 97.601,
      "eval_steps_per_second": 6.104,
      "eval_wer": 0.003745198463508323,
      "step": 7584
    },
    {
      "epoch": 77.01,
      "learning_rate": 5.592255630218174e-05,
      "loss": 0.0001,
      "step": 7585
    },
    {
      "epoch": 77.02,
      "learning_rate": 5.591076673442225e-05,
      "loss": 0.0082,
      "step": 7586
    },
    {
      "epoch": 77.03,
      "learning_rate": 5.589897683337152e-05,
      "loss": 0.0001,
      "step": 7587
    },
    {
      "epoch": 77.04,
      "learning_rate": 5.588718659969438e-05,
      "loss": 0.0002,
      "step": 7588
    },
    {
      "epoch": 77.05,
      "learning_rate": 5.5875396034055616e-05,
      "loss": 0.0023,
      "step": 7589
    },
    {
      "epoch": 77.06,
      "learning_rate": 5.58636051371201e-05,
      "loss": 0.001,
      "step": 7590
    },
    {
      "epoch": 77.07,
      "learning_rate": 5.5851813909552654e-05,
      "loss": 0.0002,
      "step": 7591
    },
    {
      "epoch": 77.08,
      "learning_rate": 5.584002235201817e-05,
      "loss": 0.0001,
      "step": 7592
    },
    {
      "epoch": 77.09,
      "learning_rate": 5.582823046518156e-05,
      "loss": 0.0013,
      "step": 7593
    },
    {
      "epoch": 77.1,
      "learning_rate": 5.581643824970768e-05,
      "loss": 0.0004,
      "step": 7594
    },
    {
      "epoch": 77.11,
      "learning_rate": 5.5804645706261514e-05,
      "loss": 0.0002,
      "step": 7595
    },
    {
      "epoch": 77.12,
      "learning_rate": 5.579285283550798e-05,
      "loss": 0.0002,
      "step": 7596
    },
    {
      "epoch": 77.13,
      "learning_rate": 5.578105963811206e-05,
      "loss": 0.0008,
      "step": 7597
    },
    {
      "epoch": 77.14,
      "learning_rate": 5.576926611473872e-05,
      "loss": 0.0005,
      "step": 7598
    },
    {
      "epoch": 77.15,
      "learning_rate": 5.575747226605298e-05,
      "loss": 0.0005,
      "step": 7599
    },
    {
      "epoch": 77.16,
      "learning_rate": 5.574567809271984e-05,
      "loss": 0.0039,
      "step": 7600
    },
    {
      "epoch": 77.17,
      "learning_rate": 5.573388359540438e-05,
      "loss": 0.0031,
      "step": 7601
    },
    {
      "epoch": 77.18,
      "learning_rate": 5.57220887747716e-05,
      "loss": 0.001,
      "step": 7602
    },
    {
      "epoch": 77.19,
      "learning_rate": 5.571029363148663e-05,
      "loss": 0.0002,
      "step": 7603
    },
    {
      "epoch": 77.2,
      "learning_rate": 5.569849816621454e-05,
      "loss": 0.0001,
      "step": 7604
    },
    {
      "epoch": 77.21,
      "learning_rate": 5.568670237962045e-05,
      "loss": 0.0009,
      "step": 7605
    },
    {
      "epoch": 77.22,
      "learning_rate": 5.567490627236946e-05,
      "loss": 0.0003,
      "step": 7606
    },
    {
      "epoch": 77.23,
      "learning_rate": 5.566310984512678e-05,
      "loss": 0.0002,
      "step": 7607
    },
    {
      "epoch": 77.24,
      "learning_rate": 5.5651313098557524e-05,
      "loss": 0.0001,
      "step": 7608
    },
    {
      "epoch": 77.25,
      "learning_rate": 5.563951603332689e-05,
      "loss": 0.0013,
      "step": 7609
    },
    {
      "epoch": 77.26,
      "learning_rate": 5.562771865010009e-05,
      "loss": 0.0012,
      "step": 7610
    },
    {
      "epoch": 77.27,
      "learning_rate": 5.5615920949542344e-05,
      "loss": 0.0007,
      "step": 7611
    },
    {
      "epoch": 77.28,
      "learning_rate": 5.560412293231888e-05,
      "loss": 0.0001,
      "step": 7612
    },
    {
      "epoch": 77.29,
      "learning_rate": 5.559232459909496e-05,
      "loss": 0.0007,
      "step": 7613
    },
    {
      "epoch": 77.3,
      "learning_rate": 5.5580525950535856e-05,
      "loss": 0.0009,
      "step": 7614
    },
    {
      "epoch": 77.31,
      "learning_rate": 5.5568726987306875e-05,
      "loss": 0.0002,
      "step": 7615
    },
    {
      "epoch": 77.32,
      "learning_rate": 5.5556927710073314e-05,
      "loss": 0.0018,
      "step": 7616
    },
    {
      "epoch": 77.33,
      "learning_rate": 5.554512811950049e-05,
      "loss": 0.0007,
      "step": 7617
    },
    {
      "epoch": 77.34,
      "learning_rate": 5.553332821625377e-05,
      "loss": 0.0001,
      "step": 7618
    },
    {
      "epoch": 77.35,
      "learning_rate": 5.552152800099849e-05,
      "loss": 0.0002,
      "step": 7619
    },
    {
      "epoch": 77.36,
      "learning_rate": 5.550972747440006e-05,
      "loss": 0.0003,
      "step": 7620
    },
    {
      "epoch": 77.37,
      "learning_rate": 5.5497926637123865e-05,
      "loss": 0.002,
      "step": 7621
    },
    {
      "epoch": 77.38,
      "learning_rate": 5.548612548983532e-05,
      "loss": 0.0011,
      "step": 7622
    },
    {
      "epoch": 77.39,
      "learning_rate": 5.5474324033199854e-05,
      "loss": 0.0002,
      "step": 7623
    },
    {
      "epoch": 77.4,
      "learning_rate": 5.546252226788293e-05,
      "loss": 0.0001,
      "step": 7624
    },
    {
      "epoch": 77.41,
      "learning_rate": 5.545072019455e-05,
      "loss": 0.0068,
      "step": 7625
    },
    {
      "epoch": 77.42,
      "learning_rate": 5.5438917813866554e-05,
      "loss": 0.0041,
      "step": 7626
    },
    {
      "epoch": 77.43,
      "learning_rate": 5.542711512649809e-05,
      "loss": 0.0,
      "step": 7627
    },
    {
      "epoch": 77.44,
      "learning_rate": 5.541531213311014e-05,
      "loss": 0.0022,
      "step": 7628
    },
    {
      "epoch": 77.45,
      "learning_rate": 5.540350883436825e-05,
      "loss": 0.0018,
      "step": 7629
    },
    {
      "epoch": 77.46,
      "learning_rate": 5.539170523093794e-05,
      "loss": 0.0003,
      "step": 7630
    },
    {
      "epoch": 77.47,
      "learning_rate": 5.537990132348481e-05,
      "loss": 0.0022,
      "step": 7631
    },
    {
      "epoch": 77.48,
      "learning_rate": 5.536809711267443e-05,
      "loss": 0.0002,
      "step": 7632
    },
    {
      "epoch": 77.49,
      "learning_rate": 5.5356292599172434e-05,
      "loss": 0.0007,
      "step": 7633
    },
    {
      "epoch": 77.5,
      "learning_rate": 5.5344487783644406e-05,
      "loss": 0.0005,
      "step": 7634
    },
    {
      "epoch": 77.51,
      "learning_rate": 5.533268266675601e-05,
      "loss": 0.001,
      "step": 7635
    },
    {
      "epoch": 77.52,
      "learning_rate": 5.53208772491729e-05,
      "loss": 0.0032,
      "step": 7636
    },
    {
      "epoch": 77.53,
      "learning_rate": 5.530907153156076e-05,
      "loss": 0.0004,
      "step": 7637
    },
    {
      "epoch": 77.54,
      "learning_rate": 5.529726551458526e-05,
      "loss": 0.0002,
      "step": 7638
    },
    {
      "epoch": 77.55,
      "learning_rate": 5.5285459198912114e-05,
      "loss": 0.0128,
      "step": 7639
    },
    {
      "epoch": 77.56,
      "learning_rate": 5.527365258520705e-05,
      "loss": 0.0008,
      "step": 7640
    },
    {
      "epoch": 77.57,
      "learning_rate": 5.526184567413581e-05,
      "loss": 0.0001,
      "step": 7641
    },
    {
      "epoch": 77.58,
      "learning_rate": 5.525003846636415e-05,
      "loss": 0.0002,
      "step": 7642
    },
    {
      "epoch": 77.59,
      "learning_rate": 5.523823096255784e-05,
      "loss": 0.0053,
      "step": 7643
    },
    {
      "epoch": 77.6,
      "learning_rate": 5.522642316338268e-05,
      "loss": 0.0002,
      "step": 7644
    },
    {
      "epoch": 77.61,
      "learning_rate": 5.5214615069504474e-05,
      "loss": 0.004,
      "step": 7645
    },
    {
      "epoch": 77.62,
      "learning_rate": 5.5202806681589045e-05,
      "loss": 0.0003,
      "step": 7646
    },
    {
      "epoch": 77.63,
      "learning_rate": 5.519099800030223e-05,
      "loss": 0.002,
      "step": 7647
    },
    {
      "epoch": 77.64,
      "learning_rate": 5.51791890263099e-05,
      "loss": 0.0021,
      "step": 7648
    },
    {
      "epoch": 77.65,
      "learning_rate": 5.516737976027793e-05,
      "loss": 0.0141,
      "step": 7649
    },
    {
      "epoch": 77.66,
      "learning_rate": 5.5155570202872186e-05,
      "loss": 0.0008,
      "step": 7650
    },
    {
      "epoch": 77.68,
      "learning_rate": 5.51437603547586e-05,
      "loss": 0.0001,
      "step": 7651
    },
    {
      "epoch": 77.69,
      "learning_rate": 5.513195021660308e-05,
      "loss": 0.0,
      "step": 7652
    },
    {
      "epoch": 77.7,
      "learning_rate": 5.512013978907157e-05,
      "loss": 0.0023,
      "step": 7653
    },
    {
      "epoch": 77.71,
      "learning_rate": 5.510832907283004e-05,
      "loss": 0.0001,
      "step": 7654
    },
    {
      "epoch": 77.72,
      "learning_rate": 5.509651806854445e-05,
      "loss": 0.0,
      "step": 7655
    },
    {
      "epoch": 77.73,
      "learning_rate": 5.508470677688079e-05,
      "loss": 0.012,
      "step": 7656
    },
    {
      "epoch": 77.74,
      "learning_rate": 5.507289519850506e-05,
      "loss": 0.0002,
      "step": 7657
    },
    {
      "epoch": 77.75,
      "learning_rate": 5.506108333408329e-05,
      "loss": 0.0015,
      "step": 7658
    },
    {
      "epoch": 77.76,
      "learning_rate": 5.5049271184281514e-05,
      "loss": 0.0002,
      "step": 7659
    },
    {
      "epoch": 77.77,
      "learning_rate": 5.503745874976579e-05,
      "loss": 0.0001,
      "step": 7660
    },
    {
      "epoch": 77.78,
      "learning_rate": 5.502564603120217e-05,
      "loss": 0.0001,
      "step": 7661
    },
    {
      "epoch": 77.79,
      "learning_rate": 5.5013833029256764e-05,
      "loss": 0.0008,
      "step": 7662
    },
    {
      "epoch": 77.8,
      "learning_rate": 5.500201974459567e-05,
      "loss": 0.0372,
      "step": 7663
    },
    {
      "epoch": 77.81,
      "learning_rate": 5.499020617788497e-05,
      "loss": 0.0037,
      "step": 7664
    },
    {
      "epoch": 77.82,
      "learning_rate": 5.497839232979084e-05,
      "loss": 0.0127,
      "step": 7665
    },
    {
      "epoch": 77.83,
      "learning_rate": 5.4966578200979414e-05,
      "loss": 0.0002,
      "step": 7666
    },
    {
      "epoch": 77.84,
      "learning_rate": 5.495476379211685e-05,
      "loss": 0.0054,
      "step": 7667
    },
    {
      "epoch": 77.85,
      "learning_rate": 5.494294910386933e-05,
      "loss": 0.0097,
      "step": 7668
    },
    {
      "epoch": 77.86,
      "learning_rate": 5.493113413690306e-05,
      "loss": 0.0006,
      "step": 7669
    },
    {
      "epoch": 77.87,
      "learning_rate": 5.4919318891884254e-05,
      "loss": 0.0049,
      "step": 7670
    },
    {
      "epoch": 77.88,
      "learning_rate": 5.4907503369479116e-05,
      "loss": 0.0005,
      "step": 7671
    },
    {
      "epoch": 77.89,
      "learning_rate": 5.489568757035391e-05,
      "loss": 0.0001,
      "step": 7672
    },
    {
      "epoch": 77.9,
      "learning_rate": 5.488387149517491e-05,
      "loss": 0.0106,
      "step": 7673
    },
    {
      "epoch": 77.91,
      "learning_rate": 5.487205514460836e-05,
      "loss": 0.0009,
      "step": 7674
    },
    {
      "epoch": 77.92,
      "learning_rate": 5.486023851932056e-05,
      "loss": 0.003,
      "step": 7675
    },
    {
      "epoch": 77.93,
      "learning_rate": 5.4848421619977816e-05,
      "loss": 0.0001,
      "step": 7676
    },
    {
      "epoch": 77.94,
      "learning_rate": 5.4836604447246454e-05,
      "loss": 0.0001,
      "step": 7677
    },
    {
      "epoch": 77.95,
      "learning_rate": 5.482478700179281e-05,
      "loss": 0.0002,
      "step": 7678
    },
    {
      "epoch": 77.96,
      "learning_rate": 5.4812969284283245e-05,
      "loss": 0.0052,
      "step": 7679
    },
    {
      "epoch": 77.97,
      "learning_rate": 5.480115129538409e-05,
      "loss": 0.0003,
      "step": 7680
    },
    {
      "epoch": 77.98,
      "learning_rate": 5.478933303576177e-05,
      "loss": 0.0003,
      "step": 7681
    },
    {
      "epoch": 77.99,
      "learning_rate": 5.4777514506082664e-05,
      "loss": 0.0007,
      "step": 7682
    },
    {
      "epoch": 78.0,
      "learning_rate": 5.4765695707013186e-05,
      "loss": 0.0001,
      "step": 7683
    },
    {
      "epoch": 78.0,
      "eval_loss": 0.018569594249129295,
      "eval_runtime": 31.949,
      "eval_samples_per_second": 98.595,
      "eval_steps_per_second": 6.166,
      "eval_wer": 0.0031049935979513446,
      "step": 7683
    },
    {
      "epoch": 78.01,
      "learning_rate": 5.475387663921975e-05,
      "loss": 0.0003,
      "step": 7684
    },
    {
      "epoch": 78.02,
      "learning_rate": 5.474205730336883e-05,
      "loss": 0.0004,
      "step": 7685
    },
    {
      "epoch": 78.03,
      "learning_rate": 5.473023770012686e-05,
      "loss": 0.0078,
      "step": 7686
    },
    {
      "epoch": 78.04,
      "learning_rate": 5.471841783016034e-05,
      "loss": 0.0004,
      "step": 7687
    },
    {
      "epoch": 78.05,
      "learning_rate": 5.470659769413571e-05,
      "loss": 0.0001,
      "step": 7688
    },
    {
      "epoch": 78.06,
      "learning_rate": 5.469477729271954e-05,
      "loss": 0.0156,
      "step": 7689
    },
    {
      "epoch": 78.07,
      "learning_rate": 5.468295662657829e-05,
      "loss": 0.0013,
      "step": 7690
    },
    {
      "epoch": 78.08,
      "learning_rate": 5.467113569637852e-05,
      "loss": 0.0075,
      "step": 7691
    },
    {
      "epoch": 78.09,
      "learning_rate": 5.465931450278676e-05,
      "loss": 0.0003,
      "step": 7692
    },
    {
      "epoch": 78.1,
      "learning_rate": 5.464749304646962e-05,
      "loss": 0.0007,
      "step": 7693
    },
    {
      "epoch": 78.11,
      "learning_rate": 5.463567132809363e-05,
      "loss": 0.0025,
      "step": 7694
    },
    {
      "epoch": 78.12,
      "learning_rate": 5.46238493483254e-05,
      "loss": 0.009,
      "step": 7695
    },
    {
      "epoch": 78.13,
      "learning_rate": 5.461202710783154e-05,
      "loss": 0.0009,
      "step": 7696
    },
    {
      "epoch": 78.14,
      "learning_rate": 5.460020460727866e-05,
      "loss": 0.0003,
      "step": 7697
    },
    {
      "epoch": 78.15,
      "learning_rate": 5.4588381847333416e-05,
      "loss": 0.004,
      "step": 7698
    },
    {
      "epoch": 78.16,
      "learning_rate": 5.4576558828662436e-05,
      "loss": 0.0013,
      "step": 7699
    },
    {
      "epoch": 78.17,
      "learning_rate": 5.456473555193242e-05,
      "loss": 0.0003,
      "step": 7700
    },
    {
      "epoch": 78.18,
      "learning_rate": 5.455291201781001e-05,
      "loss": 0.001,
      "step": 7701
    },
    {
      "epoch": 78.19,
      "learning_rate": 5.454108822696194e-05,
      "loss": 0.0002,
      "step": 7702
    },
    {
      "epoch": 78.2,
      "learning_rate": 5.4529264180054886e-05,
      "loss": 0.003,
      "step": 7703
    },
    {
      "epoch": 78.21,
      "learning_rate": 5.451743987775559e-05,
      "loss": 0.0004,
      "step": 7704
    },
    {
      "epoch": 78.22,
      "learning_rate": 5.4505615320730784e-05,
      "loss": 0.0032,
      "step": 7705
    },
    {
      "epoch": 78.23,
      "learning_rate": 5.4493790509647225e-05,
      "loss": 0.0018,
      "step": 7706
    },
    {
      "epoch": 78.24,
      "learning_rate": 5.448196544517168e-05,
      "loss": 0.0004,
      "step": 7707
    },
    {
      "epoch": 78.25,
      "learning_rate": 5.447014012797094e-05,
      "loss": 0.0,
      "step": 7708
    },
    {
      "epoch": 78.26,
      "learning_rate": 5.4458314558711767e-05,
      "loss": 0.0006,
      "step": 7709
    },
    {
      "epoch": 78.27,
      "learning_rate": 5.444648873806101e-05,
      "loss": 0.0004,
      "step": 7710
    },
    {
      "epoch": 78.28,
      "learning_rate": 5.443466266668546e-05,
      "loss": 0.0009,
      "step": 7711
    },
    {
      "epoch": 78.29,
      "learning_rate": 5.442283634525199e-05,
      "loss": 0.0164,
      "step": 7712
    },
    {
      "epoch": 78.3,
      "learning_rate": 5.441100977442743e-05,
      "loss": 0.0021,
      "step": 7713
    },
    {
      "epoch": 78.31,
      "learning_rate": 5.4399182954878656e-05,
      "loss": 0.0158,
      "step": 7714
    },
    {
      "epoch": 78.32,
      "learning_rate": 5.4387355887272525e-05,
      "loss": 0.0242,
      "step": 7715
    },
    {
      "epoch": 78.34,
      "learning_rate": 5.437552857227597e-05,
      "loss": 0.0001,
      "step": 7716
    },
    {
      "epoch": 78.35,
      "learning_rate": 5.4363701010555866e-05,
      "loss": 0.0001,
      "step": 7717
    },
    {
      "epoch": 78.36,
      "learning_rate": 5.4351873202779156e-05,
      "loss": 0.0028,
      "step": 7718
    },
    {
      "epoch": 78.37,
      "learning_rate": 5.4340045149612786e-05,
      "loss": 0.0002,
      "step": 7719
    },
    {
      "epoch": 78.38,
      "learning_rate": 5.432821685172367e-05,
      "loss": 0.0002,
      "step": 7720
    },
    {
      "epoch": 78.39,
      "learning_rate": 5.431638830977879e-05,
      "loss": 0.0001,
      "step": 7721
    },
    {
      "epoch": 78.4,
      "learning_rate": 5.430455952444513e-05,
      "loss": 0.005,
      "step": 7722
    },
    {
      "epoch": 78.41,
      "learning_rate": 5.429273049638969e-05,
      "loss": 0.0018,
      "step": 7723
    },
    {
      "epoch": 78.42,
      "learning_rate": 5.4280901226279444e-05,
      "loss": 0.0007,
      "step": 7724
    },
    {
      "epoch": 78.43,
      "learning_rate": 5.426907171478143e-05,
      "loss": 0.0002,
      "step": 7725
    },
    {
      "epoch": 78.44,
      "learning_rate": 5.4257241962562676e-05,
      "loss": 0.0002,
      "step": 7726
    },
    {
      "epoch": 78.45,
      "learning_rate": 5.424541197029024e-05,
      "loss": 0.0071,
      "step": 7727
    },
    {
      "epoch": 78.46,
      "learning_rate": 5.4233581738631165e-05,
      "loss": 0.0001,
      "step": 7728
    },
    {
      "epoch": 78.47,
      "learning_rate": 5.422175126825253e-05,
      "loss": 0.0004,
      "step": 7729
    },
    {
      "epoch": 78.48,
      "learning_rate": 5.420992055982143e-05,
      "loss": 0.0003,
      "step": 7730
    },
    {
      "epoch": 78.49,
      "learning_rate": 5.4198089614004956e-05,
      "loss": 0.0007,
      "step": 7731
    },
    {
      "epoch": 78.5,
      "learning_rate": 5.418625843147021e-05,
      "loss": 0.0009,
      "step": 7732
    },
    {
      "epoch": 78.51,
      "learning_rate": 5.417442701288434e-05,
      "loss": 0.0002,
      "step": 7733
    },
    {
      "epoch": 78.52,
      "learning_rate": 5.416259535891447e-05,
      "loss": 0.0,
      "step": 7734
    },
    {
      "epoch": 78.53,
      "learning_rate": 5.415076347022776e-05,
      "loss": 0.0001,
      "step": 7735
    },
    {
      "epoch": 78.54,
      "learning_rate": 5.413893134749139e-05,
      "loss": 0.0001,
      "step": 7736
    },
    {
      "epoch": 78.55,
      "learning_rate": 5.412709899137252e-05,
      "loss": 0.008,
      "step": 7737
    },
    {
      "epoch": 78.56,
      "learning_rate": 5.4115266402538334e-05,
      "loss": 0.0017,
      "step": 7738
    },
    {
      "epoch": 78.57,
      "learning_rate": 5.410343358165606e-05,
      "loss": 0.0108,
      "step": 7739
    },
    {
      "epoch": 78.58,
      "learning_rate": 5.409160052939292e-05,
      "loss": 0.0031,
      "step": 7740
    },
    {
      "epoch": 78.59,
      "learning_rate": 5.4079767246416114e-05,
      "loss": 0.0042,
      "step": 7741
    },
    {
      "epoch": 78.6,
      "learning_rate": 5.4067933733392915e-05,
      "loss": 0.0003,
      "step": 7742
    },
    {
      "epoch": 78.61,
      "learning_rate": 5.405609999099057e-05,
      "loss": 0.0,
      "step": 7743
    },
    {
      "epoch": 78.62,
      "learning_rate": 5.4044266019876374e-05,
      "loss": 0.0008,
      "step": 7744
    },
    {
      "epoch": 78.63,
      "learning_rate": 5.403243182071758e-05,
      "loss": 0.0003,
      "step": 7745
    },
    {
      "epoch": 78.64,
      "learning_rate": 5.402059739418148e-05,
      "loss": 0.0,
      "step": 7746
    },
    {
      "epoch": 78.65,
      "learning_rate": 5.4008762740935416e-05,
      "loss": 0.0009,
      "step": 7747
    },
    {
      "epoch": 78.66,
      "learning_rate": 5.399692786164668e-05,
      "loss": 0.0081,
      "step": 7748
    },
    {
      "epoch": 78.67,
      "learning_rate": 5.3985092756982636e-05,
      "loss": 0.0004,
      "step": 7749
    },
    {
      "epoch": 78.68,
      "learning_rate": 5.39732574276106e-05,
      "loss": 0.0,
      "step": 7750
    },
    {
      "epoch": 78.69,
      "learning_rate": 5.396142187419795e-05,
      "loss": 0.0,
      "step": 7751
    },
    {
      "epoch": 78.7,
      "learning_rate": 5.3949586097412066e-05,
      "loss": 0.0,
      "step": 7752
    },
    {
      "epoch": 78.71,
      "learning_rate": 5.3937750097920316e-05,
      "loss": 0.0001,
      "step": 7753
    },
    {
      "epoch": 78.72,
      "learning_rate": 5.39259138763901e-05,
      "loss": 0.0006,
      "step": 7754
    },
    {
      "epoch": 78.73,
      "learning_rate": 5.391407743348884e-05,
      "loss": 0.0005,
      "step": 7755
    },
    {
      "epoch": 78.74,
      "learning_rate": 5.390224076988396e-05,
      "loss": 0.0,
      "step": 7756
    },
    {
      "epoch": 78.75,
      "learning_rate": 5.389040388624289e-05,
      "loss": 0.0,
      "step": 7757
    },
    {
      "epoch": 78.76,
      "learning_rate": 5.3878566783233074e-05,
      "loss": 0.0232,
      "step": 7758
    },
    {
      "epoch": 78.77,
      "learning_rate": 5.386672946152197e-05,
      "loss": 0.001,
      "step": 7759
    },
    {
      "epoch": 78.78,
      "learning_rate": 5.385489192177706e-05,
      "loss": 0.0027,
      "step": 7760
    },
    {
      "epoch": 78.79,
      "learning_rate": 5.384305416466584e-05,
      "loss": 0.0002,
      "step": 7761
    },
    {
      "epoch": 78.8,
      "learning_rate": 5.383121619085577e-05,
      "loss": 0.0006,
      "step": 7762
    },
    {
      "epoch": 78.81,
      "learning_rate": 5.3819378001014395e-05,
      "loss": 0.0004,
      "step": 7763
    },
    {
      "epoch": 78.82,
      "learning_rate": 5.380753959580922e-05,
      "loss": 0.0001,
      "step": 7764
    },
    {
      "epoch": 78.83,
      "learning_rate": 5.37957009759078e-05,
      "loss": 0.0001,
      "step": 7765
    },
    {
      "epoch": 78.84,
      "learning_rate": 5.378386214197764e-05,
      "loss": 0.003,
      "step": 7766
    },
    {
      "epoch": 78.85,
      "learning_rate": 5.377202309468633e-05,
      "loss": 0.0001,
      "step": 7767
    },
    {
      "epoch": 78.86,
      "learning_rate": 5.3760183834701436e-05,
      "loss": 0.008,
      "step": 7768
    },
    {
      "epoch": 78.87,
      "learning_rate": 5.374834436269054e-05,
      "loss": 0.0006,
      "step": 7769
    },
    {
      "epoch": 78.88,
      "learning_rate": 5.373650467932122e-05,
      "loss": 0.0003,
      "step": 7770
    },
    {
      "epoch": 78.89,
      "learning_rate": 5.3724664785261103e-05,
      "loss": 0.0003,
      "step": 7771
    },
    {
      "epoch": 78.9,
      "learning_rate": 5.371282468117779e-05,
      "loss": 0.0007,
      "step": 7772
    },
    {
      "epoch": 78.91,
      "learning_rate": 5.370098436773893e-05,
      "loss": 0.0013,
      "step": 7773
    },
    {
      "epoch": 78.92,
      "learning_rate": 5.368914384561213e-05,
      "loss": 0.0008,
      "step": 7774
    },
    {
      "epoch": 78.93,
      "learning_rate": 5.367730311546508e-05,
      "loss": 0.0001,
      "step": 7775
    },
    {
      "epoch": 78.94,
      "learning_rate": 5.366546217796542e-05,
      "loss": 0.0,
      "step": 7776
    },
    {
      "epoch": 78.95,
      "learning_rate": 5.365362103378084e-05,
      "loss": 0.0004,
      "step": 7777
    },
    {
      "epoch": 78.96,
      "learning_rate": 5.364177968357904e-05,
      "loss": 0.0001,
      "step": 7778
    },
    {
      "epoch": 78.97,
      "learning_rate": 5.362993812802769e-05,
      "loss": 0.0007,
      "step": 7779
    },
    {
      "epoch": 78.98,
      "learning_rate": 5.361809636779452e-05,
      "loss": 0.0089,
      "step": 7780
    },
    {
      "epoch": 78.99,
      "learning_rate": 5.3606254403547255e-05,
      "loss": 0.0011,
      "step": 7781
    },
    {
      "epoch": 78.99,
      "eval_loss": 0.01967792771756649,
      "eval_runtime": 31.8128,
      "eval_samples_per_second": 99.017,
      "eval_steps_per_second": 6.192,
      "eval_wer": 0.0030729833546734955,
      "step": 7781
    },
    {
      "epoch": 79.01,
      "learning_rate": 5.359441223595363e-05,
      "loss": 0.0,
      "step": 7782
    },
    {
      "epoch": 79.02,
      "learning_rate": 5.3582569865681366e-05,
      "loss": 0.0007,
      "step": 7783
    },
    {
      "epoch": 79.03,
      "learning_rate": 5.3570727293398246e-05,
      "loss": 0.0001,
      "step": 7784
    },
    {
      "epoch": 79.04,
      "learning_rate": 5.355888451977203e-05,
      "loss": 0.0003,
      "step": 7785
    },
    {
      "epoch": 79.05,
      "learning_rate": 5.354704154547052e-05,
      "loss": 0.0002,
      "step": 7786
    },
    {
      "epoch": 79.06,
      "learning_rate": 5.353519837116145e-05,
      "loss": 0.0003,
      "step": 7787
    },
    {
      "epoch": 79.07,
      "learning_rate": 5.35233549975127e-05,
      "loss": 0.001,
      "step": 7788
    },
    {
      "epoch": 79.08,
      "learning_rate": 5.351151142519202e-05,
      "loss": 0.0008,
      "step": 7789
    },
    {
      "epoch": 79.09,
      "learning_rate": 5.349966765486728e-05,
      "loss": 0.0021,
      "step": 7790
    },
    {
      "epoch": 79.1,
      "learning_rate": 5.348782368720626e-05,
      "loss": 0.0122,
      "step": 7791
    },
    {
      "epoch": 79.11,
      "learning_rate": 5.347597952287687e-05,
      "loss": 0.0003,
      "step": 7792
    },
    {
      "epoch": 79.12,
      "learning_rate": 5.3464135162546935e-05,
      "loss": 0.0029,
      "step": 7793
    },
    {
      "epoch": 79.13,
      "learning_rate": 5.345229060688434e-05,
      "loss": 0.0002,
      "step": 7794
    },
    {
      "epoch": 79.14,
      "learning_rate": 5.344044585655694e-05,
      "loss": 0.0077,
      "step": 7795
    },
    {
      "epoch": 79.15,
      "learning_rate": 5.342860091223266e-05,
      "loss": 0.0033,
      "step": 7796
    },
    {
      "epoch": 79.16,
      "learning_rate": 5.341675577457937e-05,
      "loss": 0.0002,
      "step": 7797
    },
    {
      "epoch": 79.17,
      "learning_rate": 5.340491044426501e-05,
      "loss": 0.0001,
      "step": 7798
    },
    {
      "epoch": 79.18,
      "learning_rate": 5.3393064921957494e-05,
      "loss": 0.0027,
      "step": 7799
    },
    {
      "epoch": 79.19,
      "learning_rate": 5.338121920832475e-05,
      "loss": 0.0014,
      "step": 7800
    },
    {
      "epoch": 79.2,
      "learning_rate": 5.336937330403474e-05,
      "loss": 0.0001,
      "step": 7801
    },
    {
      "epoch": 79.21,
      "learning_rate": 5.3357527209755396e-05,
      "loss": 0.004,
      "step": 7802
    },
    {
      "epoch": 79.22,
      "learning_rate": 5.334568092615473e-05,
      "loss": 0.0001,
      "step": 7803
    },
    {
      "epoch": 79.23,
      "learning_rate": 5.333383445390066e-05,
      "loss": 0.0001,
      "step": 7804
    },
    {
      "epoch": 79.24,
      "learning_rate": 5.332198779366122e-05,
      "loss": 0.0002,
      "step": 7805
    },
    {
      "epoch": 79.25,
      "learning_rate": 5.331014094610438e-05,
      "loss": 0.0114,
      "step": 7806
    },
    {
      "epoch": 79.26,
      "learning_rate": 5.329829391189819e-05,
      "loss": 0.0004,
      "step": 7807
    },
    {
      "epoch": 79.27,
      "learning_rate": 5.328644669171061e-05,
      "loss": 0.0066,
      "step": 7808
    },
    {
      "epoch": 79.28,
      "learning_rate": 5.327459928620974e-05,
      "loss": 0.0001,
      "step": 7809
    },
    {
      "epoch": 79.29,
      "learning_rate": 5.326275169606356e-05,
      "loss": 0.0021,
      "step": 7810
    },
    {
      "epoch": 79.3,
      "learning_rate": 5.3250903921940174e-05,
      "loss": 0.0006,
      "step": 7811
    },
    {
      "epoch": 79.31,
      "learning_rate": 5.323905596450759e-05,
      "loss": 0.0022,
      "step": 7812
    },
    {
      "epoch": 79.32,
      "learning_rate": 5.3227207824433935e-05,
      "loss": 0.0002,
      "step": 7813
    },
    {
      "epoch": 79.33,
      "learning_rate": 5.3215359502387255e-05,
      "loss": 0.0007,
      "step": 7814
    },
    {
      "epoch": 79.34,
      "learning_rate": 5.320351099903565e-05,
      "loss": 0.005,
      "step": 7815
    },
    {
      "epoch": 79.35,
      "learning_rate": 5.319166231504723e-05,
      "loss": 0.0004,
      "step": 7816
    },
    {
      "epoch": 79.36,
      "learning_rate": 5.317981345109011e-05,
      "loss": 0.0004,
      "step": 7817
    },
    {
      "epoch": 79.37,
      "learning_rate": 5.31679644078324e-05,
      "loss": 0.0004,
      "step": 7818
    },
    {
      "epoch": 79.38,
      "learning_rate": 5.315611518594224e-05,
      "loss": 0.0001,
      "step": 7819
    },
    {
      "epoch": 79.39,
      "learning_rate": 5.314426578608779e-05,
      "loss": 0.0001,
      "step": 7820
    },
    {
      "epoch": 79.4,
      "learning_rate": 5.313241620893719e-05,
      "loss": 0.0239,
      "step": 7821
    },
    {
      "epoch": 79.41,
      "learning_rate": 5.3120566455158604e-05,
      "loss": 0.0007,
      "step": 7822
    },
    {
      "epoch": 79.42,
      "learning_rate": 5.310871652542019e-05,
      "loss": 0.0055,
      "step": 7823
    },
    {
      "epoch": 79.43,
      "learning_rate": 5.309686642039016e-05,
      "loss": 0.0011,
      "step": 7824
    },
    {
      "epoch": 79.44,
      "learning_rate": 5.308501614073669e-05,
      "loss": 0.0001,
      "step": 7825
    },
    {
      "epoch": 79.45,
      "learning_rate": 5.307316568712799e-05,
      "loss": 0.003,
      "step": 7826
    },
    {
      "epoch": 79.46,
      "learning_rate": 5.306131506023226e-05,
      "loss": 0.023,
      "step": 7827
    },
    {
      "epoch": 79.47,
      "learning_rate": 5.304946426071775e-05,
      "loss": 0.0002,
      "step": 7828
    },
    {
      "epoch": 79.48,
      "learning_rate": 5.303761328925266e-05,
      "loss": 0.0003,
      "step": 7829
    },
    {
      "epoch": 79.49,
      "learning_rate": 5.302576214650528e-05,
      "loss": 0.001,
      "step": 7830
    },
    {
      "epoch": 79.5,
      "learning_rate": 5.301391083314381e-05,
      "loss": 0.0125,
      "step": 7831
    },
    {
      "epoch": 79.51,
      "learning_rate": 5.300205934983653e-05,
      "loss": 0.002,
      "step": 7832
    },
    {
      "epoch": 79.52,
      "learning_rate": 5.299020769725172e-05,
      "loss": 0.0033,
      "step": 7833
    },
    {
      "epoch": 79.53,
      "learning_rate": 5.2978355876057654e-05,
      "loss": 0.0009,
      "step": 7834
    },
    {
      "epoch": 79.54,
      "learning_rate": 5.296650388692261e-05,
      "loss": 0.0015,
      "step": 7835
    },
    {
      "epoch": 79.55,
      "learning_rate": 5.2954651730514914e-05,
      "loss": 0.0013,
      "step": 7836
    },
    {
      "epoch": 79.56,
      "learning_rate": 5.294279940750286e-05,
      "loss": 0.0004,
      "step": 7837
    },
    {
      "epoch": 79.57,
      "learning_rate": 5.293094691855477e-05,
      "loss": 0.0002,
      "step": 7838
    },
    {
      "epoch": 79.58,
      "learning_rate": 5.2919094264338976e-05,
      "loss": 0.0,
      "step": 7839
    },
    {
      "epoch": 79.59,
      "learning_rate": 5.290724144552379e-05,
      "loss": 0.0107,
      "step": 7840
    },
    {
      "epoch": 79.6,
      "learning_rate": 5.28953884627776e-05,
      "loss": 0.0013,
      "step": 7841
    },
    {
      "epoch": 79.61,
      "learning_rate": 5.288353531676873e-05,
      "loss": 0.0003,
      "step": 7842
    },
    {
      "epoch": 79.62,
      "learning_rate": 5.2871682008165555e-05,
      "loss": 0.0036,
      "step": 7843
    },
    {
      "epoch": 79.63,
      "learning_rate": 5.285982853763646e-05,
      "loss": 0.0001,
      "step": 7844
    },
    {
      "epoch": 79.64,
      "learning_rate": 5.284797490584979e-05,
      "loss": 0.0001,
      "step": 7845
    },
    {
      "epoch": 79.65,
      "learning_rate": 5.283612111347399e-05,
      "loss": 0.0001,
      "step": 7846
    },
    {
      "epoch": 79.66,
      "learning_rate": 5.282426716117743e-05,
      "loss": 0.0034,
      "step": 7847
    },
    {
      "epoch": 79.68,
      "learning_rate": 5.2812413049628526e-05,
      "loss": 0.0017,
      "step": 7848
    },
    {
      "epoch": 79.69,
      "learning_rate": 5.28005587794957e-05,
      "loss": 0.0,
      "step": 7849
    },
    {
      "epoch": 79.7,
      "learning_rate": 5.278870435144737e-05,
      "loss": 0.011,
      "step": 7850
    },
    {
      "epoch": 79.71,
      "learning_rate": 5.2776849766152e-05,
      "loss": 0.0,
      "step": 7851
    },
    {
      "epoch": 79.72,
      "learning_rate": 5.276499502427801e-05,
      "loss": 0.0001,
      "step": 7852
    },
    {
      "epoch": 79.73,
      "learning_rate": 5.275314012649385e-05,
      "loss": 0.0012,
      "step": 7853
    },
    {
      "epoch": 79.74,
      "learning_rate": 5.274128507346801e-05,
      "loss": 0.0023,
      "step": 7854
    },
    {
      "epoch": 79.75,
      "learning_rate": 5.272942986586895e-05,
      "loss": 0.0006,
      "step": 7855
    },
    {
      "epoch": 79.76,
      "learning_rate": 5.271757450436514e-05,
      "loss": 0.0041,
      "step": 7856
    },
    {
      "epoch": 79.77,
      "learning_rate": 5.2705718989625084e-05,
      "loss": 0.0,
      "step": 7857
    },
    {
      "epoch": 79.78,
      "learning_rate": 5.269386332231727e-05,
      "loss": 0.0004,
      "step": 7858
    },
    {
      "epoch": 79.79,
      "learning_rate": 5.268200750311022e-05,
      "loss": 0.0002,
      "step": 7859
    },
    {
      "epoch": 79.8,
      "learning_rate": 5.267015153267245e-05,
      "loss": 0.0012,
      "step": 7860
    },
    {
      "epoch": 79.81,
      "learning_rate": 5.2658295411672476e-05,
      "loss": 0.0028,
      "step": 7861
    },
    {
      "epoch": 79.82,
      "learning_rate": 5.264643914077881e-05,
      "loss": 0.0017,
      "step": 7862
    },
    {
      "epoch": 79.83,
      "learning_rate": 5.263458272066003e-05,
      "loss": 0.0001,
      "step": 7863
    },
    {
      "epoch": 79.84,
      "learning_rate": 5.262272615198468e-05,
      "loss": 0.0004,
      "step": 7864
    },
    {
      "epoch": 79.85,
      "learning_rate": 5.2610869435421274e-05,
      "loss": 0.0015,
      "step": 7865
    },
    {
      "epoch": 79.86,
      "learning_rate": 5.259901257163844e-05,
      "loss": 0.0004,
      "step": 7866
    },
    {
      "epoch": 79.87,
      "learning_rate": 5.2587155561304726e-05,
      "loss": 0.0001,
      "step": 7867
    },
    {
      "epoch": 79.88,
      "learning_rate": 5.25752984050887e-05,
      "loss": 0.0011,
      "step": 7868
    },
    {
      "epoch": 79.89,
      "learning_rate": 5.256344110365896e-05,
      "loss": 0.0001,
      "step": 7869
    },
    {
      "epoch": 79.9,
      "learning_rate": 5.255158365768413e-05,
      "loss": 0.0047,
      "step": 7870
    },
    {
      "epoch": 79.91,
      "learning_rate": 5.2539726067832796e-05,
      "loss": 0.0,
      "step": 7871
    },
    {
      "epoch": 79.92,
      "learning_rate": 5.252786833477358e-05,
      "loss": 0.0001,
      "step": 7872
    },
    {
      "epoch": 79.93,
      "learning_rate": 5.2516010459175094e-05,
      "loss": 0.0,
      "step": 7873
    },
    {
      "epoch": 79.94,
      "learning_rate": 5.2504152441705964e-05,
      "loss": 0.001,
      "step": 7874
    },
    {
      "epoch": 79.95,
      "learning_rate": 5.249229428303486e-05,
      "loss": 0.0,
      "step": 7875
    },
    {
      "epoch": 79.96,
      "learning_rate": 5.2480435983830424e-05,
      "loss": 0.0002,
      "step": 7876
    },
    {
      "epoch": 79.97,
      "learning_rate": 5.246857754476129e-05,
      "loss": 0.0163,
      "step": 7877
    },
    {
      "epoch": 79.98,
      "learning_rate": 5.245671896649612e-05,
      "loss": 0.0004,
      "step": 7878
    },
    {
      "epoch": 79.99,
      "learning_rate": 5.2444860249703606e-05,
      "loss": 0.001,
      "step": 7879
    },
    {
      "epoch": 80.0,
      "learning_rate": 5.243300139505242e-05,
      "loss": 0.0001,
      "step": 7880
    },
    {
      "epoch": 80.0,
      "eval_loss": 0.021407969295978546,
      "eval_runtime": 32.8842,
      "eval_samples_per_second": 95.791,
      "eval_steps_per_second": 5.991,
      "eval_wer": 0.003585147247119078,
      "step": 7880
    },
    {
      "epoch": 80.01,
      "learning_rate": 5.242114240321125e-05,
      "loss": 0.0,
      "step": 7881
    },
    {
      "epoch": 80.02,
      "learning_rate": 5.240928327484879e-05,
      "loss": 0.005,
      "step": 7882
    },
    {
      "epoch": 80.03,
      "learning_rate": 5.2397424010633746e-05,
      "loss": 0.0002,
      "step": 7883
    },
    {
      "epoch": 80.04,
      "learning_rate": 5.238556461123481e-05,
      "loss": 0.0,
      "step": 7884
    },
    {
      "epoch": 80.05,
      "learning_rate": 5.237370507732072e-05,
      "loss": 0.0016,
      "step": 7885
    },
    {
      "epoch": 80.06,
      "learning_rate": 5.236184540956017e-05,
      "loss": 0.0001,
      "step": 7886
    },
    {
      "epoch": 80.07,
      "learning_rate": 5.2349985608621956e-05,
      "loss": 0.0001,
      "step": 7887
    },
    {
      "epoch": 80.08,
      "learning_rate": 5.2338125675174754e-05,
      "loss": 0.0003,
      "step": 7888
    },
    {
      "epoch": 80.09,
      "learning_rate": 5.232626560988735e-05,
      "loss": 0.0001,
      "step": 7889
    },
    {
      "epoch": 80.1,
      "learning_rate": 5.2314405413428456e-05,
      "loss": 0.0058,
      "step": 7890
    },
    {
      "epoch": 80.11,
      "learning_rate": 5.230254508646689e-05,
      "loss": 0.0003,
      "step": 7891
    },
    {
      "epoch": 80.12,
      "learning_rate": 5.2290684629671384e-05,
      "loss": 0.0078,
      "step": 7892
    },
    {
      "epoch": 80.13,
      "learning_rate": 5.227882404371074e-05,
      "loss": 0.0045,
      "step": 7893
    },
    {
      "epoch": 80.14,
      "learning_rate": 5.226696332925371e-05,
      "loss": 0.0003,
      "step": 7894
    },
    {
      "epoch": 80.15,
      "learning_rate": 5.225510248696912e-05,
      "loss": 0.0014,
      "step": 7895
    },
    {
      "epoch": 80.16,
      "learning_rate": 5.2243241517525754e-05,
      "loss": 0.0002,
      "step": 7896
    },
    {
      "epoch": 80.17,
      "learning_rate": 5.2231380421592416e-05,
      "loss": 0.0002,
      "step": 7897
    },
    {
      "epoch": 80.18,
      "learning_rate": 5.221951919983791e-05,
      "loss": 0.0013,
      "step": 7898
    },
    {
      "epoch": 80.19,
      "learning_rate": 5.220765785293108e-05,
      "loss": 0.0011,
      "step": 7899
    },
    {
      "epoch": 80.2,
      "learning_rate": 5.219579638154074e-05,
      "loss": 0.0005,
      "step": 7900
    },
    {
      "epoch": 80.21,
      "learning_rate": 5.218393478633572e-05,
      "loss": 0.0005,
      "step": 7901
    },
    {
      "epoch": 80.22,
      "learning_rate": 5.217207306798487e-05,
      "loss": 0.0,
      "step": 7902
    },
    {
      "epoch": 80.23,
      "learning_rate": 5.216021122715703e-05,
      "loss": 0.0119,
      "step": 7903
    },
    {
      "epoch": 80.24,
      "learning_rate": 5.214834926452108e-05,
      "loss": 0.0109,
      "step": 7904
    },
    {
      "epoch": 80.25,
      "learning_rate": 5.213648718074584e-05,
      "loss": 0.0001,
      "step": 7905
    },
    {
      "epoch": 80.26,
      "learning_rate": 5.212462497650022e-05,
      "loss": 0.002,
      "step": 7906
    },
    {
      "epoch": 80.27,
      "learning_rate": 5.211276265245306e-05,
      "loss": 0.0004,
      "step": 7907
    },
    {
      "epoch": 80.28,
      "learning_rate": 5.2100900209273274e-05,
      "loss": 0.0002,
      "step": 7908
    },
    {
      "epoch": 80.29,
      "learning_rate": 5.2089037647629726e-05,
      "loss": 0.0001,
      "step": 7909
    },
    {
      "epoch": 80.3,
      "learning_rate": 5.2077174968191346e-05,
      "loss": 0.0036,
      "step": 7910
    },
    {
      "epoch": 80.31,
      "learning_rate": 5.206531217162698e-05,
      "loss": 0.019,
      "step": 7911
    },
    {
      "epoch": 80.32,
      "learning_rate": 5.205344925860559e-05,
      "loss": 0.0021,
      "step": 7912
    },
    {
      "epoch": 80.34,
      "learning_rate": 5.204158622979607e-05,
      "loss": 0.0004,
      "step": 7913
    },
    {
      "epoch": 80.35,
      "learning_rate": 5.202972308586735e-05,
      "loss": 0.001,
      "step": 7914
    },
    {
      "epoch": 80.36,
      "learning_rate": 5.2017859827488336e-05,
      "loss": 0.0002,
      "step": 7915
    },
    {
      "epoch": 80.37,
      "learning_rate": 5.2005996455328e-05,
      "loss": 0.0001,
      "step": 7916
    },
    {
      "epoch": 80.38,
      "learning_rate": 5.199413297005525e-05,
      "loss": 0.0071,
      "step": 7917
    },
    {
      "epoch": 80.39,
      "learning_rate": 5.1982269372339055e-05,
      "loss": 0.0006,
      "step": 7918
    },
    {
      "epoch": 80.4,
      "learning_rate": 5.197040566284836e-05,
      "loss": 0.0007,
      "step": 7919
    },
    {
      "epoch": 80.41,
      "learning_rate": 5.195854184225214e-05,
      "loss": 0.0001,
      "step": 7920
    },
    {
      "epoch": 80.42,
      "learning_rate": 5.1946677911219334e-05,
      "loss": 0.002,
      "step": 7921
    },
    {
      "epoch": 80.43,
      "learning_rate": 5.193481387041894e-05,
      "loss": 0.0039,
      "step": 7922
    },
    {
      "epoch": 80.44,
      "learning_rate": 5.192294972051992e-05,
      "loss": 0.0001,
      "step": 7923
    },
    {
      "epoch": 80.45,
      "learning_rate": 5.191108546219128e-05,
      "loss": 0.0002,
      "step": 7924
    },
    {
      "epoch": 80.46,
      "learning_rate": 5.189922109610199e-05,
      "loss": 0.0002,
      "step": 7925
    },
    {
      "epoch": 80.47,
      "learning_rate": 5.188735662292107e-05,
      "loss": 0.0002,
      "step": 7926
    },
    {
      "epoch": 80.48,
      "learning_rate": 5.1875492043317495e-05,
      "loss": 0.0002,
      "step": 7927
    },
    {
      "epoch": 80.49,
      "learning_rate": 5.186362735796029e-05,
      "loss": 0.0016,
      "step": 7928
    },
    {
      "epoch": 80.5,
      "learning_rate": 5.185176256751849e-05,
      "loss": 0.0003,
      "step": 7929
    },
    {
      "epoch": 80.51,
      "learning_rate": 5.183989767266109e-05,
      "loss": 0.0043,
      "step": 7930
    },
    {
      "epoch": 80.52,
      "learning_rate": 5.182803267405712e-05,
      "loss": 0.0008,
      "step": 7931
    },
    {
      "epoch": 80.53,
      "learning_rate": 5.1816167572375606e-05,
      "loss": 0.0001,
      "step": 7932
    },
    {
      "epoch": 80.54,
      "learning_rate": 5.180430236828563e-05,
      "loss": 0.0029,
      "step": 7933
    },
    {
      "epoch": 80.55,
      "learning_rate": 5.179243706245619e-05,
      "loss": 0.0009,
      "step": 7934
    },
    {
      "epoch": 80.56,
      "learning_rate": 5.1780571655556356e-05,
      "loss": 0.0004,
      "step": 7935
    },
    {
      "epoch": 80.57,
      "learning_rate": 5.1768706148255175e-05,
      "loss": 0.0062,
      "step": 7936
    },
    {
      "epoch": 80.58,
      "learning_rate": 5.175684054122173e-05,
      "loss": 0.0008,
      "step": 7937
    },
    {
      "epoch": 80.59,
      "learning_rate": 5.174497483512506e-05,
      "loss": 0.0002,
      "step": 7938
    },
    {
      "epoch": 80.6,
      "learning_rate": 5.173310903063425e-05,
      "loss": 0.0005,
      "step": 7939
    },
    {
      "epoch": 80.61,
      "learning_rate": 5.172124312841839e-05,
      "loss": 0.0003,
      "step": 7940
    },
    {
      "epoch": 80.62,
      "learning_rate": 5.170937712914655e-05,
      "loss": 0.0003,
      "step": 7941
    },
    {
      "epoch": 80.63,
      "learning_rate": 5.1697511033487835e-05,
      "loss": 0.0001,
      "step": 7942
    },
    {
      "epoch": 80.64,
      "learning_rate": 5.1685644842111326e-05,
      "loss": 0.006,
      "step": 7943
    },
    {
      "epoch": 80.65,
      "learning_rate": 5.1673778555686126e-05,
      "loss": 0.0088,
      "step": 7944
    },
    {
      "epoch": 80.66,
      "learning_rate": 5.166191217488133e-05,
      "loss": 0.0001,
      "step": 7945
    },
    {
      "epoch": 80.67,
      "learning_rate": 5.165004570036609e-05,
      "loss": 0.0006,
      "step": 7946
    },
    {
      "epoch": 80.68,
      "learning_rate": 5.1638179132809486e-05,
      "loss": 0.0007,
      "step": 7947
    },
    {
      "epoch": 80.69,
      "learning_rate": 5.1626312472880636e-05,
      "loss": 0.0001,
      "step": 7948
    },
    {
      "epoch": 80.7,
      "learning_rate": 5.1614445721248685e-05,
      "loss": 0.0,
      "step": 7949
    },
    {
      "epoch": 80.71,
      "learning_rate": 5.1602578878582776e-05,
      "loss": 0.0018,
      "step": 7950
    },
    {
      "epoch": 80.72,
      "learning_rate": 5.1590711945552004e-05,
      "loss": 0.0001,
      "step": 7951
    },
    {
      "epoch": 80.73,
      "learning_rate": 5.157884492282555e-05,
      "loss": 0.0004,
      "step": 7952
    },
    {
      "epoch": 80.74,
      "learning_rate": 5.156697781107255e-05,
      "loss": 0.0001,
      "step": 7953
    },
    {
      "epoch": 80.75,
      "learning_rate": 5.155511061096215e-05,
      "loss": 0.0005,
      "step": 7954
    },
    {
      "epoch": 80.76,
      "learning_rate": 5.1543243323163516e-05,
      "loss": 0.0035,
      "step": 7955
    },
    {
      "epoch": 80.77,
      "learning_rate": 5.1531375948345803e-05,
      "loss": 0.0081,
      "step": 7956
    },
    {
      "epoch": 80.78,
      "learning_rate": 5.151950848717819e-05,
      "loss": 0.0001,
      "step": 7957
    },
    {
      "epoch": 80.79,
      "learning_rate": 5.150764094032985e-05,
      "loss": 0.0006,
      "step": 7958
    },
    {
      "epoch": 80.8,
      "learning_rate": 5.149577330846993e-05,
      "loss": 0.0038,
      "step": 7959
    },
    {
      "epoch": 80.81,
      "learning_rate": 5.1483905592267646e-05,
      "loss": 0.0008,
      "step": 7960
    },
    {
      "epoch": 80.82,
      "learning_rate": 5.147203779239216e-05,
      "loss": 0.0016,
      "step": 7961
    },
    {
      "epoch": 80.83,
      "learning_rate": 5.146016990951269e-05,
      "loss": 0.0006,
      "step": 7962
    },
    {
      "epoch": 80.84,
      "learning_rate": 5.1448301944298414e-05,
      "loss": 0.0002,
      "step": 7963
    },
    {
      "epoch": 80.85,
      "learning_rate": 5.143643389741854e-05,
      "loss": 0.0,
      "step": 7964
    },
    {
      "epoch": 80.86,
      "learning_rate": 5.142456576954225e-05,
      "loss": 0.0018,
      "step": 7965
    },
    {
      "epoch": 80.87,
      "learning_rate": 5.1412697561338785e-05,
      "loss": 0.0011,
      "step": 7966
    },
    {
      "epoch": 80.88,
      "learning_rate": 5.140082927347736e-05,
      "loss": 0.0009,
      "step": 7967
    },
    {
      "epoch": 80.89,
      "learning_rate": 5.1388960906627146e-05,
      "loss": 0.0002,
      "step": 7968
    },
    {
      "epoch": 80.9,
      "learning_rate": 5.137709246145744e-05,
      "loss": 0.0002,
      "step": 7969
    },
    {
      "epoch": 80.91,
      "learning_rate": 5.136522393863741e-05,
      "loss": 0.0006,
      "step": 7970
    },
    {
      "epoch": 80.92,
      "learning_rate": 5.135335533883632e-05,
      "loss": 0.0,
      "step": 7971
    },
    {
      "epoch": 80.93,
      "learning_rate": 5.134148666272338e-05,
      "loss": 0.0,
      "step": 7972
    },
    {
      "epoch": 80.94,
      "learning_rate": 5.1329617910967865e-05,
      "loss": 0.0001,
      "step": 7973
    },
    {
      "epoch": 80.95,
      "learning_rate": 5.1317749084238984e-05,
      "loss": 0.0003,
      "step": 7974
    },
    {
      "epoch": 80.96,
      "learning_rate": 5.1305880183206015e-05,
      "loss": 0.0003,
      "step": 7975
    },
    {
      "epoch": 80.97,
      "learning_rate": 5.129401120853819e-05,
      "loss": 0.0001,
      "step": 7976
    },
    {
      "epoch": 80.98,
      "learning_rate": 5.128214216090478e-05,
      "loss": 0.0004,
      "step": 7977
    },
    {
      "epoch": 80.99,
      "learning_rate": 5.127027304097504e-05,
      "loss": 0.0001,
      "step": 7978
    },
    {
      "epoch": 80.99,
      "eval_loss": 0.01763118989765644,
      "eval_runtime": 31.9307,
      "eval_samples_per_second": 98.651,
      "eval_steps_per_second": 6.17,
      "eval_wer": 0.003201024327784891,
      "step": 7978
    },
    {
      "epoch": 81.01,
      "learning_rate": 5.1258403849418245e-05,
      "loss": 0.0087,
      "step": 7979
    },
    {
      "epoch": 81.02,
      "learning_rate": 5.124653458690365e-05,
      "loss": 0.0016,
      "step": 7980
    },
    {
      "epoch": 81.03,
      "learning_rate": 5.123466525410054e-05,
      "loss": 0.0,
      "step": 7981
    },
    {
      "epoch": 81.04,
      "learning_rate": 5.1222795851678184e-05,
      "loss": 0.0007,
      "step": 7982
    },
    {
      "epoch": 81.05,
      "learning_rate": 5.121092638030588e-05,
      "loss": 0.005,
      "step": 7983
    },
    {
      "epoch": 81.06,
      "learning_rate": 5.11990568406529e-05,
      "loss": 0.0002,
      "step": 7984
    },
    {
      "epoch": 81.07,
      "learning_rate": 5.1187187233388525e-05,
      "loss": 0.0048,
      "step": 7985
    },
    {
      "epoch": 81.08,
      "learning_rate": 5.117531755918208e-05,
      "loss": 0.0001,
      "step": 7986
    },
    {
      "epoch": 81.09,
      "learning_rate": 5.116344781870281e-05,
      "loss": 0.0002,
      "step": 7987
    },
    {
      "epoch": 81.1,
      "learning_rate": 5.1151578012620086e-05,
      "loss": 0.0001,
      "step": 7988
    },
    {
      "epoch": 81.11,
      "learning_rate": 5.1139708141603136e-05,
      "loss": 0.0001,
      "step": 7989
    },
    {
      "epoch": 81.12,
      "learning_rate": 5.1127838206321335e-05,
      "loss": 0.0001,
      "step": 7990
    },
    {
      "epoch": 81.13,
      "learning_rate": 5.111596820744394e-05,
      "loss": 0.0003,
      "step": 7991
    },
    {
      "epoch": 81.14,
      "learning_rate": 5.110409814564032e-05,
      "loss": 0.0001,
      "step": 7992
    },
    {
      "epoch": 81.15,
      "learning_rate": 5.109222802157974e-05,
      "loss": 0.0001,
      "step": 7993
    },
    {
      "epoch": 81.16,
      "learning_rate": 5.108035783593156e-05,
      "loss": 0.0002,
      "step": 7994
    },
    {
      "epoch": 81.17,
      "learning_rate": 5.1068487589365076e-05,
      "loss": 0.0025,
      "step": 7995
    },
    {
      "epoch": 81.18,
      "learning_rate": 5.1056617282549654e-05,
      "loss": 0.0001,
      "step": 7996
    },
    {
      "epoch": 81.19,
      "learning_rate": 5.10447469161546e-05,
      "loss": 0.0097,
      "step": 7997
    },
    {
      "epoch": 81.2,
      "learning_rate": 5.1032876490849255e-05,
      "loss": 0.0006,
      "step": 7998
    },
    {
      "epoch": 81.21,
      "learning_rate": 5.1021006007302964e-05,
      "loss": 0.0001,
      "step": 7999
    },
    {
      "epoch": 81.22,
      "learning_rate": 5.100913546618506e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 81.23,
      "learning_rate": 5.0997264868164903e-05,
      "loss": 0.0002,
      "step": 8001
    },
    {
      "epoch": 81.24,
      "learning_rate": 5.098539421391184e-05,
      "loss": 0.0003,
      "step": 8002
    },
    {
      "epoch": 81.25,
      "learning_rate": 5.09735235040952e-05,
      "loss": 0.0162,
      "step": 8003
    },
    {
      "epoch": 81.26,
      "learning_rate": 5.0961652739384356e-05,
      "loss": 0.0,
      "step": 8004
    },
    {
      "epoch": 81.27,
      "learning_rate": 5.094978192044868e-05,
      "loss": 0.0061,
      "step": 8005
    },
    {
      "epoch": 81.28,
      "learning_rate": 5.093791104795751e-05,
      "loss": 0.0001,
      "step": 8006
    },
    {
      "epoch": 81.29,
      "learning_rate": 5.092604012258023e-05,
      "loss": 0.0001,
      "step": 8007
    },
    {
      "epoch": 81.3,
      "learning_rate": 5.091416914498619e-05,
      "loss": 0.006,
      "step": 8008
    },
    {
      "epoch": 81.31,
      "learning_rate": 5.090229811584476e-05,
      "loss": 0.002,
      "step": 8009
    },
    {
      "epoch": 81.32,
      "learning_rate": 5.089042703582533e-05,
      "loss": 0.0001,
      "step": 8010
    },
    {
      "epoch": 81.33,
      "learning_rate": 5.087855590559727e-05,
      "loss": 0.0003,
      "step": 8011
    },
    {
      "epoch": 81.34,
      "learning_rate": 5.086668472582995e-05,
      "loss": 0.0002,
      "step": 8012
    },
    {
      "epoch": 81.35,
      "learning_rate": 5.085481349719276e-05,
      "loss": 0.0004,
      "step": 8013
    },
    {
      "epoch": 81.36,
      "learning_rate": 5.084294222035508e-05,
      "loss": 0.0002,
      "step": 8014
    },
    {
      "epoch": 81.37,
      "learning_rate": 5.083107089598632e-05,
      "loss": 0.0001,
      "step": 8015
    },
    {
      "epoch": 81.38,
      "learning_rate": 5.081919952475584e-05,
      "loss": 0.0089,
      "step": 8016
    },
    {
      "epoch": 81.39,
      "learning_rate": 5.080732810733304e-05,
      "loss": 0.0012,
      "step": 8017
    },
    {
      "epoch": 81.4,
      "learning_rate": 5.07954566443873e-05,
      "loss": 0.0098,
      "step": 8018
    },
    {
      "epoch": 81.41,
      "learning_rate": 5.0783585136588066e-05,
      "loss": 0.0053,
      "step": 8019
    },
    {
      "epoch": 81.42,
      "learning_rate": 5.077171358460469e-05,
      "loss": 0.0031,
      "step": 8020
    },
    {
      "epoch": 81.43,
      "learning_rate": 5.075984198910659e-05,
      "loss": 0.004,
      "step": 8021
    },
    {
      "epoch": 81.44,
      "learning_rate": 5.074797035076319e-05,
      "loss": 0.0005,
      "step": 8022
    },
    {
      "epoch": 81.45,
      "learning_rate": 5.073609867024388e-05,
      "loss": 0.0001,
      "step": 8023
    },
    {
      "epoch": 81.46,
      "learning_rate": 5.0724226948218055e-05,
      "loss": 0.0003,
      "step": 8024
    },
    {
      "epoch": 81.47,
      "learning_rate": 5.0712355185355166e-05,
      "loss": 0.0001,
      "step": 8025
    },
    {
      "epoch": 81.48,
      "learning_rate": 5.070048338232459e-05,
      "loss": 0.0043,
      "step": 8026
    },
    {
      "epoch": 81.49,
      "learning_rate": 5.068861153979577e-05,
      "loss": 0.0004,
      "step": 8027
    },
    {
      "epoch": 81.5,
      "learning_rate": 5.067673965843812e-05,
      "loss": 0.0002,
      "step": 8028
    },
    {
      "epoch": 81.51,
      "learning_rate": 5.066486773892105e-05,
      "loss": 0.0004,
      "step": 8029
    },
    {
      "epoch": 81.52,
      "learning_rate": 5.0652995781913993e-05,
      "loss": 0.0013,
      "step": 8030
    },
    {
      "epoch": 81.53,
      "learning_rate": 5.064112378808637e-05,
      "loss": 0.0009,
      "step": 8031
    },
    {
      "epoch": 81.54,
      "learning_rate": 5.062925175810762e-05,
      "loss": 0.0141,
      "step": 8032
    },
    {
      "epoch": 81.55,
      "learning_rate": 5.061737969264715e-05,
      "loss": 0.0159,
      "step": 8033
    },
    {
      "epoch": 81.56,
      "learning_rate": 5.060550759237441e-05,
      "loss": 0.0005,
      "step": 8034
    },
    {
      "epoch": 81.57,
      "learning_rate": 5.059363545795883e-05,
      "loss": 0.0003,
      "step": 8035
    },
    {
      "epoch": 81.58,
      "learning_rate": 5.0581763290069865e-05,
      "loss": 0.0004,
      "step": 8036
    },
    {
      "epoch": 81.59,
      "learning_rate": 5.056989108937691e-05,
      "loss": 0.0035,
      "step": 8037
    },
    {
      "epoch": 81.6,
      "learning_rate": 5.0558018856549425e-05,
      "loss": 0.0008,
      "step": 8038
    },
    {
      "epoch": 81.61,
      "learning_rate": 5.054614659225686e-05,
      "loss": 0.0015,
      "step": 8039
    },
    {
      "epoch": 81.62,
      "learning_rate": 5.053427429716867e-05,
      "loss": 0.0001,
      "step": 8040
    },
    {
      "epoch": 81.63,
      "learning_rate": 5.052240197195426e-05,
      "loss": 0.0001,
      "step": 8041
    },
    {
      "epoch": 81.64,
      "learning_rate": 5.05105296172831e-05,
      "loss": 0.0026,
      "step": 8042
    },
    {
      "epoch": 81.65,
      "learning_rate": 5.049865723382463e-05,
      "loss": 0.0001,
      "step": 8043
    },
    {
      "epoch": 81.66,
      "learning_rate": 5.048678482224831e-05,
      "loss": 0.0008,
      "step": 8044
    },
    {
      "epoch": 81.68,
      "learning_rate": 5.0474912383223604e-05,
      "loss": 0.0002,
      "step": 8045
    },
    {
      "epoch": 81.69,
      "learning_rate": 5.046303991741993e-05,
      "loss": 0.0127,
      "step": 8046
    },
    {
      "epoch": 81.7,
      "learning_rate": 5.045116742550676e-05,
      "loss": 0.0037,
      "step": 8047
    },
    {
      "epoch": 81.71,
      "learning_rate": 5.043929490815356e-05,
      "loss": 0.0002,
      "step": 8048
    },
    {
      "epoch": 81.72,
      "learning_rate": 5.0427422366029775e-05,
      "loss": 0.0,
      "step": 8049
    },
    {
      "epoch": 81.73,
      "learning_rate": 5.041554979980486e-05,
      "loss": 0.0002,
      "step": 8050
    },
    {
      "epoch": 81.74,
      "learning_rate": 5.040367721014828e-05,
      "loss": 0.0003,
      "step": 8051
    },
    {
      "epoch": 81.75,
      "learning_rate": 5.03918045977295e-05,
      "loss": 0.001,
      "step": 8052
    },
    {
      "epoch": 81.76,
      "learning_rate": 5.037993196321798e-05,
      "loss": 0.012,
      "step": 8053
    },
    {
      "epoch": 81.77,
      "learning_rate": 5.036805930728319e-05,
      "loss": 0.0001,
      "step": 8054
    },
    {
      "epoch": 81.78,
      "learning_rate": 5.035618663059458e-05,
      "loss": 0.0027,
      "step": 8055
    },
    {
      "epoch": 81.79,
      "learning_rate": 5.034431393382163e-05,
      "loss": 0.0003,
      "step": 8056
    },
    {
      "epoch": 81.8,
      "learning_rate": 5.0332441217633804e-05,
      "loss": 0.0017,
      "step": 8057
    },
    {
      "epoch": 81.81,
      "learning_rate": 5.0320568482700556e-05,
      "loss": 0.0057,
      "step": 8058
    },
    {
      "epoch": 81.82,
      "learning_rate": 5.030869572969138e-05,
      "loss": 0.0006,
      "step": 8059
    },
    {
      "epoch": 81.83,
      "learning_rate": 5.029682295927574e-05,
      "loss": 0.0027,
      "step": 8060
    },
    {
      "epoch": 81.84,
      "learning_rate": 5.02849501721231e-05,
      "loss": 0.0001,
      "step": 8061
    },
    {
      "epoch": 81.85,
      "learning_rate": 5.0273077368902935e-05,
      "loss": 0.0003,
      "step": 8062
    },
    {
      "epoch": 81.86,
      "learning_rate": 5.02612045502847e-05,
      "loss": 0.0003,
      "step": 8063
    },
    {
      "epoch": 81.87,
      "learning_rate": 5.024933171693791e-05,
      "loss": 0.012,
      "step": 8064
    },
    {
      "epoch": 81.88,
      "learning_rate": 5.0237458869532006e-05,
      "loss": 0.0001,
      "step": 8065
    },
    {
      "epoch": 81.89,
      "learning_rate": 5.022558600873649e-05,
      "loss": 0.0057,
      "step": 8066
    },
    {
      "epoch": 81.9,
      "learning_rate": 5.0213713135220806e-05,
      "loss": 0.0002,
      "step": 8067
    },
    {
      "epoch": 81.91,
      "learning_rate": 5.0201840249654464e-05,
      "loss": 0.0002,
      "step": 8068
    },
    {
      "epoch": 81.92,
      "learning_rate": 5.018996735270693e-05,
      "loss": 0.0063,
      "step": 8069
    },
    {
      "epoch": 81.93,
      "learning_rate": 5.0178094445047675e-05,
      "loss": 0.0007,
      "step": 8070
    },
    {
      "epoch": 81.94,
      "learning_rate": 5.016622152734617e-05,
      "loss": 0.0006,
      "step": 8071
    },
    {
      "epoch": 81.95,
      "learning_rate": 5.015434860027193e-05,
      "loss": 0.0002,
      "step": 8072
    },
    {
      "epoch": 81.96,
      "learning_rate": 5.01424756644944e-05,
      "loss": 0.0138,
      "step": 8073
    },
    {
      "epoch": 81.97,
      "learning_rate": 5.0130602720683085e-05,
      "loss": 0.003,
      "step": 8074
    },
    {
      "epoch": 81.98,
      "learning_rate": 5.011872976950744e-05,
      "loss": 0.0035,
      "step": 8075
    },
    {
      "epoch": 81.99,
      "learning_rate": 5.0106856811636985e-05,
      "loss": 0.0001,
      "step": 8076
    },
    {
      "epoch": 82.0,
      "learning_rate": 5.009498384774117e-05,
      "loss": 0.0028,
      "step": 8077
    },
    {
      "epoch": 82.0,
      "eval_loss": 0.016654426231980324,
      "eval_runtime": 31.8939,
      "eval_samples_per_second": 98.765,
      "eval_steps_per_second": 6.177,
      "eval_wer": 0.003201024327784891,
      "step": 8077
    },
    {
      "epoch": 82.01,
      "learning_rate": 5.008311087848949e-05,
      "loss": 0.0,
      "step": 8078
    },
    {
      "epoch": 82.02,
      "learning_rate": 5.0071237904551415e-05,
      "loss": 0.0001,
      "step": 8079
    },
    {
      "epoch": 82.03,
      "learning_rate": 5.005936492659645e-05,
      "loss": 0.0019,
      "step": 8080
    },
    {
      "epoch": 82.04,
      "learning_rate": 5.004749194529407e-05,
      "loss": 0.0,
      "step": 8081
    },
    {
      "epoch": 82.05,
      "learning_rate": 5.0035618961313747e-05,
      "loss": 0.0032,
      "step": 8082
    },
    {
      "epoch": 82.06,
      "learning_rate": 5.002374597532497e-05,
      "loss": 0.0004,
      "step": 8083
    },
    {
      "epoch": 82.07,
      "learning_rate": 5.001187298799723e-05,
      "loss": 0.0004,
      "step": 8084
    },
    {
      "epoch": 82.08,
      "learning_rate": 5e-05,
      "loss": 0.0007,
      "step": 8085
    },
    {
      "epoch": 82.09,
      "learning_rate": 4.998812701200278e-05,
      "loss": 0.0002,
      "step": 8086
    },
    {
      "epoch": 82.1,
      "learning_rate": 4.9976254024675044e-05,
      "loss": 0.0066,
      "step": 8087
    },
    {
      "epoch": 82.11,
      "learning_rate": 4.996438103868626e-05,
      "loss": 0.0022,
      "step": 8088
    },
    {
      "epoch": 82.12,
      "learning_rate": 4.995250805470596e-05,
      "loss": 0.0022,
      "step": 8089
    },
    {
      "epoch": 82.13,
      "learning_rate": 4.994063507340356e-05,
      "loss": 0.0001,
      "step": 8090
    },
    {
      "epoch": 82.14,
      "learning_rate": 4.992876209544859e-05,
      "loss": 0.0052,
      "step": 8091
    },
    {
      "epoch": 82.15,
      "learning_rate": 4.991688912151053e-05,
      "loss": 0.0003,
      "step": 8092
    },
    {
      "epoch": 82.16,
      "learning_rate": 4.990501615225884e-05,
      "loss": 0.0043,
      "step": 8093
    },
    {
      "epoch": 82.17,
      "learning_rate": 4.989314318836302e-05,
      "loss": 0.001,
      "step": 8094
    },
    {
      "epoch": 82.18,
      "learning_rate": 4.988127023049257e-05,
      "loss": 0.0124,
      "step": 8095
    },
    {
      "epoch": 82.19,
      "learning_rate": 4.986939727931692e-05,
      "loss": 0.0001,
      "step": 8096
    },
    {
      "epoch": 82.2,
      "learning_rate": 4.9857524335505624e-05,
      "loss": 0.0004,
      "step": 8097
    },
    {
      "epoch": 82.21,
      "learning_rate": 4.9845651399728084e-05,
      "loss": 0.0042,
      "step": 8098
    },
    {
      "epoch": 82.22,
      "learning_rate": 4.9833778472653834e-05,
      "loss": 0.0001,
      "step": 8099
    },
    {
      "epoch": 82.23,
      "learning_rate": 4.982190555495235e-05,
      "loss": 0.0144,
      "step": 8100
    },
    {
      "epoch": 82.24,
      "learning_rate": 4.981003264729309e-05,
      "loss": 0.0002,
      "step": 8101
    },
    {
      "epoch": 82.25,
      "learning_rate": 4.9798159750345534e-05,
      "loss": 0.0,
      "step": 8102
    },
    {
      "epoch": 82.26,
      "learning_rate": 4.97862868647792e-05,
      "loss": 0.0003,
      "step": 8103
    },
    {
      "epoch": 82.27,
      "learning_rate": 4.977441399126353e-05,
      "loss": 0.0024,
      "step": 8104
    },
    {
      "epoch": 82.28,
      "learning_rate": 4.9762541130468006e-05,
      "loss": 0.0,
      "step": 8105
    },
    {
      "epoch": 82.29,
      "learning_rate": 4.9750668283062104e-05,
      "loss": 0.0004,
      "step": 8106
    },
    {
      "epoch": 82.3,
      "learning_rate": 4.97387954497153e-05,
      "loss": 0.0005,
      "step": 8107
    },
    {
      "epoch": 82.31,
      "learning_rate": 4.9726922631097097e-05,
      "loss": 0.0001,
      "step": 8108
    },
    {
      "epoch": 82.32,
      "learning_rate": 4.971504982787691e-05,
      "loss": 0.0003,
      "step": 8109
    },
    {
      "epoch": 82.34,
      "learning_rate": 4.9703177040724266e-05,
      "loss": 0.0037,
      "step": 8110
    },
    {
      "epoch": 82.35,
      "learning_rate": 4.9691304270308624e-05,
      "loss": 0.0006,
      "step": 8111
    },
    {
      "epoch": 82.36,
      "learning_rate": 4.967943151729945e-05,
      "loss": 0.0002,
      "step": 8112
    },
    {
      "epoch": 82.37,
      "learning_rate": 4.966755878236622e-05,
      "loss": 0.003,
      "step": 8113
    },
    {
      "epoch": 82.38,
      "learning_rate": 4.965568606617839e-05,
      "loss": 0.0007,
      "step": 8114
    },
    {
      "epoch": 82.39,
      "learning_rate": 4.964381336940542e-05,
      "loss": 0.0003,
      "step": 8115
    },
    {
      "epoch": 82.4,
      "learning_rate": 4.963194069271683e-05,
      "loss": 0.009,
      "step": 8116
    },
    {
      "epoch": 82.41,
      "learning_rate": 4.962006803678202e-05,
      "loss": 0.0012,
      "step": 8117
    },
    {
      "epoch": 82.42,
      "learning_rate": 4.96081954022705e-05,
      "loss": 0.0001,
      "step": 8118
    },
    {
      "epoch": 82.43,
      "learning_rate": 4.959632278985174e-05,
      "loss": 0.0,
      "step": 8119
    },
    {
      "epoch": 82.44,
      "learning_rate": 4.9584450200195156e-05,
      "loss": 0.0007,
      "step": 8120
    },
    {
      "epoch": 82.45,
      "learning_rate": 4.957257763397024e-05,
      "loss": 0.0,
      "step": 8121
    },
    {
      "epoch": 82.46,
      "learning_rate": 4.956070509184646e-05,
      "loss": 0.0,
      "step": 8122
    },
    {
      "epoch": 82.47,
      "learning_rate": 4.9548832574493235e-05,
      "loss": 0.0,
      "step": 8123
    },
    {
      "epoch": 82.48,
      "learning_rate": 4.953696008258008e-05,
      "loss": 0.0043,
      "step": 8124
    },
    {
      "epoch": 82.49,
      "learning_rate": 4.952508761677641e-05,
      "loss": 0.009,
      "step": 8125
    },
    {
      "epoch": 82.5,
      "learning_rate": 4.95132151777517e-05,
      "loss": 0.0,
      "step": 8126
    },
    {
      "epoch": 82.51,
      "learning_rate": 4.950134276617538e-05,
      "loss": 0.0,
      "step": 8127
    },
    {
      "epoch": 82.52,
      "learning_rate": 4.9489470382716915e-05,
      "loss": 0.0001,
      "step": 8128
    },
    {
      "epoch": 82.53,
      "learning_rate": 4.9477598028045766e-05,
      "loss": 0.0052,
      "step": 8129
    },
    {
      "epoch": 82.54,
      "learning_rate": 4.9465725702831346e-05,
      "loss": 0.0009,
      "step": 8130
    },
    {
      "epoch": 82.55,
      "learning_rate": 4.945385340774314e-05,
      "loss": 0.0002,
      "step": 8131
    },
    {
      "epoch": 82.56,
      "learning_rate": 4.9441981143450586e-05,
      "loss": 0.0003,
      "step": 8132
    },
    {
      "epoch": 82.57,
      "learning_rate": 4.94301089106231e-05,
      "loss": 0.0011,
      "step": 8133
    },
    {
      "epoch": 82.58,
      "learning_rate": 4.941823670993016e-05,
      "loss": 0.0052,
      "step": 8134
    },
    {
      "epoch": 82.59,
      "learning_rate": 4.940636454204118e-05,
      "loss": 0.0003,
      "step": 8135
    },
    {
      "epoch": 82.6,
      "learning_rate": 4.939449240762559e-05,
      "loss": 0.0001,
      "step": 8136
    },
    {
      "epoch": 82.61,
      "learning_rate": 4.938262030735287e-05,
      "loss": 0.0013,
      "step": 8137
    },
    {
      "epoch": 82.62,
      "learning_rate": 4.937074824189239e-05,
      "loss": 0.0002,
      "step": 8138
    },
    {
      "epoch": 82.63,
      "learning_rate": 4.935887621191364e-05,
      "loss": 0.0014,
      "step": 8139
    },
    {
      "epoch": 82.64,
      "learning_rate": 4.934700421808602e-05,
      "loss": 0.004,
      "step": 8140
    },
    {
      "epoch": 82.65,
      "learning_rate": 4.933513226107896e-05,
      "loss": 0.0026,
      "step": 8141
    },
    {
      "epoch": 82.66,
      "learning_rate": 4.93232603415619e-05,
      "loss": 0.0002,
      "step": 8142
    },
    {
      "epoch": 82.67,
      "learning_rate": 4.9311388460204246e-05,
      "loss": 0.0001,
      "step": 8143
    },
    {
      "epoch": 82.68,
      "learning_rate": 4.929951661767541e-05,
      "loss": 0.0001,
      "step": 8144
    },
    {
      "epoch": 82.69,
      "learning_rate": 4.928764481464485e-05,
      "loss": 0.0061,
      "step": 8145
    },
    {
      "epoch": 82.7,
      "learning_rate": 4.927577305178195e-05,
      "loss": 0.002,
      "step": 8146
    },
    {
      "epoch": 82.71,
      "learning_rate": 4.926390132975614e-05,
      "loss": 0.0,
      "step": 8147
    },
    {
      "epoch": 82.72,
      "learning_rate": 4.925202964923683e-05,
      "loss": 0.0002,
      "step": 8148
    },
    {
      "epoch": 82.73,
      "learning_rate": 4.9240158010893415e-05,
      "loss": 0.0056,
      "step": 8149
    },
    {
      "epoch": 82.74,
      "learning_rate": 4.922828641539534e-05,
      "loss": 0.0023,
      "step": 8150
    },
    {
      "epoch": 82.75,
      "learning_rate": 4.921641486341195e-05,
      "loss": 0.0009,
      "step": 8151
    },
    {
      "epoch": 82.76,
      "learning_rate": 4.9204543355612706e-05,
      "loss": 0.0001,
      "step": 8152
    },
    {
      "epoch": 82.77,
      "learning_rate": 4.9192671892666984e-05,
      "loss": 0.0003,
      "step": 8153
    },
    {
      "epoch": 82.78,
      "learning_rate": 4.918080047524418e-05,
      "loss": 0.0003,
      "step": 8154
    },
    {
      "epoch": 82.79,
      "learning_rate": 4.9168929104013697e-05,
      "loss": 0.0001,
      "step": 8155
    },
    {
      "epoch": 82.8,
      "learning_rate": 4.915705777964493e-05,
      "loss": 0.0114,
      "step": 8156
    },
    {
      "epoch": 82.81,
      "learning_rate": 4.914518650280724e-05,
      "loss": 0.0034,
      "step": 8157
    },
    {
      "epoch": 82.82,
      "learning_rate": 4.913331527417007e-05,
      "loss": 0.0006,
      "step": 8158
    },
    {
      "epoch": 82.83,
      "learning_rate": 4.9121444094402744e-05,
      "loss": 0.0002,
      "step": 8159
    },
    {
      "epoch": 82.84,
      "learning_rate": 4.9109572964174675e-05,
      "loss": 0.0006,
      "step": 8160
    },
    {
      "epoch": 82.85,
      "learning_rate": 4.909770188415525e-05,
      "loss": 0.007,
      "step": 8161
    },
    {
      "epoch": 82.86,
      "learning_rate": 4.9085830855013826e-05,
      "loss": 0.0167,
      "step": 8162
    },
    {
      "epoch": 82.87,
      "learning_rate": 4.907395987741979e-05,
      "loss": 0.0003,
      "step": 8163
    },
    {
      "epoch": 82.88,
      "learning_rate": 4.906208895204251e-05,
      "loss": 0.0173,
      "step": 8164
    },
    {
      "epoch": 82.89,
      "learning_rate": 4.9050218079551325e-05,
      "loss": 0.0001,
      "step": 8165
    },
    {
      "epoch": 82.9,
      "learning_rate": 4.903834726061565e-05,
      "loss": 0.0002,
      "step": 8166
    },
    {
      "epoch": 82.91,
      "learning_rate": 4.9026476495904814e-05,
      "loss": 0.0019,
      "step": 8167
    },
    {
      "epoch": 82.92,
      "learning_rate": 4.901460578608817e-05,
      "loss": 0.0146,
      "step": 8168
    },
    {
      "epoch": 82.93,
      "learning_rate": 4.900273513183511e-05,
      "loss": 0.0065,
      "step": 8169
    },
    {
      "epoch": 82.94,
      "learning_rate": 4.899086453381494e-05,
      "loss": 0.0059,
      "step": 8170
    },
    {
      "epoch": 82.95,
      "learning_rate": 4.8978993992697055e-05,
      "loss": 0.0,
      "step": 8171
    },
    {
      "epoch": 82.96,
      "learning_rate": 4.896712350915075e-05,
      "loss": 0.0002,
      "step": 8172
    },
    {
      "epoch": 82.97,
      "learning_rate": 4.8955253083845406e-05,
      "loss": 0.0001,
      "step": 8173
    },
    {
      "epoch": 82.98,
      "learning_rate": 4.894338271745036e-05,
      "loss": 0.0001,
      "step": 8174
    },
    {
      "epoch": 82.99,
      "learning_rate": 4.893151241063493e-05,
      "loss": 0.0001,
      "step": 8175
    },
    {
      "epoch": 82.99,
      "eval_loss": 0.019251884892582893,
      "eval_runtime": 31.9364,
      "eval_samples_per_second": 98.633,
      "eval_steps_per_second": 6.169,
      "eval_wer": 0.003297055057618438,
      "step": 8175
    },
    {
      "epoch": 83.01,
      "learning_rate": 4.891964216406844e-05,
      "loss": 0.0,
      "step": 8176
    },
    {
      "epoch": 83.02,
      "learning_rate": 4.890777197842028e-05,
      "loss": 0.0004,
      "step": 8177
    },
    {
      "epoch": 83.03,
      "learning_rate": 4.889590185435969e-05,
      "loss": 0.0039,
      "step": 8178
    },
    {
      "epoch": 83.04,
      "learning_rate": 4.888403179255608e-05,
      "loss": 0.0003,
      "step": 8179
    },
    {
      "epoch": 83.05,
      "learning_rate": 4.887216179367868e-05,
      "loss": 0.0002,
      "step": 8180
    },
    {
      "epoch": 83.06,
      "learning_rate": 4.886029185839686e-05,
      "loss": 0.0002,
      "step": 8181
    },
    {
      "epoch": 83.07,
      "learning_rate": 4.884842198737994e-05,
      "loss": 0.0028,
      "step": 8182
    },
    {
      "epoch": 83.08,
      "learning_rate": 4.883655218129719e-05,
      "loss": 0.0005,
      "step": 8183
    },
    {
      "epoch": 83.09,
      "learning_rate": 4.8824682440817926e-05,
      "loss": 0.0,
      "step": 8184
    },
    {
      "epoch": 83.1,
      "learning_rate": 4.8812812766611486e-05,
      "loss": 0.0,
      "step": 8185
    },
    {
      "epoch": 83.11,
      "learning_rate": 4.8800943159347104e-05,
      "loss": 0.0003,
      "step": 8186
    },
    {
      "epoch": 83.12,
      "learning_rate": 4.878907361969414e-05,
      "loss": 0.0001,
      "step": 8187
    },
    {
      "epoch": 83.13,
      "learning_rate": 4.877720414832182e-05,
      "loss": 0.0002,
      "step": 8188
    },
    {
      "epoch": 83.14,
      "learning_rate": 4.876533474589947e-05,
      "loss": 0.0009,
      "step": 8189
    },
    {
      "epoch": 83.15,
      "learning_rate": 4.875346541309637e-05,
      "loss": 0.0001,
      "step": 8190
    },
    {
      "epoch": 83.16,
      "learning_rate": 4.874159615058177e-05,
      "loss": 0.0,
      "step": 8191
    },
    {
      "epoch": 83.17,
      "learning_rate": 4.872972695902499e-05,
      "loss": 0.0217,
      "step": 8192
    },
    {
      "epoch": 83.18,
      "learning_rate": 4.871785783909523e-05,
      "loss": 0.0,
      "step": 8193
    },
    {
      "epoch": 83.19,
      "learning_rate": 4.870598879146182e-05,
      "loss": 0.0001,
      "step": 8194
    },
    {
      "epoch": 83.2,
      "learning_rate": 4.8694119816794004e-05,
      "loss": 0.0031,
      "step": 8195
    },
    {
      "epoch": 83.21,
      "learning_rate": 4.868225091576103e-05,
      "loss": 0.0006,
      "step": 8196
    },
    {
      "epoch": 83.22,
      "learning_rate": 4.867038208903214e-05,
      "loss": 0.0001,
      "step": 8197
    },
    {
      "epoch": 83.23,
      "learning_rate": 4.865851333727663e-05,
      "loss": 0.0005,
      "step": 8198
    },
    {
      "epoch": 83.24,
      "learning_rate": 4.8646644661163686e-05,
      "loss": 0.0018,
      "step": 8199
    },
    {
      "epoch": 83.25,
      "learning_rate": 4.8634776061362616e-05,
      "loss": 0.0197,
      "step": 8200
    },
    {
      "epoch": 83.26,
      "learning_rate": 4.862290753854257e-05,
      "loss": 0.0002,
      "step": 8201
    },
    {
      "epoch": 83.27,
      "learning_rate": 4.8611039093372846e-05,
      "loss": 0.0003,
      "step": 8202
    },
    {
      "epoch": 83.28,
      "learning_rate": 4.859917072652266e-05,
      "loss": 0.0001,
      "step": 8203
    },
    {
      "epoch": 83.29,
      "learning_rate": 4.8587302438661227e-05,
      "loss": 0.0001,
      "step": 8204
    },
    {
      "epoch": 83.3,
      "learning_rate": 4.8575434230457745e-05,
      "loss": 0.0001,
      "step": 8205
    },
    {
      "epoch": 83.31,
      "learning_rate": 4.8563566102581474e-05,
      "loss": 0.0,
      "step": 8206
    },
    {
      "epoch": 83.32,
      "learning_rate": 4.85516980557016e-05,
      "loss": 0.0124,
      "step": 8207
    },
    {
      "epoch": 83.33,
      "learning_rate": 4.8539830090487325e-05,
      "loss": 0.0002,
      "step": 8208
    },
    {
      "epoch": 83.34,
      "learning_rate": 4.8527962207607846e-05,
      "loss": 0.0255,
      "step": 8209
    },
    {
      "epoch": 83.35,
      "learning_rate": 4.851609440773237e-05,
      "loss": 0.0003,
      "step": 8210
    },
    {
      "epoch": 83.36,
      "learning_rate": 4.850422669153009e-05,
      "loss": 0.0001,
      "step": 8211
    },
    {
      "epoch": 83.37,
      "learning_rate": 4.849235905967017e-05,
      "loss": 0.0,
      "step": 8212
    },
    {
      "epoch": 83.38,
      "learning_rate": 4.848049151282181e-05,
      "loss": 0.0021,
      "step": 8213
    },
    {
      "epoch": 83.39,
      "learning_rate": 4.84686240516542e-05,
      "loss": 0.0067,
      "step": 8214
    },
    {
      "epoch": 83.4,
      "learning_rate": 4.845675667683649e-05,
      "loss": 0.0003,
      "step": 8215
    },
    {
      "epoch": 83.41,
      "learning_rate": 4.8444889389037866e-05,
      "loss": 0.0003,
      "step": 8216
    },
    {
      "epoch": 83.42,
      "learning_rate": 4.843302218892747e-05,
      "loss": 0.0001,
      "step": 8217
    },
    {
      "epoch": 83.43,
      "learning_rate": 4.842115507717445e-05,
      "loss": 0.0064,
      "step": 8218
    },
    {
      "epoch": 83.44,
      "learning_rate": 4.8409288054448014e-05,
      "loss": 0.001,
      "step": 8219
    },
    {
      "epoch": 83.45,
      "learning_rate": 4.839742112141724e-05,
      "loss": 0.0001,
      "step": 8220
    },
    {
      "epoch": 83.46,
      "learning_rate": 4.838555427875131e-05,
      "loss": 0.0001,
      "step": 8221
    },
    {
      "epoch": 83.47,
      "learning_rate": 4.8373687527119376e-05,
      "loss": 0.0001,
      "step": 8222
    },
    {
      "epoch": 83.48,
      "learning_rate": 4.836182086719053e-05,
      "loss": 0.0001,
      "step": 8223
    },
    {
      "epoch": 83.49,
      "learning_rate": 4.834995429963393e-05,
      "loss": 0.0027,
      "step": 8224
    },
    {
      "epoch": 83.5,
      "learning_rate": 4.8338087825118675e-05,
      "loss": 0.0189,
      "step": 8225
    },
    {
      "epoch": 83.51,
      "learning_rate": 4.832622144431388e-05,
      "loss": 0.0002,
      "step": 8226
    },
    {
      "epoch": 83.52,
      "learning_rate": 4.8314355157888686e-05,
      "loss": 0.0001,
      "step": 8227
    },
    {
      "epoch": 83.53,
      "learning_rate": 4.830248896651217e-05,
      "loss": 0.0,
      "step": 8228
    },
    {
      "epoch": 83.54,
      "learning_rate": 4.829062287085347e-05,
      "loss": 0.0001,
      "step": 8229
    },
    {
      "epoch": 83.55,
      "learning_rate": 4.827875687158162e-05,
      "loss": 0.0001,
      "step": 8230
    },
    {
      "epoch": 83.56,
      "learning_rate": 4.826689096936576e-05,
      "loss": 0.0002,
      "step": 8231
    },
    {
      "epoch": 83.57,
      "learning_rate": 4.825502516487497e-05,
      "loss": 0.012,
      "step": 8232
    },
    {
      "epoch": 83.58,
      "learning_rate": 4.8243159458778286e-05,
      "loss": 0.0004,
      "step": 8233
    },
    {
      "epoch": 83.59,
      "learning_rate": 4.823129385174483e-05,
      "loss": 0.0001,
      "step": 8234
    },
    {
      "epoch": 83.6,
      "learning_rate": 4.821942834444366e-05,
      "loss": 0.0001,
      "step": 8235
    },
    {
      "epoch": 83.61,
      "learning_rate": 4.8207562937543824e-05,
      "loss": 0.0001,
      "step": 8236
    },
    {
      "epoch": 83.62,
      "learning_rate": 4.8195697631714396e-05,
      "loss": 0.001,
      "step": 8237
    },
    {
      "epoch": 83.63,
      "learning_rate": 4.81838324276244e-05,
      "loss": 0.0126,
      "step": 8238
    },
    {
      "epoch": 83.64,
      "learning_rate": 4.817196732594289e-05,
      "loss": 0.0032,
      "step": 8239
    },
    {
      "epoch": 83.65,
      "learning_rate": 4.8160102327338944e-05,
      "loss": 0.0002,
      "step": 8240
    },
    {
      "epoch": 83.66,
      "learning_rate": 4.814823743248152e-05,
      "loss": 0.0001,
      "step": 8241
    },
    {
      "epoch": 83.68,
      "learning_rate": 4.8136372642039704e-05,
      "loss": 0.0002,
      "step": 8242
    },
    {
      "epoch": 83.69,
      "learning_rate": 4.8124507956682517e-05,
      "loss": 0.0,
      "step": 8243
    },
    {
      "epoch": 83.7,
      "learning_rate": 4.8112643377078944e-05,
      "loss": 0.0101,
      "step": 8244
    },
    {
      "epoch": 83.71,
      "learning_rate": 4.810077890389803e-05,
      "loss": 0.0002,
      "step": 8245
    },
    {
      "epoch": 83.72,
      "learning_rate": 4.808891453780874e-05,
      "loss": 0.0002,
      "step": 8246
    },
    {
      "epoch": 83.73,
      "learning_rate": 4.807705027948008e-05,
      "loss": 0.0001,
      "step": 8247
    },
    {
      "epoch": 83.74,
      "learning_rate": 4.8065186129581076e-05,
      "loss": 0.0008,
      "step": 8248
    },
    {
      "epoch": 83.75,
      "learning_rate": 4.805332208878067e-05,
      "loss": 0.005,
      "step": 8249
    },
    {
      "epoch": 83.76,
      "learning_rate": 4.804145815774787e-05,
      "loss": 0.0002,
      "step": 8250
    },
    {
      "epoch": 83.77,
      "learning_rate": 4.802959433715165e-05,
      "loss": 0.0058,
      "step": 8251
    },
    {
      "epoch": 83.78,
      "learning_rate": 4.8017730627660956e-05,
      "loss": 0.0006,
      "step": 8252
    },
    {
      "epoch": 83.79,
      "learning_rate": 4.8005867029944766e-05,
      "loss": 0.0006,
      "step": 8253
    },
    {
      "epoch": 83.8,
      "learning_rate": 4.799400354467201e-05,
      "loss": 0.0054,
      "step": 8254
    },
    {
      "epoch": 83.81,
      "learning_rate": 4.798214017251166e-05,
      "loss": 0.0001,
      "step": 8255
    },
    {
      "epoch": 83.82,
      "learning_rate": 4.797027691413267e-05,
      "loss": 0.0001,
      "step": 8256
    },
    {
      "epoch": 83.83,
      "learning_rate": 4.795841377020394e-05,
      "loss": 0.0057,
      "step": 8257
    },
    {
      "epoch": 83.84,
      "learning_rate": 4.7946550741394416e-05,
      "loss": 0.0123,
      "step": 8258
    },
    {
      "epoch": 83.85,
      "learning_rate": 4.793468782837304e-05,
      "loss": 0.0001,
      "step": 8259
    },
    {
      "epoch": 83.86,
      "learning_rate": 4.792282503180867e-05,
      "loss": 0.0001,
      "step": 8260
    },
    {
      "epoch": 83.87,
      "learning_rate": 4.791096235237029e-05,
      "loss": 0.0006,
      "step": 8261
    },
    {
      "epoch": 83.88,
      "learning_rate": 4.789909979072674e-05,
      "loss": 0.0029,
      "step": 8262
    },
    {
      "epoch": 83.89,
      "learning_rate": 4.788723734754694e-05,
      "loss": 0.0004,
      "step": 8263
    },
    {
      "epoch": 83.9,
      "learning_rate": 4.7875375023499795e-05,
      "loss": 0.0004,
      "step": 8264
    },
    {
      "epoch": 83.91,
      "learning_rate": 4.786351281925417e-05,
      "loss": 0.0031,
      "step": 8265
    },
    {
      "epoch": 83.92,
      "learning_rate": 4.785165073547895e-05,
      "loss": 0.0002,
      "step": 8266
    },
    {
      "epoch": 83.93,
      "learning_rate": 4.783978877284298e-05,
      "loss": 0.0,
      "step": 8267
    },
    {
      "epoch": 83.94,
      "learning_rate": 4.7827926932015134e-05,
      "loss": 0.0033,
      "step": 8268
    },
    {
      "epoch": 83.95,
      "learning_rate": 4.7816065213664293e-05,
      "loss": 0.0037,
      "step": 8269
    },
    {
      "epoch": 83.96,
      "learning_rate": 4.780420361845927e-05,
      "loss": 0.0001,
      "step": 8270
    },
    {
      "epoch": 83.97,
      "learning_rate": 4.779234214706892e-05,
      "loss": 0.0088,
      "step": 8271
    },
    {
      "epoch": 83.98,
      "learning_rate": 4.77804808001621e-05,
      "loss": 0.0,
      "step": 8272
    },
    {
      "epoch": 83.99,
      "learning_rate": 4.77686195784076e-05,
      "loss": 0.0012,
      "step": 8273
    },
    {
      "epoch": 84.0,
      "learning_rate": 4.775675848247427e-05,
      "loss": 0.0015,
      "step": 8274
    },
    {
      "epoch": 84.0,
      "eval_loss": 0.021807441487908363,
      "eval_runtime": 33.0304,
      "eval_samples_per_second": 95.367,
      "eval_steps_per_second": 5.964,
      "eval_wer": 0.0034250960307298335,
      "step": 8274
    },
    {
      "epoch": 84.01,
      "learning_rate": 4.7744897513030884e-05,
      "loss": 0.0044,
      "step": 8275
    },
    {
      "epoch": 84.02,
      "learning_rate": 4.773303667074629e-05,
      "loss": 0.0004,
      "step": 8276
    },
    {
      "epoch": 84.03,
      "learning_rate": 4.772117595628928e-05,
      "loss": 0.0003,
      "step": 8277
    },
    {
      "epoch": 84.04,
      "learning_rate": 4.770931537032862e-05,
      "loss": 0.0008,
      "step": 8278
    },
    {
      "epoch": 84.05,
      "learning_rate": 4.769745491353311e-05,
      "loss": 0.0002,
      "step": 8279
    },
    {
      "epoch": 84.06,
      "learning_rate": 4.7685594586571556e-05,
      "loss": 0.0004,
      "step": 8280
    },
    {
      "epoch": 84.07,
      "learning_rate": 4.767373439011267e-05,
      "loss": 0.0003,
      "step": 8281
    },
    {
      "epoch": 84.08,
      "learning_rate": 4.766187432482527e-05,
      "loss": 0.0003,
      "step": 8282
    },
    {
      "epoch": 84.09,
      "learning_rate": 4.765001439137806e-05,
      "loss": 0.0012,
      "step": 8283
    },
    {
      "epoch": 84.1,
      "learning_rate": 4.763815459043982e-05,
      "loss": 0.0016,
      "step": 8284
    },
    {
      "epoch": 84.11,
      "learning_rate": 4.7626294922679304e-05,
      "loss": 0.0002,
      "step": 8285
    },
    {
      "epoch": 84.12,
      "learning_rate": 4.7614435388765204e-05,
      "loss": 0.0001,
      "step": 8286
    },
    {
      "epoch": 84.13,
      "learning_rate": 4.760257598936626e-05,
      "loss": 0.01,
      "step": 8287
    },
    {
      "epoch": 84.14,
      "learning_rate": 4.759071672515123e-05,
      "loss": 0.0002,
      "step": 8288
    },
    {
      "epoch": 84.15,
      "learning_rate": 4.7578857596788754e-05,
      "loss": 0.0001,
      "step": 8289
    },
    {
      "epoch": 84.16,
      "learning_rate": 4.7566998604947585e-05,
      "loss": 0.0,
      "step": 8290
    },
    {
      "epoch": 84.17,
      "learning_rate": 4.75551397502964e-05,
      "loss": 0.0003,
      "step": 8291
    },
    {
      "epoch": 84.18,
      "learning_rate": 4.754328103350389e-05,
      "loss": 0.0015,
      "step": 8292
    },
    {
      "epoch": 84.19,
      "learning_rate": 4.7531422455238736e-05,
      "loss": 0.0006,
      "step": 8293
    },
    {
      "epoch": 84.2,
      "learning_rate": 4.751956401616959e-05,
      "loss": 0.0,
      "step": 8294
    },
    {
      "epoch": 84.21,
      "learning_rate": 4.750770571696514e-05,
      "loss": 0.0018,
      "step": 8295
    },
    {
      "epoch": 84.22,
      "learning_rate": 4.749584755829404e-05,
      "loss": 0.0001,
      "step": 8296
    },
    {
      "epoch": 84.23,
      "learning_rate": 4.7483989540824924e-05,
      "loss": 0.0,
      "step": 8297
    },
    {
      "epoch": 84.24,
      "learning_rate": 4.7472131665226447e-05,
      "loss": 0.0064,
      "step": 8298
    },
    {
      "epoch": 84.25,
      "learning_rate": 4.746027393216722e-05,
      "loss": 0.0005,
      "step": 8299
    },
    {
      "epoch": 84.26,
      "learning_rate": 4.7448416342315865e-05,
      "loss": 0.0032,
      "step": 8300
    },
    {
      "epoch": 84.27,
      "learning_rate": 4.743655889634105e-05,
      "loss": 0.0013,
      "step": 8301
    },
    {
      "epoch": 84.28,
      "learning_rate": 4.74247015949113e-05,
      "loss": 0.0006,
      "step": 8302
    },
    {
      "epoch": 84.29,
      "learning_rate": 4.7412844438695306e-05,
      "loss": 0.0014,
      "step": 8303
    },
    {
      "epoch": 84.3,
      "learning_rate": 4.740098742836156e-05,
      "loss": 0.0001,
      "step": 8304
    },
    {
      "epoch": 84.31,
      "learning_rate": 4.7389130564578724e-05,
      "loss": 0.0003,
      "step": 8305
    },
    {
      "epoch": 84.32,
      "learning_rate": 4.737727384801535e-05,
      "loss": 0.0017,
      "step": 8306
    },
    {
      "epoch": 84.34,
      "learning_rate": 4.736541727933998e-05,
      "loss": 0.001,
      "step": 8307
    },
    {
      "epoch": 84.35,
      "learning_rate": 4.735356085922118e-05,
      "loss": 0.0138,
      "step": 8308
    },
    {
      "epoch": 84.36,
      "learning_rate": 4.734170458832754e-05,
      "loss": 0.0071,
      "step": 8309
    },
    {
      "epoch": 84.37,
      "learning_rate": 4.732984846732755e-05,
      "loss": 0.0001,
      "step": 8310
    },
    {
      "epoch": 84.38,
      "learning_rate": 4.731799249688978e-05,
      "loss": 0.0018,
      "step": 8311
    },
    {
      "epoch": 84.39,
      "learning_rate": 4.730613667768273e-05,
      "loss": 0.0013,
      "step": 8312
    },
    {
      "epoch": 84.4,
      "learning_rate": 4.729428101037493e-05,
      "loss": 0.0075,
      "step": 8313
    },
    {
      "epoch": 84.41,
      "learning_rate": 4.728242549563488e-05,
      "loss": 0.0005,
      "step": 8314
    },
    {
      "epoch": 84.42,
      "learning_rate": 4.727057013413107e-05,
      "loss": 0.006,
      "step": 8315
    },
    {
      "epoch": 84.43,
      "learning_rate": 4.725871492653199e-05,
      "loss": 0.0001,
      "step": 8316
    },
    {
      "epoch": 84.44,
      "learning_rate": 4.724685987350616e-05,
      "loss": 0.0001,
      "step": 8317
    },
    {
      "epoch": 84.45,
      "learning_rate": 4.723500497572201e-05,
      "loss": 0.0012,
      "step": 8318
    },
    {
      "epoch": 84.46,
      "learning_rate": 4.7223150233848025e-05,
      "loss": 0.001,
      "step": 8319
    },
    {
      "epoch": 84.47,
      "learning_rate": 4.721129564855264e-05,
      "loss": 0.0002,
      "step": 8320
    },
    {
      "epoch": 84.48,
      "learning_rate": 4.7199441220504306e-05,
      "loss": 0.0,
      "step": 8321
    },
    {
      "epoch": 84.49,
      "learning_rate": 4.718758695037149e-05,
      "loss": 0.0003,
      "step": 8322
    },
    {
      "epoch": 84.5,
      "learning_rate": 4.717573283882257e-05,
      "loss": 0.0016,
      "step": 8323
    },
    {
      "epoch": 84.51,
      "learning_rate": 4.716387888652601e-05,
      "loss": 0.0015,
      "step": 8324
    },
    {
      "epoch": 84.52,
      "learning_rate": 4.715202509415021e-05,
      "loss": 0.0006,
      "step": 8325
    },
    {
      "epoch": 84.53,
      "learning_rate": 4.714017146236356e-05,
      "loss": 0.0002,
      "step": 8326
    },
    {
      "epoch": 84.54,
      "learning_rate": 4.7128317991834463e-05,
      "loss": 0.0001,
      "step": 8327
    },
    {
      "epoch": 84.55,
      "learning_rate": 4.711646468323129e-05,
      "loss": 0.0,
      "step": 8328
    },
    {
      "epoch": 84.56,
      "learning_rate": 4.7104611537222407e-05,
      "loss": 0.0003,
      "step": 8329
    },
    {
      "epoch": 84.57,
      "learning_rate": 4.709275855447621e-05,
      "loss": 0.0001,
      "step": 8330
    },
    {
      "epoch": 84.58,
      "learning_rate": 4.708090573566104e-05,
      "loss": 0.0003,
      "step": 8331
    },
    {
      "epoch": 84.59,
      "learning_rate": 4.706905308144524e-05,
      "loss": 0.0001,
      "step": 8332
    },
    {
      "epoch": 84.6,
      "learning_rate": 4.7057200592497155e-05,
      "loss": 0.0001,
      "step": 8333
    },
    {
      "epoch": 84.61,
      "learning_rate": 4.70453482694851e-05,
      "loss": 0.0004,
      "step": 8334
    },
    {
      "epoch": 84.62,
      "learning_rate": 4.7033496113077406e-05,
      "loss": 0.0005,
      "step": 8335
    },
    {
      "epoch": 84.63,
      "learning_rate": 4.702164412394236e-05,
      "loss": 0.0005,
      "step": 8336
    },
    {
      "epoch": 84.64,
      "learning_rate": 4.700979230274829e-05,
      "loss": 0.0,
      "step": 8337
    },
    {
      "epoch": 84.65,
      "learning_rate": 4.6997940650163485e-05,
      "loss": 0.0002,
      "step": 8338
    },
    {
      "epoch": 84.66,
      "learning_rate": 4.6986089166856204e-05,
      "loss": 0.0002,
      "step": 8339
    },
    {
      "epoch": 84.67,
      "learning_rate": 4.697423785349475e-05,
      "loss": 0.0029,
      "step": 8340
    },
    {
      "epoch": 84.68,
      "learning_rate": 4.696238671074734e-05,
      "loss": 0.0002,
      "step": 8341
    },
    {
      "epoch": 84.69,
      "learning_rate": 4.6950535739282245e-05,
      "loss": 0.0019,
      "step": 8342
    },
    {
      "epoch": 84.7,
      "learning_rate": 4.693868493976775e-05,
      "loss": 0.0002,
      "step": 8343
    },
    {
      "epoch": 84.71,
      "learning_rate": 4.692683431287202e-05,
      "loss": 0.007,
      "step": 8344
    },
    {
      "epoch": 84.72,
      "learning_rate": 4.691498385926332e-05,
      "loss": 0.0001,
      "step": 8345
    },
    {
      "epoch": 84.73,
      "learning_rate": 4.690313357960985e-05,
      "loss": 0.0001,
      "step": 8346
    },
    {
      "epoch": 84.74,
      "learning_rate": 4.689128347457982e-05,
      "loss": 0.0066,
      "step": 8347
    },
    {
      "epoch": 84.75,
      "learning_rate": 4.687943354484142e-05,
      "loss": 0.0004,
      "step": 8348
    },
    {
      "epoch": 84.76,
      "learning_rate": 4.686758379106283e-05,
      "loss": 0.0002,
      "step": 8349
    },
    {
      "epoch": 84.77,
      "learning_rate": 4.685573421391221e-05,
      "loss": 0.0005,
      "step": 8350
    },
    {
      "epoch": 84.78,
      "learning_rate": 4.684388481405776e-05,
      "loss": 0.0002,
      "step": 8351
    },
    {
      "epoch": 84.79,
      "learning_rate": 4.683203559216761e-05,
      "loss": 0.0,
      "step": 8352
    },
    {
      "epoch": 84.8,
      "learning_rate": 4.68201865489099e-05,
      "loss": 0.0002,
      "step": 8353
    },
    {
      "epoch": 84.81,
      "learning_rate": 4.6808337684952784e-05,
      "loss": 0.0004,
      "step": 8354
    },
    {
      "epoch": 84.82,
      "learning_rate": 4.679648900096436e-05,
      "loss": 0.0001,
      "step": 8355
    },
    {
      "epoch": 84.83,
      "learning_rate": 4.678464049761277e-05,
      "loss": 0.0001,
      "step": 8356
    },
    {
      "epoch": 84.84,
      "learning_rate": 4.6772792175566076e-05,
      "loss": 0.0002,
      "step": 8357
    },
    {
      "epoch": 84.85,
      "learning_rate": 4.6760944035492404e-05,
      "loss": 0.0086,
      "step": 8358
    },
    {
      "epoch": 84.86,
      "learning_rate": 4.6749096078059844e-05,
      "loss": 0.0008,
      "step": 8359
    },
    {
      "epoch": 84.87,
      "learning_rate": 4.673724830393644e-05,
      "loss": 0.0014,
      "step": 8360
    },
    {
      "epoch": 84.88,
      "learning_rate": 4.672540071379027e-05,
      "loss": 0.0002,
      "step": 8361
    },
    {
      "epoch": 84.89,
      "learning_rate": 4.6713553308289395e-05,
      "loss": 0.0004,
      "step": 8362
    },
    {
      "epoch": 84.9,
      "learning_rate": 4.6701706088101825e-05,
      "loss": 0.0003,
      "step": 8363
    },
    {
      "epoch": 84.91,
      "learning_rate": 4.668985905389563e-05,
      "loss": 0.0003,
      "step": 8364
    },
    {
      "epoch": 84.92,
      "learning_rate": 4.6678012206338793e-05,
      "loss": 0.0,
      "step": 8365
    },
    {
      "epoch": 84.93,
      "learning_rate": 4.666616554609935e-05,
      "loss": 0.0017,
      "step": 8366
    },
    {
      "epoch": 84.94,
      "learning_rate": 4.66543190738453e-05,
      "loss": 0.0027,
      "step": 8367
    },
    {
      "epoch": 84.95,
      "learning_rate": 4.664247279024461e-05,
      "loss": 0.0004,
      "step": 8368
    },
    {
      "epoch": 84.96,
      "learning_rate": 4.663062669596528e-05,
      "loss": 0.0,
      "step": 8369
    },
    {
      "epoch": 84.97,
      "learning_rate": 4.6618780791675265e-05,
      "loss": 0.0,
      "step": 8370
    },
    {
      "epoch": 84.98,
      "learning_rate": 4.660693507804251e-05,
      "loss": 0.0031,
      "step": 8371
    },
    {
      "epoch": 84.99,
      "learning_rate": 4.6595089555735e-05,
      "loss": 0.0011,
      "step": 8372
    },
    {
      "epoch": 84.99,
      "eval_loss": 0.020176485180854797,
      "eval_runtime": 31.9261,
      "eval_samples_per_second": 98.665,
      "eval_steps_per_second": 6.171,
      "eval_wer": 0.004545454545454545,
      "step": 8372
    },
    {
      "epoch": 85.01,
      "learning_rate": 4.658324422542063e-05,
      "loss": 0.0,
      "step": 8373
    },
    {
      "epoch": 85.02,
      "learning_rate": 4.657139908776735e-05,
      "loss": 0.0001,
      "step": 8374
    },
    {
      "epoch": 85.03,
      "learning_rate": 4.6559554143443066e-05,
      "loss": 0.0001,
      "step": 8375
    },
    {
      "epoch": 85.04,
      "learning_rate": 4.654770939311568e-05,
      "loss": 0.0005,
      "step": 8376
    },
    {
      "epoch": 85.05,
      "learning_rate": 4.6535864837453084e-05,
      "loss": 0.0009,
      "step": 8377
    },
    {
      "epoch": 85.06,
      "learning_rate": 4.6524020477123134e-05,
      "loss": 0.0035,
      "step": 8378
    },
    {
      "epoch": 85.07,
      "learning_rate": 4.6512176312793736e-05,
      "loss": 0.0003,
      "step": 8379
    },
    {
      "epoch": 85.08,
      "learning_rate": 4.650033234513275e-05,
      "loss": 0.0043,
      "step": 8380
    },
    {
      "epoch": 85.09,
      "learning_rate": 4.6488488574807984e-05,
      "loss": 0.0,
      "step": 8381
    },
    {
      "epoch": 85.1,
      "learning_rate": 4.64766450024873e-05,
      "loss": 0.0041,
      "step": 8382
    },
    {
      "epoch": 85.11,
      "learning_rate": 4.646480162883855e-05,
      "loss": 0.0008,
      "step": 8383
    },
    {
      "epoch": 85.12,
      "learning_rate": 4.645295845452949e-05,
      "loss": 0.0,
      "step": 8384
    },
    {
      "epoch": 85.13,
      "learning_rate": 4.644111548022798e-05,
      "loss": 0.0015,
      "step": 8385
    },
    {
      "epoch": 85.14,
      "learning_rate": 4.642927270660176e-05,
      "loss": 0.0001,
      "step": 8386
    },
    {
      "epoch": 85.15,
      "learning_rate": 4.641743013431864e-05,
      "loss": 0.0003,
      "step": 8387
    },
    {
      "epoch": 85.16,
      "learning_rate": 4.640558776404639e-05,
      "loss": 0.0052,
      "step": 8388
    },
    {
      "epoch": 85.17,
      "learning_rate": 4.639374559645275e-05,
      "loss": 0.0,
      "step": 8389
    },
    {
      "epoch": 85.18,
      "learning_rate": 4.638190363220547e-05,
      "loss": 0.0016,
      "step": 8390
    },
    {
      "epoch": 85.19,
      "learning_rate": 4.6370061871972326e-05,
      "loss": 0.0095,
      "step": 8391
    },
    {
      "epoch": 85.2,
      "learning_rate": 4.635822031642096e-05,
      "loss": 0.0,
      "step": 8392
    },
    {
      "epoch": 85.21,
      "learning_rate": 4.6346378966219164e-05,
      "loss": 0.0018,
      "step": 8393
    },
    {
      "epoch": 85.22,
      "learning_rate": 4.633453782203458e-05,
      "loss": 0.0,
      "step": 8394
    },
    {
      "epoch": 85.23,
      "learning_rate": 4.632269688453493e-05,
      "loss": 0.0012,
      "step": 8395
    },
    {
      "epoch": 85.24,
      "learning_rate": 4.6310856154387886e-05,
      "loss": 0.0001,
      "step": 8396
    },
    {
      "epoch": 85.25,
      "learning_rate": 4.629901563226109e-05,
      "loss": 0.0004,
      "step": 8397
    },
    {
      "epoch": 85.26,
      "learning_rate": 4.628717531882222e-05,
      "loss": 0.0002,
      "step": 8398
    },
    {
      "epoch": 85.27,
      "learning_rate": 4.6275335214738915e-05,
      "loss": 0.0003,
      "step": 8399
    },
    {
      "epoch": 85.28,
      "learning_rate": 4.626349532067879e-05,
      "loss": 0.0013,
      "step": 8400
    },
    {
      "epoch": 85.29,
      "learning_rate": 4.625165563730948e-05,
      "loss": 0.0008,
      "step": 8401
    },
    {
      "epoch": 85.3,
      "learning_rate": 4.6239816165298576e-05,
      "loss": 0.0002,
      "step": 8402
    },
    {
      "epoch": 85.31,
      "learning_rate": 4.6227976905313665e-05,
      "loss": 0.0047,
      "step": 8403
    },
    {
      "epoch": 85.32,
      "learning_rate": 4.621613785802238e-05,
      "loss": 0.0014,
      "step": 8404
    },
    {
      "epoch": 85.33,
      "learning_rate": 4.620429902409221e-05,
      "loss": 0.0004,
      "step": 8405
    },
    {
      "epoch": 85.34,
      "learning_rate": 4.619246040419079e-05,
      "loss": 0.0002,
      "step": 8406
    },
    {
      "epoch": 85.35,
      "learning_rate": 4.618062199898561e-05,
      "loss": 0.0027,
      "step": 8407
    },
    {
      "epoch": 85.36,
      "learning_rate": 4.616878380914423e-05,
      "loss": 0.0001,
      "step": 8408
    },
    {
      "epoch": 85.37,
      "learning_rate": 4.6156945835334184e-05,
      "loss": 0.0001,
      "step": 8409
    },
    {
      "epoch": 85.38,
      "learning_rate": 4.6145108078222945e-05,
      "loss": 0.0206,
      "step": 8410
    },
    {
      "epoch": 85.39,
      "learning_rate": 4.613327053847803e-05,
      "loss": 0.0025,
      "step": 8411
    },
    {
      "epoch": 85.4,
      "learning_rate": 4.612143321676694e-05,
      "loss": 0.0009,
      "step": 8412
    },
    {
      "epoch": 85.41,
      "learning_rate": 4.610959611375712e-05,
      "loss": 0.0013,
      "step": 8413
    },
    {
      "epoch": 85.42,
      "learning_rate": 4.6097759230116055e-05,
      "loss": 0.0017,
      "step": 8414
    },
    {
      "epoch": 85.43,
      "learning_rate": 4.608592256651117e-05,
      "loss": 0.0002,
      "step": 8415
    },
    {
      "epoch": 85.44,
      "learning_rate": 4.6074086123609905e-05,
      "loss": 0.0001,
      "step": 8416
    },
    {
      "epoch": 85.45,
      "learning_rate": 4.606224990207971e-05,
      "loss": 0.0,
      "step": 8417
    },
    {
      "epoch": 85.46,
      "learning_rate": 4.6050413902587945e-05,
      "loss": 0.0,
      "step": 8418
    },
    {
      "epoch": 85.47,
      "learning_rate": 4.603857812580205e-05,
      "loss": 0.0039,
      "step": 8419
    },
    {
      "epoch": 85.48,
      "learning_rate": 4.602674257238941e-05,
      "loss": 0.0014,
      "step": 8420
    },
    {
      "epoch": 85.49,
      "learning_rate": 4.601490724301738e-05,
      "loss": 0.0026,
      "step": 8421
    },
    {
      "epoch": 85.5,
      "learning_rate": 4.600307213835333e-05,
      "loss": 0.0001,
      "step": 8422
    },
    {
      "epoch": 85.51,
      "learning_rate": 4.59912372590646e-05,
      "loss": 0.0125,
      "step": 8423
    },
    {
      "epoch": 85.52,
      "learning_rate": 4.597940260581852e-05,
      "loss": 0.0108,
      "step": 8424
    },
    {
      "epoch": 85.53,
      "learning_rate": 4.596756817928245e-05,
      "loss": 0.0002,
      "step": 8425
    },
    {
      "epoch": 85.54,
      "learning_rate": 4.595573398012364e-05,
      "loss": 0.0032,
      "step": 8426
    },
    {
      "epoch": 85.55,
      "learning_rate": 4.594390000900942e-05,
      "loss": 0.0011,
      "step": 8427
    },
    {
      "epoch": 85.56,
      "learning_rate": 4.593206626660709e-05,
      "loss": 0.0236,
      "step": 8428
    },
    {
      "epoch": 85.57,
      "learning_rate": 4.592023275358389e-05,
      "loss": 0.0004,
      "step": 8429
    },
    {
      "epoch": 85.58,
      "learning_rate": 4.590839947060711e-05,
      "loss": 0.0119,
      "step": 8430
    },
    {
      "epoch": 85.59,
      "learning_rate": 4.589656641834396e-05,
      "loss": 0.0001,
      "step": 8431
    },
    {
      "epoch": 85.6,
      "learning_rate": 4.5884733597461664e-05,
      "loss": 0.0005,
      "step": 8432
    },
    {
      "epoch": 85.61,
      "learning_rate": 4.58729010086275e-05,
      "loss": 0.0024,
      "step": 8433
    },
    {
      "epoch": 85.62,
      "learning_rate": 4.586106865250862e-05,
      "loss": 0.0007,
      "step": 8434
    },
    {
      "epoch": 85.63,
      "learning_rate": 4.584923652977224e-05,
      "loss": 0.0004,
      "step": 8435
    },
    {
      "epoch": 85.64,
      "learning_rate": 4.583740464108554e-05,
      "loss": 0.0002,
      "step": 8436
    },
    {
      "epoch": 85.65,
      "learning_rate": 4.582557298711567e-05,
      "loss": 0.001,
      "step": 8437
    },
    {
      "epoch": 85.66,
      "learning_rate": 4.581374156852981e-05,
      "loss": 0.0001,
      "step": 8438
    },
    {
      "epoch": 85.68,
      "learning_rate": 4.5801910385995055e-05,
      "loss": 0.0001,
      "step": 8439
    },
    {
      "epoch": 85.69,
      "learning_rate": 4.579007944017858e-05,
      "loss": 0.0001,
      "step": 8440
    },
    {
      "epoch": 85.7,
      "learning_rate": 4.577824873174747e-05,
      "loss": 0.0003,
      "step": 8441
    },
    {
      "epoch": 85.71,
      "learning_rate": 4.576641826136884e-05,
      "loss": 0.0009,
      "step": 8442
    },
    {
      "epoch": 85.72,
      "learning_rate": 4.575458802970978e-05,
      "loss": 0.0005,
      "step": 8443
    },
    {
      "epoch": 85.73,
      "learning_rate": 4.5742758037437335e-05,
      "loss": 0.0005,
      "step": 8444
    },
    {
      "epoch": 85.74,
      "learning_rate": 4.5730928285218575e-05,
      "loss": 0.0008,
      "step": 8445
    },
    {
      "epoch": 85.75,
      "learning_rate": 4.571909877372058e-05,
      "loss": 0.0007,
      "step": 8446
    },
    {
      "epoch": 85.76,
      "learning_rate": 4.570726950361033e-05,
      "loss": 0.0002,
      "step": 8447
    },
    {
      "epoch": 85.77,
      "learning_rate": 4.569544047555487e-05,
      "loss": 0.0114,
      "step": 8448
    },
    {
      "epoch": 85.78,
      "learning_rate": 4.568361169022122e-05,
      "loss": 0.0023,
      "step": 8449
    },
    {
      "epoch": 85.79,
      "learning_rate": 4.567178314827634e-05,
      "loss": 0.0004,
      "step": 8450
    },
    {
      "epoch": 85.8,
      "learning_rate": 4.565995485038724e-05,
      "loss": 0.0001,
      "step": 8451
    },
    {
      "epoch": 85.81,
      "learning_rate": 4.5648126797220856e-05,
      "loss": 0.0005,
      "step": 8452
    },
    {
      "epoch": 85.82,
      "learning_rate": 4.5636298989444126e-05,
      "loss": 0.0001,
      "step": 8453
    },
    {
      "epoch": 85.83,
      "learning_rate": 4.562447142772404e-05,
      "loss": 0.0009,
      "step": 8454
    },
    {
      "epoch": 85.84,
      "learning_rate": 4.561264411272748e-05,
      "loss": 0.0008,
      "step": 8455
    },
    {
      "epoch": 85.85,
      "learning_rate": 4.5600817045121356e-05,
      "loss": 0.0005,
      "step": 8456
    },
    {
      "epoch": 85.86,
      "learning_rate": 4.5588990225572585e-05,
      "loss": 0.0001,
      "step": 8457
    },
    {
      "epoch": 85.87,
      "learning_rate": 4.5577163654748025e-05,
      "loss": 0.0001,
      "step": 8458
    },
    {
      "epoch": 85.88,
      "learning_rate": 4.5565337333314556e-05,
      "loss": 0.0005,
      "step": 8459
    },
    {
      "epoch": 85.89,
      "learning_rate": 4.5553511261939e-05,
      "loss": 0.0,
      "step": 8460
    },
    {
      "epoch": 85.9,
      "learning_rate": 4.554168544128824e-05,
      "loss": 0.002,
      "step": 8461
    },
    {
      "epoch": 85.91,
      "learning_rate": 4.5529859872029086e-05,
      "loss": 0.0003,
      "step": 8462
    },
    {
      "epoch": 85.92,
      "learning_rate": 4.551803455482833e-05,
      "loss": 0.0025,
      "step": 8463
    },
    {
      "epoch": 85.93,
      "learning_rate": 4.550620949035278e-05,
      "loss": 0.0,
      "step": 8464
    },
    {
      "epoch": 85.94,
      "learning_rate": 4.549438467926923e-05,
      "loss": 0.0036,
      "step": 8465
    },
    {
      "epoch": 85.95,
      "learning_rate": 4.548256012224441e-05,
      "loss": 0.0003,
      "step": 8466
    },
    {
      "epoch": 85.96,
      "learning_rate": 4.547073581994514e-05,
      "loss": 0.0001,
      "step": 8467
    },
    {
      "epoch": 85.97,
      "learning_rate": 4.545891177303807e-05,
      "loss": 0.0,
      "step": 8468
    },
    {
      "epoch": 85.98,
      "learning_rate": 4.544708798218998e-05,
      "loss": 0.0001,
      "step": 8469
    },
    {
      "epoch": 85.99,
      "learning_rate": 4.543526444806759e-05,
      "loss": 0.0004,
      "step": 8470
    },
    {
      "epoch": 86.0,
      "learning_rate": 4.542344117133757e-05,
      "loss": 0.0001,
      "step": 8471
    },
    {
      "epoch": 86.0,
      "eval_loss": 0.023822084069252014,
      "eval_runtime": 31.6801,
      "eval_samples_per_second": 99.432,
      "eval_steps_per_second": 6.218,
      "eval_wer": 0.0031690140845070424,
      "step": 8471
    },
    {
      "epoch": 86.01,
      "learning_rate": 4.541161815266658e-05,
      "loss": 0.0013,
      "step": 8472
    },
    {
      "epoch": 86.02,
      "learning_rate": 4.5399795392721356e-05,
      "loss": 0.0,
      "step": 8473
    },
    {
      "epoch": 86.03,
      "learning_rate": 4.538797289216847e-05,
      "loss": 0.0007,
      "step": 8474
    },
    {
      "epoch": 86.04,
      "learning_rate": 4.5376150651674614e-05,
      "loss": 0.001,
      "step": 8475
    },
    {
      "epoch": 86.05,
      "learning_rate": 4.5364328671906384e-05,
      "loss": 0.0001,
      "step": 8476
    },
    {
      "epoch": 86.06,
      "learning_rate": 4.535250695353039e-05,
      "loss": 0.0005,
      "step": 8477
    },
    {
      "epoch": 86.07,
      "learning_rate": 4.534068549721325e-05,
      "loss": 0.0001,
      "step": 8478
    },
    {
      "epoch": 86.08,
      "learning_rate": 4.53288643036215e-05,
      "loss": 0.0048,
      "step": 8479
    },
    {
      "epoch": 86.09,
      "learning_rate": 4.531704337342174e-05,
      "loss": 0.0032,
      "step": 8480
    },
    {
      "epoch": 86.1,
      "learning_rate": 4.530522270728048e-05,
      "loss": 0.0001,
      "step": 8481
    },
    {
      "epoch": 86.11,
      "learning_rate": 4.529340230586429e-05,
      "loss": 0.0001,
      "step": 8482
    },
    {
      "epoch": 86.12,
      "learning_rate": 4.528158216983969e-05,
      "loss": 0.0,
      "step": 8483
    },
    {
      "epoch": 86.13,
      "learning_rate": 4.526976229987315e-05,
      "loss": 0.0002,
      "step": 8484
    },
    {
      "epoch": 86.14,
      "learning_rate": 4.525794269663117e-05,
      "loss": 0.0001,
      "step": 8485
    },
    {
      "epoch": 86.15,
      "learning_rate": 4.5246123360780263e-05,
      "loss": 0.0001,
      "step": 8486
    },
    {
      "epoch": 86.16,
      "learning_rate": 4.523430429298683e-05,
      "loss": 0.0077,
      "step": 8487
    },
    {
      "epoch": 86.17,
      "learning_rate": 4.522248549391737e-05,
      "loss": 0.0043,
      "step": 8488
    },
    {
      "epoch": 86.18,
      "learning_rate": 4.521066696423824e-05,
      "loss": 0.0005,
      "step": 8489
    },
    {
      "epoch": 86.19,
      "learning_rate": 4.5198848704615914e-05,
      "loss": 0.001,
      "step": 8490
    },
    {
      "epoch": 86.2,
      "learning_rate": 4.518703071571678e-05,
      "loss": 0.0005,
      "step": 8491
    },
    {
      "epoch": 86.21,
      "learning_rate": 4.51752129982072e-05,
      "loss": 0.0,
      "step": 8492
    },
    {
      "epoch": 86.22,
      "learning_rate": 4.516339555275354e-05,
      "loss": 0.0,
      "step": 8493
    },
    {
      "epoch": 86.23,
      "learning_rate": 4.515157838002219e-05,
      "loss": 0.0,
      "step": 8494
    },
    {
      "epoch": 86.24,
      "learning_rate": 4.513976148067945e-05,
      "loss": 0.0002,
      "step": 8495
    },
    {
      "epoch": 86.25,
      "learning_rate": 4.512794485539166e-05,
      "loss": 0.0017,
      "step": 8496
    },
    {
      "epoch": 86.26,
      "learning_rate": 4.511612850482511e-05,
      "loss": 0.0061,
      "step": 8497
    },
    {
      "epoch": 86.27,
      "learning_rate": 4.510431242964609e-05,
      "loss": 0.0035,
      "step": 8498
    },
    {
      "epoch": 86.28,
      "learning_rate": 4.5092496630520895e-05,
      "loss": 0.0002,
      "step": 8499
    },
    {
      "epoch": 86.29,
      "learning_rate": 4.508068110811576e-05,
      "loss": 0.0056,
      "step": 8500
    },
    {
      "epoch": 86.3,
      "learning_rate": 4.506886586309694e-05,
      "loss": 0.0,
      "step": 8501
    },
    {
      "epoch": 86.31,
      "learning_rate": 4.505705089613068e-05,
      "loss": 0.0006,
      "step": 8502
    },
    {
      "epoch": 86.32,
      "learning_rate": 4.504523620788316e-05,
      "loss": 0.0005,
      "step": 8503
    },
    {
      "epoch": 86.34,
      "learning_rate": 4.503342179902061e-05,
      "loss": 0.0112,
      "step": 8504
    },
    {
      "epoch": 86.35,
      "learning_rate": 4.502160767020918e-05,
      "loss": 0.0004,
      "step": 8505
    },
    {
      "epoch": 86.36,
      "learning_rate": 4.5009793822115025e-05,
      "loss": 0.0014,
      "step": 8506
    },
    {
      "epoch": 86.37,
      "learning_rate": 4.499798025540436e-05,
      "loss": 0.0001,
      "step": 8507
    },
    {
      "epoch": 86.38,
      "learning_rate": 4.498616697074324e-05,
      "loss": 0.0001,
      "step": 8508
    },
    {
      "epoch": 86.39,
      "learning_rate": 4.497435396879783e-05,
      "loss": 0.0003,
      "step": 8509
    },
    {
      "epoch": 86.4,
      "learning_rate": 4.496254125023422e-05,
      "loss": 0.0045,
      "step": 8510
    },
    {
      "epoch": 86.41,
      "learning_rate": 4.495072881571849e-05,
      "loss": 0.0001,
      "step": 8511
    },
    {
      "epoch": 86.42,
      "learning_rate": 4.493891666591672e-05,
      "loss": 0.0003,
      "step": 8512
    },
    {
      "epoch": 86.43,
      "learning_rate": 4.492710480149495e-05,
      "loss": 0.0,
      "step": 8513
    },
    {
      "epoch": 86.44,
      "learning_rate": 4.4915293223119206e-05,
      "loss": 0.0001,
      "step": 8514
    },
    {
      "epoch": 86.45,
      "learning_rate": 4.490348193145556e-05,
      "loss": 0.0,
      "step": 8515
    },
    {
      "epoch": 86.46,
      "learning_rate": 4.489167092716996e-05,
      "loss": 0.0003,
      "step": 8516
    },
    {
      "epoch": 86.47,
      "learning_rate": 4.487986021092844e-05,
      "loss": 0.0,
      "step": 8517
    },
    {
      "epoch": 86.48,
      "learning_rate": 4.486804978339693e-05,
      "loss": 0.0006,
      "step": 8518
    },
    {
      "epoch": 86.49,
      "learning_rate": 4.4856239645241414e-05,
      "loss": 0.0001,
      "step": 8519
    },
    {
      "epoch": 86.5,
      "learning_rate": 4.484442979712783e-05,
      "loss": 0.0001,
      "step": 8520
    },
    {
      "epoch": 86.51,
      "learning_rate": 4.4832620239722084e-05,
      "loss": 0.0071,
      "step": 8521
    },
    {
      "epoch": 86.52,
      "learning_rate": 4.4820810973690106e-05,
      "loss": 0.0011,
      "step": 8522
    },
    {
      "epoch": 86.53,
      "learning_rate": 4.4809001999697775e-05,
      "loss": 0.0005,
      "step": 8523
    },
    {
      "epoch": 86.54,
      "learning_rate": 4.479719331841097e-05,
      "loss": 0.0019,
      "step": 8524
    },
    {
      "epoch": 86.55,
      "learning_rate": 4.4785384930495545e-05,
      "loss": 0.0004,
      "step": 8525
    },
    {
      "epoch": 86.56,
      "learning_rate": 4.477357683661734e-05,
      "loss": 0.0002,
      "step": 8526
    },
    {
      "epoch": 86.57,
      "learning_rate": 4.476176903744216e-05,
      "loss": 0.0001,
      "step": 8527
    },
    {
      "epoch": 86.58,
      "learning_rate": 4.4749961533635876e-05,
      "loss": 0.0002,
      "step": 8528
    },
    {
      "epoch": 86.59,
      "learning_rate": 4.47381543258642e-05,
      "loss": 0.0063,
      "step": 8529
    },
    {
      "epoch": 86.6,
      "learning_rate": 4.472634741479296e-05,
      "loss": 0.0001,
      "step": 8530
    },
    {
      "epoch": 86.61,
      "learning_rate": 4.47145408010879e-05,
      "loss": 0.0001,
      "step": 8531
    },
    {
      "epoch": 86.62,
      "learning_rate": 4.4702734485414756e-05,
      "loss": 0.0037,
      "step": 8532
    },
    {
      "epoch": 86.63,
      "learning_rate": 4.4690928468439265e-05,
      "loss": 0.0004,
      "step": 8533
    },
    {
      "epoch": 86.64,
      "learning_rate": 4.4679122750827105e-05,
      "loss": 0.0,
      "step": 8534
    },
    {
      "epoch": 86.65,
      "learning_rate": 4.466731733324399e-05,
      "loss": 0.0067,
      "step": 8535
    },
    {
      "epoch": 86.66,
      "learning_rate": 4.4655512216355605e-05,
      "loss": 0.0007,
      "step": 8536
    },
    {
      "epoch": 86.67,
      "learning_rate": 4.4643707400827585e-05,
      "loss": 0.001,
      "step": 8537
    },
    {
      "epoch": 86.68,
      "learning_rate": 4.4631902887325574e-05,
      "loss": 0.0001,
      "step": 8538
    },
    {
      "epoch": 86.69,
      "learning_rate": 4.462009867651521e-05,
      "loss": 0.0001,
      "step": 8539
    },
    {
      "epoch": 86.7,
      "learning_rate": 4.4608294769062075e-05,
      "loss": 0.0,
      "step": 8540
    },
    {
      "epoch": 86.71,
      "learning_rate": 4.4596491165631785e-05,
      "loss": 0.0001,
      "step": 8541
    },
    {
      "epoch": 86.72,
      "learning_rate": 4.4584687866889864e-05,
      "loss": 0.0003,
      "step": 8542
    },
    {
      "epoch": 86.73,
      "learning_rate": 4.457288487350191e-05,
      "loss": 0.0001,
      "step": 8543
    },
    {
      "epoch": 86.74,
      "learning_rate": 4.4561082186133464e-05,
      "loss": 0.0001,
      "step": 8544
    },
    {
      "epoch": 86.75,
      "learning_rate": 4.454927980545002e-05,
      "loss": 0.0009,
      "step": 8545
    },
    {
      "epoch": 86.76,
      "learning_rate": 4.4537477732117094e-05,
      "loss": 0.0001,
      "step": 8546
    },
    {
      "epoch": 86.77,
      "learning_rate": 4.4525675966800165e-05,
      "loss": 0.0004,
      "step": 8547
    },
    {
      "epoch": 86.78,
      "learning_rate": 4.451387451016468e-05,
      "loss": 0.0101,
      "step": 8548
    },
    {
      "epoch": 86.79,
      "learning_rate": 4.450207336287615e-05,
      "loss": 0.0002,
      "step": 8549
    },
    {
      "epoch": 86.8,
      "learning_rate": 4.449027252559994e-05,
      "loss": 0.0001,
      "step": 8550
    },
    {
      "epoch": 86.81,
      "learning_rate": 4.447847199900151e-05,
      "loss": 0.0002,
      "step": 8551
    },
    {
      "epoch": 86.82,
      "learning_rate": 4.446667178374624e-05,
      "loss": 0.0009,
      "step": 8552
    },
    {
      "epoch": 86.83,
      "learning_rate": 4.445487188049952e-05,
      "loss": 0.003,
      "step": 8553
    },
    {
      "epoch": 86.84,
      "learning_rate": 4.4443072289926704e-05,
      "loss": 0.0007,
      "step": 8554
    },
    {
      "epoch": 86.85,
      "learning_rate": 4.443127301269314e-05,
      "loss": 0.003,
      "step": 8555
    },
    {
      "epoch": 86.86,
      "learning_rate": 4.4419474049464135e-05,
      "loss": 0.007,
      "step": 8556
    },
    {
      "epoch": 86.87,
      "learning_rate": 4.4407675400905054e-05,
      "loss": 0.0,
      "step": 8557
    },
    {
      "epoch": 86.88,
      "learning_rate": 4.439587706768113e-05,
      "loss": 0.0008,
      "step": 8558
    },
    {
      "epoch": 86.89,
      "learning_rate": 4.438407905045767e-05,
      "loss": 0.0005,
      "step": 8559
    },
    {
      "epoch": 86.9,
      "learning_rate": 4.437228134989992e-05,
      "loss": 0.0035,
      "step": 8560
    },
    {
      "epoch": 86.91,
      "learning_rate": 4.436048396667312e-05,
      "loss": 0.0001,
      "step": 8561
    },
    {
      "epoch": 86.92,
      "learning_rate": 4.43486869014425e-05,
      "loss": 0.0027,
      "step": 8562
    },
    {
      "epoch": 86.93,
      "learning_rate": 4.433689015487324e-05,
      "loss": 0.0,
      "step": 8563
    },
    {
      "epoch": 86.94,
      "learning_rate": 4.4325093727630536e-05,
      "loss": 0.0,
      "step": 8564
    },
    {
      "epoch": 86.95,
      "learning_rate": 4.4313297620379575e-05,
      "loss": 0.0002,
      "step": 8565
    },
    {
      "epoch": 86.96,
      "learning_rate": 4.430150183378547e-05,
      "loss": 0.004,
      "step": 8566
    },
    {
      "epoch": 86.97,
      "learning_rate": 4.4289706368513366e-05,
      "loss": 0.0016,
      "step": 8567
    },
    {
      "epoch": 86.98,
      "learning_rate": 4.4277911225228414e-05,
      "loss": 0.0001,
      "step": 8568
    },
    {
      "epoch": 86.99,
      "learning_rate": 4.426611640459564e-05,
      "loss": 0.0,
      "step": 8569
    },
    {
      "epoch": 86.99,
      "eval_loss": 0.01834523119032383,
      "eval_runtime": 31.7477,
      "eval_samples_per_second": 99.22,
      "eval_steps_per_second": 6.205,
      "eval_wer": 0.0031690140845070424,
      "step": 8569
    },
    {
      "epoch": 87.01,
      "learning_rate": 4.4254321907280176e-05,
      "loss": 0.0294,
      "step": 8570
    },
    {
      "epoch": 87.02,
      "learning_rate": 4.424252773394704e-05,
      "loss": 0.0,
      "step": 8571
    },
    {
      "epoch": 87.03,
      "learning_rate": 4.4230733885261286e-05,
      "loss": 0.0039,
      "step": 8572
    },
    {
      "epoch": 87.04,
      "learning_rate": 4.421894036188796e-05,
      "loss": 0.001,
      "step": 8573
    },
    {
      "epoch": 87.05,
      "learning_rate": 4.420714716449203e-05,
      "loss": 0.0001,
      "step": 8574
    },
    {
      "epoch": 87.06,
      "learning_rate": 4.4195354293738484e-05,
      "loss": 0.0001,
      "step": 8575
    },
    {
      "epoch": 87.07,
      "learning_rate": 4.418356175029233e-05,
      "loss": 0.0003,
      "step": 8576
    },
    {
      "epoch": 87.08,
      "learning_rate": 4.417176953481845e-05,
      "loss": 0.0001,
      "step": 8577
    },
    {
      "epoch": 87.09,
      "learning_rate": 4.415997764798183e-05,
      "loss": 0.0011,
      "step": 8578
    },
    {
      "epoch": 87.1,
      "learning_rate": 4.414818609044735e-05,
      "loss": 0.0,
      "step": 8579
    },
    {
      "epoch": 87.11,
      "learning_rate": 4.4136394862879914e-05,
      "loss": 0.0102,
      "step": 8580
    },
    {
      "epoch": 87.12,
      "learning_rate": 4.41246039659444e-05,
      "loss": 0.0002,
      "step": 8581
    },
    {
      "epoch": 87.13,
      "learning_rate": 4.411281340030563e-05,
      "loss": 0.0016,
      "step": 8582
    },
    {
      "epoch": 87.14,
      "learning_rate": 4.4101023166628504e-05,
      "loss": 0.0,
      "step": 8583
    },
    {
      "epoch": 87.15,
      "learning_rate": 4.408923326557777e-05,
      "loss": 0.017,
      "step": 8584
    },
    {
      "epoch": 87.16,
      "learning_rate": 4.407744369781826e-05,
      "loss": 0.0001,
      "step": 8585
    },
    {
      "epoch": 87.17,
      "learning_rate": 4.406565446401477e-05,
      "loss": 0.0,
      "step": 8586
    },
    {
      "epoch": 87.18,
      "learning_rate": 4.405386556483203e-05,
      "loss": 0.0001,
      "step": 8587
    },
    {
      "epoch": 87.19,
      "learning_rate": 4.404207700093478e-05,
      "loss": 0.0,
      "step": 8588
    },
    {
      "epoch": 87.2,
      "learning_rate": 4.403028877298779e-05,
      "loss": 0.0004,
      "step": 8589
    },
    {
      "epoch": 87.21,
      "learning_rate": 4.401850088165571e-05,
      "loss": 0.0,
      "step": 8590
    },
    {
      "epoch": 87.22,
      "learning_rate": 4.4006713327603276e-05,
      "loss": 0.0,
      "step": 8591
    },
    {
      "epoch": 87.23,
      "learning_rate": 4.3994926111495095e-05,
      "loss": 0.0021,
      "step": 8592
    },
    {
      "epoch": 87.24,
      "learning_rate": 4.3983139233995856e-05,
      "loss": 0.0044,
      "step": 8593
    },
    {
      "epoch": 87.25,
      "learning_rate": 4.3971352695770196e-05,
      "loss": 0.0001,
      "step": 8594
    },
    {
      "epoch": 87.26,
      "learning_rate": 4.395956649748268e-05,
      "loss": 0.0,
      "step": 8595
    },
    {
      "epoch": 87.27,
      "learning_rate": 4.3947780639797926e-05,
      "loss": 0.0043,
      "step": 8596
    },
    {
      "epoch": 87.28,
      "learning_rate": 4.393599512338052e-05,
      "loss": 0.0,
      "step": 8597
    },
    {
      "epoch": 87.29,
      "learning_rate": 4.392420994889498e-05,
      "loss": 0.0001,
      "step": 8598
    },
    {
      "epoch": 87.3,
      "learning_rate": 4.391242511700588e-05,
      "loss": 0.0029,
      "step": 8599
    },
    {
      "epoch": 87.31,
      "learning_rate": 4.390064062837769e-05,
      "loss": 0.0004,
      "step": 8600
    },
    {
      "epoch": 87.32,
      "learning_rate": 4.3888856483674914e-05,
      "loss": 0.0001,
      "step": 8601
    },
    {
      "epoch": 87.33,
      "learning_rate": 4.387707268356205e-05,
      "loss": 0.0066,
      "step": 8602
    },
    {
      "epoch": 87.34,
      "learning_rate": 4.386528922870351e-05,
      "loss": 0.0015,
      "step": 8603
    },
    {
      "epoch": 87.35,
      "learning_rate": 4.385350611976376e-05,
      "loss": 0.0192,
      "step": 8604
    },
    {
      "epoch": 87.36,
      "learning_rate": 4.384172335740724e-05,
      "loss": 0.0001,
      "step": 8605
    },
    {
      "epoch": 87.37,
      "learning_rate": 4.38299409422983e-05,
      "loss": 0.0001,
      "step": 8606
    },
    {
      "epoch": 87.38,
      "learning_rate": 4.3818158875101334e-05,
      "loss": 0.0016,
      "step": 8607
    },
    {
      "epoch": 87.39,
      "learning_rate": 4.38063771564807e-05,
      "loss": 0.0002,
      "step": 8608
    },
    {
      "epoch": 87.4,
      "learning_rate": 4.379459578710072e-05,
      "loss": 0.0,
      "step": 8609
    },
    {
      "epoch": 87.41,
      "learning_rate": 4.378281476762576e-05,
      "loss": 0.0001,
      "step": 8610
    },
    {
      "epoch": 87.42,
      "learning_rate": 4.377103409872004e-05,
      "loss": 0.0113,
      "step": 8611
    },
    {
      "epoch": 87.43,
      "learning_rate": 4.3759253781047906e-05,
      "loss": 0.0,
      "step": 8612
    },
    {
      "epoch": 87.44,
      "learning_rate": 4.3747473815273596e-05,
      "loss": 0.0027,
      "step": 8613
    },
    {
      "epoch": 87.45,
      "learning_rate": 4.373569420206134e-05,
      "loss": 0.0001,
      "step": 8614
    },
    {
      "epoch": 87.46,
      "learning_rate": 4.372391494207537e-05,
      "loss": 0.0002,
      "step": 8615
    },
    {
      "epoch": 87.47,
      "learning_rate": 4.3712136035979876e-05,
      "loss": 0.0001,
      "step": 8616
    },
    {
      "epoch": 87.48,
      "learning_rate": 4.3700357484439015e-05,
      "loss": 0.0006,
      "step": 8617
    },
    {
      "epoch": 87.49,
      "learning_rate": 4.368857928811699e-05,
      "loss": 0.0001,
      "step": 8618
    },
    {
      "epoch": 87.5,
      "learning_rate": 4.367680144767791e-05,
      "loss": 0.0015,
      "step": 8619
    },
    {
      "epoch": 87.51,
      "learning_rate": 4.3665023963785915e-05,
      "loss": 0.0001,
      "step": 8620
    },
    {
      "epoch": 87.52,
      "learning_rate": 4.365324683710508e-05,
      "loss": 0.0004,
      "step": 8621
    },
    {
      "epoch": 87.53,
      "learning_rate": 4.364147006829949e-05,
      "loss": 0.0028,
      "step": 8622
    },
    {
      "epoch": 87.54,
      "learning_rate": 4.362969365803321e-05,
      "loss": 0.005,
      "step": 8623
    },
    {
      "epoch": 87.55,
      "learning_rate": 4.361791760697027e-05,
      "loss": 0.0012,
      "step": 8624
    },
    {
      "epoch": 87.56,
      "learning_rate": 4.3606141915774693e-05,
      "loss": 0.0014,
      "step": 8625
    },
    {
      "epoch": 87.57,
      "learning_rate": 4.3594366585110496e-05,
      "loss": 0.0005,
      "step": 8626
    },
    {
      "epoch": 87.58,
      "learning_rate": 4.358259161564162e-05,
      "loss": 0.0101,
      "step": 8627
    },
    {
      "epoch": 87.59,
      "learning_rate": 4.357081700803205e-05,
      "loss": 0.001,
      "step": 8628
    },
    {
      "epoch": 87.6,
      "learning_rate": 4.35590427629457e-05,
      "loss": 0.0002,
      "step": 8629
    },
    {
      "epoch": 87.61,
      "learning_rate": 4.3547268881046485e-05,
      "loss": 0.0001,
      "step": 8630
    },
    {
      "epoch": 87.62,
      "learning_rate": 4.353549536299835e-05,
      "loss": 0.0039,
      "step": 8631
    },
    {
      "epoch": 87.63,
      "learning_rate": 4.35237222094651e-05,
      "loss": 0.0004,
      "step": 8632
    },
    {
      "epoch": 87.64,
      "learning_rate": 4.351194942111063e-05,
      "loss": 0.0059,
      "step": 8633
    },
    {
      "epoch": 87.65,
      "learning_rate": 4.3500176998598775e-05,
      "loss": 0.0005,
      "step": 8634
    },
    {
      "epoch": 87.66,
      "learning_rate": 4.3488404942593334e-05,
      "loss": 0.0005,
      "step": 8635
    },
    {
      "epoch": 87.68,
      "learning_rate": 4.347663325375811e-05,
      "loss": 0.0014,
      "step": 8636
    },
    {
      "epoch": 87.69,
      "learning_rate": 4.346486193275686e-05,
      "loss": 0.0078,
      "step": 8637
    },
    {
      "epoch": 87.7,
      "learning_rate": 4.345309098025333e-05,
      "loss": 0.0001,
      "step": 8638
    },
    {
      "epoch": 87.71,
      "learning_rate": 4.344132039691129e-05,
      "loss": 0.0009,
      "step": 8639
    },
    {
      "epoch": 87.72,
      "learning_rate": 4.3429550183394415e-05,
      "loss": 0.0,
      "step": 8640
    },
    {
      "epoch": 87.73,
      "learning_rate": 4.34177803403664e-05,
      "loss": 0.0161,
      "step": 8641
    },
    {
      "epoch": 87.74,
      "learning_rate": 4.340601086849093e-05,
      "loss": 0.0,
      "step": 8642
    },
    {
      "epoch": 87.75,
      "learning_rate": 4.3394241768431635e-05,
      "loss": 0.0001,
      "step": 8643
    },
    {
      "epoch": 87.76,
      "learning_rate": 4.338247304085214e-05,
      "loss": 0.0024,
      "step": 8644
    },
    {
      "epoch": 87.77,
      "learning_rate": 4.337070468641604e-05,
      "loss": 0.0,
      "step": 8645
    },
    {
      "epoch": 87.78,
      "learning_rate": 4.335893670578694e-05,
      "loss": 0.0,
      "step": 8646
    },
    {
      "epoch": 87.79,
      "learning_rate": 4.334716909962841e-05,
      "loss": 0.0001,
      "step": 8647
    },
    {
      "epoch": 87.8,
      "learning_rate": 4.333540186860395e-05,
      "loss": 0.0,
      "step": 8648
    },
    {
      "epoch": 87.81,
      "learning_rate": 4.3323635013377126e-05,
      "loss": 0.0,
      "step": 8649
    },
    {
      "epoch": 87.82,
      "learning_rate": 4.3311868534611425e-05,
      "loss": 0.0006,
      "step": 8650
    },
    {
      "epoch": 87.83,
      "learning_rate": 4.330010243297029e-05,
      "loss": 0.0058,
      "step": 8651
    },
    {
      "epoch": 87.84,
      "learning_rate": 4.328833670911724e-05,
      "loss": 0.001,
      "step": 8652
    },
    {
      "epoch": 87.85,
      "learning_rate": 4.327657136371565e-05,
      "loss": 0.0056,
      "step": 8653
    },
    {
      "epoch": 87.86,
      "learning_rate": 4.326480639742897e-05,
      "loss": 0.0,
      "step": 8654
    },
    {
      "epoch": 87.87,
      "learning_rate": 4.325304181092059e-05,
      "loss": 0.0123,
      "step": 8655
    },
    {
      "epoch": 87.88,
      "learning_rate": 4.324127760485387e-05,
      "loss": 0.0003,
      "step": 8656
    },
    {
      "epoch": 87.89,
      "learning_rate": 4.3229513779892175e-05,
      "loss": 0.0003,
      "step": 8657
    },
    {
      "epoch": 87.9,
      "learning_rate": 4.321775033669881e-05,
      "loss": 0.0001,
      "step": 8658
    },
    {
      "epoch": 87.91,
      "learning_rate": 4.320598727593709e-05,
      "loss": 0.0023,
      "step": 8659
    },
    {
      "epoch": 87.92,
      "learning_rate": 4.3194224598270314e-05,
      "loss": 0.0001,
      "step": 8660
    },
    {
      "epoch": 87.93,
      "learning_rate": 4.318246230436174e-05,
      "loss": 0.0012,
      "step": 8661
    },
    {
      "epoch": 87.94,
      "learning_rate": 4.31707003948746e-05,
      "loss": 0.0001,
      "step": 8662
    },
    {
      "epoch": 87.95,
      "learning_rate": 4.315893887047214e-05,
      "loss": 0.0001,
      "step": 8663
    },
    {
      "epoch": 87.96,
      "learning_rate": 4.314717773181752e-05,
      "loss": 0.0034,
      "step": 8664
    },
    {
      "epoch": 87.97,
      "learning_rate": 4.3135416979573957e-05,
      "loss": 0.0052,
      "step": 8665
    },
    {
      "epoch": 87.98,
      "learning_rate": 4.312365661440456e-05,
      "loss": 0.002,
      "step": 8666
    },
    {
      "epoch": 87.99,
      "learning_rate": 4.31118966369725e-05,
      "loss": 0.0003,
      "step": 8667
    },
    {
      "epoch": 88.0,
      "learning_rate": 4.31001370479409e-05,
      "loss": 0.0,
      "step": 8668
    },
    {
      "epoch": 88.0,
      "eval_loss": 0.023090897127985954,
      "eval_runtime": 33.0176,
      "eval_samples_per_second": 95.404,
      "eval_steps_per_second": 5.967,
      "eval_wer": 0.004193341869398208,
      "step": 8668
    },
    {
      "epoch": 88.01,
      "learning_rate": 4.3088377847972804e-05,
      "loss": 0.0001,
      "step": 8669
    },
    {
      "epoch": 88.02,
      "learning_rate": 4.307661903773129e-05,
      "loss": 0.0136,
      "step": 8670
    },
    {
      "epoch": 88.03,
      "learning_rate": 4.306486061787945e-05,
      "loss": 0.0167,
      "step": 8671
    },
    {
      "epoch": 88.04,
      "learning_rate": 4.305310258908025e-05,
      "loss": 0.0,
      "step": 8672
    },
    {
      "epoch": 88.05,
      "learning_rate": 4.3041344951996746e-05,
      "loss": 0.0009,
      "step": 8673
    },
    {
      "epoch": 88.06,
      "learning_rate": 4.3029587707291854e-05,
      "loss": 0.0006,
      "step": 8674
    },
    {
      "epoch": 88.07,
      "learning_rate": 4.301783085562857e-05,
      "loss": 0.0003,
      "step": 8675
    },
    {
      "epoch": 88.08,
      "learning_rate": 4.3006074397669836e-05,
      "loss": 0.0033,
      "step": 8676
    },
    {
      "epoch": 88.09,
      "learning_rate": 4.299431833407855e-05,
      "loss": 0.0003,
      "step": 8677
    },
    {
      "epoch": 88.1,
      "learning_rate": 4.298256266551758e-05,
      "loss": 0.0051,
      "step": 8678
    },
    {
      "epoch": 88.11,
      "learning_rate": 4.297080739264987e-05,
      "loss": 0.0001,
      "step": 8679
    },
    {
      "epoch": 88.12,
      "learning_rate": 4.295905251613817e-05,
      "loss": 0.0001,
      "step": 8680
    },
    {
      "epoch": 88.13,
      "learning_rate": 4.294729803664538e-05,
      "loss": 0.0003,
      "step": 8681
    },
    {
      "epoch": 88.14,
      "learning_rate": 4.2935543954834255e-05,
      "loss": 0.0001,
      "step": 8682
    },
    {
      "epoch": 88.15,
      "learning_rate": 4.29237902713676e-05,
      "loss": 0.0001,
      "step": 8683
    },
    {
      "epoch": 88.16,
      "learning_rate": 4.2912036986908164e-05,
      "loss": 0.0002,
      "step": 8684
    },
    {
      "epoch": 88.17,
      "learning_rate": 4.290028410211866e-05,
      "loss": 0.0067,
      "step": 8685
    },
    {
      "epoch": 88.18,
      "learning_rate": 4.288853161766183e-05,
      "loss": 0.0081,
      "step": 8686
    },
    {
      "epoch": 88.19,
      "learning_rate": 4.287677953420036e-05,
      "loss": 0.0019,
      "step": 8687
    },
    {
      "epoch": 88.2,
      "learning_rate": 4.28650278523969e-05,
      "loss": 0.0001,
      "step": 8688
    },
    {
      "epoch": 88.21,
      "learning_rate": 4.285327657291411e-05,
      "loss": 0.0045,
      "step": 8689
    },
    {
      "epoch": 88.22,
      "learning_rate": 4.28415256964146e-05,
      "loss": 0.0061,
      "step": 8690
    },
    {
      "epoch": 88.23,
      "learning_rate": 4.2829775223560956e-05,
      "loss": 0.0004,
      "step": 8691
    },
    {
      "epoch": 88.24,
      "learning_rate": 4.2818025155015795e-05,
      "loss": 0.0005,
      "step": 8692
    },
    {
      "epoch": 88.25,
      "learning_rate": 4.280627549144161e-05,
      "loss": 0.0014,
      "step": 8693
    },
    {
      "epoch": 88.26,
      "learning_rate": 4.2794526233501006e-05,
      "loss": 0.0002,
      "step": 8694
    },
    {
      "epoch": 88.27,
      "learning_rate": 4.278277738185642e-05,
      "loss": 0.0007,
      "step": 8695
    },
    {
      "epoch": 88.28,
      "learning_rate": 4.277102893717036e-05,
      "loss": 0.0004,
      "step": 8696
    },
    {
      "epoch": 88.29,
      "learning_rate": 4.275928090010532e-05,
      "loss": 0.0001,
      "step": 8697
    },
    {
      "epoch": 88.3,
      "learning_rate": 4.274753327132369e-05,
      "loss": 0.0202,
      "step": 8698
    },
    {
      "epoch": 88.31,
      "learning_rate": 4.2735786051487894e-05,
      "loss": 0.0008,
      "step": 8699
    },
    {
      "epoch": 88.32,
      "learning_rate": 4.272403924126035e-05,
      "loss": 0.0137,
      "step": 8700
    },
    {
      "epoch": 88.34,
      "learning_rate": 4.271229284130341e-05,
      "loss": 0.0002,
      "step": 8701
    },
    {
      "epoch": 88.35,
      "learning_rate": 4.270054685227943e-05,
      "loss": 0.0057,
      "step": 8702
    },
    {
      "epoch": 88.36,
      "learning_rate": 4.268880127485072e-05,
      "loss": 0.0001,
      "step": 8703
    },
    {
      "epoch": 88.37,
      "learning_rate": 4.2677056109679584e-05,
      "loss": 0.0,
      "step": 8704
    },
    {
      "epoch": 88.38,
      "learning_rate": 4.26653113574283e-05,
      "loss": 0.0254,
      "step": 8705
    },
    {
      "epoch": 88.39,
      "learning_rate": 4.265356701875911e-05,
      "loss": 0.0003,
      "step": 8706
    },
    {
      "epoch": 88.4,
      "learning_rate": 4.2641823094334254e-05,
      "loss": 0.0016,
      "step": 8707
    },
    {
      "epoch": 88.41,
      "learning_rate": 4.2630079584815954e-05,
      "loss": 0.0024,
      "step": 8708
    },
    {
      "epoch": 88.42,
      "learning_rate": 4.261833649086636e-05,
      "loss": 0.0,
      "step": 8709
    },
    {
      "epoch": 88.43,
      "learning_rate": 4.260659381314766e-05,
      "loss": 0.0081,
      "step": 8710
    },
    {
      "epoch": 88.44,
      "learning_rate": 4.259485155232197e-05,
      "loss": 0.0013,
      "step": 8711
    },
    {
      "epoch": 88.45,
      "learning_rate": 4.2583109709051396e-05,
      "loss": 0.0,
      "step": 8712
    },
    {
      "epoch": 88.46,
      "learning_rate": 4.2571368283998075e-05,
      "loss": 0.0001,
      "step": 8713
    },
    {
      "epoch": 88.47,
      "learning_rate": 4.255962727782401e-05,
      "loss": 0.0074,
      "step": 8714
    },
    {
      "epoch": 88.48,
      "learning_rate": 4.254788669119127e-05,
      "loss": 0.0,
      "step": 8715
    },
    {
      "epoch": 88.49,
      "learning_rate": 4.25361465247619e-05,
      "loss": 0.0004,
      "step": 8716
    },
    {
      "epoch": 88.5,
      "learning_rate": 4.252440677919785e-05,
      "loss": 0.0036,
      "step": 8717
    },
    {
      "epoch": 88.51,
      "learning_rate": 4.251266745516112e-05,
      "loss": 0.0,
      "step": 8718
    },
    {
      "epoch": 88.52,
      "learning_rate": 4.250092855331365e-05,
      "loss": 0.0,
      "step": 8719
    },
    {
      "epoch": 88.53,
      "learning_rate": 4.248919007431733e-05,
      "loss": 0.0003,
      "step": 8720
    },
    {
      "epoch": 88.54,
      "learning_rate": 4.247745201883412e-05,
      "loss": 0.0001,
      "step": 8721
    },
    {
      "epoch": 88.55,
      "learning_rate": 4.246571438752585e-05,
      "loss": 0.0001,
      "step": 8722
    },
    {
      "epoch": 88.56,
      "learning_rate": 4.245397718105439e-05,
      "loss": 0.0012,
      "step": 8723
    },
    {
      "epoch": 88.57,
      "learning_rate": 4.244224040008156e-05,
      "loss": 0.0001,
      "step": 8724
    },
    {
      "epoch": 88.58,
      "learning_rate": 4.2430504045269165e-05,
      "loss": 0.0373,
      "step": 8725
    },
    {
      "epoch": 88.59,
      "learning_rate": 4.2418768117278996e-05,
      "loss": 0.0029,
      "step": 8726
    },
    {
      "epoch": 88.6,
      "learning_rate": 4.2407032616772777e-05,
      "loss": 0.0005,
      "step": 8727
    },
    {
      "epoch": 88.61,
      "learning_rate": 4.239529754441227e-05,
      "loss": 0.0001,
      "step": 8728
    },
    {
      "epoch": 88.62,
      "learning_rate": 4.238356290085919e-05,
      "loss": 0.0029,
      "step": 8729
    },
    {
      "epoch": 88.63,
      "learning_rate": 4.237182868677519e-05,
      "loss": 0.0,
      "step": 8730
    },
    {
      "epoch": 88.64,
      "learning_rate": 4.2360094902821944e-05,
      "loss": 0.0004,
      "step": 8731
    },
    {
      "epoch": 88.65,
      "learning_rate": 4.234836154966108e-05,
      "loss": 0.0117,
      "step": 8732
    },
    {
      "epoch": 88.66,
      "learning_rate": 4.23366286279542e-05,
      "loss": 0.0003,
      "step": 8733
    },
    {
      "epoch": 88.67,
      "learning_rate": 4.2324896138362935e-05,
      "loss": 0.0015,
      "step": 8734
    },
    {
      "epoch": 88.68,
      "learning_rate": 4.231316408154878e-05,
      "loss": 0.0049,
      "step": 8735
    },
    {
      "epoch": 88.69,
      "learning_rate": 4.230143245817332e-05,
      "loss": 0.0002,
      "step": 8736
    },
    {
      "epoch": 88.7,
      "learning_rate": 4.228970126889806e-05,
      "loss": 0.0284,
      "step": 8737
    },
    {
      "epoch": 88.71,
      "learning_rate": 4.2277970514384476e-05,
      "loss": 0.0003,
      "step": 8738
    },
    {
      "epoch": 88.72,
      "learning_rate": 4.2266240195294045e-05,
      "loss": 0.0,
      "step": 8739
    },
    {
      "epoch": 88.73,
      "learning_rate": 4.225451031228819e-05,
      "loss": 0.0001,
      "step": 8740
    },
    {
      "epoch": 88.74,
      "learning_rate": 4.224278086602831e-05,
      "loss": 0.0022,
      "step": 8741
    },
    {
      "epoch": 88.75,
      "learning_rate": 4.223105185717586e-05,
      "loss": 0.0003,
      "step": 8742
    },
    {
      "epoch": 88.76,
      "learning_rate": 4.221932328639214e-05,
      "loss": 0.0006,
      "step": 8743
    },
    {
      "epoch": 88.77,
      "learning_rate": 4.220759515433852e-05,
      "loss": 0.0081,
      "step": 8744
    },
    {
      "epoch": 88.78,
      "learning_rate": 4.219586746167632e-05,
      "loss": 0.0001,
      "step": 8745
    },
    {
      "epoch": 88.79,
      "learning_rate": 4.218414020906681e-05,
      "loss": 0.0001,
      "step": 8746
    },
    {
      "epoch": 88.8,
      "learning_rate": 4.2172413397171274e-05,
      "loss": 0.0002,
      "step": 8747
    },
    {
      "epoch": 88.81,
      "learning_rate": 4.216068702665093e-05,
      "loss": 0.0001,
      "step": 8748
    },
    {
      "epoch": 88.82,
      "learning_rate": 4.2148961098167025e-05,
      "loss": 0.0012,
      "step": 8749
    },
    {
      "epoch": 88.83,
      "learning_rate": 4.213723561238074e-05,
      "loss": 0.0,
      "step": 8750
    },
    {
      "epoch": 88.84,
      "learning_rate": 4.212551056995323e-05,
      "loss": 0.0001,
      "step": 8751
    },
    {
      "epoch": 88.85,
      "learning_rate": 4.2113785971545654e-05,
      "loss": 0.0,
      "step": 8752
    },
    {
      "epoch": 88.86,
      "learning_rate": 4.2102061817819124e-05,
      "loss": 0.0002,
      "step": 8753
    },
    {
      "epoch": 88.87,
      "learning_rate": 4.209033810943471e-05,
      "loss": 0.0008,
      "step": 8754
    },
    {
      "epoch": 88.88,
      "learning_rate": 4.207861484705352e-05,
      "loss": 0.0038,
      "step": 8755
    },
    {
      "epoch": 88.89,
      "learning_rate": 4.2066892031336546e-05,
      "loss": 0.0,
      "step": 8756
    },
    {
      "epoch": 88.9,
      "learning_rate": 4.2055169662944836e-05,
      "loss": 0.0111,
      "step": 8757
    },
    {
      "epoch": 88.91,
      "learning_rate": 4.2043447742539385e-05,
      "loss": 0.0,
      "step": 8758
    },
    {
      "epoch": 88.92,
      "learning_rate": 4.2031726270781136e-05,
      "loss": 0.0002,
      "step": 8759
    },
    {
      "epoch": 88.93,
      "learning_rate": 4.2020005248331054e-05,
      "loss": 0.0001,
      "step": 8760
    },
    {
      "epoch": 88.94,
      "learning_rate": 4.2008284675850027e-05,
      "loss": 0.0007,
      "step": 8761
    },
    {
      "epoch": 88.95,
      "learning_rate": 4.199656455399894e-05,
      "loss": 0.0003,
      "step": 8762
    },
    {
      "epoch": 88.96,
      "learning_rate": 4.198484488343871e-05,
      "loss": 0.0001,
      "step": 8763
    },
    {
      "epoch": 88.97,
      "learning_rate": 4.1973125664830124e-05,
      "loss": 0.0002,
      "step": 8764
    },
    {
      "epoch": 88.98,
      "learning_rate": 4.196140689883402e-05,
      "loss": 0.0017,
      "step": 8765
    },
    {
      "epoch": 88.99,
      "learning_rate": 4.194968858611117e-05,
      "loss": 0.0002,
      "step": 8766
    },
    {
      "epoch": 88.99,
      "eval_loss": 0.01957923360168934,
      "eval_runtime": 31.8243,
      "eval_samples_per_second": 98.981,
      "eval_steps_per_second": 6.19,
      "eval_wer": 0.003297055057618438,
      "step": 8766
    },
    {
      "epoch": 89.01,
      "learning_rate": 4.193797072732235e-05,
      "loss": 0.0014,
      "step": 8767
    },
    {
      "epoch": 89.02,
      "learning_rate": 4.1926253323128294e-05,
      "loss": 0.0,
      "step": 8768
    },
    {
      "epoch": 89.03,
      "learning_rate": 4.1914536374189685e-05,
      "loss": 0.0004,
      "step": 8769
    },
    {
      "epoch": 89.04,
      "learning_rate": 4.190281988116725e-05,
      "loss": 0.0073,
      "step": 8770
    },
    {
      "epoch": 89.05,
      "learning_rate": 4.1891103844721636e-05,
      "loss": 0.0,
      "step": 8771
    },
    {
      "epoch": 89.06,
      "learning_rate": 4.1879388265513466e-05,
      "loss": 0.0099,
      "step": 8772
    },
    {
      "epoch": 89.07,
      "learning_rate": 4.186767314420333e-05,
      "loss": 0.0025,
      "step": 8773
    },
    {
      "epoch": 89.08,
      "learning_rate": 4.1855958481451886e-05,
      "loss": 0.0001,
      "step": 8774
    },
    {
      "epoch": 89.09,
      "learning_rate": 4.184424427791959e-05,
      "loss": 0.0052,
      "step": 8775
    },
    {
      "epoch": 89.1,
      "learning_rate": 4.183253053426706e-05,
      "loss": 0.0003,
      "step": 8776
    },
    {
      "epoch": 89.11,
      "learning_rate": 4.182081725115473e-05,
      "loss": 0.0005,
      "step": 8777
    },
    {
      "epoch": 89.12,
      "learning_rate": 4.180910442924312e-05,
      "loss": 0.0002,
      "step": 8778
    },
    {
      "epoch": 89.13,
      "learning_rate": 4.179739206919268e-05,
      "loss": 0.0009,
      "step": 8779
    },
    {
      "epoch": 89.14,
      "learning_rate": 4.178568017166382e-05,
      "loss": 0.0007,
      "step": 8780
    },
    {
      "epoch": 89.15,
      "learning_rate": 4.1773968737316935e-05,
      "loss": 0.0005,
      "step": 8781
    },
    {
      "epoch": 89.16,
      "learning_rate": 4.176225776681244e-05,
      "loss": 0.0003,
      "step": 8782
    },
    {
      "epoch": 89.17,
      "learning_rate": 4.1750547260810634e-05,
      "loss": 0.0004,
      "step": 8783
    },
    {
      "epoch": 89.18,
      "learning_rate": 4.1738837219971884e-05,
      "loss": 0.0012,
      "step": 8784
    },
    {
      "epoch": 89.19,
      "learning_rate": 4.172712764495644e-05,
      "loss": 0.0002,
      "step": 8785
    },
    {
      "epoch": 89.2,
      "learning_rate": 4.171541853642461e-05,
      "loss": 0.0,
      "step": 8786
    },
    {
      "epoch": 89.21,
      "learning_rate": 4.1703709895036625e-05,
      "loss": 0.0002,
      "step": 8787
    },
    {
      "epoch": 89.22,
      "learning_rate": 4.169200172145267e-05,
      "loss": 0.0132,
      "step": 8788
    },
    {
      "epoch": 89.23,
      "learning_rate": 4.168029401633298e-05,
      "loss": 0.0018,
      "step": 8789
    },
    {
      "epoch": 89.24,
      "learning_rate": 4.166858678033771e-05,
      "loss": 0.0001,
      "step": 8790
    },
    {
      "epoch": 89.25,
      "learning_rate": 4.1656880014126995e-05,
      "loss": 0.0001,
      "step": 8791
    },
    {
      "epoch": 89.26,
      "learning_rate": 4.1645173718360936e-05,
      "loss": 0.0,
      "step": 8792
    },
    {
      "epoch": 89.27,
      "learning_rate": 4.163346789369962e-05,
      "loss": 0.0001,
      "step": 8793
    },
    {
      "epoch": 89.28,
      "learning_rate": 4.162176254080309e-05,
      "loss": 0.0,
      "step": 8794
    },
    {
      "epoch": 89.29,
      "learning_rate": 4.161005766033143e-05,
      "loss": 0.0021,
      "step": 8795
    },
    {
      "epoch": 89.3,
      "learning_rate": 4.159835325294458e-05,
      "loss": 0.0001,
      "step": 8796
    },
    {
      "epoch": 89.31,
      "learning_rate": 4.158664931930258e-05,
      "loss": 0.0063,
      "step": 8797
    },
    {
      "epoch": 89.32,
      "learning_rate": 4.157494586006532e-05,
      "loss": 0.0002,
      "step": 8798
    },
    {
      "epoch": 89.33,
      "learning_rate": 4.156324287589275e-05,
      "loss": 0.0001,
      "step": 8799
    },
    {
      "epoch": 89.34,
      "learning_rate": 4.1551540367444796e-05,
      "loss": 0.0005,
      "step": 8800
    },
    {
      "epoch": 89.35,
      "learning_rate": 4.153983833538129e-05,
      "loss": 0.0,
      "step": 8801
    },
    {
      "epoch": 89.36,
      "learning_rate": 4.152813678036208e-05,
      "loss": 0.0,
      "step": 8802
    },
    {
      "epoch": 89.37,
      "learning_rate": 4.151643570304701e-05,
      "loss": 0.0001,
      "step": 8803
    },
    {
      "epoch": 89.38,
      "learning_rate": 4.150473510409585e-05,
      "loss": 0.0005,
      "step": 8804
    },
    {
      "epoch": 89.39,
      "learning_rate": 4.149303498416838e-05,
      "loss": 0.0002,
      "step": 8805
    },
    {
      "epoch": 89.4,
      "learning_rate": 4.148133534392431e-05,
      "loss": 0.0008,
      "step": 8806
    },
    {
      "epoch": 89.41,
      "learning_rate": 4.146963618402336e-05,
      "loss": 0.0001,
      "step": 8807
    },
    {
      "epoch": 89.42,
      "learning_rate": 4.145793750512523e-05,
      "loss": 0.0007,
      "step": 8808
    },
    {
      "epoch": 89.43,
      "learning_rate": 4.1446239307889534e-05,
      "loss": 0.0004,
      "step": 8809
    },
    {
      "epoch": 89.44,
      "learning_rate": 4.143454159297594e-05,
      "loss": 0.0002,
      "step": 8810
    },
    {
      "epoch": 89.45,
      "learning_rate": 4.1422844361044046e-05,
      "loss": 0.0,
      "step": 8811
    },
    {
      "epoch": 89.46,
      "learning_rate": 4.14111476127534e-05,
      "loss": 0.0,
      "step": 8812
    },
    {
      "epoch": 89.47,
      "learning_rate": 4.1399451348763575e-05,
      "loss": 0.0004,
      "step": 8813
    },
    {
      "epoch": 89.48,
      "learning_rate": 4.138775556973406e-05,
      "loss": 0.0054,
      "step": 8814
    },
    {
      "epoch": 89.49,
      "learning_rate": 4.1376060276324356e-05,
      "loss": 0.0008,
      "step": 8815
    },
    {
      "epoch": 89.5,
      "learning_rate": 4.136436546919397e-05,
      "loss": 0.0019,
      "step": 8816
    },
    {
      "epoch": 89.51,
      "learning_rate": 4.135267114900227e-05,
      "loss": 0.0001,
      "step": 8817
    },
    {
      "epoch": 89.52,
      "learning_rate": 4.134097731640871e-05,
      "loss": 0.0005,
      "step": 8818
    },
    {
      "epoch": 89.53,
      "learning_rate": 4.1329283972072674e-05,
      "loss": 0.0053,
      "step": 8819
    },
    {
      "epoch": 89.54,
      "learning_rate": 4.131759111665349e-05,
      "loss": 0.0005,
      "step": 8820
    },
    {
      "epoch": 89.55,
      "learning_rate": 4.13058987508105e-05,
      "loss": 0.0019,
      "step": 8821
    },
    {
      "epoch": 89.56,
      "learning_rate": 4.1294206875203e-05,
      "loss": 0.0,
      "step": 8822
    },
    {
      "epoch": 89.57,
      "learning_rate": 4.128251549049025e-05,
      "loss": 0.0001,
      "step": 8823
    },
    {
      "epoch": 89.58,
      "learning_rate": 4.127082459733152e-05,
      "loss": 0.0001,
      "step": 8824
    },
    {
      "epoch": 89.59,
      "learning_rate": 4.1259134196386004e-05,
      "loss": 0.0167,
      "step": 8825
    },
    {
      "epoch": 89.6,
      "learning_rate": 4.12474442883129e-05,
      "loss": 0.0001,
      "step": 8826
    },
    {
      "epoch": 89.61,
      "learning_rate": 4.1235754873771375e-05,
      "loss": 0.0159,
      "step": 8827
    },
    {
      "epoch": 89.62,
      "learning_rate": 4.1224065953420544e-05,
      "loss": 0.0005,
      "step": 8828
    },
    {
      "epoch": 89.63,
      "learning_rate": 4.121237752791953e-05,
      "loss": 0.0001,
      "step": 8829
    },
    {
      "epoch": 89.64,
      "learning_rate": 4.120068959792738e-05,
      "loss": 0.0003,
      "step": 8830
    },
    {
      "epoch": 89.65,
      "learning_rate": 4.118900216410317e-05,
      "loss": 0.0003,
      "step": 8831
    },
    {
      "epoch": 89.66,
      "learning_rate": 4.117731522710593e-05,
      "loss": 0.0,
      "step": 8832
    },
    {
      "epoch": 89.68,
      "learning_rate": 4.116562878759462e-05,
      "loss": 0.0,
      "step": 8833
    },
    {
      "epoch": 89.69,
      "learning_rate": 4.115394284622824e-05,
      "loss": 0.0001,
      "step": 8834
    },
    {
      "epoch": 89.7,
      "learning_rate": 4.114225740366569e-05,
      "loss": 0.0,
      "step": 8835
    },
    {
      "epoch": 89.71,
      "learning_rate": 4.11305724605659e-05,
      "loss": 0.0001,
      "step": 8836
    },
    {
      "epoch": 89.72,
      "learning_rate": 4.111888801758776e-05,
      "loss": 0.0001,
      "step": 8837
    },
    {
      "epoch": 89.73,
      "learning_rate": 4.1107204075390096e-05,
      "loss": 0.0011,
      "step": 8838
    },
    {
      "epoch": 89.74,
      "learning_rate": 4.109552063463175e-05,
      "loss": 0.0001,
      "step": 8839
    },
    {
      "epoch": 89.75,
      "learning_rate": 4.108383769597153e-05,
      "loss": 0.0001,
      "step": 8840
    },
    {
      "epoch": 89.76,
      "learning_rate": 4.107215526006817e-05,
      "loss": 0.0088,
      "step": 8841
    },
    {
      "epoch": 89.77,
      "learning_rate": 4.106047332758045e-05,
      "loss": 0.0,
      "step": 8842
    },
    {
      "epoch": 89.78,
      "learning_rate": 4.1048791899167033e-05,
      "loss": 0.0001,
      "step": 8843
    },
    {
      "epoch": 89.79,
      "learning_rate": 4.103711097548662e-05,
      "loss": 0.0089,
      "step": 8844
    },
    {
      "epoch": 89.8,
      "learning_rate": 4.1025430557197894e-05,
      "loss": 0.0208,
      "step": 8845
    },
    {
      "epoch": 89.81,
      "learning_rate": 4.101375064495944e-05,
      "loss": 0.0,
      "step": 8846
    },
    {
      "epoch": 89.82,
      "learning_rate": 4.100207123942988e-05,
      "loss": 0.0127,
      "step": 8847
    },
    {
      "epoch": 89.83,
      "learning_rate": 4.099039234126778e-05,
      "loss": 0.0001,
      "step": 8848
    },
    {
      "epoch": 89.84,
      "learning_rate": 4.097871395113167e-05,
      "loss": 0.0002,
      "step": 8849
    },
    {
      "epoch": 89.85,
      "learning_rate": 4.096703606968006e-05,
      "loss": 0.0001,
      "step": 8850
    },
    {
      "epoch": 89.86,
      "learning_rate": 4.095535869757143e-05,
      "loss": 0.0036,
      "step": 8851
    },
    {
      "epoch": 89.87,
      "learning_rate": 4.094368183546425e-05,
      "loss": 0.0001,
      "step": 8852
    },
    {
      "epoch": 89.88,
      "learning_rate": 4.093200548401694e-05,
      "loss": 0.0014,
      "step": 8853
    },
    {
      "epoch": 89.89,
      "learning_rate": 4.092032964388789e-05,
      "loss": 0.0012,
      "step": 8854
    },
    {
      "epoch": 89.9,
      "learning_rate": 4.0908654315735466e-05,
      "loss": 0.0106,
      "step": 8855
    },
    {
      "epoch": 89.91,
      "learning_rate": 4.089697950021802e-05,
      "loss": 0.0076,
      "step": 8856
    },
    {
      "epoch": 89.92,
      "learning_rate": 4.088530519799382e-05,
      "loss": 0.0023,
      "step": 8857
    },
    {
      "epoch": 89.93,
      "learning_rate": 4.087363140972123e-05,
      "loss": 0.0003,
      "step": 8858
    },
    {
      "epoch": 89.94,
      "learning_rate": 4.0861958136058395e-05,
      "loss": 0.0001,
      "step": 8859
    },
    {
      "epoch": 89.95,
      "learning_rate": 4.085028537766361e-05,
      "loss": 0.0,
      "step": 8860
    },
    {
      "epoch": 89.96,
      "learning_rate": 4.083861313519506e-05,
      "loss": 0.0001,
      "step": 8861
    },
    {
      "epoch": 89.97,
      "learning_rate": 4.082694140931089e-05,
      "loss": 0.0003,
      "step": 8862
    },
    {
      "epoch": 89.98,
      "learning_rate": 4.0815270200669234e-05,
      "loss": 0.001,
      "step": 8863
    },
    {
      "epoch": 89.99,
      "learning_rate": 4.0803599509928235e-05,
      "loss": 0.0001,
      "step": 8864
    },
    {
      "epoch": 90.0,
      "learning_rate": 4.0791929337745915e-05,
      "loss": 0.0001,
      "step": 8865
    },
    {
      "epoch": 90.0,
      "eval_loss": 0.021907590329647064,
      "eval_runtime": 31.8874,
      "eval_samples_per_second": 98.785,
      "eval_steps_per_second": 6.178,
      "eval_wer": 0.003969270166453265,
      "step": 8865
    },
    {
      "epoch": 90.01,
      "learning_rate": 4.078025968478037e-05,
      "loss": 0.0011,
      "step": 8866
    },
    {
      "epoch": 90.02,
      "learning_rate": 4.076859055168959e-05,
      "loss": 0.0003,
      "step": 8867
    },
    {
      "epoch": 90.03,
      "learning_rate": 4.0756921939131565e-05,
      "loss": 0.0003,
      "step": 8868
    },
    {
      "epoch": 90.04,
      "learning_rate": 4.074525384776428e-05,
      "loss": 0.0016,
      "step": 8869
    },
    {
      "epoch": 90.05,
      "learning_rate": 4.0733586278245635e-05,
      "loss": 0.0118,
      "step": 8870
    },
    {
      "epoch": 90.06,
      "learning_rate": 4.072191923123355e-05,
      "loss": 0.0003,
      "step": 8871
    },
    {
      "epoch": 90.07,
      "learning_rate": 4.071025270738587e-05,
      "loss": 0.001,
      "step": 8872
    },
    {
      "epoch": 90.08,
      "learning_rate": 4.069858670736047e-05,
      "loss": 0.001,
      "step": 8873
    },
    {
      "epoch": 90.09,
      "learning_rate": 4.068692123181515e-05,
      "loss": 0.0001,
      "step": 8874
    },
    {
      "epoch": 90.1,
      "learning_rate": 4.067525628140769e-05,
      "loss": 0.0003,
      "step": 8875
    },
    {
      "epoch": 90.11,
      "learning_rate": 4.066359185679583e-05,
      "loss": 0.0002,
      "step": 8876
    },
    {
      "epoch": 90.12,
      "learning_rate": 4.065192795863734e-05,
      "loss": 0.0022,
      "step": 8877
    },
    {
      "epoch": 90.13,
      "learning_rate": 4.064026458758985e-05,
      "loss": 0.0007,
      "step": 8878
    },
    {
      "epoch": 90.14,
      "learning_rate": 4.062860174431109e-05,
      "loss": 0.0001,
      "step": 8879
    },
    {
      "epoch": 90.15,
      "learning_rate": 4.061693942945863e-05,
      "loss": 0.0022,
      "step": 8880
    },
    {
      "epoch": 90.16,
      "learning_rate": 4.060527764369011e-05,
      "loss": 0.0004,
      "step": 8881
    },
    {
      "epoch": 90.17,
      "learning_rate": 4.0593616387663115e-05,
      "loss": 0.0027,
      "step": 8882
    },
    {
      "epoch": 90.18,
      "learning_rate": 4.058195566203517e-05,
      "loss": 0.0009,
      "step": 8883
    },
    {
      "epoch": 90.19,
      "learning_rate": 4.057029546746376e-05,
      "loss": 0.0004,
      "step": 8884
    },
    {
      "epoch": 90.2,
      "learning_rate": 4.055863580460646e-05,
      "loss": 0.001,
      "step": 8885
    },
    {
      "epoch": 90.21,
      "learning_rate": 4.054697667412063e-05,
      "loss": 0.0006,
      "step": 8886
    },
    {
      "epoch": 90.22,
      "learning_rate": 4.053531807666375e-05,
      "loss": 0.0003,
      "step": 8887
    },
    {
      "epoch": 90.23,
      "learning_rate": 4.0523660012893194e-05,
      "loss": 0.0001,
      "step": 8888
    },
    {
      "epoch": 90.24,
      "learning_rate": 4.0512002483466335e-05,
      "loss": 0.0002,
      "step": 8889
    },
    {
      "epoch": 90.25,
      "learning_rate": 4.0500345489040515e-05,
      "loss": 0.0001,
      "step": 8890
    },
    {
      "epoch": 90.26,
      "learning_rate": 4.0488689030273006e-05,
      "loss": 0.0004,
      "step": 8891
    },
    {
      "epoch": 90.27,
      "learning_rate": 4.047703310782111e-05,
      "loss": 0.0006,
      "step": 8892
    },
    {
      "epoch": 90.28,
      "learning_rate": 4.046537772234208e-05,
      "loss": 0.0121,
      "step": 8893
    },
    {
      "epoch": 90.29,
      "learning_rate": 4.045372287449311e-05,
      "loss": 0.0001,
      "step": 8894
    },
    {
      "epoch": 90.3,
      "learning_rate": 4.04420685649314e-05,
      "loss": 0.0001,
      "step": 8895
    },
    {
      "epoch": 90.31,
      "learning_rate": 4.0430414794314074e-05,
      "loss": 0.0144,
      "step": 8896
    },
    {
      "epoch": 90.32,
      "learning_rate": 4.041876156329827e-05,
      "loss": 0.0012,
      "step": 8897
    },
    {
      "epoch": 90.34,
      "learning_rate": 4.040710887254111e-05,
      "loss": 0.0002,
      "step": 8898
    },
    {
      "epoch": 90.35,
      "learning_rate": 4.03954567226996e-05,
      "loss": 0.0002,
      "step": 8899
    },
    {
      "epoch": 90.36,
      "learning_rate": 4.0383805114430836e-05,
      "loss": 0.0002,
      "step": 8900
    },
    {
      "epoch": 90.37,
      "learning_rate": 4.0372154048391745e-05,
      "loss": 0.0001,
      "step": 8901
    },
    {
      "epoch": 90.38,
      "learning_rate": 4.036050352523935e-05,
      "loss": 0.0001,
      "step": 8902
    },
    {
      "epoch": 90.39,
      "learning_rate": 4.0348853545630585e-05,
      "loss": 0.0,
      "step": 8903
    },
    {
      "epoch": 90.4,
      "learning_rate": 4.0337204110222346e-05,
      "loss": 0.0004,
      "step": 8904
    },
    {
      "epoch": 90.41,
      "learning_rate": 4.03255552196715e-05,
      "loss": 0.001,
      "step": 8905
    },
    {
      "epoch": 90.42,
      "learning_rate": 4.0313906874634936e-05,
      "loss": 0.0011,
      "step": 8906
    },
    {
      "epoch": 90.43,
      "learning_rate": 4.030225907576943e-05,
      "loss": 0.0004,
      "step": 8907
    },
    {
      "epoch": 90.44,
      "learning_rate": 4.02906118237318e-05,
      "loss": 0.0,
      "step": 8908
    },
    {
      "epoch": 90.45,
      "learning_rate": 4.027896511917877e-05,
      "loss": 0.0003,
      "step": 8909
    },
    {
      "epoch": 90.46,
      "learning_rate": 4.026731896276708e-05,
      "loss": 0.0002,
      "step": 8910
    },
    {
      "epoch": 90.47,
      "learning_rate": 4.0255673355153435e-05,
      "loss": 0.0006,
      "step": 8911
    },
    {
      "epoch": 90.48,
      "learning_rate": 4.0244028296994464e-05,
      "loss": 0.0,
      "step": 8912
    },
    {
      "epoch": 90.49,
      "learning_rate": 4.023238378894683e-05,
      "loss": 0.0016,
      "step": 8913
    },
    {
      "epoch": 90.5,
      "learning_rate": 4.022073983166713e-05,
      "loss": 0.0,
      "step": 8914
    },
    {
      "epoch": 90.51,
      "learning_rate": 4.020909642581192e-05,
      "loss": 0.0002,
      "step": 8915
    },
    {
      "epoch": 90.52,
      "learning_rate": 4.019745357203775e-05,
      "loss": 0.0018,
      "step": 8916
    },
    {
      "epoch": 90.53,
      "learning_rate": 4.018581127100112e-05,
      "loss": 0.0001,
      "step": 8917
    },
    {
      "epoch": 90.54,
      "learning_rate": 4.017416952335849e-05,
      "loss": 0.0214,
      "step": 8918
    },
    {
      "epoch": 90.55,
      "learning_rate": 4.0162528329766356e-05,
      "loss": 0.0001,
      "step": 8919
    },
    {
      "epoch": 90.56,
      "learning_rate": 4.015088769088107e-05,
      "loss": 0.0,
      "step": 8920
    },
    {
      "epoch": 90.57,
      "learning_rate": 4.013924760735905e-05,
      "loss": 0.0003,
      "step": 8921
    },
    {
      "epoch": 90.58,
      "learning_rate": 4.012760807985665e-05,
      "loss": 0.0001,
      "step": 8922
    },
    {
      "epoch": 90.59,
      "learning_rate": 4.011596910903017e-05,
      "loss": 0.0002,
      "step": 8923
    },
    {
      "epoch": 90.6,
      "learning_rate": 4.010433069553592e-05,
      "loss": 0.009,
      "step": 8924
    },
    {
      "epoch": 90.61,
      "learning_rate": 4.0092692840030134e-05,
      "loss": 0.0081,
      "step": 8925
    },
    {
      "epoch": 90.62,
      "learning_rate": 4.0081055543169034e-05,
      "loss": 0.0006,
      "step": 8926
    },
    {
      "epoch": 90.63,
      "learning_rate": 4.006941880560885e-05,
      "loss": 0.0197,
      "step": 8927
    },
    {
      "epoch": 90.64,
      "learning_rate": 4.0057782628005716e-05,
      "loss": 0.0008,
      "step": 8928
    },
    {
      "epoch": 90.65,
      "learning_rate": 4.004614701101576e-05,
      "loss": 0.0,
      "step": 8929
    },
    {
      "epoch": 90.66,
      "learning_rate": 4.003451195529511e-05,
      "loss": 0.0001,
      "step": 8930
    },
    {
      "epoch": 90.67,
      "learning_rate": 4.00228774614998e-05,
      "loss": 0.009,
      "step": 8931
    },
    {
      "epoch": 90.68,
      "learning_rate": 4.001124353028588e-05,
      "loss": 0.0078,
      "step": 8932
    },
    {
      "epoch": 90.69,
      "learning_rate": 3.9999610162309344e-05,
      "loss": 0.0,
      "step": 8933
    },
    {
      "epoch": 90.7,
      "learning_rate": 3.998797735822618e-05,
      "loss": 0.0004,
      "step": 8934
    },
    {
      "epoch": 90.71,
      "learning_rate": 3.997634511869233e-05,
      "loss": 0.0001,
      "step": 8935
    },
    {
      "epoch": 90.72,
      "learning_rate": 3.9964713444363685e-05,
      "loss": 0.0001,
      "step": 8936
    },
    {
      "epoch": 90.73,
      "learning_rate": 3.995308233589615e-05,
      "loss": 0.001,
      "step": 8937
    },
    {
      "epoch": 90.74,
      "learning_rate": 3.994145179394554e-05,
      "loss": 0.0,
      "step": 8938
    },
    {
      "epoch": 90.75,
      "learning_rate": 3.992982181916766e-05,
      "loss": 0.0,
      "step": 8939
    },
    {
      "epoch": 90.76,
      "learning_rate": 3.991819241221835e-05,
      "loss": 0.0003,
      "step": 8940
    },
    {
      "epoch": 90.77,
      "learning_rate": 3.9906563573753285e-05,
      "loss": 0.0003,
      "step": 8941
    },
    {
      "epoch": 90.78,
      "learning_rate": 3.989493530442823e-05,
      "loss": 0.0,
      "step": 8942
    },
    {
      "epoch": 90.79,
      "learning_rate": 3.9883307604898866e-05,
      "loss": 0.0002,
      "step": 8943
    },
    {
      "epoch": 90.8,
      "learning_rate": 3.9871680475820824e-05,
      "loss": 0.0001,
      "step": 8944
    },
    {
      "epoch": 90.81,
      "learning_rate": 3.9860053917849746e-05,
      "loss": 0.0013,
      "step": 8945
    },
    {
      "epoch": 90.82,
      "learning_rate": 3.98484279316412e-05,
      "loss": 0.0001,
      "step": 8946
    },
    {
      "epoch": 90.83,
      "learning_rate": 3.9836802517850746e-05,
      "loss": 0.0,
      "step": 8947
    },
    {
      "epoch": 90.84,
      "learning_rate": 3.982517767713394e-05,
      "loss": 0.0001,
      "step": 8948
    },
    {
      "epoch": 90.85,
      "learning_rate": 3.981355341014623e-05,
      "loss": 0.0,
      "step": 8949
    },
    {
      "epoch": 90.86,
      "learning_rate": 3.98019297175431e-05,
      "loss": 0.0004,
      "step": 8950
    },
    {
      "epoch": 90.87,
      "learning_rate": 3.979030659997997e-05,
      "loss": 0.0006,
      "step": 8951
    },
    {
      "epoch": 90.88,
      "learning_rate": 3.977868405811223e-05,
      "loss": 0.0131,
      "step": 8952
    },
    {
      "epoch": 90.89,
      "learning_rate": 3.976706209259526e-05,
      "loss": 0.0004,
      "step": 8953
    },
    {
      "epoch": 90.9,
      "learning_rate": 3.975544070408435e-05,
      "loss": 0.0016,
      "step": 8954
    },
    {
      "epoch": 90.91,
      "learning_rate": 3.9743819893234836e-05,
      "loss": 0.0036,
      "step": 8955
    },
    {
      "epoch": 90.92,
      "learning_rate": 3.9732199660701985e-05,
      "loss": 0.0008,
      "step": 8956
    },
    {
      "epoch": 90.93,
      "learning_rate": 3.9720580007140995e-05,
      "loss": 0.0068,
      "step": 8957
    },
    {
      "epoch": 90.94,
      "learning_rate": 3.9708960933207084e-05,
      "loss": 0.0001,
      "step": 8958
    },
    {
      "epoch": 90.95,
      "learning_rate": 3.969734243955543e-05,
      "loss": 0.0,
      "step": 8959
    },
    {
      "epoch": 90.96,
      "learning_rate": 3.968572452684113e-05,
      "loss": 0.004,
      "step": 8960
    },
    {
      "epoch": 90.97,
      "learning_rate": 3.967410719571934e-05,
      "loss": 0.0005,
      "step": 8961
    },
    {
      "epoch": 90.98,
      "learning_rate": 3.966249044684506e-05,
      "loss": 0.0095,
      "step": 8962
    },
    {
      "epoch": 90.99,
      "learning_rate": 3.965087428087339e-05,
      "loss": 0.0001,
      "step": 8963
    },
    {
      "epoch": 90.99,
      "eval_loss": 0.020864984020590782,
      "eval_runtime": 31.7903,
      "eval_samples_per_second": 99.087,
      "eval_steps_per_second": 6.197,
      "eval_wer": 0.0039372599231754166,
      "step": 8963
    },
    {
      "epoch": 91.01,
      "learning_rate": 3.963925869845929e-05,
      "loss": 0.0008,
      "step": 8964
    },
    {
      "epoch": 91.02,
      "learning_rate": 3.962764370025775e-05,
      "loss": 0.0,
      "step": 8965
    },
    {
      "epoch": 91.03,
      "learning_rate": 3.9616029286923684e-05,
      "loss": 0.0104,
      "step": 8966
    },
    {
      "epoch": 91.04,
      "learning_rate": 3.960441545911204e-05,
      "loss": 0.0001,
      "step": 8967
    },
    {
      "epoch": 91.05,
      "learning_rate": 3.959280221747764e-05,
      "loss": 0.0005,
      "step": 8968
    },
    {
      "epoch": 91.06,
      "learning_rate": 3.958118956267535e-05,
      "loss": 0.0007,
      "step": 8969
    },
    {
      "epoch": 91.07,
      "learning_rate": 3.9569577495359964e-05,
      "loss": 0.0,
      "step": 8970
    },
    {
      "epoch": 91.08,
      "learning_rate": 3.9557966016186254e-05,
      "loss": 0.0004,
      "step": 8971
    },
    {
      "epoch": 91.09,
      "learning_rate": 3.9546355125808965e-05,
      "loss": 0.0006,
      "step": 8972
    },
    {
      "epoch": 91.1,
      "learning_rate": 3.953474482488279e-05,
      "loss": 0.0001,
      "step": 8973
    },
    {
      "epoch": 91.11,
      "learning_rate": 3.9523135114062416e-05,
      "loss": 0.0001,
      "step": 8974
    },
    {
      "epoch": 91.12,
      "learning_rate": 3.951152599400245e-05,
      "loss": 0.006,
      "step": 8975
    },
    {
      "epoch": 91.13,
      "learning_rate": 3.9499917465357534e-05,
      "loss": 0.0001,
      "step": 8976
    },
    {
      "epoch": 91.14,
      "learning_rate": 3.948830952878223e-05,
      "loss": 0.0002,
      "step": 8977
    },
    {
      "epoch": 91.15,
      "learning_rate": 3.947670218493106e-05,
      "loss": 0.0108,
      "step": 8978
    },
    {
      "epoch": 91.16,
      "learning_rate": 3.9465095434458536e-05,
      "loss": 0.0051,
      "step": 8979
    },
    {
      "epoch": 91.17,
      "learning_rate": 3.9453489278019165e-05,
      "loss": 0.0,
      "step": 8980
    },
    {
      "epoch": 91.18,
      "learning_rate": 3.9441883716267316e-05,
      "loss": 0.0003,
      "step": 8981
    },
    {
      "epoch": 91.19,
      "learning_rate": 3.9430278749857466e-05,
      "loss": 0.0037,
      "step": 8982
    },
    {
      "epoch": 91.2,
      "learning_rate": 3.941867437944392e-05,
      "loss": 0.0013,
      "step": 8983
    },
    {
      "epoch": 91.21,
      "learning_rate": 3.940707060568105e-05,
      "loss": 0.0002,
      "step": 8984
    },
    {
      "epoch": 91.22,
      "learning_rate": 3.9395467429223174e-05,
      "loss": 0.0,
      "step": 8985
    },
    {
      "epoch": 91.23,
      "learning_rate": 3.9383864850724536e-05,
      "loss": 0.0003,
      "step": 8986
    },
    {
      "epoch": 91.24,
      "learning_rate": 3.937226287083936e-05,
      "loss": 0.012,
      "step": 8987
    },
    {
      "epoch": 91.25,
      "learning_rate": 3.936066149022191e-05,
      "loss": 0.0,
      "step": 8988
    },
    {
      "epoch": 91.26,
      "learning_rate": 3.934906070952627e-05,
      "loss": 0.0,
      "step": 8989
    },
    {
      "epoch": 91.27,
      "learning_rate": 3.933746052940664e-05,
      "loss": 0.0002,
      "step": 8990
    },
    {
      "epoch": 91.28,
      "learning_rate": 3.9325860950517097e-05,
      "loss": 0.0,
      "step": 8991
    },
    {
      "epoch": 91.29,
      "learning_rate": 3.93142619735117e-05,
      "loss": 0.0008,
      "step": 8992
    },
    {
      "epoch": 91.3,
      "learning_rate": 3.930266359904451e-05,
      "loss": 0.0,
      "step": 8993
    },
    {
      "epoch": 91.31,
      "learning_rate": 3.9291065827769485e-05,
      "loss": 0.0067,
      "step": 8994
    },
    {
      "epoch": 91.32,
      "learning_rate": 3.9279468660340626e-05,
      "loss": 0.0004,
      "step": 8995
    },
    {
      "epoch": 91.33,
      "learning_rate": 3.926787209741186e-05,
      "loss": 0.0024,
      "step": 8996
    },
    {
      "epoch": 91.34,
      "learning_rate": 3.925627613963706e-05,
      "loss": 0.0,
      "step": 8997
    },
    {
      "epoch": 91.35,
      "learning_rate": 3.924468078767012e-05,
      "loss": 0.008,
      "step": 8998
    },
    {
      "epoch": 91.36,
      "learning_rate": 3.923308604216484e-05,
      "loss": 0.0,
      "step": 8999
    },
    {
      "epoch": 91.37,
      "learning_rate": 3.922149190377501e-05,
      "loss": 0.0001,
      "step": 9000
    },
    {
      "epoch": 91.38,
      "learning_rate": 3.920989837315445e-05,
      "loss": 0.007,
      "step": 9001
    },
    {
      "epoch": 91.39,
      "learning_rate": 3.919830545095681e-05,
      "loss": 0.0003,
      "step": 9002
    },
    {
      "epoch": 91.4,
      "learning_rate": 3.9186713137835826e-05,
      "loss": 0.0,
      "step": 9003
    },
    {
      "epoch": 91.41,
      "learning_rate": 3.917512143444515e-05,
      "loss": 0.0001,
      "step": 9004
    },
    {
      "epoch": 91.42,
      "learning_rate": 3.91635303414384e-05,
      "loss": 0.0006,
      "step": 9005
    },
    {
      "epoch": 91.43,
      "learning_rate": 3.915193985946917e-05,
      "loss": 0.0,
      "step": 9006
    },
    {
      "epoch": 91.44,
      "learning_rate": 3.914034998919099e-05,
      "loss": 0.0,
      "step": 9007
    },
    {
      "epoch": 91.45,
      "learning_rate": 3.912876073125739e-05,
      "loss": 0.0008,
      "step": 9008
    },
    {
      "epoch": 91.46,
      "learning_rate": 3.911717208632189e-05,
      "loss": 0.0018,
      "step": 9009
    },
    {
      "epoch": 91.47,
      "learning_rate": 3.91055840550379e-05,
      "loss": 0.0001,
      "step": 9010
    },
    {
      "epoch": 91.48,
      "learning_rate": 3.909399663805886e-05,
      "loss": 0.0001,
      "step": 9011
    },
    {
      "epoch": 91.49,
      "learning_rate": 3.908240983603813e-05,
      "loss": 0.0006,
      "step": 9012
    },
    {
      "epoch": 91.5,
      "learning_rate": 3.907082364962907e-05,
      "loss": 0.0001,
      "step": 9013
    },
    {
      "epoch": 91.51,
      "learning_rate": 3.905923807948499e-05,
      "loss": 0.0106,
      "step": 9014
    },
    {
      "epoch": 91.52,
      "learning_rate": 3.904765312625916e-05,
      "loss": 0.0,
      "step": 9015
    },
    {
      "epoch": 91.53,
      "learning_rate": 3.903606879060483e-05,
      "loss": 0.015,
      "step": 9016
    },
    {
      "epoch": 91.54,
      "learning_rate": 3.902448507317522e-05,
      "loss": 0.0086,
      "step": 9017
    },
    {
      "epoch": 91.55,
      "learning_rate": 3.9012901974623475e-05,
      "loss": 0.0022,
      "step": 9018
    },
    {
      "epoch": 91.56,
      "learning_rate": 3.9001319495602766e-05,
      "loss": 0.0003,
      "step": 9019
    },
    {
      "epoch": 91.57,
      "learning_rate": 3.898973763676616e-05,
      "loss": 0.0003,
      "step": 9020
    },
    {
      "epoch": 91.58,
      "learning_rate": 3.897815639876673e-05,
      "loss": 0.0001,
      "step": 9021
    },
    {
      "epoch": 91.59,
      "learning_rate": 3.896657578225755e-05,
      "loss": 0.0044,
      "step": 9022
    },
    {
      "epoch": 91.6,
      "learning_rate": 3.895499578789157e-05,
      "loss": 0.0001,
      "step": 9023
    },
    {
      "epoch": 91.61,
      "learning_rate": 3.894341641632176e-05,
      "loss": 0.0002,
      "step": 9024
    },
    {
      "epoch": 91.62,
      "learning_rate": 3.893183766820109e-05,
      "loss": 0.0013,
      "step": 9025
    },
    {
      "epoch": 91.63,
      "learning_rate": 3.8920259544182404e-05,
      "loss": 0.0009,
      "step": 9026
    },
    {
      "epoch": 91.64,
      "learning_rate": 3.8908682044918584e-05,
      "loss": 0.0206,
      "step": 9027
    },
    {
      "epoch": 91.65,
      "learning_rate": 3.889710517106243e-05,
      "loss": 0.0001,
      "step": 9028
    },
    {
      "epoch": 91.66,
      "learning_rate": 3.888552892326674e-05,
      "loss": 0.0015,
      "step": 9029
    },
    {
      "epoch": 91.68,
      "learning_rate": 3.887395330218429e-05,
      "loss": 0.0177,
      "step": 9030
    },
    {
      "epoch": 91.69,
      "learning_rate": 3.886237830846776e-05,
      "loss": 0.0,
      "step": 9031
    },
    {
      "epoch": 91.7,
      "learning_rate": 3.885080394276984e-05,
      "loss": 0.0001,
      "step": 9032
    },
    {
      "epoch": 91.71,
      "learning_rate": 3.8839230205743206e-05,
      "loss": 0.0001,
      "step": 9033
    },
    {
      "epoch": 91.72,
      "learning_rate": 3.882765709804042e-05,
      "loss": 0.0,
      "step": 9034
    },
    {
      "epoch": 91.73,
      "learning_rate": 3.8816084620314095e-05,
      "loss": 0.0075,
      "step": 9035
    },
    {
      "epoch": 91.74,
      "learning_rate": 3.8804512773216733e-05,
      "loss": 0.0,
      "step": 9036
    },
    {
      "epoch": 91.75,
      "learning_rate": 3.879294155740087e-05,
      "loss": 0.0001,
      "step": 9037
    },
    {
      "epoch": 91.76,
      "learning_rate": 3.8781370973518974e-05,
      "loss": 0.0001,
      "step": 9038
    },
    {
      "epoch": 91.77,
      "learning_rate": 3.876980102222345e-05,
      "loss": 0.0017,
      "step": 9039
    },
    {
      "epoch": 91.78,
      "learning_rate": 3.8758231704166715e-05,
      "loss": 0.0003,
      "step": 9040
    },
    {
      "epoch": 91.79,
      "learning_rate": 3.874666302000113e-05,
      "loss": 0.0002,
      "step": 9041
    },
    {
      "epoch": 91.8,
      "learning_rate": 3.8735094970378994e-05,
      "loss": 0.0128,
      "step": 9042
    },
    {
      "epoch": 91.81,
      "learning_rate": 3.872352755595265e-05,
      "loss": 0.0005,
      "step": 9043
    },
    {
      "epoch": 91.82,
      "learning_rate": 3.871196077737429e-05,
      "loss": 0.0003,
      "step": 9044
    },
    {
      "epoch": 91.83,
      "learning_rate": 3.870039463529617e-05,
      "loss": 0.0001,
      "step": 9045
    },
    {
      "epoch": 91.84,
      "learning_rate": 3.868882913037046e-05,
      "loss": 0.0001,
      "step": 9046
    },
    {
      "epoch": 91.85,
      "learning_rate": 3.8677264263249313e-05,
      "loss": 0.0106,
      "step": 9047
    },
    {
      "epoch": 91.86,
      "learning_rate": 3.866570003458484e-05,
      "loss": 0.0004,
      "step": 9048
    },
    {
      "epoch": 91.87,
      "learning_rate": 3.865413644502909e-05,
      "loss": 0.0004,
      "step": 9049
    },
    {
      "epoch": 91.88,
      "learning_rate": 3.864257349523411e-05,
      "loss": 0.0007,
      "step": 9050
    },
    {
      "epoch": 91.89,
      "learning_rate": 3.863101118585194e-05,
      "loss": 0.0015,
      "step": 9051
    },
    {
      "epoch": 91.9,
      "learning_rate": 3.861944951753449e-05,
      "loss": 0.0019,
      "step": 9052
    },
    {
      "epoch": 91.91,
      "learning_rate": 3.8607888490933724e-05,
      "loss": 0.0001,
      "step": 9053
    },
    {
      "epoch": 91.92,
      "learning_rate": 3.859632810670153e-05,
      "loss": 0.0106,
      "step": 9054
    },
    {
      "epoch": 91.93,
      "learning_rate": 3.8584768365489766e-05,
      "loss": 0.0,
      "step": 9055
    },
    {
      "epoch": 91.94,
      "learning_rate": 3.857320926795024e-05,
      "loss": 0.0006,
      "step": 9056
    },
    {
      "epoch": 91.95,
      "learning_rate": 3.856165081473474e-05,
      "loss": 0.0001,
      "step": 9057
    },
    {
      "epoch": 91.96,
      "learning_rate": 3.855009300649502e-05,
      "loss": 0.0001,
      "step": 9058
    },
    {
      "epoch": 91.97,
      "learning_rate": 3.85385358438828e-05,
      "loss": 0.0003,
      "step": 9059
    },
    {
      "epoch": 91.98,
      "learning_rate": 3.8526979327549736e-05,
      "loss": 0.0004,
      "step": 9060
    },
    {
      "epoch": 91.99,
      "learning_rate": 3.8515423458147473e-05,
      "loss": 0.0084,
      "step": 9061
    },
    {
      "epoch": 92.0,
      "learning_rate": 3.8503868236327635e-05,
      "loss": 0.0001,
      "step": 9062
    },
    {
      "epoch": 92.0,
      "eval_loss": 0.019517788663506508,
      "eval_runtime": 32.0648,
      "eval_samples_per_second": 98.239,
      "eval_steps_per_second": 6.144,
      "eval_wer": 0.0033290653008962866,
      "step": 9062
    },
    {
      "epoch": 92.01,
      "learning_rate": 3.849231366274174e-05,
      "loss": 0.0019,
      "step": 9063
    },
    {
      "epoch": 92.02,
      "learning_rate": 3.848075973804139e-05,
      "loss": 0.0063,
      "step": 9064
    },
    {
      "epoch": 92.03,
      "learning_rate": 3.846920646287799e-05,
      "loss": 0.0001,
      "step": 9065
    },
    {
      "epoch": 92.04,
      "learning_rate": 3.8457653837903065e-05,
      "loss": 0.0,
      "step": 9066
    },
    {
      "epoch": 92.05,
      "learning_rate": 3.8446101863768015e-05,
      "loss": 0.003,
      "step": 9067
    },
    {
      "epoch": 92.06,
      "learning_rate": 3.84345505411242e-05,
      "loss": 0.0001,
      "step": 9068
    },
    {
      "epoch": 92.07,
      "learning_rate": 3.842299987062298e-05,
      "loss": 0.0217,
      "step": 9069
    },
    {
      "epoch": 92.08,
      "learning_rate": 3.84114498529157e-05,
      "loss": 0.0003,
      "step": 9070
    },
    {
      "epoch": 92.09,
      "learning_rate": 3.839990048865357e-05,
      "loss": 0.0007,
      "step": 9071
    },
    {
      "epoch": 92.1,
      "learning_rate": 3.838835177848788e-05,
      "loss": 0.0001,
      "step": 9072
    },
    {
      "epoch": 92.11,
      "learning_rate": 3.8376803723069794e-05,
      "loss": 0.0011,
      "step": 9073
    },
    {
      "epoch": 92.12,
      "learning_rate": 3.836525632305048e-05,
      "loss": 0.0001,
      "step": 9074
    },
    {
      "epoch": 92.13,
      "learning_rate": 3.8353709579081084e-05,
      "loss": 0.0,
      "step": 9075
    },
    {
      "epoch": 92.14,
      "learning_rate": 3.834216349181266e-05,
      "loss": 0.0001,
      "step": 9076
    },
    {
      "epoch": 92.15,
      "learning_rate": 3.8330618061896293e-05,
      "loss": 0.0003,
      "step": 9077
    },
    {
      "epoch": 92.16,
      "learning_rate": 3.831907328998295e-05,
      "loss": 0.0001,
      "step": 9078
    },
    {
      "epoch": 92.17,
      "learning_rate": 3.830752917672366e-05,
      "loss": 0.0125,
      "step": 9079
    },
    {
      "epoch": 92.18,
      "learning_rate": 3.829598572276935e-05,
      "loss": 0.0004,
      "step": 9080
    },
    {
      "epoch": 92.19,
      "learning_rate": 3.82844429287709e-05,
      "loss": 0.0001,
      "step": 9081
    },
    {
      "epoch": 92.2,
      "learning_rate": 3.8272900795379175e-05,
      "loss": 0.0001,
      "step": 9082
    },
    {
      "epoch": 92.21,
      "learning_rate": 3.826135932324505e-05,
      "loss": 0.0001,
      "step": 9083
    },
    {
      "epoch": 92.22,
      "learning_rate": 3.8249818513019244e-05,
      "loss": 0.0031,
      "step": 9084
    },
    {
      "epoch": 92.23,
      "learning_rate": 3.823827836535259e-05,
      "loss": 0.0072,
      "step": 9085
    },
    {
      "epoch": 92.24,
      "learning_rate": 3.822673888089572e-05,
      "loss": 0.0,
      "step": 9086
    },
    {
      "epoch": 92.25,
      "learning_rate": 3.821520006029937e-05,
      "loss": 0.0001,
      "step": 9087
    },
    {
      "epoch": 92.26,
      "learning_rate": 3.820366190421417e-05,
      "loss": 0.0002,
      "step": 9088
    },
    {
      "epoch": 92.27,
      "learning_rate": 3.819212441329071e-05,
      "loss": 0.0008,
      "step": 9089
    },
    {
      "epoch": 92.28,
      "learning_rate": 3.818058758817956e-05,
      "loss": 0.0,
      "step": 9090
    },
    {
      "epoch": 92.29,
      "learning_rate": 3.8169051429531274e-05,
      "loss": 0.0002,
      "step": 9091
    },
    {
      "epoch": 92.3,
      "learning_rate": 3.81575159379963e-05,
      "loss": 0.0001,
      "step": 9092
    },
    {
      "epoch": 92.31,
      "learning_rate": 3.814598111422513e-05,
      "loss": 0.0,
      "step": 9093
    },
    {
      "epoch": 92.32,
      "learning_rate": 3.8134446958868155e-05,
      "loss": 0.0001,
      "step": 9094
    },
    {
      "epoch": 92.34,
      "learning_rate": 3.8122913472575764e-05,
      "loss": 0.0003,
      "step": 9095
    },
    {
      "epoch": 92.35,
      "learning_rate": 3.81113806559983e-05,
      "loss": 0.001,
      "step": 9096
    },
    {
      "epoch": 92.36,
      "learning_rate": 3.809984850978604e-05,
      "loss": 0.0001,
      "step": 9097
    },
    {
      "epoch": 92.37,
      "learning_rate": 3.808831703458928e-05,
      "loss": 0.0001,
      "step": 9098
    },
    {
      "epoch": 92.38,
      "learning_rate": 3.807678623105825e-05,
      "loss": 0.0003,
      "step": 9099
    },
    {
      "epoch": 92.39,
      "learning_rate": 3.806525609984312e-05,
      "loss": 0.0,
      "step": 9100
    },
    {
      "epoch": 92.4,
      "learning_rate": 3.8053726641594046e-05,
      "loss": 0.0002,
      "step": 9101
    },
    {
      "epoch": 92.41,
      "learning_rate": 3.8042197856961134e-05,
      "loss": 0.0,
      "step": 9102
    },
    {
      "epoch": 92.42,
      "learning_rate": 3.803066974659445e-05,
      "loss": 0.0142,
      "step": 9103
    },
    {
      "epoch": 92.43,
      "learning_rate": 3.801914231114409e-05,
      "loss": 0.0,
      "step": 9104
    },
    {
      "epoch": 92.44,
      "learning_rate": 3.8007615551259965e-05,
      "loss": 0.0001,
      "step": 9105
    },
    {
      "epoch": 92.45,
      "learning_rate": 3.79960894675921e-05,
      "loss": 0.0001,
      "step": 9106
    },
    {
      "epoch": 92.46,
      "learning_rate": 3.798456406079041e-05,
      "loss": 0.0,
      "step": 9107
    },
    {
      "epoch": 92.47,
      "learning_rate": 3.797303933150476e-05,
      "loss": 0.0001,
      "step": 9108
    },
    {
      "epoch": 92.48,
      "learning_rate": 3.7961515280385016e-05,
      "loss": 0.0039,
      "step": 9109
    },
    {
      "epoch": 92.49,
      "learning_rate": 3.794999190808096e-05,
      "loss": 0.0015,
      "step": 9110
    },
    {
      "epoch": 92.5,
      "learning_rate": 3.793846921524237e-05,
      "loss": 0.0042,
      "step": 9111
    },
    {
      "epoch": 92.51,
      "learning_rate": 3.792694720251901e-05,
      "loss": 0.0006,
      "step": 9112
    },
    {
      "epoch": 92.52,
      "learning_rate": 3.7915425870560535e-05,
      "loss": 0.0297,
      "step": 9113
    },
    {
      "epoch": 92.53,
      "learning_rate": 3.790390522001662e-05,
      "loss": 0.0039,
      "step": 9114
    },
    {
      "epoch": 92.54,
      "learning_rate": 3.789238525153687e-05,
      "loss": 0.0,
      "step": 9115
    },
    {
      "epoch": 92.55,
      "learning_rate": 3.7880865965770876e-05,
      "loss": 0.0002,
      "step": 9116
    },
    {
      "epoch": 92.56,
      "learning_rate": 3.786934736336817e-05,
      "loss": 0.0001,
      "step": 9117
    },
    {
      "epoch": 92.57,
      "learning_rate": 3.785782944497823e-05,
      "loss": 0.0002,
      "step": 9118
    },
    {
      "epoch": 92.58,
      "learning_rate": 3.7846312211250556e-05,
      "loss": 0.0001,
      "step": 9119
    },
    {
      "epoch": 92.59,
      "learning_rate": 3.783479566283457e-05,
      "loss": 0.0001,
      "step": 9120
    },
    {
      "epoch": 92.6,
      "learning_rate": 3.7823279800379636e-05,
      "loss": 0.001,
      "step": 9121
    },
    {
      "epoch": 92.61,
      "learning_rate": 3.781176462453511e-05,
      "loss": 0.0005,
      "step": 9122
    },
    {
      "epoch": 92.62,
      "learning_rate": 3.78002501359503e-05,
      "loss": 0.0008,
      "step": 9123
    },
    {
      "epoch": 92.63,
      "learning_rate": 3.7788736335274456e-05,
      "loss": 0.0004,
      "step": 9124
    },
    {
      "epoch": 92.64,
      "learning_rate": 3.777722322315685e-05,
      "loss": 0.001,
      "step": 9125
    },
    {
      "epoch": 92.65,
      "learning_rate": 3.776571080024663e-05,
      "loss": 0.0,
      "step": 9126
    },
    {
      "epoch": 92.66,
      "learning_rate": 3.775419906719298e-05,
      "loss": 0.0112,
      "step": 9127
    },
    {
      "epoch": 92.67,
      "learning_rate": 3.774268802464501e-05,
      "loss": 0.0003,
      "step": 9128
    },
    {
      "epoch": 92.68,
      "learning_rate": 3.773117767325177e-05,
      "loss": 0.0001,
      "step": 9129
    },
    {
      "epoch": 92.69,
      "learning_rate": 3.7719668013662326e-05,
      "loss": 0.0001,
      "step": 9130
    },
    {
      "epoch": 92.7,
      "learning_rate": 3.770815904652566e-05,
      "loss": 0.001,
      "step": 9131
    },
    {
      "epoch": 92.71,
      "learning_rate": 3.7696650772490705e-05,
      "loss": 0.0005,
      "step": 9132
    },
    {
      "epoch": 92.72,
      "learning_rate": 3.768514319220643e-05,
      "loss": 0.0164,
      "step": 9133
    },
    {
      "epoch": 92.73,
      "learning_rate": 3.767363630632169e-05,
      "loss": 0.0094,
      "step": 9134
    },
    {
      "epoch": 92.74,
      "learning_rate": 3.7662130115485314e-05,
      "loss": 0.0001,
      "step": 9135
    },
    {
      "epoch": 92.75,
      "learning_rate": 3.7650624620346135e-05,
      "loss": 0.0041,
      "step": 9136
    },
    {
      "epoch": 92.76,
      "learning_rate": 3.7639119821552884e-05,
      "loss": 0.0001,
      "step": 9137
    },
    {
      "epoch": 92.77,
      "learning_rate": 3.762761571975429e-05,
      "loss": 0.0003,
      "step": 9138
    },
    {
      "epoch": 92.78,
      "learning_rate": 3.7616112315599035e-05,
      "loss": 0.0001,
      "step": 9139
    },
    {
      "epoch": 92.79,
      "learning_rate": 3.7604609609735766e-05,
      "loss": 0.0003,
      "step": 9140
    },
    {
      "epoch": 92.8,
      "learning_rate": 3.759310760281312e-05,
      "loss": 0.0001,
      "step": 9141
    },
    {
      "epoch": 92.81,
      "learning_rate": 3.7581606295479606e-05,
      "loss": 0.0021,
      "step": 9142
    },
    {
      "epoch": 92.82,
      "learning_rate": 3.757010568838378e-05,
      "loss": 0.0001,
      "step": 9143
    },
    {
      "epoch": 92.83,
      "learning_rate": 3.7558605782174134e-05,
      "loss": 0.0002,
      "step": 9144
    },
    {
      "epoch": 92.84,
      "learning_rate": 3.754710657749909e-05,
      "loss": 0.0002,
      "step": 9145
    },
    {
      "epoch": 92.85,
      "learning_rate": 3.7535608075007094e-05,
      "loss": 0.0001,
      "step": 9146
    },
    {
      "epoch": 92.86,
      "learning_rate": 3.752411027534647e-05,
      "loss": 0.0002,
      "step": 9147
    },
    {
      "epoch": 92.87,
      "learning_rate": 3.751261317916556e-05,
      "loss": 0.0001,
      "step": 9148
    },
    {
      "epoch": 92.88,
      "learning_rate": 3.750111678711268e-05,
      "loss": 0.0,
      "step": 9149
    },
    {
      "epoch": 92.89,
      "learning_rate": 3.7489621099836045e-05,
      "loss": 0.0004,
      "step": 9150
    },
    {
      "epoch": 92.9,
      "learning_rate": 3.747812611798389e-05,
      "loss": 0.0004,
      "step": 9151
    },
    {
      "epoch": 92.91,
      "learning_rate": 3.746663184220436e-05,
      "loss": 0.0006,
      "step": 9152
    },
    {
      "epoch": 92.92,
      "learning_rate": 3.7455138273145585e-05,
      "loss": 0.0156,
      "step": 9153
    },
    {
      "epoch": 92.93,
      "learning_rate": 3.7443645411455685e-05,
      "loss": 0.0,
      "step": 9154
    },
    {
      "epoch": 92.94,
      "learning_rate": 3.7432153257782675e-05,
      "loss": 0.0023,
      "step": 9155
    },
    {
      "epoch": 92.95,
      "learning_rate": 3.742066181277458e-05,
      "loss": 0.0013,
      "step": 9156
    },
    {
      "epoch": 92.96,
      "learning_rate": 3.7409171077079376e-05,
      "loss": 0.0001,
      "step": 9157
    },
    {
      "epoch": 92.97,
      "learning_rate": 3.739768105134498e-05,
      "loss": 0.0001,
      "step": 9158
    },
    {
      "epoch": 92.98,
      "learning_rate": 3.7386191736219286e-05,
      "loss": 0.0001,
      "step": 9159
    },
    {
      "epoch": 92.99,
      "learning_rate": 3.737470313235013e-05,
      "loss": 0.0016,
      "step": 9160
    },
    {
      "epoch": 92.99,
      "eval_loss": 0.019519073888659477,
      "eval_runtime": 32.6424,
      "eval_samples_per_second": 96.5,
      "eval_steps_per_second": 6.035,
      "eval_wer": 0.004001280409731114,
      "step": 9160
    },
    {
      "epoch": 93.01,
      "learning_rate": 3.736321524038535e-05,
      "loss": 0.0036,
      "step": 9161
    },
    {
      "epoch": 93.02,
      "learning_rate": 3.735172806097271e-05,
      "loss": 0.0002,
      "step": 9162
    },
    {
      "epoch": 93.03,
      "learning_rate": 3.7340241594759916e-05,
      "loss": 0.0007,
      "step": 9163
    },
    {
      "epoch": 93.04,
      "learning_rate": 3.7328755842394674e-05,
      "loss": 0.0001,
      "step": 9164
    },
    {
      "epoch": 93.05,
      "learning_rate": 3.731727080452464e-05,
      "loss": 0.0001,
      "step": 9165
    },
    {
      "epoch": 93.06,
      "learning_rate": 3.730578648179739e-05,
      "loss": 0.0101,
      "step": 9166
    },
    {
      "epoch": 93.07,
      "learning_rate": 3.729430287486055e-05,
      "loss": 0.0153,
      "step": 9167
    },
    {
      "epoch": 93.08,
      "learning_rate": 3.728281998436158e-05,
      "loss": 0.0001,
      "step": 9168
    },
    {
      "epoch": 93.09,
      "learning_rate": 3.727133781094801e-05,
      "loss": 0.002,
      "step": 9169
    },
    {
      "epoch": 93.1,
      "learning_rate": 3.7259856355267273e-05,
      "loss": 0.0002,
      "step": 9170
    },
    {
      "epoch": 93.11,
      "learning_rate": 3.7248375617966784e-05,
      "loss": 0.0001,
      "step": 9171
    },
    {
      "epoch": 93.12,
      "learning_rate": 3.723689559969389e-05,
      "loss": 0.0002,
      "step": 9172
    },
    {
      "epoch": 93.13,
      "learning_rate": 3.722541630109596e-05,
      "loss": 0.0005,
      "step": 9173
    },
    {
      "epoch": 93.14,
      "learning_rate": 3.721393772282022e-05,
      "loss": 0.001,
      "step": 9174
    },
    {
      "epoch": 93.15,
      "learning_rate": 3.720245986551396e-05,
      "loss": 0.0004,
      "step": 9175
    },
    {
      "epoch": 93.16,
      "learning_rate": 3.719098272982436e-05,
      "loss": 0.0,
      "step": 9176
    },
    {
      "epoch": 93.17,
      "learning_rate": 3.717950631639858e-05,
      "loss": 0.0038,
      "step": 9177
    },
    {
      "epoch": 93.18,
      "learning_rate": 3.7168030625883774e-05,
      "loss": 0.0116,
      "step": 9178
    },
    {
      "epoch": 93.19,
      "learning_rate": 3.715655565892699e-05,
      "loss": 0.004,
      "step": 9179
    },
    {
      "epoch": 93.2,
      "learning_rate": 3.7145081416175265e-05,
      "loss": 0.0212,
      "step": 9180
    },
    {
      "epoch": 93.21,
      "learning_rate": 3.713360789827563e-05,
      "loss": 0.0004,
      "step": 9181
    },
    {
      "epoch": 93.22,
      "learning_rate": 3.712213510587502e-05,
      "loss": 0.0001,
      "step": 9182
    },
    {
      "epoch": 93.23,
      "learning_rate": 3.7110663039620375e-05,
      "loss": 0.0001,
      "step": 9183
    },
    {
      "epoch": 93.24,
      "learning_rate": 3.709919170015854e-05,
      "loss": 0.0001,
      "step": 9184
    },
    {
      "epoch": 93.25,
      "learning_rate": 3.708772108813636e-05,
      "loss": 0.0,
      "step": 9185
    },
    {
      "epoch": 93.26,
      "learning_rate": 3.7076251204200665e-05,
      "loss": 0.0006,
      "step": 9186
    },
    {
      "epoch": 93.27,
      "learning_rate": 3.706478204899816e-05,
      "loss": 0.0002,
      "step": 9187
    },
    {
      "epoch": 93.28,
      "learning_rate": 3.70533136231756e-05,
      "loss": 0.0002,
      "step": 9188
    },
    {
      "epoch": 93.29,
      "learning_rate": 3.704184592737962e-05,
      "loss": 0.0002,
      "step": 9189
    },
    {
      "epoch": 93.3,
      "learning_rate": 3.703037896225686e-05,
      "loss": 0.0041,
      "step": 9190
    },
    {
      "epoch": 93.31,
      "learning_rate": 3.701891272845394e-05,
      "loss": 0.0001,
      "step": 9191
    },
    {
      "epoch": 93.32,
      "learning_rate": 3.7007447226617366e-05,
      "loss": 0.0001,
      "step": 9192
    },
    {
      "epoch": 93.33,
      "learning_rate": 3.699598245739365e-05,
      "loss": 0.0001,
      "step": 9193
    },
    {
      "epoch": 93.34,
      "learning_rate": 3.698451842142931e-05,
      "loss": 0.0,
      "step": 9194
    },
    {
      "epoch": 93.35,
      "learning_rate": 3.69730551193707e-05,
      "loss": 0.0,
      "step": 9195
    },
    {
      "epoch": 93.36,
      "learning_rate": 3.696159255186425e-05,
      "loss": 0.0001,
      "step": 9196
    },
    {
      "epoch": 93.37,
      "learning_rate": 3.695013071955628e-05,
      "loss": 0.0001,
      "step": 9197
    },
    {
      "epoch": 93.38,
      "learning_rate": 3.6938669623093084e-05,
      "loss": 0.0002,
      "step": 9198
    },
    {
      "epoch": 93.39,
      "learning_rate": 3.692720926312095e-05,
      "loss": 0.0004,
      "step": 9199
    },
    {
      "epoch": 93.4,
      "learning_rate": 3.691574964028606e-05,
      "loss": 0.0006,
      "step": 9200
    },
    {
      "epoch": 93.41,
      "learning_rate": 3.6904290755234604e-05,
      "loss": 0.0007,
      "step": 9201
    },
    {
      "epoch": 93.42,
      "learning_rate": 3.689283260861274e-05,
      "loss": 0.0014,
      "step": 9202
    },
    {
      "epoch": 93.43,
      "learning_rate": 3.688137520106652e-05,
      "loss": 0.0,
      "step": 9203
    },
    {
      "epoch": 93.44,
      "learning_rate": 3.686991853324202e-05,
      "loss": 0.0008,
      "step": 9204
    },
    {
      "epoch": 93.45,
      "learning_rate": 3.685846260578524e-05,
      "loss": 0.0001,
      "step": 9205
    },
    {
      "epoch": 93.46,
      "learning_rate": 3.684700741934213e-05,
      "loss": 0.0,
      "step": 9206
    },
    {
      "epoch": 93.47,
      "learning_rate": 3.683555297455867e-05,
      "loss": 0.0052,
      "step": 9207
    },
    {
      "epoch": 93.48,
      "learning_rate": 3.6824099272080667e-05,
      "loss": 0.0122,
      "step": 9208
    },
    {
      "epoch": 93.49,
      "learning_rate": 3.681264631255402e-05,
      "loss": 0.0004,
      "step": 9209
    },
    {
      "epoch": 93.5,
      "learning_rate": 3.680119409662452e-05,
      "loss": 0.0,
      "step": 9210
    },
    {
      "epoch": 93.51,
      "learning_rate": 3.678974262493789e-05,
      "loss": 0.0024,
      "step": 9211
    },
    {
      "epoch": 93.52,
      "learning_rate": 3.67782918981399e-05,
      "loss": 0.0,
      "step": 9212
    },
    {
      "epoch": 93.53,
      "learning_rate": 3.6766841916876174e-05,
      "loss": 0.0041,
      "step": 9213
    },
    {
      "epoch": 93.54,
      "learning_rate": 3.675539268179236e-05,
      "loss": 0.0004,
      "step": 9214
    },
    {
      "epoch": 93.55,
      "learning_rate": 3.674394419353407e-05,
      "loss": 0.003,
      "step": 9215
    },
    {
      "epoch": 93.56,
      "learning_rate": 3.6732496452746825e-05,
      "loss": 0.0027,
      "step": 9216
    },
    {
      "epoch": 93.57,
      "learning_rate": 3.672104946007614e-05,
      "loss": 0.0023,
      "step": 9217
    },
    {
      "epoch": 93.58,
      "learning_rate": 3.670960321616748e-05,
      "loss": 0.0002,
      "step": 9218
    },
    {
      "epoch": 93.59,
      "learning_rate": 3.6698157721666246e-05,
      "loss": 0.0001,
      "step": 9219
    },
    {
      "epoch": 93.6,
      "learning_rate": 3.668671297721786e-05,
      "loss": 0.0,
      "step": 9220
    },
    {
      "epoch": 93.61,
      "learning_rate": 3.6675268983467604e-05,
      "loss": 0.001,
      "step": 9221
    },
    {
      "epoch": 93.62,
      "learning_rate": 3.6663825741060806e-05,
      "loss": 0.0004,
      "step": 9222
    },
    {
      "epoch": 93.63,
      "learning_rate": 3.665238325064273e-05,
      "loss": 0.0008,
      "step": 9223
    },
    {
      "epoch": 93.64,
      "learning_rate": 3.664094151285855e-05,
      "loss": 0.0046,
      "step": 9224
    },
    {
      "epoch": 93.65,
      "learning_rate": 3.662950052835346e-05,
      "loss": 0.0001,
      "step": 9225
    },
    {
      "epoch": 93.66,
      "learning_rate": 3.661806029777257e-05,
      "loss": 0.0001,
      "step": 9226
    },
    {
      "epoch": 93.68,
      "learning_rate": 3.660662082176095e-05,
      "loss": 0.0154,
      "step": 9227
    },
    {
      "epoch": 93.69,
      "learning_rate": 3.659518210096369e-05,
      "loss": 0.0,
      "step": 9228
    },
    {
      "epoch": 93.7,
      "learning_rate": 3.658374413602571e-05,
      "loss": 0.0,
      "step": 9229
    },
    {
      "epoch": 93.71,
      "learning_rate": 3.657230692759203e-05,
      "loss": 0.0,
      "step": 9230
    },
    {
      "epoch": 93.72,
      "learning_rate": 3.656087047630754e-05,
      "loss": 0.0001,
      "step": 9231
    },
    {
      "epoch": 93.73,
      "learning_rate": 3.65494347828171e-05,
      "loss": 0.0001,
      "step": 9232
    },
    {
      "epoch": 93.74,
      "learning_rate": 3.6537999847765555e-05,
      "loss": 0.0,
      "step": 9233
    },
    {
      "epoch": 93.75,
      "learning_rate": 3.652656567179766e-05,
      "loss": 0.0027,
      "step": 9234
    },
    {
      "epoch": 93.76,
      "learning_rate": 3.651513225555816e-05,
      "loss": 0.0001,
      "step": 9235
    },
    {
      "epoch": 93.77,
      "learning_rate": 3.650369959969179e-05,
      "loss": 0.0001,
      "step": 9236
    },
    {
      "epoch": 93.78,
      "learning_rate": 3.6492267704843166e-05,
      "loss": 0.002,
      "step": 9237
    },
    {
      "epoch": 93.79,
      "learning_rate": 3.648083657165691e-05,
      "loss": 0.0002,
      "step": 9238
    },
    {
      "epoch": 93.8,
      "learning_rate": 3.64694062007776e-05,
      "loss": 0.0007,
      "step": 9239
    },
    {
      "epoch": 93.81,
      "learning_rate": 3.6457976592849754e-05,
      "loss": 0.0053,
      "step": 9240
    },
    {
      "epoch": 93.82,
      "learning_rate": 3.644654774851786e-05,
      "loss": 0.0006,
      "step": 9241
    },
    {
      "epoch": 93.83,
      "learning_rate": 3.643511966842633e-05,
      "loss": 0.0095,
      "step": 9242
    },
    {
      "epoch": 93.84,
      "learning_rate": 3.64236923532196e-05,
      "loss": 0.0001,
      "step": 9243
    },
    {
      "epoch": 93.85,
      "learning_rate": 3.641226580354202e-05,
      "loss": 0.0,
      "step": 9244
    },
    {
      "epoch": 93.86,
      "learning_rate": 3.6400840020037874e-05,
      "loss": 0.0001,
      "step": 9245
    },
    {
      "epoch": 93.87,
      "learning_rate": 3.638941500335145e-05,
      "loss": 0.0014,
      "step": 9246
    },
    {
      "epoch": 93.88,
      "learning_rate": 3.637799075412697e-05,
      "loss": 0.0,
      "step": 9247
    },
    {
      "epoch": 93.89,
      "learning_rate": 3.636656727300859e-05,
      "loss": 0.0117,
      "step": 9248
    },
    {
      "epoch": 93.9,
      "learning_rate": 3.63551445606405e-05,
      "loss": 0.0001,
      "step": 9249
    },
    {
      "epoch": 93.91,
      "learning_rate": 3.6343722617666734e-05,
      "loss": 0.0005,
      "step": 9250
    },
    {
      "epoch": 93.92,
      "learning_rate": 3.6332301444731377e-05,
      "loss": 0.0,
      "step": 9251
    },
    {
      "epoch": 93.93,
      "learning_rate": 3.632088104247844e-05,
      "loss": 0.0002,
      "step": 9252
    },
    {
      "epoch": 93.94,
      "learning_rate": 3.630946141155187e-05,
      "loss": 0.0,
      "step": 9253
    },
    {
      "epoch": 93.95,
      "learning_rate": 3.62980425525956e-05,
      "loss": 0.0,
      "step": 9254
    },
    {
      "epoch": 93.96,
      "learning_rate": 3.628662446625349e-05,
      "loss": 0.0001,
      "step": 9255
    },
    {
      "epoch": 93.97,
      "learning_rate": 3.6275207153169375e-05,
      "loss": 0.0,
      "step": 9256
    },
    {
      "epoch": 93.98,
      "learning_rate": 3.626379061398708e-05,
      "loss": 0.0004,
      "step": 9257
    },
    {
      "epoch": 93.99,
      "learning_rate": 3.625237484935031e-05,
      "loss": 0.0005,
      "step": 9258
    },
    {
      "epoch": 94.0,
      "learning_rate": 3.624095985990278e-05,
      "loss": 0.0,
      "step": 9259
    },
    {
      "epoch": 94.0,
      "eval_loss": 0.019149644300341606,
      "eval_runtime": 31.7143,
      "eval_samples_per_second": 99.324,
      "eval_steps_per_second": 6.212,
      "eval_wer": 0.003265044814340589,
      "step": 9259
    },
    {
      "epoch": 94.01,
      "learning_rate": 3.622954564628816e-05,
      "loss": 0.0,
      "step": 9260
    },
    {
      "epoch": 94.02,
      "learning_rate": 3.6218132209150045e-05,
      "loss": 0.0015,
      "step": 9261
    },
    {
      "epoch": 94.03,
      "learning_rate": 3.620671954913203e-05,
      "loss": 0.0047,
      "step": 9262
    },
    {
      "epoch": 94.04,
      "learning_rate": 3.6195307666877606e-05,
      "loss": 0.0,
      "step": 9263
    },
    {
      "epoch": 94.05,
      "learning_rate": 3.6183896563030295e-05,
      "loss": 0.0001,
      "step": 9264
    },
    {
      "epoch": 94.06,
      "learning_rate": 3.617248623823353e-05,
      "loss": 0.0001,
      "step": 9265
    },
    {
      "epoch": 94.07,
      "learning_rate": 3.616107669313068e-05,
      "loss": 0.0002,
      "step": 9266
    },
    {
      "epoch": 94.08,
      "learning_rate": 3.614966792836512e-05,
      "loss": 0.0108,
      "step": 9267
    },
    {
      "epoch": 94.09,
      "learning_rate": 3.6138259944580155e-05,
      "loss": 0.0005,
      "step": 9268
    },
    {
      "epoch": 94.1,
      "learning_rate": 3.612685274241903e-05,
      "loss": 0.0003,
      "step": 9269
    },
    {
      "epoch": 94.11,
      "learning_rate": 3.6115446322525e-05,
      "loss": 0.0,
      "step": 9270
    },
    {
      "epoch": 94.12,
      "learning_rate": 3.61040406855412e-05,
      "loss": 0.0043,
      "step": 9271
    },
    {
      "epoch": 94.13,
      "learning_rate": 3.6092635832110784e-05,
      "loss": 0.0,
      "step": 9272
    },
    {
      "epoch": 94.14,
      "learning_rate": 3.608123176287685e-05,
      "loss": 0.0001,
      "step": 9273
    },
    {
      "epoch": 94.15,
      "learning_rate": 3.6069828478482415e-05,
      "loss": 0.0021,
      "step": 9274
    },
    {
      "epoch": 94.16,
      "learning_rate": 3.6058425979570485e-05,
      "loss": 0.0001,
      "step": 9275
    },
    {
      "epoch": 94.17,
      "learning_rate": 3.604702426678404e-05,
      "loss": 0.0004,
      "step": 9276
    },
    {
      "epoch": 94.18,
      "learning_rate": 3.603562334076594e-05,
      "loss": 0.0001,
      "step": 9277
    },
    {
      "epoch": 94.19,
      "learning_rate": 3.60242232021591e-05,
      "loss": 0.0,
      "step": 9278
    },
    {
      "epoch": 94.2,
      "learning_rate": 3.601282385160631e-05,
      "loss": 0.0,
      "step": 9279
    },
    {
      "epoch": 94.21,
      "learning_rate": 3.6001425289750366e-05,
      "loss": 0.0029,
      "step": 9280
    },
    {
      "epoch": 94.22,
      "learning_rate": 3.5990027517233994e-05,
      "loss": 0.0001,
      "step": 9281
    },
    {
      "epoch": 94.23,
      "learning_rate": 3.597863053469987e-05,
      "loss": 0.0033,
      "step": 9282
    },
    {
      "epoch": 94.24,
      "learning_rate": 3.596723434279063e-05,
      "loss": 0.0001,
      "step": 9283
    },
    {
      "epoch": 94.25,
      "learning_rate": 3.595583894214892e-05,
      "loss": 0.002,
      "step": 9284
    },
    {
      "epoch": 94.26,
      "learning_rate": 3.594444433341725e-05,
      "loss": 0.0002,
      "step": 9285
    },
    {
      "epoch": 94.27,
      "learning_rate": 3.5933050517238155e-05,
      "loss": 0.0006,
      "step": 9286
    },
    {
      "epoch": 94.28,
      "learning_rate": 3.5921657494254066e-05,
      "loss": 0.0,
      "step": 9287
    },
    {
      "epoch": 94.29,
      "learning_rate": 3.5910265265107426e-05,
      "loss": 0.0002,
      "step": 9288
    },
    {
      "epoch": 94.3,
      "learning_rate": 3.589887383044063e-05,
      "loss": 0.0004,
      "step": 9289
    },
    {
      "epoch": 94.31,
      "learning_rate": 3.588748319089596e-05,
      "loss": 0.0009,
      "step": 9290
    },
    {
      "epoch": 94.32,
      "learning_rate": 3.587609334711576e-05,
      "loss": 0.0055,
      "step": 9291
    },
    {
      "epoch": 94.34,
      "learning_rate": 3.586470429974221e-05,
      "loss": 0.0007,
      "step": 9292
    },
    {
      "epoch": 94.35,
      "learning_rate": 3.5853316049417544e-05,
      "loss": 0.0006,
      "step": 9293
    },
    {
      "epoch": 94.36,
      "learning_rate": 3.584192859678392e-05,
      "loss": 0.0002,
      "step": 9294
    },
    {
      "epoch": 94.37,
      "learning_rate": 3.58305419424834e-05,
      "loss": 0.0,
      "step": 9295
    },
    {
      "epoch": 94.38,
      "learning_rate": 3.5819156087158075e-05,
      "loss": 0.0012,
      "step": 9296
    },
    {
      "epoch": 94.39,
      "learning_rate": 3.5807771031449974e-05,
      "loss": 0.0,
      "step": 9297
    },
    {
      "epoch": 94.4,
      "learning_rate": 3.5796386776001046e-05,
      "loss": 0.0021,
      "step": 9298
    },
    {
      "epoch": 94.41,
      "learning_rate": 3.5785003321453224e-05,
      "loss": 0.0006,
      "step": 9299
    },
    {
      "epoch": 94.42,
      "learning_rate": 3.5773620668448384e-05,
      "loss": 0.0005,
      "step": 9300
    },
    {
      "epoch": 94.43,
      "learning_rate": 3.576223881762836e-05,
      "loss": 0.0,
      "step": 9301
    },
    {
      "epoch": 94.44,
      "learning_rate": 3.575085776963496e-05,
      "loss": 0.0003,
      "step": 9302
    },
    {
      "epoch": 94.45,
      "learning_rate": 3.57394775251099e-05,
      "loss": 0.0001,
      "step": 9303
    },
    {
      "epoch": 94.46,
      "learning_rate": 3.5728098084694894e-05,
      "loss": 0.0,
      "step": 9304
    },
    {
      "epoch": 94.47,
      "learning_rate": 3.571671944903161e-05,
      "loss": 0.0,
      "step": 9305
    },
    {
      "epoch": 94.48,
      "learning_rate": 3.570534161876163e-05,
      "loss": 0.0,
      "step": 9306
    },
    {
      "epoch": 94.49,
      "learning_rate": 3.5693964594526546e-05,
      "loss": 0.0001,
      "step": 9307
    },
    {
      "epoch": 94.5,
      "learning_rate": 3.568258837696785e-05,
      "loss": 0.0001,
      "step": 9308
    },
    {
      "epoch": 94.51,
      "learning_rate": 3.567121296672701e-05,
      "loss": 0.0023,
      "step": 9309
    },
    {
      "epoch": 94.52,
      "learning_rate": 3.5659838364445505e-05,
      "loss": 0.0,
      "step": 9310
    },
    {
      "epoch": 94.53,
      "learning_rate": 3.564846457076464e-05,
      "loss": 0.0055,
      "step": 9311
    },
    {
      "epoch": 94.54,
      "learning_rate": 3.56370915863258e-05,
      "loss": 0.0001,
      "step": 9312
    },
    {
      "epoch": 94.55,
      "learning_rate": 3.5625719411770273e-05,
      "loss": 0.003,
      "step": 9313
    },
    {
      "epoch": 94.56,
      "learning_rate": 3.56143480477393e-05,
      "loss": 0.0019,
      "step": 9314
    },
    {
      "epoch": 94.57,
      "learning_rate": 3.560297749487407e-05,
      "loss": 0.0001,
      "step": 9315
    },
    {
      "epoch": 94.58,
      "learning_rate": 3.559160775381573e-05,
      "loss": 0.0001,
      "step": 9316
    },
    {
      "epoch": 94.59,
      "learning_rate": 3.5580238825205395e-05,
      "loss": 0.0013,
      "step": 9317
    },
    {
      "epoch": 94.6,
      "learning_rate": 3.5568870709684145e-05,
      "loss": 0.0001,
      "step": 9318
    },
    {
      "epoch": 94.61,
      "learning_rate": 3.5557503407892966e-05,
      "loss": 0.0,
      "step": 9319
    },
    {
      "epoch": 94.62,
      "learning_rate": 3.5546136920472845e-05,
      "loss": 0.007,
      "step": 9320
    },
    {
      "epoch": 94.63,
      "learning_rate": 3.5534771248064716e-05,
      "loss": 0.0004,
      "step": 9321
    },
    {
      "epoch": 94.64,
      "learning_rate": 3.5523406391309424e-05,
      "loss": 0.0026,
      "step": 9322
    },
    {
      "epoch": 94.65,
      "learning_rate": 3.5512042350847826e-05,
      "loss": 0.0083,
      "step": 9323
    },
    {
      "epoch": 94.66,
      "learning_rate": 3.550067912732069e-05,
      "loss": 0.0006,
      "step": 9324
    },
    {
      "epoch": 94.67,
      "learning_rate": 3.548931672136878e-05,
      "loss": 0.0,
      "step": 9325
    },
    {
      "epoch": 94.68,
      "learning_rate": 3.547795513363278e-05,
      "loss": 0.0,
      "step": 9326
    },
    {
      "epoch": 94.69,
      "learning_rate": 3.5466594364753326e-05,
      "loss": 0.008,
      "step": 9327
    },
    {
      "epoch": 94.7,
      "learning_rate": 3.545523441537103e-05,
      "loss": 0.0085,
      "step": 9328
    },
    {
      "epoch": 94.71,
      "learning_rate": 3.5443875286126435e-05,
      "loss": 0.0001,
      "step": 9329
    },
    {
      "epoch": 94.72,
      "learning_rate": 3.543251697766006e-05,
      "loss": 0.0001,
      "step": 9330
    },
    {
      "epoch": 94.73,
      "learning_rate": 3.5421159490612386e-05,
      "loss": 0.0,
      "step": 9331
    },
    {
      "epoch": 94.74,
      "learning_rate": 3.540980282562378e-05,
      "loss": 0.0,
      "step": 9332
    },
    {
      "epoch": 94.75,
      "learning_rate": 3.539844698333465e-05,
      "loss": 0.0001,
      "step": 9333
    },
    {
      "epoch": 94.76,
      "learning_rate": 3.5387091964385324e-05,
      "loss": 0.0,
      "step": 9334
    },
    {
      "epoch": 94.77,
      "learning_rate": 3.537573776941606e-05,
      "loss": 0.0001,
      "step": 9335
    },
    {
      "epoch": 94.78,
      "learning_rate": 3.53643843990671e-05,
      "loss": 0.0005,
      "step": 9336
    },
    {
      "epoch": 94.79,
      "learning_rate": 3.5353031853978614e-05,
      "loss": 0.0008,
      "step": 9337
    },
    {
      "epoch": 94.8,
      "learning_rate": 3.534168013479073e-05,
      "loss": 0.0002,
      "step": 9338
    },
    {
      "epoch": 94.81,
      "learning_rate": 3.533032924214358e-05,
      "loss": 0.0005,
      "step": 9339
    },
    {
      "epoch": 94.82,
      "learning_rate": 3.531897917667718e-05,
      "loss": 0.0141,
      "step": 9340
    },
    {
      "epoch": 94.83,
      "learning_rate": 3.5307629939031527e-05,
      "loss": 0.0214,
      "step": 9341
    },
    {
      "epoch": 94.84,
      "learning_rate": 3.52962815298466e-05,
      "loss": 0.0001,
      "step": 9342
    },
    {
      "epoch": 94.85,
      "learning_rate": 3.528493394976226e-05,
      "loss": 0.0003,
      "step": 9343
    },
    {
      "epoch": 94.86,
      "learning_rate": 3.52735871994184e-05,
      "loss": 0.003,
      "step": 9344
    },
    {
      "epoch": 94.87,
      "learning_rate": 3.5262241279454785e-05,
      "loss": 0.0055,
      "step": 9345
    },
    {
      "epoch": 94.88,
      "learning_rate": 3.5250896190511236e-05,
      "loss": 0.0001,
      "step": 9346
    },
    {
      "epoch": 94.89,
      "learning_rate": 3.523955193322745e-05,
      "loss": 0.0001,
      "step": 9347
    },
    {
      "epoch": 94.9,
      "learning_rate": 3.5228208508243076e-05,
      "loss": 0.0002,
      "step": 9348
    },
    {
      "epoch": 94.91,
      "learning_rate": 3.5216865916197764e-05,
      "loss": 0.0088,
      "step": 9349
    },
    {
      "epoch": 94.92,
      "learning_rate": 3.520552415773108e-05,
      "loss": 0.0004,
      "step": 9350
    },
    {
      "epoch": 94.93,
      "learning_rate": 3.5194183233482534e-05,
      "loss": 0.0011,
      "step": 9351
    },
    {
      "epoch": 94.94,
      "learning_rate": 3.518284314409166e-05,
      "loss": 0.0001,
      "step": 9352
    },
    {
      "epoch": 94.95,
      "learning_rate": 3.517150389019783e-05,
      "loss": 0.0013,
      "step": 9353
    },
    {
      "epoch": 94.96,
      "learning_rate": 3.5160165472440473e-05,
      "loss": 0.0046,
      "step": 9354
    },
    {
      "epoch": 94.97,
      "learning_rate": 3.514882789145892e-05,
      "loss": 0.0007,
      "step": 9355
    },
    {
      "epoch": 94.98,
      "learning_rate": 3.513749114789246e-05,
      "loss": 0.0,
      "step": 9356
    },
    {
      "epoch": 94.99,
      "learning_rate": 3.512615524238034e-05,
      "loss": 0.0,
      "step": 9357
    },
    {
      "epoch": 94.99,
      "eval_loss": 0.018790438771247864,
      "eval_runtime": 31.7711,
      "eval_samples_per_second": 99.147,
      "eval_steps_per_second": 6.201,
      "eval_wer": 0.0031049935979513446,
      "step": 9357
    },
    {
      "epoch": 95.01,
      "learning_rate": 3.5114820175561794e-05,
      "loss": 0.0001,
      "step": 9358
    },
    {
      "epoch": 95.02,
      "learning_rate": 3.51034859480759e-05,
      "loss": 0.0002,
      "step": 9359
    },
    {
      "epoch": 95.03,
      "learning_rate": 3.509215256056183e-05,
      "loss": 0.0093,
      "step": 9360
    },
    {
      "epoch": 95.04,
      "learning_rate": 3.508082001365861e-05,
      "loss": 0.001,
      "step": 9361
    },
    {
      "epoch": 95.05,
      "learning_rate": 3.506948830800525e-05,
      "loss": 0.0001,
      "step": 9362
    },
    {
      "epoch": 95.06,
      "learning_rate": 3.505815744424074e-05,
      "loss": 0.0002,
      "step": 9363
    },
    {
      "epoch": 95.07,
      "learning_rate": 3.5046827423003956e-05,
      "loss": 0.0004,
      "step": 9364
    },
    {
      "epoch": 95.08,
      "learning_rate": 3.5035498244933795e-05,
      "loss": 0.0001,
      "step": 9365
    },
    {
      "epoch": 95.09,
      "learning_rate": 3.502416991066904e-05,
      "loss": 0.0001,
      "step": 9366
    },
    {
      "epoch": 95.1,
      "learning_rate": 3.50128424208485e-05,
      "loss": 0.0,
      "step": 9367
    },
    {
      "epoch": 95.11,
      "learning_rate": 3.500151577611091e-05,
      "loss": 0.0002,
      "step": 9368
    },
    {
      "epoch": 95.12,
      "learning_rate": 3.49901899770949e-05,
      "loss": 0.0004,
      "step": 9369
    },
    {
      "epoch": 95.13,
      "learning_rate": 3.497886502443914e-05,
      "loss": 0.0001,
      "step": 9370
    },
    {
      "epoch": 95.14,
      "learning_rate": 3.49675409187822e-05,
      "loss": 0.0002,
      "step": 9371
    },
    {
      "epoch": 95.15,
      "learning_rate": 3.495621766076259e-05,
      "loss": 0.0,
      "step": 9372
    },
    {
      "epoch": 95.16,
      "learning_rate": 3.494489525101884e-05,
      "loss": 0.0,
      "step": 9373
    },
    {
      "epoch": 95.17,
      "learning_rate": 3.493357369018935e-05,
      "loss": 0.0001,
      "step": 9374
    },
    {
      "epoch": 95.18,
      "learning_rate": 3.4922252978912526e-05,
      "loss": 0.0056,
      "step": 9375
    },
    {
      "epoch": 95.19,
      "learning_rate": 3.4910933117826716e-05,
      "loss": 0.0001,
      "step": 9376
    },
    {
      "epoch": 95.2,
      "learning_rate": 3.489961410757021e-05,
      "loss": 0.0001,
      "step": 9377
    },
    {
      "epoch": 95.21,
      "learning_rate": 3.488829594878123e-05,
      "loss": 0.0,
      "step": 9378
    },
    {
      "epoch": 95.22,
      "learning_rate": 3.487697864209803e-05,
      "loss": 0.0,
      "step": 9379
    },
    {
      "epoch": 95.23,
      "learning_rate": 3.486566218815871e-05,
      "loss": 0.0,
      "step": 9380
    },
    {
      "epoch": 95.24,
      "learning_rate": 3.48543465876014e-05,
      "loss": 0.0,
      "step": 9381
    },
    {
      "epoch": 95.25,
      "learning_rate": 3.484303184106413e-05,
      "loss": 0.0001,
      "step": 9382
    },
    {
      "epoch": 95.26,
      "learning_rate": 3.483171794918493e-05,
      "loss": 0.0,
      "step": 9383
    },
    {
      "epoch": 95.27,
      "learning_rate": 3.482040491260176e-05,
      "loss": 0.0,
      "step": 9384
    },
    {
      "epoch": 95.28,
      "learning_rate": 3.48090927319525e-05,
      "loss": 0.0178,
      "step": 9385
    },
    {
      "epoch": 95.29,
      "learning_rate": 3.479778140787504e-05,
      "loss": 0.0002,
      "step": 9386
    },
    {
      "epoch": 95.3,
      "learning_rate": 3.478647094100719e-05,
      "loss": 0.0006,
      "step": 9387
    },
    {
      "epoch": 95.31,
      "learning_rate": 3.4775161331986695e-05,
      "loss": 0.0006,
      "step": 9388
    },
    {
      "epoch": 95.32,
      "learning_rate": 3.476385258145129e-05,
      "loss": 0.0011,
      "step": 9389
    },
    {
      "epoch": 95.33,
      "learning_rate": 3.4752544690038647e-05,
      "loss": 0.0003,
      "step": 9390
    },
    {
      "epoch": 95.34,
      "learning_rate": 3.474123765838636e-05,
      "loss": 0.0001,
      "step": 9391
    },
    {
      "epoch": 95.35,
      "learning_rate": 3.472993148713204e-05,
      "loss": 0.0003,
      "step": 9392
    },
    {
      "epoch": 95.36,
      "learning_rate": 3.471862617691316e-05,
      "loss": 0.0,
      "step": 9393
    },
    {
      "epoch": 95.37,
      "learning_rate": 3.4707321728367246e-05,
      "loss": 0.0002,
      "step": 9394
    },
    {
      "epoch": 95.38,
      "learning_rate": 3.469601814213167e-05,
      "loss": 0.0,
      "step": 9395
    },
    {
      "epoch": 95.39,
      "learning_rate": 3.468471541884385e-05,
      "loss": 0.0001,
      "step": 9396
    },
    {
      "epoch": 95.4,
      "learning_rate": 3.467341355914111e-05,
      "loss": 0.0,
      "step": 9397
    },
    {
      "epoch": 95.41,
      "learning_rate": 3.466211256366071e-05,
      "loss": 0.0009,
      "step": 9398
    },
    {
      "epoch": 95.42,
      "learning_rate": 3.465081243303988e-05,
      "loss": 0.0265,
      "step": 9399
    },
    {
      "epoch": 95.43,
      "learning_rate": 3.463951316791584e-05,
      "loss": 0.0,
      "step": 9400
    },
    {
      "epoch": 95.44,
      "learning_rate": 3.462821476892568e-05,
      "loss": 0.0003,
      "step": 9401
    },
    {
      "epoch": 95.45,
      "learning_rate": 3.461691723670651e-05,
      "loss": 0.0,
      "step": 9402
    },
    {
      "epoch": 95.46,
      "learning_rate": 3.4605620571895356e-05,
      "loss": 0.0,
      "step": 9403
    },
    {
      "epoch": 95.47,
      "learning_rate": 3.45943247751292e-05,
      "loss": 0.0,
      "step": 9404
    },
    {
      "epoch": 95.48,
      "learning_rate": 3.458302984704499e-05,
      "loss": 0.0002,
      "step": 9405
    },
    {
      "epoch": 95.49,
      "learning_rate": 3.45717357882796e-05,
      "loss": 0.0,
      "step": 9406
    },
    {
      "epoch": 95.5,
      "learning_rate": 3.456044259946988e-05,
      "loss": 0.0031,
      "step": 9407
    },
    {
      "epoch": 95.51,
      "learning_rate": 3.4549150281252636e-05,
      "loss": 0.0207,
      "step": 9408
    },
    {
      "epoch": 95.52,
      "learning_rate": 3.453785883426458e-05,
      "loss": 0.0,
      "step": 9409
    },
    {
      "epoch": 95.53,
      "learning_rate": 3.452656825914242e-05,
      "loss": 0.0003,
      "step": 9410
    },
    {
      "epoch": 95.54,
      "learning_rate": 3.45152785565228e-05,
      "loss": 0.0,
      "step": 9411
    },
    {
      "epoch": 95.55,
      "learning_rate": 3.45039897270423e-05,
      "loss": 0.0002,
      "step": 9412
    },
    {
      "epoch": 95.56,
      "learning_rate": 3.44927017713375e-05,
      "loss": 0.0001,
      "step": 9413
    },
    {
      "epoch": 95.57,
      "learning_rate": 3.448141469004484e-05,
      "loss": 0.0,
      "step": 9414
    },
    {
      "epoch": 95.58,
      "learning_rate": 3.4470128483800815e-05,
      "loss": 0.0002,
      "step": 9415
    },
    {
      "epoch": 95.59,
      "learning_rate": 3.4458843153241806e-05,
      "loss": 0.0001,
      "step": 9416
    },
    {
      "epoch": 95.6,
      "learning_rate": 3.4447558699004145e-05,
      "loss": 0.005,
      "step": 9417
    },
    {
      "epoch": 95.61,
      "learning_rate": 3.443627512172416e-05,
      "loss": 0.0022,
      "step": 9418
    },
    {
      "epoch": 95.62,
      "learning_rate": 3.4424992422038084e-05,
      "loss": 0.0,
      "step": 9419
    },
    {
      "epoch": 95.63,
      "learning_rate": 3.44137106005821e-05,
      "loss": 0.0064,
      "step": 9420
    },
    {
      "epoch": 95.64,
      "learning_rate": 3.4402429657992385e-05,
      "loss": 0.0,
      "step": 9421
    },
    {
      "epoch": 95.65,
      "learning_rate": 3.4391149594905016e-05,
      "loss": 0.0007,
      "step": 9422
    },
    {
      "epoch": 95.66,
      "learning_rate": 3.4379870411956063e-05,
      "loss": 0.0009,
      "step": 9423
    },
    {
      "epoch": 95.68,
      "learning_rate": 3.436859210978153e-05,
      "loss": 0.0,
      "step": 9424
    },
    {
      "epoch": 95.69,
      "learning_rate": 3.435731468901734e-05,
      "loss": 0.0,
      "step": 9425
    },
    {
      "epoch": 95.7,
      "learning_rate": 3.434603815029943e-05,
      "loss": 0.0008,
      "step": 9426
    },
    {
      "epoch": 95.71,
      "learning_rate": 3.4334762494263604e-05,
      "loss": 0.0,
      "step": 9427
    },
    {
      "epoch": 95.72,
      "learning_rate": 3.43234877215457e-05,
      "loss": 0.0,
      "step": 9428
    },
    {
      "epoch": 95.73,
      "learning_rate": 3.4312213832781485e-05,
      "loss": 0.0009,
      "step": 9429
    },
    {
      "epoch": 95.74,
      "learning_rate": 3.4300940828606625e-05,
      "loss": 0.0,
      "step": 9430
    },
    {
      "epoch": 95.75,
      "learning_rate": 3.42896687096568e-05,
      "loss": 0.0,
      "step": 9431
    },
    {
      "epoch": 95.76,
      "learning_rate": 3.427839747656759e-05,
      "loss": 0.0003,
      "step": 9432
    },
    {
      "epoch": 95.77,
      "learning_rate": 3.426712712997454e-05,
      "loss": 0.0001,
      "step": 9433
    },
    {
      "epoch": 95.78,
      "learning_rate": 3.42558576705132e-05,
      "loss": 0.0002,
      "step": 9434
    },
    {
      "epoch": 95.79,
      "learning_rate": 3.424458909881897e-05,
      "loss": 0.0004,
      "step": 9435
    },
    {
      "epoch": 95.8,
      "learning_rate": 3.423332141552727e-05,
      "loss": 0.0002,
      "step": 9436
    },
    {
      "epoch": 95.81,
      "learning_rate": 3.4222054621273486e-05,
      "loss": 0.0002,
      "step": 9437
    },
    {
      "epoch": 95.82,
      "learning_rate": 3.4210788716692874e-05,
      "loss": 0.0001,
      "step": 9438
    },
    {
      "epoch": 95.83,
      "learning_rate": 3.419952370242071e-05,
      "loss": 0.0,
      "step": 9439
    },
    {
      "epoch": 95.84,
      "learning_rate": 3.418825957909219e-05,
      "loss": 0.0004,
      "step": 9440
    },
    {
      "epoch": 95.85,
      "learning_rate": 3.4176996347342446e-05,
      "loss": 0.0021,
      "step": 9441
    },
    {
      "epoch": 95.86,
      "learning_rate": 3.416573400780662e-05,
      "loss": 0.0,
      "step": 9442
    },
    {
      "epoch": 95.87,
      "learning_rate": 3.415447256111973e-05,
      "loss": 0.0003,
      "step": 9443
    },
    {
      "epoch": 95.88,
      "learning_rate": 3.414321200791679e-05,
      "loss": 0.0001,
      "step": 9444
    },
    {
      "epoch": 95.89,
      "learning_rate": 3.4131952348832765e-05,
      "loss": 0.0041,
      "step": 9445
    },
    {
      "epoch": 95.9,
      "learning_rate": 3.412069358450252e-05,
      "loss": 0.0002,
      "step": 9446
    },
    {
      "epoch": 95.91,
      "learning_rate": 3.4109435715560937e-05,
      "loss": 0.0001,
      "step": 9447
    },
    {
      "epoch": 95.92,
      "learning_rate": 3.409817874264278e-05,
      "loss": 0.0001,
      "step": 9448
    },
    {
      "epoch": 95.93,
      "learning_rate": 3.408692266638283e-05,
      "loss": 0.0026,
      "step": 9449
    },
    {
      "epoch": 95.94,
      "learning_rate": 3.4075667487415785e-05,
      "loss": 0.0001,
      "step": 9450
    },
    {
      "epoch": 95.95,
      "learning_rate": 3.406441320637627e-05,
      "loss": 0.0,
      "step": 9451
    },
    {
      "epoch": 95.96,
      "learning_rate": 3.4053159823898894e-05,
      "loss": 0.0007,
      "step": 9452
    },
    {
      "epoch": 95.97,
      "learning_rate": 3.404190734061821e-05,
      "loss": 0.0,
      "step": 9453
    },
    {
      "epoch": 95.98,
      "learning_rate": 3.4030655757168684e-05,
      "loss": 0.0006,
      "step": 9454
    },
    {
      "epoch": 95.99,
      "learning_rate": 3.401940507418482e-05,
      "loss": 0.0003,
      "step": 9455
    },
    {
      "epoch": 96.0,
      "learning_rate": 3.4008155292300934e-05,
      "loss": 0.0186,
      "step": 9456
    },
    {
      "epoch": 96.0,
      "eval_loss": 0.019977381452918053,
      "eval_runtime": 31.852,
      "eval_samples_per_second": 98.895,
      "eval_steps_per_second": 6.185,
      "eval_wer": 0.0031370038412291933,
      "step": 9456
    },
    {
      "epoch": 96.01,
      "learning_rate": 3.399690641215142e-05,
      "loss": 0.0001,
      "step": 9457
    },
    {
      "epoch": 96.02,
      "learning_rate": 3.398565843437057e-05,
      "loss": 0.004,
      "step": 9458
    },
    {
      "epoch": 96.03,
      "learning_rate": 3.3974411359592606e-05,
      "loss": 0.0,
      "step": 9459
    },
    {
      "epoch": 96.04,
      "learning_rate": 3.3963165188451717e-05,
      "loss": 0.0001,
      "step": 9460
    },
    {
      "epoch": 96.05,
      "learning_rate": 3.395191992158208e-05,
      "loss": 0.0,
      "step": 9461
    },
    {
      "epoch": 96.06,
      "learning_rate": 3.3940675559617724e-05,
      "loss": 0.0,
      "step": 9462
    },
    {
      "epoch": 96.07,
      "learning_rate": 3.392943210319274e-05,
      "loss": 0.0001,
      "step": 9463
    },
    {
      "epoch": 96.08,
      "learning_rate": 3.391818955294108e-05,
      "loss": 0.0003,
      "step": 9464
    },
    {
      "epoch": 96.09,
      "learning_rate": 3.3906947909496695e-05,
      "loss": 0.0001,
      "step": 9465
    },
    {
      "epoch": 96.1,
      "learning_rate": 3.3895707173493477e-05,
      "loss": 0.0002,
      "step": 9466
    },
    {
      "epoch": 96.11,
      "learning_rate": 3.388446734556523e-05,
      "loss": 0.0014,
      "step": 9467
    },
    {
      "epoch": 96.12,
      "learning_rate": 3.387322842634576e-05,
      "loss": 0.0235,
      "step": 9468
    },
    {
      "epoch": 96.13,
      "learning_rate": 3.386199041646878e-05,
      "loss": 0.0048,
      "step": 9469
    },
    {
      "epoch": 96.14,
      "learning_rate": 3.385075331656798e-05,
      "loss": 0.0005,
      "step": 9470
    },
    {
      "epoch": 96.15,
      "learning_rate": 3.383951712727701e-05,
      "loss": 0.0,
      "step": 9471
    },
    {
      "epoch": 96.16,
      "learning_rate": 3.38282818492294e-05,
      "loss": 0.0001,
      "step": 9472
    },
    {
      "epoch": 96.17,
      "learning_rate": 3.38170474830587e-05,
      "loss": 0.0012,
      "step": 9473
    },
    {
      "epoch": 96.18,
      "learning_rate": 3.380581402939841e-05,
      "loss": 0.0,
      "step": 9474
    },
    {
      "epoch": 96.19,
      "learning_rate": 3.3794581488881896e-05,
      "loss": 0.0003,
      "step": 9475
    },
    {
      "epoch": 96.2,
      "learning_rate": 3.3783349862142585e-05,
      "loss": 0.0,
      "step": 9476
    },
    {
      "epoch": 96.21,
      "learning_rate": 3.377211914981375e-05,
      "loss": 0.0001,
      "step": 9477
    },
    {
      "epoch": 96.22,
      "learning_rate": 3.376088935252868e-05,
      "loss": 0.0011,
      "step": 9478
    },
    {
      "epoch": 96.23,
      "learning_rate": 3.3749660470920595e-05,
      "loss": 0.0065,
      "step": 9479
    },
    {
      "epoch": 96.24,
      "learning_rate": 3.373843250562265e-05,
      "loss": 0.0,
      "step": 9480
    },
    {
      "epoch": 96.25,
      "learning_rate": 3.372720545726795e-05,
      "loss": 0.0,
      "step": 9481
    },
    {
      "epoch": 96.26,
      "learning_rate": 3.37159793264896e-05,
      "loss": 0.0023,
      "step": 9482
    },
    {
      "epoch": 96.27,
      "learning_rate": 3.370475411392055e-05,
      "loss": 0.0004,
      "step": 9483
    },
    {
      "epoch": 96.28,
      "learning_rate": 3.369352982019379e-05,
      "loss": 0.0009,
      "step": 9484
    },
    {
      "epoch": 96.29,
      "learning_rate": 3.3682306445942224e-05,
      "loss": 0.0001,
      "step": 9485
    },
    {
      "epoch": 96.3,
      "learning_rate": 3.36710839917987e-05,
      "loss": 0.0003,
      "step": 9486
    },
    {
      "epoch": 96.31,
      "learning_rate": 3.365986245839603e-05,
      "loss": 0.0001,
      "step": 9487
    },
    {
      "epoch": 96.32,
      "learning_rate": 3.364864184636694e-05,
      "loss": 0.0022,
      "step": 9488
    },
    {
      "epoch": 96.34,
      "learning_rate": 3.363742215634415e-05,
      "loss": 0.0,
      "step": 9489
    },
    {
      "epoch": 96.35,
      "learning_rate": 3.362620338896032e-05,
      "loss": 0.0005,
      "step": 9490
    },
    {
      "epoch": 96.36,
      "learning_rate": 3.361498554484801e-05,
      "loss": 0.0006,
      "step": 9491
    },
    {
      "epoch": 96.37,
      "learning_rate": 3.360376862463979e-05,
      "loss": 0.0,
      "step": 9492
    },
    {
      "epoch": 96.38,
      "learning_rate": 3.3592552628968126e-05,
      "loss": 0.0001,
      "step": 9493
    },
    {
      "epoch": 96.39,
      "learning_rate": 3.3581337558465456e-05,
      "loss": 0.0,
      "step": 9494
    },
    {
      "epoch": 96.4,
      "learning_rate": 3.357012341376421e-05,
      "loss": 0.013,
      "step": 9495
    },
    {
      "epoch": 96.41,
      "learning_rate": 3.3558910195496657e-05,
      "loss": 0.0152,
      "step": 9496
    },
    {
      "epoch": 96.42,
      "learning_rate": 3.3547697904295115e-05,
      "loss": 0.0,
      "step": 9497
    },
    {
      "epoch": 96.43,
      "learning_rate": 3.3536486540791826e-05,
      "loss": 0.0002,
      "step": 9498
    },
    {
      "epoch": 96.44,
      "learning_rate": 3.352527610561894e-05,
      "loss": 0.0,
      "step": 9499
    },
    {
      "epoch": 96.45,
      "learning_rate": 3.35140665994086e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 96.46,
      "learning_rate": 3.350285802279285e-05,
      "loss": 0.0072,
      "step": 9501
    },
    {
      "epoch": 96.47,
      "learning_rate": 3.349165037640372e-05,
      "loss": 0.0011,
      "step": 9502
    },
    {
      "epoch": 96.48,
      "learning_rate": 3.348044366087321e-05,
      "loss": 0.0,
      "step": 9503
    },
    {
      "epoch": 96.49,
      "learning_rate": 3.3469237876833195e-05,
      "loss": 0.0001,
      "step": 9504
    },
    {
      "epoch": 96.5,
      "learning_rate": 3.345803302491556e-05,
      "loss": 0.0,
      "step": 9505
    },
    {
      "epoch": 96.51,
      "learning_rate": 3.34468291057521e-05,
      "loss": 0.0001,
      "step": 9506
    },
    {
      "epoch": 96.52,
      "learning_rate": 3.343562611997459e-05,
      "loss": 0.0,
      "step": 9507
    },
    {
      "epoch": 96.53,
      "learning_rate": 3.342442406821471e-05,
      "loss": 0.0001,
      "step": 9508
    },
    {
      "epoch": 96.54,
      "learning_rate": 3.341322295110411e-05,
      "loss": 0.0001,
      "step": 9509
    },
    {
      "epoch": 96.55,
      "learning_rate": 3.3402022769274425e-05,
      "loss": 0.0,
      "step": 9510
    },
    {
      "epoch": 96.56,
      "learning_rate": 3.339082352335717e-05,
      "loss": 0.0007,
      "step": 9511
    },
    {
      "epoch": 96.57,
      "learning_rate": 3.337962521398385e-05,
      "loss": 0.0103,
      "step": 9512
    },
    {
      "epoch": 96.58,
      "learning_rate": 3.336842784178591e-05,
      "loss": 0.0,
      "step": 9513
    },
    {
      "epoch": 96.59,
      "learning_rate": 3.3357231407394724e-05,
      "loss": 0.0001,
      "step": 9514
    },
    {
      "epoch": 96.6,
      "learning_rate": 3.334603591144162e-05,
      "loss": 0.0,
      "step": 9515
    },
    {
      "epoch": 96.61,
      "learning_rate": 3.333484135455792e-05,
      "loss": 0.0001,
      "step": 9516
    },
    {
      "epoch": 96.62,
      "learning_rate": 3.332364773737481e-05,
      "loss": 0.0002,
      "step": 9517
    },
    {
      "epoch": 96.63,
      "learning_rate": 3.3312455060523486e-05,
      "loss": 0.0015,
      "step": 9518
    },
    {
      "epoch": 96.64,
      "learning_rate": 3.3301263324635065e-05,
      "loss": 0.0,
      "step": 9519
    },
    {
      "epoch": 96.65,
      "learning_rate": 3.329007253034063e-05,
      "loss": 0.0,
      "step": 9520
    },
    {
      "epoch": 96.66,
      "learning_rate": 3.327888267827118e-05,
      "loss": 0.0001,
      "step": 9521
    },
    {
      "epoch": 96.67,
      "learning_rate": 3.32676937690577e-05,
      "loss": 0.0001,
      "step": 9522
    },
    {
      "epoch": 96.68,
      "learning_rate": 3.325650580333106e-05,
      "loss": 0.0019,
      "step": 9523
    },
    {
      "epoch": 96.69,
      "learning_rate": 3.324531878172216e-05,
      "loss": 0.0086,
      "step": 9524
    },
    {
      "epoch": 96.7,
      "learning_rate": 3.323413270486179e-05,
      "loss": 0.0018,
      "step": 9525
    },
    {
      "epoch": 96.71,
      "learning_rate": 3.322294757338069e-05,
      "loss": 0.0002,
      "step": 9526
    },
    {
      "epoch": 96.72,
      "learning_rate": 3.3211763387909585e-05,
      "loss": 0.0038,
      "step": 9527
    },
    {
      "epoch": 96.73,
      "learning_rate": 3.320058014907909e-05,
      "loss": 0.0,
      "step": 9528
    },
    {
      "epoch": 96.74,
      "learning_rate": 3.318939785751981e-05,
      "loss": 0.0026,
      "step": 9529
    },
    {
      "epoch": 96.75,
      "learning_rate": 3.3178216513862265e-05,
      "loss": 0.0,
      "step": 9530
    },
    {
      "epoch": 96.76,
      "learning_rate": 3.316703611873696e-05,
      "loss": 0.0002,
      "step": 9531
    },
    {
      "epoch": 96.77,
      "learning_rate": 3.3155856672774335e-05,
      "loss": 0.0001,
      "step": 9532
    },
    {
      "epoch": 96.78,
      "learning_rate": 3.314467817660474e-05,
      "loss": 0.0001,
      "step": 9533
    },
    {
      "epoch": 96.79,
      "learning_rate": 3.313350063085851e-05,
      "loss": 0.0001,
      "step": 9534
    },
    {
      "epoch": 96.8,
      "learning_rate": 3.3122324036165913e-05,
      "loss": 0.0021,
      "step": 9535
    },
    {
      "epoch": 96.81,
      "learning_rate": 3.311114839315715e-05,
      "loss": 0.0001,
      "step": 9536
    },
    {
      "epoch": 96.82,
      "learning_rate": 3.309997370246244e-05,
      "loss": 0.0002,
      "step": 9537
    },
    {
      "epoch": 96.83,
      "learning_rate": 3.3088799964711815e-05,
      "loss": 0.005,
      "step": 9538
    },
    {
      "epoch": 96.84,
      "learning_rate": 3.307762718053537e-05,
      "loss": 0.0023,
      "step": 9539
    },
    {
      "epoch": 96.85,
      "learning_rate": 3.306645535056312e-05,
      "loss": 0.0137,
      "step": 9540
    },
    {
      "epoch": 96.86,
      "learning_rate": 3.305528447542499e-05,
      "loss": 0.0007,
      "step": 9541
    },
    {
      "epoch": 96.87,
      "learning_rate": 3.304411455575088e-05,
      "loss": 0.0106,
      "step": 9542
    },
    {
      "epoch": 96.88,
      "learning_rate": 3.303294559217063e-05,
      "loss": 0.0001,
      "step": 9543
    },
    {
      "epoch": 96.89,
      "learning_rate": 3.3021777585314003e-05,
      "loss": 0.0,
      "step": 9544
    },
    {
      "epoch": 96.9,
      "learning_rate": 3.301061053581078e-05,
      "loss": 0.0007,
      "step": 9545
    },
    {
      "epoch": 96.91,
      "learning_rate": 3.29994444442906e-05,
      "loss": 0.0011,
      "step": 9546
    },
    {
      "epoch": 96.92,
      "learning_rate": 3.2988279311383094e-05,
      "loss": 0.0117,
      "step": 9547
    },
    {
      "epoch": 96.93,
      "learning_rate": 3.2977115137717854e-05,
      "loss": 0.0007,
      "step": 9548
    },
    {
      "epoch": 96.94,
      "learning_rate": 3.2965951923924364e-05,
      "loss": 0.0001,
      "step": 9549
    },
    {
      "epoch": 96.95,
      "learning_rate": 3.295478967063211e-05,
      "loss": 0.0001,
      "step": 9550
    },
    {
      "epoch": 96.96,
      "learning_rate": 3.294362837847048e-05,
      "loss": 0.0007,
      "step": 9551
    },
    {
      "epoch": 96.97,
      "learning_rate": 3.293246804806884e-05,
      "loss": 0.0211,
      "step": 9552
    },
    {
      "epoch": 96.98,
      "learning_rate": 3.29213086800565e-05,
      "loss": 0.0001,
      "step": 9553
    },
    {
      "epoch": 96.99,
      "learning_rate": 3.2910150275062666e-05,
      "loss": 0.0,
      "step": 9554
    },
    {
      "epoch": 96.99,
      "eval_loss": 0.020175915211439133,
      "eval_runtime": 32.832,
      "eval_samples_per_second": 95.943,
      "eval_steps_per_second": 6.0,
      "eval_wer": 0.003297055057618438,
      "step": 9554
    },
    {
      "epoch": 97.01,
      "learning_rate": 3.289899283371657e-05,
      "loss": 0.0,
      "step": 9555
    },
    {
      "epoch": 97.02,
      "learning_rate": 3.288783635664733e-05,
      "loss": 0.0116,
      "step": 9556
    },
    {
      "epoch": 97.03,
      "learning_rate": 3.287668084448402e-05,
      "loss": 0.0004,
      "step": 9557
    },
    {
      "epoch": 97.04,
      "learning_rate": 3.28655262978557e-05,
      "loss": 0.0,
      "step": 9558
    },
    {
      "epoch": 97.05,
      "learning_rate": 3.2854372717391294e-05,
      "loss": 0.0006,
      "step": 9559
    },
    {
      "epoch": 97.06,
      "learning_rate": 3.284322010371975e-05,
      "loss": 0.0002,
      "step": 9560
    },
    {
      "epoch": 97.07,
      "learning_rate": 3.2832068457469945e-05,
      "loss": 0.0,
      "step": 9561
    },
    {
      "epoch": 97.08,
      "learning_rate": 3.282091777927065e-05,
      "loss": 0.0007,
      "step": 9562
    },
    {
      "epoch": 97.09,
      "learning_rate": 3.280976806975065e-05,
      "loss": 0.0003,
      "step": 9563
    },
    {
      "epoch": 97.1,
      "learning_rate": 3.279861932953865e-05,
      "loss": 0.0019,
      "step": 9564
    },
    {
      "epoch": 97.11,
      "learning_rate": 3.278747155926326e-05,
      "loss": 0.0059,
      "step": 9565
    },
    {
      "epoch": 97.12,
      "learning_rate": 3.277632475955311e-05,
      "loss": 0.0,
      "step": 9566
    },
    {
      "epoch": 97.13,
      "learning_rate": 3.276517893103672e-05,
      "loss": 0.0,
      "step": 9567
    },
    {
      "epoch": 97.14,
      "learning_rate": 3.2754034074342555e-05,
      "loss": 0.0014,
      "step": 9568
    },
    {
      "epoch": 97.15,
      "learning_rate": 3.2742890190099076e-05,
      "loss": 0.0004,
      "step": 9569
    },
    {
      "epoch": 97.16,
      "learning_rate": 3.273174727893463e-05,
      "loss": 0.0001,
      "step": 9570
    },
    {
      "epoch": 97.17,
      "learning_rate": 3.272060534147754e-05,
      "loss": 0.0004,
      "step": 9571
    },
    {
      "epoch": 97.18,
      "learning_rate": 3.2709464378356056e-05,
      "loss": 0.0011,
      "step": 9572
    },
    {
      "epoch": 97.19,
      "learning_rate": 3.2698324390198396e-05,
      "loss": 0.0009,
      "step": 9573
    },
    {
      "epoch": 97.2,
      "learning_rate": 3.268718537763273e-05,
      "loss": 0.0,
      "step": 9574
    },
    {
      "epoch": 97.21,
      "learning_rate": 3.267604734128713e-05,
      "loss": 0.0002,
      "step": 9575
    },
    {
      "epoch": 97.22,
      "learning_rate": 3.266491028178964e-05,
      "loss": 0.0,
      "step": 9576
    },
    {
      "epoch": 97.23,
      "learning_rate": 3.265377419976827e-05,
      "loss": 0.0,
      "step": 9577
    },
    {
      "epoch": 97.24,
      "learning_rate": 3.264263909585092e-05,
      "loss": 0.0,
      "step": 9578
    },
    {
      "epoch": 97.25,
      "learning_rate": 3.26315049706655e-05,
      "loss": 0.0,
      "step": 9579
    },
    {
      "epoch": 97.26,
      "learning_rate": 3.262037182483979e-05,
      "loss": 0.0,
      "step": 9580
    },
    {
      "epoch": 97.27,
      "learning_rate": 3.260923965900159e-05,
      "loss": 0.0001,
      "step": 9581
    },
    {
      "epoch": 97.28,
      "learning_rate": 3.25981084737786e-05,
      "loss": 0.0004,
      "step": 9582
    },
    {
      "epoch": 97.29,
      "learning_rate": 3.258697826979847e-05,
      "loss": 0.0,
      "step": 9583
    },
    {
      "epoch": 97.3,
      "learning_rate": 3.25758490476888e-05,
      "loss": 0.0013,
      "step": 9584
    },
    {
      "epoch": 97.31,
      "learning_rate": 3.256472080807716e-05,
      "loss": 0.0,
      "step": 9585
    },
    {
      "epoch": 97.32,
      "learning_rate": 3.2553593551591e-05,
      "loss": 0.0005,
      "step": 9586
    },
    {
      "epoch": 97.33,
      "learning_rate": 3.2542467278857793e-05,
      "loss": 0.0001,
      "step": 9587
    },
    {
      "epoch": 97.34,
      "learning_rate": 3.2531341990504896e-05,
      "loss": 0.0003,
      "step": 9588
    },
    {
      "epoch": 97.35,
      "learning_rate": 3.2520217687159626e-05,
      "loss": 0.0001,
      "step": 9589
    },
    {
      "epoch": 97.36,
      "learning_rate": 3.250909436944928e-05,
      "loss": 0.0035,
      "step": 9590
    },
    {
      "epoch": 97.37,
      "learning_rate": 3.249797203800102e-05,
      "loss": 0.0005,
      "step": 9591
    },
    {
      "epoch": 97.38,
      "learning_rate": 3.248685069344205e-05,
      "loss": 0.0055,
      "step": 9592
    },
    {
      "epoch": 97.39,
      "learning_rate": 3.2475730336399454e-05,
      "loss": 0.0001,
      "step": 9593
    },
    {
      "epoch": 97.4,
      "learning_rate": 3.246461096750028e-05,
      "loss": 0.0037,
      "step": 9594
    },
    {
      "epoch": 97.41,
      "learning_rate": 3.2453492587371516e-05,
      "loss": 0.0018,
      "step": 9595
    },
    {
      "epoch": 97.42,
      "learning_rate": 3.2442375196640086e-05,
      "loss": 0.0001,
      "step": 9596
    },
    {
      "epoch": 97.43,
      "learning_rate": 3.243125879593286e-05,
      "loss": 0.0011,
      "step": 9597
    },
    {
      "epoch": 97.44,
      "learning_rate": 3.242014338587671e-05,
      "loss": 0.0,
      "step": 9598
    },
    {
      "epoch": 97.45,
      "learning_rate": 3.240902896709834e-05,
      "loss": 0.0191,
      "step": 9599
    },
    {
      "epoch": 97.46,
      "learning_rate": 3.239791554022449e-05,
      "loss": 0.0001,
      "step": 9600
    },
    {
      "epoch": 97.47,
      "learning_rate": 3.238680310588184e-05,
      "loss": 0.0,
      "step": 9601
    },
    {
      "epoch": 97.48,
      "learning_rate": 3.2375691664696926e-05,
      "loss": 0.0002,
      "step": 9602
    },
    {
      "epoch": 97.49,
      "learning_rate": 3.2364581217296355e-05,
      "loss": 0.0112,
      "step": 9603
    },
    {
      "epoch": 97.5,
      "learning_rate": 3.235347176430656e-05,
      "loss": 0.0,
      "step": 9604
    },
    {
      "epoch": 97.51,
      "learning_rate": 3.2342363306354e-05,
      "loss": 0.0,
      "step": 9605
    },
    {
      "epoch": 97.52,
      "learning_rate": 3.233125584406505e-05,
      "loss": 0.0002,
      "step": 9606
    },
    {
      "epoch": 97.53,
      "learning_rate": 3.232014937806602e-05,
      "loss": 0.0001,
      "step": 9607
    },
    {
      "epoch": 97.54,
      "learning_rate": 3.230904390898318e-05,
      "loss": 0.0001,
      "step": 9608
    },
    {
      "epoch": 97.55,
      "learning_rate": 3.229793943744271e-05,
      "loss": 0.0013,
      "step": 9609
    },
    {
      "epoch": 97.56,
      "learning_rate": 3.2286835964070796e-05,
      "loss": 0.0001,
      "step": 9610
    },
    {
      "epoch": 97.57,
      "learning_rate": 3.2275733489493513e-05,
      "loss": 0.0002,
      "step": 9611
    },
    {
      "epoch": 97.58,
      "learning_rate": 3.226463201433688e-05,
      "loss": 0.0,
      "step": 9612
    },
    {
      "epoch": 97.59,
      "learning_rate": 3.225353153922691e-05,
      "loss": 0.0,
      "step": 9613
    },
    {
      "epoch": 97.6,
      "learning_rate": 3.224243206478952e-05,
      "loss": 0.0018,
      "step": 9614
    },
    {
      "epoch": 97.61,
      "learning_rate": 3.223133359165056e-05,
      "loss": 0.0,
      "step": 9615
    },
    {
      "epoch": 97.62,
      "learning_rate": 3.2220236120435866e-05,
      "loss": 0.0,
      "step": 9616
    },
    {
      "epoch": 97.63,
      "learning_rate": 3.220913965177117e-05,
      "loss": 0.0,
      "step": 9617
    },
    {
      "epoch": 97.64,
      "learning_rate": 3.219804418628216e-05,
      "loss": 0.0,
      "step": 9618
    },
    {
      "epoch": 97.65,
      "learning_rate": 3.218694972459453e-05,
      "loss": 0.0,
      "step": 9619
    },
    {
      "epoch": 97.66,
      "learning_rate": 3.21758562673338e-05,
      "loss": 0.0006,
      "step": 9620
    },
    {
      "epoch": 97.68,
      "learning_rate": 3.216476381512554e-05,
      "loss": 0.004,
      "step": 9621
    },
    {
      "epoch": 97.69,
      "learning_rate": 3.2153672368595223e-05,
      "loss": 0.0001,
      "step": 9622
    },
    {
      "epoch": 97.7,
      "learning_rate": 3.214258192836824e-05,
      "loss": 0.0004,
      "step": 9623
    },
    {
      "epoch": 97.71,
      "learning_rate": 3.213149249506997e-05,
      "loss": 0.0132,
      "step": 9624
    },
    {
      "epoch": 97.72,
      "learning_rate": 3.212040406932569e-05,
      "loss": 0.0001,
      "step": 9625
    },
    {
      "epoch": 97.73,
      "learning_rate": 3.210931665176066e-05,
      "loss": 0.0,
      "step": 9626
    },
    {
      "epoch": 97.74,
      "learning_rate": 3.209823024300009e-05,
      "loss": 0.001,
      "step": 9627
    },
    {
      "epoch": 97.75,
      "learning_rate": 3.208714484366907e-05,
      "loss": 0.0001,
      "step": 9628
    },
    {
      "epoch": 97.76,
      "learning_rate": 3.2076060454392695e-05,
      "loss": 0.0,
      "step": 9629
    },
    {
      "epoch": 97.77,
      "learning_rate": 3.206497707579599e-05,
      "loss": 0.0002,
      "step": 9630
    },
    {
      "epoch": 97.78,
      "learning_rate": 3.20538947085039e-05,
      "loss": 0.0,
      "step": 9631
    },
    {
      "epoch": 97.79,
      "learning_rate": 3.204281335314133e-05,
      "loss": 0.0002,
      "step": 9632
    },
    {
      "epoch": 97.8,
      "learning_rate": 3.203173301033312e-05,
      "loss": 0.0001,
      "step": 9633
    },
    {
      "epoch": 97.81,
      "learning_rate": 3.202065368070407e-05,
      "loss": 0.0,
      "step": 9634
    },
    {
      "epoch": 97.82,
      "learning_rate": 3.200957536487893e-05,
      "loss": 0.004,
      "step": 9635
    },
    {
      "epoch": 97.83,
      "learning_rate": 3.199849806348233e-05,
      "loss": 0.0009,
      "step": 9636
    },
    {
      "epoch": 97.84,
      "learning_rate": 3.1987421777138915e-05,
      "loss": 0.0,
      "step": 9637
    },
    {
      "epoch": 97.85,
      "learning_rate": 3.1976346506473254e-05,
      "loss": 0.0,
      "step": 9638
    },
    {
      "epoch": 97.86,
      "learning_rate": 3.1965272252109816e-05,
      "loss": 0.0065,
      "step": 9639
    },
    {
      "epoch": 97.87,
      "learning_rate": 3.19541990146731e-05,
      "loss": 0.0125,
      "step": 9640
    },
    {
      "epoch": 97.88,
      "learning_rate": 3.194312679478743e-05,
      "loss": 0.0027,
      "step": 9641
    },
    {
      "epoch": 97.89,
      "learning_rate": 3.193205559307717e-05,
      "loss": 0.0001,
      "step": 9642
    },
    {
      "epoch": 97.9,
      "learning_rate": 3.192098541016662e-05,
      "loss": 0.005,
      "step": 9643
    },
    {
      "epoch": 97.91,
      "learning_rate": 3.1909916246679936e-05,
      "loss": 0.0,
      "step": 9644
    },
    {
      "epoch": 97.92,
      "learning_rate": 3.189884810324133e-05,
      "loss": 0.0001,
      "step": 9645
    },
    {
      "epoch": 97.93,
      "learning_rate": 3.1887780980474865e-05,
      "loss": 0.0001,
      "step": 9646
    },
    {
      "epoch": 97.94,
      "learning_rate": 3.1876714879004596e-05,
      "loss": 0.0,
      "step": 9647
    },
    {
      "epoch": 97.95,
      "learning_rate": 3.186564979945453e-05,
      "loss": 0.0,
      "step": 9648
    },
    {
      "epoch": 97.96,
      "learning_rate": 3.1854585742448573e-05,
      "loss": 0.0001,
      "step": 9649
    },
    {
      "epoch": 97.97,
      "learning_rate": 3.1843522708610594e-05,
      "loss": 0.0002,
      "step": 9650
    },
    {
      "epoch": 97.98,
      "learning_rate": 3.183246069856443e-05,
      "loss": 0.0,
      "step": 9651
    },
    {
      "epoch": 97.99,
      "learning_rate": 3.1821399712933805e-05,
      "loss": 0.0001,
      "step": 9652
    },
    {
      "epoch": 98.0,
      "learning_rate": 3.1810339752342446e-05,
      "loss": 0.0,
      "step": 9653
    },
    {
      "epoch": 98.0,
      "eval_loss": 0.021165698766708374,
      "eval_runtime": 31.8589,
      "eval_samples_per_second": 98.873,
      "eval_steps_per_second": 6.184,
      "eval_wer": 0.0033290653008962866,
      "step": 9653
    },
    {
      "epoch": 98.01,
      "learning_rate": 3.1799280817413944e-05,
      "loss": 0.0,
      "step": 9654
    },
    {
      "epoch": 98.02,
      "learning_rate": 3.1788222908771934e-05,
      "loss": 0.0,
      "step": 9655
    },
    {
      "epoch": 98.03,
      "learning_rate": 3.1777166027039926e-05,
      "loss": 0.0002,
      "step": 9656
    },
    {
      "epoch": 98.04,
      "learning_rate": 3.176611017284137e-05,
      "loss": 0.0,
      "step": 9657
    },
    {
      "epoch": 98.05,
      "learning_rate": 3.175505534679968e-05,
      "loss": 0.0006,
      "step": 9658
    },
    {
      "epoch": 98.06,
      "learning_rate": 3.1744001549538214e-05,
      "loss": 0.0001,
      "step": 9659
    },
    {
      "epoch": 98.07,
      "learning_rate": 3.173294878168025e-05,
      "loss": 0.0001,
      "step": 9660
    },
    {
      "epoch": 98.08,
      "learning_rate": 3.1721897043849056e-05,
      "loss": 0.0003,
      "step": 9661
    },
    {
      "epoch": 98.09,
      "learning_rate": 3.1710846336667753e-05,
      "loss": 0.0006,
      "step": 9662
    },
    {
      "epoch": 98.1,
      "learning_rate": 3.169979666075949e-05,
      "loss": 0.0002,
      "step": 9663
    },
    {
      "epoch": 98.11,
      "learning_rate": 3.168874801674735e-05,
      "loss": 0.0002,
      "step": 9664
    },
    {
      "epoch": 98.12,
      "learning_rate": 3.16777004052543e-05,
      "loss": 0.0004,
      "step": 9665
    },
    {
      "epoch": 98.13,
      "learning_rate": 3.166665382690327e-05,
      "loss": 0.0088,
      "step": 9666
    },
    {
      "epoch": 98.14,
      "learning_rate": 3.1655608282317204e-05,
      "loss": 0.0,
      "step": 9667
    },
    {
      "epoch": 98.15,
      "learning_rate": 3.1644563772118864e-05,
      "loss": 0.0001,
      "step": 9668
    },
    {
      "epoch": 98.16,
      "learning_rate": 3.163352029693106e-05,
      "loss": 0.0,
      "step": 9669
    },
    {
      "epoch": 98.17,
      "learning_rate": 3.162247785737649e-05,
      "loss": 0.0002,
      "step": 9670
    },
    {
      "epoch": 98.18,
      "learning_rate": 3.16114364540778e-05,
      "loss": 0.0001,
      "step": 9671
    },
    {
      "epoch": 98.19,
      "learning_rate": 3.160039608765759e-05,
      "loss": 0.0036,
      "step": 9672
    },
    {
      "epoch": 98.2,
      "learning_rate": 3.1589356758738395e-05,
      "loss": 0.0,
      "step": 9673
    },
    {
      "epoch": 98.21,
      "learning_rate": 3.157831846794267e-05,
      "loss": 0.0001,
      "step": 9674
    },
    {
      "epoch": 98.22,
      "learning_rate": 3.156728121589287e-05,
      "loss": 0.0006,
      "step": 9675
    },
    {
      "epoch": 98.23,
      "learning_rate": 3.155624500321133e-05,
      "loss": 0.0,
      "step": 9676
    },
    {
      "epoch": 98.24,
      "learning_rate": 3.154520983052036e-05,
      "loss": 0.0108,
      "step": 9677
    },
    {
      "epoch": 98.25,
      "learning_rate": 3.153417569844219e-05,
      "loss": 0.0001,
      "step": 9678
    },
    {
      "epoch": 98.26,
      "learning_rate": 3.1523142607599e-05,
      "loss": 0.0001,
      "step": 9679
    },
    {
      "epoch": 98.27,
      "learning_rate": 3.151211055861295e-05,
      "loss": 0.0,
      "step": 9680
    },
    {
      "epoch": 98.28,
      "learning_rate": 3.150107955210606e-05,
      "loss": 0.0002,
      "step": 9681
    },
    {
      "epoch": 98.29,
      "learning_rate": 3.149004958870038e-05,
      "loss": 0.0003,
      "step": 9682
    },
    {
      "epoch": 98.3,
      "learning_rate": 3.147902066901781e-05,
      "loss": 0.0017,
      "step": 9683
    },
    {
      "epoch": 98.31,
      "learning_rate": 3.146799279368027e-05,
      "loss": 0.0194,
      "step": 9684
    },
    {
      "epoch": 98.32,
      "learning_rate": 3.1456965963309596e-05,
      "loss": 0.0006,
      "step": 9685
    },
    {
      "epoch": 98.34,
      "learning_rate": 3.144594017852754e-05,
      "loss": 0.0011,
      "step": 9686
    },
    {
      "epoch": 98.35,
      "learning_rate": 3.143491543995581e-05,
      "loss": 0.0006,
      "step": 9687
    },
    {
      "epoch": 98.36,
      "learning_rate": 3.14238917482161e-05,
      "loss": 0.0092,
      "step": 9688
    },
    {
      "epoch": 98.37,
      "learning_rate": 3.141286910392996e-05,
      "loss": 0.0002,
      "step": 9689
    },
    {
      "epoch": 98.38,
      "learning_rate": 3.140184750771895e-05,
      "loss": 0.0003,
      "step": 9690
    },
    {
      "epoch": 98.39,
      "learning_rate": 3.1390826960204534e-05,
      "loss": 0.0005,
      "step": 9691
    },
    {
      "epoch": 98.4,
      "learning_rate": 3.137980746200814e-05,
      "loss": 0.0001,
      "step": 9692
    },
    {
      "epoch": 98.41,
      "learning_rate": 3.136878901375111e-05,
      "loss": 0.0007,
      "step": 9693
    },
    {
      "epoch": 98.42,
      "learning_rate": 3.135777161605475e-05,
      "loss": 0.0019,
      "step": 9694
    },
    {
      "epoch": 98.43,
      "learning_rate": 3.1346755269540303e-05,
      "loss": 0.0,
      "step": 9695
    },
    {
      "epoch": 98.44,
      "learning_rate": 3.133573997482896e-05,
      "loss": 0.0001,
      "step": 9696
    },
    {
      "epoch": 98.45,
      "learning_rate": 3.132472573254182e-05,
      "loss": 0.0001,
      "step": 9697
    },
    {
      "epoch": 98.46,
      "learning_rate": 3.131371254329997e-05,
      "loss": 0.0001,
      "step": 9698
    },
    {
      "epoch": 98.47,
      "learning_rate": 3.130270040772437e-05,
      "loss": 0.0001,
      "step": 9699
    },
    {
      "epoch": 98.48,
      "learning_rate": 3.129168932643599e-05,
      "loss": 0.0005,
      "step": 9700
    },
    {
      "epoch": 98.49,
      "learning_rate": 3.1280679300055746e-05,
      "loss": 0.0,
      "step": 9701
    },
    {
      "epoch": 98.5,
      "learning_rate": 3.12696703292044e-05,
      "loss": 0.0,
      "step": 9702
    },
    {
      "epoch": 98.51,
      "learning_rate": 3.125866241450275e-05,
      "loss": 0.0001,
      "step": 9703
    },
    {
      "epoch": 98.52,
      "learning_rate": 3.124765555657151e-05,
      "loss": 0.0,
      "step": 9704
    },
    {
      "epoch": 98.53,
      "learning_rate": 3.12366497560313e-05,
      "loss": 0.0016,
      "step": 9705
    },
    {
      "epoch": 98.54,
      "learning_rate": 3.1225645013502726e-05,
      "loss": 0.0,
      "step": 9706
    },
    {
      "epoch": 98.55,
      "learning_rate": 3.121464132960629e-05,
      "loss": 0.0018,
      "step": 9707
    },
    {
      "epoch": 98.56,
      "learning_rate": 3.120363870496247e-05,
      "loss": 0.0011,
      "step": 9708
    },
    {
      "epoch": 98.57,
      "learning_rate": 3.1192637140191696e-05,
      "loss": 0.0002,
      "step": 9709
    },
    {
      "epoch": 98.58,
      "learning_rate": 3.118163663591428e-05,
      "loss": 0.0001,
      "step": 9710
    },
    {
      "epoch": 98.59,
      "learning_rate": 3.1170637192750517e-05,
      "loss": 0.0001,
      "step": 9711
    },
    {
      "epoch": 98.6,
      "learning_rate": 3.1159638811320666e-05,
      "loss": 0.0001,
      "step": 9712
    },
    {
      "epoch": 98.61,
      "learning_rate": 3.114864149224484e-05,
      "loss": 0.0,
      "step": 9713
    },
    {
      "epoch": 98.62,
      "learning_rate": 3.1137645236143205e-05,
      "loss": 0.0002,
      "step": 9714
    },
    {
      "epoch": 98.63,
      "learning_rate": 3.112665004363575e-05,
      "loss": 0.0002,
      "step": 9715
    },
    {
      "epoch": 98.64,
      "learning_rate": 3.1115655915342496e-05,
      "loss": 0.0001,
      "step": 9716
    },
    {
      "epoch": 98.65,
      "learning_rate": 3.110466285188338e-05,
      "loss": 0.0,
      "step": 9717
    },
    {
      "epoch": 98.66,
      "learning_rate": 3.109367085387824e-05,
      "loss": 0.0,
      "step": 9718
    },
    {
      "epoch": 98.67,
      "learning_rate": 3.108267992194691e-05,
      "loss": 0.0002,
      "step": 9719
    },
    {
      "epoch": 98.68,
      "learning_rate": 3.107169005670912e-05,
      "loss": 0.0,
      "step": 9720
    },
    {
      "epoch": 98.69,
      "learning_rate": 3.106070125878455e-05,
      "loss": 0.0,
      "step": 9721
    },
    {
      "epoch": 98.7,
      "learning_rate": 3.104971352879287e-05,
      "loss": 0.0001,
      "step": 9722
    },
    {
      "epoch": 98.71,
      "learning_rate": 3.103872686735358e-05,
      "loss": 0.0,
      "step": 9723
    },
    {
      "epoch": 98.72,
      "learning_rate": 3.1027741275086235e-05,
      "loss": 0.0,
      "step": 9724
    },
    {
      "epoch": 98.73,
      "learning_rate": 3.101675675261028e-05,
      "loss": 0.0005,
      "step": 9725
    },
    {
      "epoch": 98.74,
      "learning_rate": 3.1005773300545084e-05,
      "loss": 0.0,
      "step": 9726
    },
    {
      "epoch": 98.75,
      "learning_rate": 3.0994790919509975e-05,
      "loss": 0.0002,
      "step": 9727
    },
    {
      "epoch": 98.76,
      "learning_rate": 3.098380961012422e-05,
      "loss": 0.0001,
      "step": 9728
    },
    {
      "epoch": 98.77,
      "learning_rate": 3.097282937300701e-05,
      "loss": 0.0003,
      "step": 9729
    },
    {
      "epoch": 98.78,
      "learning_rate": 3.0961850208777523e-05,
      "loss": 0.0014,
      "step": 9730
    },
    {
      "epoch": 98.79,
      "learning_rate": 3.0950872118054816e-05,
      "loss": 0.0001,
      "step": 9731
    },
    {
      "epoch": 98.8,
      "learning_rate": 3.0939895101457916e-05,
      "loss": 0.0001,
      "step": 9732
    },
    {
      "epoch": 98.81,
      "learning_rate": 3.09289191596058e-05,
      "loss": 0.0002,
      "step": 9733
    },
    {
      "epoch": 98.82,
      "learning_rate": 3.091794429311735e-05,
      "loss": 0.0,
      "step": 9734
    },
    {
      "epoch": 98.83,
      "learning_rate": 3.0906970502611426e-05,
      "loss": 0.0,
      "step": 9735
    },
    {
      "epoch": 98.84,
      "learning_rate": 3.0895997788706776e-05,
      "loss": 0.0001,
      "step": 9736
    },
    {
      "epoch": 98.85,
      "learning_rate": 3.088502615202216e-05,
      "loss": 0.0,
      "step": 9737
    },
    {
      "epoch": 98.86,
      "learning_rate": 3.0874055593176224e-05,
      "loss": 0.0006,
      "step": 9738
    },
    {
      "epoch": 98.87,
      "learning_rate": 3.086308611278754e-05,
      "loss": 0.0001,
      "step": 9739
    },
    {
      "epoch": 98.88,
      "learning_rate": 3.0852117711474684e-05,
      "loss": 0.0,
      "step": 9740
    },
    {
      "epoch": 98.89,
      "learning_rate": 3.0841150389856125e-05,
      "loss": 0.0,
      "step": 9741
    },
    {
      "epoch": 98.9,
      "learning_rate": 3.0830184148550244e-05,
      "loss": 0.0001,
      "step": 9742
    },
    {
      "epoch": 98.91,
      "learning_rate": 3.081921898817546e-05,
      "loss": 0.0002,
      "step": 9743
    },
    {
      "epoch": 98.92,
      "learning_rate": 3.080825490934999e-05,
      "loss": 0.002,
      "step": 9744
    },
    {
      "epoch": 98.93,
      "learning_rate": 3.0797291912692115e-05,
      "loss": 0.0181,
      "step": 9745
    },
    {
      "epoch": 98.94,
      "learning_rate": 3.078632999882002e-05,
      "loss": 0.0,
      "step": 9746
    },
    {
      "epoch": 98.95,
      "learning_rate": 3.0775369168351775e-05,
      "loss": 0.0171,
      "step": 9747
    },
    {
      "epoch": 98.96,
      "learning_rate": 3.076440942190546e-05,
      "loss": 0.0001,
      "step": 9748
    },
    {
      "epoch": 98.97,
      "learning_rate": 3.075345076009905e-05,
      "loss": 0.0001,
      "step": 9749
    },
    {
      "epoch": 98.98,
      "learning_rate": 3.074249318355046e-05,
      "loss": 0.0104,
      "step": 9750
    },
    {
      "epoch": 98.99,
      "learning_rate": 3.073153669287759e-05,
      "loss": 0.0001,
      "step": 9751
    },
    {
      "epoch": 98.99,
      "eval_loss": 0.02128630317747593,
      "eval_runtime": 31.8026,
      "eval_samples_per_second": 99.048,
      "eval_steps_per_second": 6.194,
      "eval_wer": 0.0028169014084507044,
      "step": 9751
    }
  ],
  "max_steps": 14700,
  "num_train_epochs": 150,
  "total_flos": 2.9559865227671844e+20,
  "trial_name": null,
  "trial_params": null
}
