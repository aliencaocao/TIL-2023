{
  "best_metric": 0.0018893387314439945,
  "best_model_checkpoint": "wav2vec2-checkpoints-audiomentations-from2337/checkpoint-468",
  "epoch": 18.997333333333334,
  "global_step": 1781,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.0,
      "loss": 0.0013,
      "step": 1
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.0,
      "loss": 0.019,
      "step": 2
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.0,
      "loss": 0.0106,
      "step": 3
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0,
      "loss": 0.0007,
      "step": 4
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0,
      "loss": 0.0018,
      "step": 5
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0,
      "loss": 0.0002,
      "step": 6
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0,
      "loss": 0.0003,
      "step": 7
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0,
      "loss": 0.0008,
      "step": 8
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0,
      "loss": 0.013,
      "step": 9
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0,
      "loss": 0.0005,
      "step": 10
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0,
      "loss": 0.0208,
      "step": 11
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0,
      "loss": 0.0032,
      "step": 12
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0,
      "loss": 0.014,
      "step": 13
    },
    {
      "epoch": 0.15,
      "learning_rate": 2.4390243902439025e-09,
      "loss": 0.0002,
      "step": 14
    },
    {
      "epoch": 0.16,
      "learning_rate": 2.4390243902439025e-09,
      "loss": 0.0347,
      "step": 15
    },
    {
      "epoch": 0.17,
      "learning_rate": 2.4390243902439025e-09,
      "loss": 0.0013,
      "step": 16
    },
    {
      "epoch": 0.18,
      "learning_rate": 2.4390243902439025e-09,
      "loss": 0.0878,
      "step": 17
    },
    {
      "epoch": 0.19,
      "learning_rate": 2.4390243902439025e-09,
      "loss": 0.0121,
      "step": 18
    },
    {
      "epoch": 0.2,
      "learning_rate": 4.878048780487805e-09,
      "loss": 0.0163,
      "step": 19
    },
    {
      "epoch": 0.21,
      "learning_rate": 7.3170731707317075e-09,
      "loss": 0.0027,
      "step": 20
    },
    {
      "epoch": 0.22,
      "learning_rate": 7.3170731707317075e-09,
      "loss": 0.0657,
      "step": 21
    },
    {
      "epoch": 0.23,
      "learning_rate": 9.75609756097561e-09,
      "loss": 0.0018,
      "step": 22
    },
    {
      "epoch": 0.25,
      "learning_rate": 1.2195121951219512e-08,
      "loss": 0.0009,
      "step": 23
    },
    {
      "epoch": 0.26,
      "learning_rate": 1.4634146341463415e-08,
      "loss": 0.0003,
      "step": 24
    },
    {
      "epoch": 0.27,
      "learning_rate": 1.707317073170732e-08,
      "loss": 0.0002,
      "step": 25
    },
    {
      "epoch": 0.28,
      "learning_rate": 1.951219512195122e-08,
      "loss": 0.0002,
      "step": 26
    },
    {
      "epoch": 0.29,
      "learning_rate": 2.195121951219512e-08,
      "loss": 0.0002,
      "step": 27
    },
    {
      "epoch": 0.3,
      "learning_rate": 2.4390243902439023e-08,
      "loss": 0.0395,
      "step": 28
    },
    {
      "epoch": 0.31,
      "learning_rate": 2.6829268292682925e-08,
      "loss": 0.0006,
      "step": 29
    },
    {
      "epoch": 0.32,
      "learning_rate": 2.6829268292682925e-08,
      "loss": 0.0616,
      "step": 30
    },
    {
      "epoch": 0.33,
      "learning_rate": 2.926829268292683e-08,
      "loss": 0.0037,
      "step": 31
    },
    {
      "epoch": 0.34,
      "learning_rate": 3.170731707317073e-08,
      "loss": 0.0479,
      "step": 32
    },
    {
      "epoch": 0.35,
      "learning_rate": 3.414634146341464e-08,
      "loss": 0.0002,
      "step": 33
    },
    {
      "epoch": 0.36,
      "learning_rate": 3.658536585365853e-08,
      "loss": 0.0308,
      "step": 34
    },
    {
      "epoch": 0.37,
      "learning_rate": 3.902439024390244e-08,
      "loss": 0.0106,
      "step": 35
    },
    {
      "epoch": 0.38,
      "learning_rate": 4.146341463414634e-08,
      "loss": 0.0661,
      "step": 36
    },
    {
      "epoch": 0.39,
      "learning_rate": 4.390243902439024e-08,
      "loss": 0.0004,
      "step": 37
    },
    {
      "epoch": 0.41,
      "learning_rate": 4.6341463414634145e-08,
      "loss": 0.0093,
      "step": 38
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.878048780487805e-08,
      "loss": 0.0373,
      "step": 39
    },
    {
      "epoch": 0.43,
      "learning_rate": 5.121951219512195e-08,
      "loss": 0.0031,
      "step": 40
    },
    {
      "epoch": 0.44,
      "learning_rate": 5.365853658536585e-08,
      "loss": 0.0071,
      "step": 41
    },
    {
      "epoch": 0.45,
      "learning_rate": 5.609756097560975e-08,
      "loss": 0.0015,
      "step": 42
    },
    {
      "epoch": 0.46,
      "learning_rate": 5.853658536585366e-08,
      "loss": 0.0021,
      "step": 43
    },
    {
      "epoch": 0.47,
      "learning_rate": 6.097560975609756e-08,
      "loss": 0.0003,
      "step": 44
    },
    {
      "epoch": 0.48,
      "learning_rate": 6.341463414634146e-08,
      "loss": 0.0471,
      "step": 45
    },
    {
      "epoch": 0.49,
      "learning_rate": 6.585365853658537e-08,
      "loss": 0.0019,
      "step": 46
    },
    {
      "epoch": 0.5,
      "learning_rate": 6.829268292682927e-08,
      "loss": 0.0003,
      "step": 47
    },
    {
      "epoch": 0.51,
      "learning_rate": 7.073170731707316e-08,
      "loss": 0.0003,
      "step": 48
    },
    {
      "epoch": 0.52,
      "learning_rate": 7.317073170731706e-08,
      "loss": 0.0002,
      "step": 49
    },
    {
      "epoch": 0.53,
      "learning_rate": 7.560975609756097e-08,
      "loss": 0.0256,
      "step": 50
    },
    {
      "epoch": 0.54,
      "learning_rate": 7.804878048780488e-08,
      "loss": 0.0916,
      "step": 51
    },
    {
      "epoch": 0.55,
      "learning_rate": 8.048780487804878e-08,
      "loss": 0.0013,
      "step": 52
    },
    {
      "epoch": 0.57,
      "learning_rate": 8.292682926829268e-08,
      "loss": 0.0056,
      "step": 53
    },
    {
      "epoch": 0.58,
      "learning_rate": 8.536585365853659e-08,
      "loss": 0.004,
      "step": 54
    },
    {
      "epoch": 0.59,
      "learning_rate": 8.780487804878047e-08,
      "loss": 0.0248,
      "step": 55
    },
    {
      "epoch": 0.6,
      "learning_rate": 9.024390243902439e-08,
      "loss": 0.0003,
      "step": 56
    },
    {
      "epoch": 0.61,
      "learning_rate": 9.268292682926829e-08,
      "loss": 0.0002,
      "step": 57
    },
    {
      "epoch": 0.62,
      "learning_rate": 9.512195121951219e-08,
      "loss": 0.0833,
      "step": 58
    },
    {
      "epoch": 0.63,
      "learning_rate": 9.75609756097561e-08,
      "loss": 0.0139,
      "step": 59
    },
    {
      "epoch": 0.64,
      "learning_rate": 1e-07,
      "loss": 0.0474,
      "step": 60
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.024390243902439e-07,
      "loss": 0.0154,
      "step": 61
    },
    {
      "epoch": 0.66,
      "learning_rate": 1.048780487804878e-07,
      "loss": 0.0051,
      "step": 62
    },
    {
      "epoch": 0.67,
      "learning_rate": 1.073170731707317e-07,
      "loss": 0.0633,
      "step": 63
    },
    {
      "epoch": 0.68,
      "learning_rate": 1.097560975609756e-07,
      "loss": 0.0204,
      "step": 64
    },
    {
      "epoch": 0.69,
      "learning_rate": 1.121951219512195e-07,
      "loss": 0.005,
      "step": 65
    },
    {
      "epoch": 0.7,
      "learning_rate": 1.1463414634146342e-07,
      "loss": 0.0006,
      "step": 66
    },
    {
      "epoch": 0.71,
      "learning_rate": 1.1707317073170732e-07,
      "loss": 0.0056,
      "step": 67
    },
    {
      "epoch": 0.73,
      "learning_rate": 1.195121951219512e-07,
      "loss": 0.0135,
      "step": 68
    },
    {
      "epoch": 0.74,
      "learning_rate": 1.219512195121951e-07,
      "loss": 0.0173,
      "step": 69
    },
    {
      "epoch": 0.75,
      "learning_rate": 1.24390243902439e-07,
      "loss": 0.0113,
      "step": 70
    },
    {
      "epoch": 0.76,
      "learning_rate": 1.2682926829268291e-07,
      "loss": 0.0136,
      "step": 71
    },
    {
      "epoch": 0.77,
      "learning_rate": 1.2926829268292682e-07,
      "loss": 0.0004,
      "step": 72
    },
    {
      "epoch": 0.78,
      "learning_rate": 1.3170731707317074e-07,
      "loss": 0.0009,
      "step": 73
    },
    {
      "epoch": 0.79,
      "learning_rate": 1.3414634146341465e-07,
      "loss": 0.0076,
      "step": 74
    },
    {
      "epoch": 0.8,
      "learning_rate": 1.3658536585365855e-07,
      "loss": 0.0239,
      "step": 75
    },
    {
      "epoch": 0.81,
      "learning_rate": 1.3902439024390245e-07,
      "loss": 0.1221,
      "step": 76
    },
    {
      "epoch": 0.82,
      "learning_rate": 1.4146341463414632e-07,
      "loss": 0.0315,
      "step": 77
    },
    {
      "epoch": 0.83,
      "learning_rate": 1.4390243902439023e-07,
      "loss": 0.0005,
      "step": 78
    },
    {
      "epoch": 0.84,
      "learning_rate": 1.4634146341463413e-07,
      "loss": 0.0079,
      "step": 79
    },
    {
      "epoch": 0.85,
      "learning_rate": 1.4878048780487803e-07,
      "loss": 0.0195,
      "step": 80
    },
    {
      "epoch": 0.86,
      "learning_rate": 1.5121951219512193e-07,
      "loss": 0.0017,
      "step": 81
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.5365853658536583e-07,
      "loss": 0.0002,
      "step": 82
    },
    {
      "epoch": 0.89,
      "learning_rate": 1.5609756097560976e-07,
      "loss": 0.0002,
      "step": 83
    },
    {
      "epoch": 0.9,
      "learning_rate": 1.5853658536585366e-07,
      "loss": 0.0002,
      "step": 84
    },
    {
      "epoch": 0.91,
      "learning_rate": 1.6097560975609756e-07,
      "loss": 0.0174,
      "step": 85
    },
    {
      "epoch": 0.92,
      "learning_rate": 1.6341463414634147e-07,
      "loss": 0.0057,
      "step": 86
    },
    {
      "epoch": 0.93,
      "learning_rate": 1.6585365853658537e-07,
      "loss": 0.0004,
      "step": 87
    },
    {
      "epoch": 0.94,
      "learning_rate": 1.6829268292682927e-07,
      "loss": 0.0012,
      "step": 88
    },
    {
      "epoch": 0.95,
      "learning_rate": 1.7073170731707317e-07,
      "loss": 0.0409,
      "step": 89
    },
    {
      "epoch": 0.96,
      "learning_rate": 1.7317073170731705e-07,
      "loss": 0.0102,
      "step": 90
    },
    {
      "epoch": 0.97,
      "learning_rate": 1.7560975609756095e-07,
      "loss": 0.0581,
      "step": 91
    },
    {
      "epoch": 0.98,
      "learning_rate": 1.7804878048780485e-07,
      "loss": 0.0023,
      "step": 92
    },
    {
      "epoch": 0.99,
      "learning_rate": 1.8048780487804878e-07,
      "loss": 0.0004,
      "step": 93
    },
    {
      "epoch": 0.99,
      "eval_loss": 0.024347595870494843,
      "eval_runtime": 12.8948,
      "eval_samples_per_second": 58.163,
      "eval_steps_per_second": 14.58,
      "eval_wer": 0.008232118758434548,
      "step": 93
    },
    {
      "epoch": 1.0,
      "learning_rate": 1.8292682926829268e-07,
      "loss": 0.017,
      "step": 94
    },
    {
      "epoch": 1.01,
      "learning_rate": 1.8536585365853658e-07,
      "loss": 0.0693,
      "step": 95
    },
    {
      "epoch": 1.02,
      "learning_rate": 1.8780487804878048e-07,
      "loss": 0.0128,
      "step": 96
    },
    {
      "epoch": 1.03,
      "learning_rate": 1.9024390243902438e-07,
      "loss": 0.0261,
      "step": 97
    },
    {
      "epoch": 1.05,
      "learning_rate": 1.9268292682926829e-07,
      "loss": 0.0002,
      "step": 98
    },
    {
      "epoch": 1.06,
      "learning_rate": 1.951219512195122e-07,
      "loss": 0.0002,
      "step": 99
    },
    {
      "epoch": 1.07,
      "learning_rate": 1.975609756097561e-07,
      "loss": 0.0104,
      "step": 100
    },
    {
      "epoch": 1.08,
      "learning_rate": 1.975609756097561e-07,
      "loss": 0.0027,
      "step": 101
    },
    {
      "epoch": 1.09,
      "learning_rate": 2e-07,
      "loss": 0.0188,
      "step": 102
    },
    {
      "epoch": 1.1,
      "learning_rate": 2.0243902439024392e-07,
      "loss": 0.0006,
      "step": 103
    },
    {
      "epoch": 1.11,
      "learning_rate": 2.048780487804878e-07,
      "loss": 0.0002,
      "step": 104
    },
    {
      "epoch": 1.12,
      "learning_rate": 2.073170731707317e-07,
      "loss": 0.0331,
      "step": 105
    },
    {
      "epoch": 1.13,
      "learning_rate": 2.097560975609756e-07,
      "loss": 0.0218,
      "step": 106
    },
    {
      "epoch": 1.14,
      "learning_rate": 2.121951219512195e-07,
      "loss": 0.0314,
      "step": 107
    },
    {
      "epoch": 1.15,
      "learning_rate": 2.146341463414634e-07,
      "loss": 0.0052,
      "step": 108
    },
    {
      "epoch": 1.16,
      "learning_rate": 2.170731707317073e-07,
      "loss": 0.0008,
      "step": 109
    },
    {
      "epoch": 1.17,
      "learning_rate": 2.195121951219512e-07,
      "loss": 0.0291,
      "step": 110
    },
    {
      "epoch": 1.18,
      "learning_rate": 2.219512195121951e-07,
      "loss": 0.012,
      "step": 111
    },
    {
      "epoch": 1.19,
      "learning_rate": 2.24390243902439e-07,
      "loss": 0.015,
      "step": 112
    },
    {
      "epoch": 1.21,
      "learning_rate": 2.2682926829268294e-07,
      "loss": 0.04,
      "step": 113
    },
    {
      "epoch": 1.22,
      "learning_rate": 2.2926829268292684e-07,
      "loss": 0.0304,
      "step": 114
    },
    {
      "epoch": 1.23,
      "learning_rate": 2.3170731707317074e-07,
      "loss": 0.0006,
      "step": 115
    },
    {
      "epoch": 1.24,
      "learning_rate": 2.3414634146341464e-07,
      "loss": 0.0003,
      "step": 116
    },
    {
      "epoch": 1.25,
      "learning_rate": 2.3658536585365852e-07,
      "loss": 0.0021,
      "step": 117
    },
    {
      "epoch": 1.26,
      "learning_rate": 2.390243902439024e-07,
      "loss": 0.0002,
      "step": 118
    },
    {
      "epoch": 1.27,
      "learning_rate": 2.4146341463414635e-07,
      "loss": 0.0357,
      "step": 119
    },
    {
      "epoch": 1.28,
      "learning_rate": 2.439024390243902e-07,
      "loss": 0.0006,
      "step": 120
    },
    {
      "epoch": 1.29,
      "learning_rate": 2.4634146341463415e-07,
      "loss": 0.0121,
      "step": 121
    },
    {
      "epoch": 1.3,
      "learning_rate": 2.48780487804878e-07,
      "loss": 0.0542,
      "step": 122
    },
    {
      "epoch": 1.31,
      "learning_rate": 2.5121951219512195e-07,
      "loss": 0.0292,
      "step": 123
    },
    {
      "epoch": 1.32,
      "learning_rate": 2.5365853658536583e-07,
      "loss": 0.0009,
      "step": 124
    },
    {
      "epoch": 1.33,
      "learning_rate": 2.5609756097560976e-07,
      "loss": 0.002,
      "step": 125
    },
    {
      "epoch": 1.34,
      "learning_rate": 2.5853658536585363e-07,
      "loss": 0.0002,
      "step": 126
    },
    {
      "epoch": 1.35,
      "learning_rate": 2.6097560975609756e-07,
      "loss": 0.0002,
      "step": 127
    },
    {
      "epoch": 1.37,
      "learning_rate": 2.634146341463415e-07,
      "loss": 0.0194,
      "step": 128
    },
    {
      "epoch": 1.38,
      "learning_rate": 2.6585365853658536e-07,
      "loss": 0.0022,
      "step": 129
    },
    {
      "epoch": 1.39,
      "learning_rate": 2.682926829268293e-07,
      "loss": 0.0002,
      "step": 130
    },
    {
      "epoch": 1.4,
      "learning_rate": 2.682926829268293e-07,
      "loss": 0.0927,
      "step": 131
    },
    {
      "epoch": 1.41,
      "learning_rate": 2.7073170731707317e-07,
      "loss": 0.008,
      "step": 132
    },
    {
      "epoch": 1.42,
      "learning_rate": 2.731707317073171e-07,
      "loss": 0.0183,
      "step": 133
    },
    {
      "epoch": 1.43,
      "learning_rate": 2.7560975609756097e-07,
      "loss": 0.0194,
      "step": 134
    },
    {
      "epoch": 1.44,
      "learning_rate": 2.780487804878049e-07,
      "loss": 0.0008,
      "step": 135
    },
    {
      "epoch": 1.45,
      "learning_rate": 2.8048780487804877e-07,
      "loss": 0.0374,
      "step": 136
    },
    {
      "epoch": 1.46,
      "learning_rate": 2.8292682926829265e-07,
      "loss": 0.0014,
      "step": 137
    },
    {
      "epoch": 1.47,
      "learning_rate": 2.853658536585365e-07,
      "loss": 0.0336,
      "step": 138
    },
    {
      "epoch": 1.48,
      "learning_rate": 2.8780487804878045e-07,
      "loss": 0.0062,
      "step": 139
    },
    {
      "epoch": 1.49,
      "learning_rate": 2.902439024390244e-07,
      "loss": 0.0627,
      "step": 140
    },
    {
      "epoch": 1.5,
      "learning_rate": 2.9268292682926825e-07,
      "loss": 0.0003,
      "step": 141
    },
    {
      "epoch": 1.51,
      "learning_rate": 2.951219512195122e-07,
      "loss": 0.0033,
      "step": 142
    },
    {
      "epoch": 1.53,
      "learning_rate": 2.9756097560975606e-07,
      "loss": 0.004,
      "step": 143
    },
    {
      "epoch": 1.54,
      "learning_rate": 3e-07,
      "loss": 0.0676,
      "step": 144
    },
    {
      "epoch": 1.55,
      "learning_rate": 3.0243902439024386e-07,
      "loss": 0.0002,
      "step": 145
    },
    {
      "epoch": 1.56,
      "learning_rate": 3.048780487804878e-07,
      "loss": 0.0027,
      "step": 146
    },
    {
      "epoch": 1.57,
      "learning_rate": 3.0731707317073167e-07,
      "loss": 0.0173,
      "step": 147
    },
    {
      "epoch": 1.58,
      "learning_rate": 3.097560975609756e-07,
      "loss": 0.01,
      "step": 148
    },
    {
      "epoch": 1.59,
      "learning_rate": 3.121951219512195e-07,
      "loss": 0.0179,
      "step": 149
    },
    {
      "epoch": 1.6,
      "learning_rate": 3.146341463414634e-07,
      "loss": 0.0935,
      "step": 150
    },
    {
      "epoch": 1.61,
      "learning_rate": 3.170731707317073e-07,
      "loss": 0.0002,
      "step": 151
    },
    {
      "epoch": 1.62,
      "learning_rate": 3.195121951219512e-07,
      "loss": 0.0541,
      "step": 152
    },
    {
      "epoch": 1.63,
      "learning_rate": 3.2195121951219513e-07,
      "loss": 0.0171,
      "step": 153
    },
    {
      "epoch": 1.64,
      "learning_rate": 3.24390243902439e-07,
      "loss": 0.0015,
      "step": 154
    },
    {
      "epoch": 1.65,
      "learning_rate": 3.2682926829268293e-07,
      "loss": 0.0342,
      "step": 155
    },
    {
      "epoch": 1.66,
      "learning_rate": 3.292682926829268e-07,
      "loss": 0.0002,
      "step": 156
    },
    {
      "epoch": 1.67,
      "learning_rate": 3.3170731707317073e-07,
      "loss": 0.0673,
      "step": 157
    },
    {
      "epoch": 1.69,
      "learning_rate": 3.3414634146341466e-07,
      "loss": 0.0022,
      "step": 158
    },
    {
      "epoch": 1.7,
      "learning_rate": 3.3658536585365854e-07,
      "loss": 0.0508,
      "step": 159
    },
    {
      "epoch": 1.71,
      "learning_rate": 3.3902439024390247e-07,
      "loss": 0.0005,
      "step": 160
    },
    {
      "epoch": 1.72,
      "learning_rate": 3.4146341463414634e-07,
      "loss": 0.022,
      "step": 161
    },
    {
      "epoch": 1.73,
      "learning_rate": 3.439024390243902e-07,
      "loss": 0.0055,
      "step": 162
    },
    {
      "epoch": 1.74,
      "learning_rate": 3.463414634146341e-07,
      "loss": 0.0002,
      "step": 163
    },
    {
      "epoch": 1.75,
      "learning_rate": 3.48780487804878e-07,
      "loss": 0.0054,
      "step": 164
    },
    {
      "epoch": 1.76,
      "learning_rate": 3.512195121951219e-07,
      "loss": 0.0007,
      "step": 165
    },
    {
      "epoch": 1.77,
      "learning_rate": 3.536585365853658e-07,
      "loss": 0.0367,
      "step": 166
    },
    {
      "epoch": 1.78,
      "learning_rate": 3.560975609756097e-07,
      "loss": 0.0004,
      "step": 167
    },
    {
      "epoch": 1.79,
      "learning_rate": 3.5853658536585363e-07,
      "loss": 0.0002,
      "step": 168
    },
    {
      "epoch": 1.8,
      "learning_rate": 3.6097560975609755e-07,
      "loss": 0.0076,
      "step": 169
    },
    {
      "epoch": 1.81,
      "learning_rate": 3.6341463414634143e-07,
      "loss": 0.026,
      "step": 170
    },
    {
      "epoch": 1.82,
      "learning_rate": 3.6585365853658536e-07,
      "loss": 0.0024,
      "step": 171
    },
    {
      "epoch": 1.83,
      "learning_rate": 3.6829268292682923e-07,
      "loss": 0.017,
      "step": 172
    },
    {
      "epoch": 1.85,
      "learning_rate": 3.7073170731707316e-07,
      "loss": 0.0698,
      "step": 173
    },
    {
      "epoch": 1.86,
      "learning_rate": 3.7317073170731704e-07,
      "loss": 0.0096,
      "step": 174
    },
    {
      "epoch": 1.87,
      "learning_rate": 3.7560975609756097e-07,
      "loss": 0.0503,
      "step": 175
    },
    {
      "epoch": 1.88,
      "learning_rate": 3.7804878048780484e-07,
      "loss": 0.0439,
      "step": 176
    },
    {
      "epoch": 1.89,
      "learning_rate": 3.8048780487804877e-07,
      "loss": 0.0172,
      "step": 177
    },
    {
      "epoch": 1.9,
      "learning_rate": 3.829268292682927e-07,
      "loss": 0.0269,
      "step": 178
    },
    {
      "epoch": 1.91,
      "learning_rate": 3.8536585365853657e-07,
      "loss": 0.0197,
      "step": 179
    },
    {
      "epoch": 1.92,
      "learning_rate": 3.878048780487805e-07,
      "loss": 0.0104,
      "step": 180
    },
    {
      "epoch": 1.93,
      "learning_rate": 3.902439024390244e-07,
      "loss": 0.0065,
      "step": 181
    },
    {
      "epoch": 1.94,
      "learning_rate": 3.926829268292683e-07,
      "loss": 0.0015,
      "step": 182
    },
    {
      "epoch": 1.95,
      "learning_rate": 3.951219512195122e-07,
      "loss": 0.0002,
      "step": 183
    },
    {
      "epoch": 1.96,
      "learning_rate": 3.975609756097561e-07,
      "loss": 0.0009,
      "step": 184
    },
    {
      "epoch": 1.97,
      "learning_rate": 4e-07,
      "loss": 0.0621,
      "step": 185
    },
    {
      "epoch": 1.98,
      "learning_rate": 4.024390243902439e-07,
      "loss": 0.0009,
      "step": 186
    },
    {
      "epoch": 1.99,
      "learning_rate": 4.0487804878048784e-07,
      "loss": 0.0591,
      "step": 187
    },
    {
      "epoch": 1.99,
      "eval_loss": 0.018270067870616913,
      "eval_runtime": 12.6507,
      "eval_samples_per_second": 59.285,
      "eval_steps_per_second": 14.861,
      "eval_wer": 0.004723346828609987,
      "step": 187
    },
    {
      "epoch": 2.01,
      "learning_rate": 4.0731707317073166e-07,
      "loss": 0.0004,
      "step": 188
    },
    {
      "epoch": 2.02,
      "learning_rate": 4.097560975609756e-07,
      "loss": 0.0002,
      "step": 189
    },
    {
      "epoch": 2.03,
      "learning_rate": 4.1219512195121946e-07,
      "loss": 0.0021,
      "step": 190
    },
    {
      "epoch": 2.04,
      "learning_rate": 4.146341463414634e-07,
      "loss": 0.0012,
      "step": 191
    },
    {
      "epoch": 2.05,
      "learning_rate": 4.1707317073170727e-07,
      "loss": 0.0528,
      "step": 192
    },
    {
      "epoch": 2.06,
      "learning_rate": 4.195121951219512e-07,
      "loss": 0.0022,
      "step": 193
    },
    {
      "epoch": 2.07,
      "learning_rate": 4.2195121951219507e-07,
      "loss": 0.0388,
      "step": 194
    },
    {
      "epoch": 2.08,
      "learning_rate": 4.24390243902439e-07,
      "loss": 0.0212,
      "step": 195
    },
    {
      "epoch": 2.09,
      "learning_rate": 4.268292682926829e-07,
      "loss": 0.0409,
      "step": 196
    },
    {
      "epoch": 2.1,
      "learning_rate": 4.292682926829268e-07,
      "loss": 0.0201,
      "step": 197
    },
    {
      "epoch": 2.11,
      "learning_rate": 4.3170731707317073e-07,
      "loss": 0.0066,
      "step": 198
    },
    {
      "epoch": 2.12,
      "learning_rate": 4.341463414634146e-07,
      "loss": 0.0021,
      "step": 199
    },
    {
      "epoch": 2.13,
      "learning_rate": 4.3658536585365853e-07,
      "loss": 0.0002,
      "step": 200
    },
    {
      "epoch": 2.14,
      "learning_rate": 4.390243902439024e-07,
      "loss": 0.0441,
      "step": 201
    },
    {
      "epoch": 2.15,
      "learning_rate": 4.4146341463414634e-07,
      "loss": 0.032,
      "step": 202
    },
    {
      "epoch": 2.17,
      "learning_rate": 4.439024390243902e-07,
      "loss": 0.0002,
      "step": 203
    },
    {
      "epoch": 2.18,
      "learning_rate": 4.4634146341463414e-07,
      "loss": 0.0028,
      "step": 204
    },
    {
      "epoch": 2.19,
      "learning_rate": 4.48780487804878e-07,
      "loss": 0.0276,
      "step": 205
    },
    {
      "epoch": 2.2,
      "learning_rate": 4.5121951219512194e-07,
      "loss": 0.0079,
      "step": 206
    },
    {
      "epoch": 2.21,
      "learning_rate": 4.5365853658536587e-07,
      "loss": 0.0078,
      "step": 207
    },
    {
      "epoch": 2.22,
      "learning_rate": 4.5609756097560975e-07,
      "loss": 0.0014,
      "step": 208
    },
    {
      "epoch": 2.23,
      "learning_rate": 4.585365853658537e-07,
      "loss": 0.0014,
      "step": 209
    },
    {
      "epoch": 2.24,
      "learning_rate": 4.6097560975609755e-07,
      "loss": 0.0673,
      "step": 210
    },
    {
      "epoch": 2.25,
      "learning_rate": 4.634146341463415e-07,
      "loss": 0.0028,
      "step": 211
    },
    {
      "epoch": 2.26,
      "learning_rate": 4.6585365853658535e-07,
      "loss": 0.0003,
      "step": 212
    },
    {
      "epoch": 2.27,
      "learning_rate": 4.682926829268293e-07,
      "loss": 0.0062,
      "step": 213
    },
    {
      "epoch": 2.28,
      "learning_rate": 4.707317073170731e-07,
      "loss": 0.1063,
      "step": 214
    },
    {
      "epoch": 2.29,
      "learning_rate": 4.7317073170731703e-07,
      "loss": 0.0031,
      "step": 215
    },
    {
      "epoch": 2.3,
      "learning_rate": 4.756097560975609e-07,
      "loss": 0.0003,
      "step": 216
    },
    {
      "epoch": 2.31,
      "learning_rate": 4.780487804878048e-07,
      "loss": 0.0322,
      "step": 217
    },
    {
      "epoch": 2.33,
      "learning_rate": 4.804878048780488e-07,
      "loss": 0.0236,
      "step": 218
    },
    {
      "epoch": 2.34,
      "learning_rate": 4.829268292682927e-07,
      "loss": 0.0002,
      "step": 219
    },
    {
      "epoch": 2.35,
      "learning_rate": 4.853658536585365e-07,
      "loss": 0.0262,
      "step": 220
    },
    {
      "epoch": 2.36,
      "learning_rate": 4.878048780487804e-07,
      "loss": 0.0249,
      "step": 221
    },
    {
      "epoch": 2.37,
      "learning_rate": 4.902439024390244e-07,
      "loss": 0.0115,
      "step": 222
    },
    {
      "epoch": 2.38,
      "learning_rate": 4.926829268292683e-07,
      "loss": 0.0783,
      "step": 223
    },
    {
      "epoch": 2.39,
      "learning_rate": 4.951219512195121e-07,
      "loss": 0.0003,
      "step": 224
    },
    {
      "epoch": 2.4,
      "learning_rate": 4.97560975609756e-07,
      "loss": 0.0043,
      "step": 225
    },
    {
      "epoch": 2.41,
      "learning_rate": 5e-07,
      "loss": 0.0122,
      "step": 226
    },
    {
      "epoch": 2.42,
      "learning_rate": 5.024390243902439e-07,
      "loss": 0.0081,
      "step": 227
    },
    {
      "epoch": 2.43,
      "learning_rate": 5.048780487804878e-07,
      "loss": 0.0003,
      "step": 228
    },
    {
      "epoch": 2.44,
      "learning_rate": 5.073170731707317e-07,
      "loss": 0.0105,
      "step": 229
    },
    {
      "epoch": 2.45,
      "learning_rate": 5.097560975609756e-07,
      "loss": 0.0323,
      "step": 230
    },
    {
      "epoch": 2.46,
      "learning_rate": 5.121951219512195e-07,
      "loss": 0.0069,
      "step": 231
    },
    {
      "epoch": 2.47,
      "learning_rate": 5.146341463414634e-07,
      "loss": 0.0003,
      "step": 232
    },
    {
      "epoch": 2.49,
      "learning_rate": 5.170731707317073e-07,
      "loss": 0.0007,
      "step": 233
    },
    {
      "epoch": 2.5,
      "learning_rate": 5.195121951219512e-07,
      "loss": 0.0463,
      "step": 234
    },
    {
      "epoch": 2.51,
      "learning_rate": 5.219512195121951e-07,
      "loss": 0.0009,
      "step": 235
    },
    {
      "epoch": 2.52,
      "learning_rate": 5.24390243902439e-07,
      "loss": 0.0208,
      "step": 236
    },
    {
      "epoch": 2.53,
      "learning_rate": 5.26829268292683e-07,
      "loss": 0.0494,
      "step": 237
    },
    {
      "epoch": 2.54,
      "learning_rate": 5.292682926829268e-07,
      "loss": 0.0267,
      "step": 238
    },
    {
      "epoch": 2.55,
      "learning_rate": 5.317073170731707e-07,
      "loss": 0.0003,
      "step": 239
    },
    {
      "epoch": 2.56,
      "learning_rate": 5.341463414634147e-07,
      "loss": 0.0002,
      "step": 240
    },
    {
      "epoch": 2.57,
      "learning_rate": 5.365853658536586e-07,
      "loss": 0.0673,
      "step": 241
    },
    {
      "epoch": 2.58,
      "learning_rate": 5.390243902439024e-07,
      "loss": 0.0002,
      "step": 242
    },
    {
      "epoch": 2.59,
      "learning_rate": 5.414634146341463e-07,
      "loss": 0.0607,
      "step": 243
    },
    {
      "epoch": 2.6,
      "learning_rate": 5.439024390243903e-07,
      "loss": 0.0006,
      "step": 244
    },
    {
      "epoch": 2.61,
      "learning_rate": 5.463414634146342e-07,
      "loss": 0.0036,
      "step": 245
    },
    {
      "epoch": 2.62,
      "learning_rate": 5.487804878048781e-07,
      "loss": 0.0002,
      "step": 246
    },
    {
      "epoch": 2.63,
      "learning_rate": 5.512195121951219e-07,
      "loss": 0.0003,
      "step": 247
    },
    {
      "epoch": 2.65,
      "learning_rate": 5.536585365853659e-07,
      "loss": 0.0041,
      "step": 248
    },
    {
      "epoch": 2.66,
      "learning_rate": 5.560975609756098e-07,
      "loss": 0.0675,
      "step": 249
    },
    {
      "epoch": 2.67,
      "learning_rate": 5.585365853658537e-07,
      "loss": 0.0149,
      "step": 250
    },
    {
      "epoch": 2.68,
      "learning_rate": 5.609756097560975e-07,
      "loss": 0.0444,
      "step": 251
    },
    {
      "epoch": 2.69,
      "learning_rate": 5.634146341463414e-07,
      "loss": 0.001,
      "step": 252
    },
    {
      "epoch": 2.7,
      "learning_rate": 5.658536585365853e-07,
      "loss": 0.0177,
      "step": 253
    },
    {
      "epoch": 2.71,
      "learning_rate": 5.682926829268292e-07,
      "loss": 0.0263,
      "step": 254
    },
    {
      "epoch": 2.72,
      "learning_rate": 5.70731707317073e-07,
      "loss": 0.0061,
      "step": 255
    },
    {
      "epoch": 2.73,
      "learning_rate": 5.73170731707317e-07,
      "loss": 0.0124,
      "step": 256
    },
    {
      "epoch": 2.74,
      "learning_rate": 5.756097560975609e-07,
      "loss": 0.0005,
      "step": 257
    },
    {
      "epoch": 2.75,
      "learning_rate": 5.780487804878048e-07,
      "loss": 0.0274,
      "step": 258
    },
    {
      "epoch": 2.76,
      "learning_rate": 5.804878048780488e-07,
      "loss": 0.0055,
      "step": 259
    },
    {
      "epoch": 2.77,
      "learning_rate": 5.829268292682926e-07,
      "loss": 0.0015,
      "step": 260
    },
    {
      "epoch": 2.78,
      "learning_rate": 5.853658536585365e-07,
      "loss": 0.0136,
      "step": 261
    },
    {
      "epoch": 2.79,
      "learning_rate": 5.878048780487804e-07,
      "loss": 0.0017,
      "step": 262
    },
    {
      "epoch": 2.81,
      "learning_rate": 5.902439024390244e-07,
      "loss": 0.0016,
      "step": 263
    },
    {
      "epoch": 2.82,
      "learning_rate": 5.926829268292682e-07,
      "loss": 0.0003,
      "step": 264
    },
    {
      "epoch": 2.83,
      "learning_rate": 5.951219512195121e-07,
      "loss": 0.0734,
      "step": 265
    },
    {
      "epoch": 2.84,
      "learning_rate": 5.97560975609756e-07,
      "loss": 0.0003,
      "step": 266
    },
    {
      "epoch": 2.85,
      "learning_rate": 6e-07,
      "loss": 0.0002,
      "step": 267
    },
    {
      "epoch": 2.86,
      "learning_rate": 6.024390243902439e-07,
      "loss": 0.0002,
      "step": 268
    },
    {
      "epoch": 2.87,
      "learning_rate": 6.048780487804877e-07,
      "loss": 0.108,
      "step": 269
    },
    {
      "epoch": 2.88,
      "learning_rate": 6.073170731707317e-07,
      "loss": 0.0002,
      "step": 270
    },
    {
      "epoch": 2.89,
      "learning_rate": 6.097560975609756e-07,
      "loss": 0.023,
      "step": 271
    },
    {
      "epoch": 2.9,
      "learning_rate": 6.121951219512195e-07,
      "loss": 0.0106,
      "step": 272
    },
    {
      "epoch": 2.91,
      "learning_rate": 6.146341463414633e-07,
      "loss": 0.0386,
      "step": 273
    },
    {
      "epoch": 2.92,
      "learning_rate": 6.170731707317073e-07,
      "loss": 0.0144,
      "step": 274
    },
    {
      "epoch": 2.93,
      "learning_rate": 6.195121951219512e-07,
      "loss": 0.0061,
      "step": 275
    },
    {
      "epoch": 2.94,
      "learning_rate": 6.219512195121951e-07,
      "loss": 0.0949,
      "step": 276
    },
    {
      "epoch": 2.95,
      "learning_rate": 6.24390243902439e-07,
      "loss": 0.0117,
      "step": 277
    },
    {
      "epoch": 2.97,
      "learning_rate": 6.268292682926829e-07,
      "loss": 0.0049,
      "step": 278
    },
    {
      "epoch": 2.98,
      "learning_rate": 6.292682926829268e-07,
      "loss": 0.0008,
      "step": 279
    },
    {
      "epoch": 2.99,
      "learning_rate": 6.317073170731707e-07,
      "loss": 0.0019,
      "step": 280
    },
    {
      "epoch": 3.0,
      "learning_rate": 6.341463414634146e-07,
      "loss": 0.0114,
      "step": 281
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.009047107771039009,
      "eval_runtime": 12.7062,
      "eval_samples_per_second": 59.026,
      "eval_steps_per_second": 14.796,
      "eval_wer": 0.0035087719298245615,
      "step": 281
    },
    {
      "epoch": 3.01,
      "learning_rate": 6.365853658536585e-07,
      "loss": 0.0199,
      "step": 282
    },
    {
      "epoch": 3.02,
      "learning_rate": 6.390243902439024e-07,
      "loss": 0.0176,
      "step": 283
    },
    {
      "epoch": 3.03,
      "learning_rate": 6.414634146341463e-07,
      "loss": 0.0568,
      "step": 284
    },
    {
      "epoch": 3.04,
      "learning_rate": 6.439024390243903e-07,
      "loss": 0.0002,
      "step": 285
    },
    {
      "epoch": 3.05,
      "learning_rate": 6.463414634146342e-07,
      "loss": 0.0159,
      "step": 286
    },
    {
      "epoch": 3.06,
      "learning_rate": 6.48780487804878e-07,
      "loss": 0.0002,
      "step": 287
    },
    {
      "epoch": 3.07,
      "learning_rate": 6.512195121951219e-07,
      "loss": 0.0002,
      "step": 288
    },
    {
      "epoch": 3.08,
      "learning_rate": 6.536585365853659e-07,
      "loss": 0.0013,
      "step": 289
    },
    {
      "epoch": 3.09,
      "learning_rate": 6.560975609756098e-07,
      "loss": 0.0003,
      "step": 290
    },
    {
      "epoch": 3.1,
      "learning_rate": 6.585365853658536e-07,
      "loss": 0.0005,
      "step": 291
    },
    {
      "epoch": 3.11,
      "learning_rate": 6.609756097560975e-07,
      "loss": 0.0113,
      "step": 292
    },
    {
      "epoch": 3.13,
      "learning_rate": 6.634146341463415e-07,
      "loss": 0.0005,
      "step": 293
    },
    {
      "epoch": 3.14,
      "learning_rate": 6.658536585365854e-07,
      "loss": 0.0002,
      "step": 294
    },
    {
      "epoch": 3.15,
      "learning_rate": 6.682926829268293e-07,
      "loss": 0.0024,
      "step": 295
    },
    {
      "epoch": 3.16,
      "learning_rate": 6.707317073170731e-07,
      "loss": 0.0146,
      "step": 296
    },
    {
      "epoch": 3.17,
      "learning_rate": 6.731707317073171e-07,
      "loss": 0.044,
      "step": 297
    },
    {
      "epoch": 3.18,
      "learning_rate": 6.75609756097561e-07,
      "loss": 0.0084,
      "step": 298
    },
    {
      "epoch": 3.19,
      "learning_rate": 6.780487804878049e-07,
      "loss": 0.0168,
      "step": 299
    },
    {
      "epoch": 3.2,
      "learning_rate": 6.804878048780488e-07,
      "loss": 0.0002,
      "step": 300
    },
    {
      "epoch": 3.21,
      "learning_rate": 6.829268292682927e-07,
      "loss": 0.0025,
      "step": 301
    },
    {
      "epoch": 3.22,
      "learning_rate": 6.853658536585366e-07,
      "loss": 0.0003,
      "step": 302
    },
    {
      "epoch": 3.23,
      "learning_rate": 6.878048780487804e-07,
      "loss": 0.028,
      "step": 303
    },
    {
      "epoch": 3.24,
      "learning_rate": 6.902439024390243e-07,
      "loss": 0.0036,
      "step": 304
    },
    {
      "epoch": 3.25,
      "learning_rate": 6.926829268292682e-07,
      "loss": 0.0074,
      "step": 305
    },
    {
      "epoch": 3.26,
      "learning_rate": 6.951219512195121e-07,
      "loss": 0.0359,
      "step": 306
    },
    {
      "epoch": 3.27,
      "learning_rate": 6.97560975609756e-07,
      "loss": 0.0002,
      "step": 307
    },
    {
      "epoch": 3.29,
      "learning_rate": 7e-07,
      "loss": 0.0501,
      "step": 308
    },
    {
      "epoch": 3.3,
      "learning_rate": 7.024390243902438e-07,
      "loss": 0.0003,
      "step": 309
    },
    {
      "epoch": 3.31,
      "learning_rate": 7.048780487804877e-07,
      "loss": 0.0002,
      "step": 310
    },
    {
      "epoch": 3.32,
      "learning_rate": 7.073170731707316e-07,
      "loss": 0.0002,
      "step": 311
    },
    {
      "epoch": 3.33,
      "learning_rate": 7.097560975609756e-07,
      "loss": 0.0263,
      "step": 312
    },
    {
      "epoch": 3.34,
      "learning_rate": 7.121951219512194e-07,
      "loss": 0.0334,
      "step": 313
    },
    {
      "epoch": 3.35,
      "learning_rate": 7.146341463414633e-07,
      "loss": 0.0271,
      "step": 314
    },
    {
      "epoch": 3.36,
      "learning_rate": 7.170731707317073e-07,
      "loss": 0.0063,
      "step": 315
    },
    {
      "epoch": 3.37,
      "learning_rate": 7.195121951219512e-07,
      "loss": 0.0139,
      "step": 316
    },
    {
      "epoch": 3.38,
      "learning_rate": 7.219512195121951e-07,
      "loss": 0.054,
      "step": 317
    },
    {
      "epoch": 3.39,
      "learning_rate": 7.243902439024389e-07,
      "loss": 0.0528,
      "step": 318
    },
    {
      "epoch": 3.4,
      "learning_rate": 7.268292682926829e-07,
      "loss": 0.0004,
      "step": 319
    },
    {
      "epoch": 3.41,
      "learning_rate": 7.292682926829268e-07,
      "loss": 0.0078,
      "step": 320
    },
    {
      "epoch": 3.42,
      "learning_rate": 7.317073170731707e-07,
      "loss": 0.0359,
      "step": 321
    },
    {
      "epoch": 3.43,
      "learning_rate": 7.341463414634145e-07,
      "loss": 0.0865,
      "step": 322
    },
    {
      "epoch": 3.45,
      "learning_rate": 7.365853658536585e-07,
      "loss": 0.0003,
      "step": 323
    },
    {
      "epoch": 3.46,
      "learning_rate": 7.390243902439024e-07,
      "loss": 0.0003,
      "step": 324
    },
    {
      "epoch": 3.47,
      "learning_rate": 7.414634146341463e-07,
      "loss": 0.0421,
      "step": 325
    },
    {
      "epoch": 3.48,
      "learning_rate": 7.439024390243903e-07,
      "loss": 0.0004,
      "step": 326
    },
    {
      "epoch": 3.49,
      "learning_rate": 7.463414634146341e-07,
      "loss": 0.0016,
      "step": 327
    },
    {
      "epoch": 3.5,
      "learning_rate": 7.48780487804878e-07,
      "loss": 0.0011,
      "step": 328
    },
    {
      "epoch": 3.51,
      "learning_rate": 7.512195121951219e-07,
      "loss": 0.0078,
      "step": 329
    },
    {
      "epoch": 3.52,
      "learning_rate": 7.536585365853659e-07,
      "loss": 0.0019,
      "step": 330
    },
    {
      "epoch": 3.53,
      "learning_rate": 7.560975609756097e-07,
      "loss": 0.0036,
      "step": 331
    },
    {
      "epoch": 3.54,
      "learning_rate": 7.585365853658536e-07,
      "loss": 0.0345,
      "step": 332
    },
    {
      "epoch": 3.55,
      "learning_rate": 7.609756097560975e-07,
      "loss": 0.0014,
      "step": 333
    },
    {
      "epoch": 3.56,
      "learning_rate": 7.634146341463415e-07,
      "loss": 0.0002,
      "step": 334
    },
    {
      "epoch": 3.57,
      "learning_rate": 7.658536585365854e-07,
      "loss": 0.0478,
      "step": 335
    },
    {
      "epoch": 3.58,
      "learning_rate": 7.682926829268292e-07,
      "loss": 0.0189,
      "step": 336
    },
    {
      "epoch": 3.59,
      "learning_rate": 7.707317073170731e-07,
      "loss": 0.0201,
      "step": 337
    },
    {
      "epoch": 3.61,
      "learning_rate": 7.731707317073171e-07,
      "loss": 0.0031,
      "step": 338
    },
    {
      "epoch": 3.62,
      "learning_rate": 7.75609756097561e-07,
      "loss": 0.0012,
      "step": 339
    },
    {
      "epoch": 3.63,
      "learning_rate": 7.780487804878048e-07,
      "loss": 0.0303,
      "step": 340
    },
    {
      "epoch": 3.64,
      "learning_rate": 7.804878048780488e-07,
      "loss": 0.0015,
      "step": 341
    },
    {
      "epoch": 3.65,
      "learning_rate": 7.829268292682927e-07,
      "loss": 0.0227,
      "step": 342
    },
    {
      "epoch": 3.66,
      "learning_rate": 7.853658536585366e-07,
      "loss": 0.0299,
      "step": 343
    },
    {
      "epoch": 3.67,
      "learning_rate": 7.878048780487805e-07,
      "loss": 0.0091,
      "step": 344
    },
    {
      "epoch": 3.68,
      "learning_rate": 7.902439024390244e-07,
      "loss": 0.0126,
      "step": 345
    },
    {
      "epoch": 3.69,
      "learning_rate": 7.926829268292683e-07,
      "loss": 0.0145,
      "step": 346
    },
    {
      "epoch": 3.7,
      "learning_rate": 7.951219512195122e-07,
      "loss": 0.0596,
      "step": 347
    },
    {
      "epoch": 3.71,
      "learning_rate": 7.975609756097561e-07,
      "loss": 0.0002,
      "step": 348
    },
    {
      "epoch": 3.72,
      "learning_rate": 8e-07,
      "loss": 0.0376,
      "step": 349
    },
    {
      "epoch": 3.73,
      "learning_rate": 8.024390243902439e-07,
      "loss": 0.0019,
      "step": 350
    },
    {
      "epoch": 3.74,
      "learning_rate": 8.048780487804878e-07,
      "loss": 0.0079,
      "step": 351
    },
    {
      "epoch": 3.75,
      "learning_rate": 8.073170731707317e-07,
      "loss": 0.025,
      "step": 352
    },
    {
      "epoch": 3.77,
      "learning_rate": 8.097560975609757e-07,
      "loss": 0.0278,
      "step": 353
    },
    {
      "epoch": 3.78,
      "learning_rate": 8.121951219512195e-07,
      "loss": 0.0044,
      "step": 354
    },
    {
      "epoch": 3.79,
      "learning_rate": 8.146341463414633e-07,
      "loss": 0.0505,
      "step": 355
    },
    {
      "epoch": 3.8,
      "learning_rate": 8.170731707317072e-07,
      "loss": 0.0242,
      "step": 356
    },
    {
      "epoch": 3.81,
      "learning_rate": 8.195121951219512e-07,
      "loss": 0.0069,
      "step": 357
    },
    {
      "epoch": 3.82,
      "learning_rate": 8.21951219512195e-07,
      "loss": 0.0197,
      "step": 358
    },
    {
      "epoch": 3.83,
      "learning_rate": 8.243902439024389e-07,
      "loss": 0.0062,
      "step": 359
    },
    {
      "epoch": 3.84,
      "learning_rate": 8.268292682926829e-07,
      "loss": 0.0194,
      "step": 360
    },
    {
      "epoch": 3.85,
      "learning_rate": 8.292682926829268e-07,
      "loss": 0.0415,
      "step": 361
    },
    {
      "epoch": 3.86,
      "learning_rate": 8.317073170731706e-07,
      "loss": 0.0016,
      "step": 362
    },
    {
      "epoch": 3.87,
      "learning_rate": 8.341463414634145e-07,
      "loss": 0.0326,
      "step": 363
    },
    {
      "epoch": 3.88,
      "learning_rate": 8.365853658536585e-07,
      "loss": 0.0065,
      "step": 364
    },
    {
      "epoch": 3.89,
      "learning_rate": 8.390243902439024e-07,
      "loss": 0.0002,
      "step": 365
    },
    {
      "epoch": 3.9,
      "learning_rate": 8.414634146341463e-07,
      "loss": 0.0537,
      "step": 366
    },
    {
      "epoch": 3.91,
      "learning_rate": 8.439024390243901e-07,
      "loss": 0.0002,
      "step": 367
    },
    {
      "epoch": 3.93,
      "learning_rate": 8.463414634146341e-07,
      "loss": 0.0298,
      "step": 368
    },
    {
      "epoch": 3.94,
      "learning_rate": 8.48780487804878e-07,
      "loss": 0.0101,
      "step": 369
    },
    {
      "epoch": 3.95,
      "learning_rate": 8.512195121951219e-07,
      "loss": 0.0144,
      "step": 370
    },
    {
      "epoch": 3.96,
      "learning_rate": 8.536585365853657e-07,
      "loss": 0.0581,
      "step": 371
    },
    {
      "epoch": 3.97,
      "learning_rate": 8.560975609756097e-07,
      "loss": 0.0349,
      "step": 372
    },
    {
      "epoch": 3.98,
      "learning_rate": 8.585365853658536e-07,
      "loss": 0.0013,
      "step": 373
    },
    {
      "epoch": 3.99,
      "learning_rate": 8.609756097560975e-07,
      "loss": 0.0314,
      "step": 374
    },
    {
      "epoch": 4.0,
      "learning_rate": 8.634146341463415e-07,
      "loss": 0.0651,
      "step": 375
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.017639651894569397,
      "eval_runtime": 13.0431,
      "eval_samples_per_second": 57.502,
      "eval_steps_per_second": 14.414,
      "eval_wer": 0.006747638326585695,
      "step": 375
    },
    {
      "epoch": 4.01,
      "learning_rate": 8.658536585365853e-07,
      "loss": 0.0004,
      "step": 376
    },
    {
      "epoch": 4.02,
      "learning_rate": 8.682926829268292e-07,
      "loss": 0.0059,
      "step": 377
    },
    {
      "epoch": 4.03,
      "learning_rate": 8.707317073170731e-07,
      "loss": 0.0002,
      "step": 378
    },
    {
      "epoch": 4.04,
      "learning_rate": 8.731707317073171e-07,
      "loss": 0.0228,
      "step": 379
    },
    {
      "epoch": 4.05,
      "learning_rate": 8.756097560975609e-07,
      "loss": 0.014,
      "step": 380
    },
    {
      "epoch": 4.06,
      "learning_rate": 8.780487804878048e-07,
      "loss": 0.0006,
      "step": 381
    },
    {
      "epoch": 4.07,
      "learning_rate": 8.804878048780487e-07,
      "loss": 0.0002,
      "step": 382
    },
    {
      "epoch": 4.09,
      "learning_rate": 8.829268292682927e-07,
      "loss": 0.0022,
      "step": 383
    },
    {
      "epoch": 4.1,
      "learning_rate": 8.853658536585366e-07,
      "loss": 0.0013,
      "step": 384
    },
    {
      "epoch": 4.11,
      "learning_rate": 8.878048780487804e-07,
      "loss": 0.004,
      "step": 385
    },
    {
      "epoch": 4.12,
      "learning_rate": 8.902439024390244e-07,
      "loss": 0.0038,
      "step": 386
    },
    {
      "epoch": 4.13,
      "learning_rate": 8.926829268292683e-07,
      "loss": 0.0002,
      "step": 387
    },
    {
      "epoch": 4.14,
      "learning_rate": 8.951219512195122e-07,
      "loss": 0.0155,
      "step": 388
    },
    {
      "epoch": 4.15,
      "learning_rate": 8.97560975609756e-07,
      "loss": 0.003,
      "step": 389
    },
    {
      "epoch": 4.16,
      "learning_rate": 9e-07,
      "loss": 0.0268,
      "step": 390
    },
    {
      "epoch": 4.17,
      "learning_rate": 9.024390243902439e-07,
      "loss": 0.0006,
      "step": 391
    },
    {
      "epoch": 4.18,
      "learning_rate": 9.048780487804878e-07,
      "loss": 0.0007,
      "step": 392
    },
    {
      "epoch": 4.19,
      "learning_rate": 9.073170731707317e-07,
      "loss": 0.0118,
      "step": 393
    },
    {
      "epoch": 4.2,
      "learning_rate": 9.097560975609756e-07,
      "loss": 0.037,
      "step": 394
    },
    {
      "epoch": 4.21,
      "learning_rate": 9.121951219512195e-07,
      "loss": 0.0003,
      "step": 395
    },
    {
      "epoch": 4.22,
      "learning_rate": 9.146341463414634e-07,
      "loss": 0.0865,
      "step": 396
    },
    {
      "epoch": 4.23,
      "learning_rate": 9.170731707317074e-07,
      "loss": 0.003,
      "step": 397
    },
    {
      "epoch": 4.25,
      "learning_rate": 9.195121951219512e-07,
      "loss": 0.0492,
      "step": 398
    },
    {
      "epoch": 4.26,
      "learning_rate": 9.219512195121951e-07,
      "loss": 0.1519,
      "step": 399
    },
    {
      "epoch": 4.27,
      "learning_rate": 9.24390243902439e-07,
      "loss": 0.0197,
      "step": 400
    },
    {
      "epoch": 4.28,
      "learning_rate": 9.26829268292683e-07,
      "loss": 0.0019,
      "step": 401
    },
    {
      "epoch": 4.29,
      "learning_rate": 9.292682926829269e-07,
      "loss": 0.0502,
      "step": 402
    },
    {
      "epoch": 4.3,
      "learning_rate": 9.317073170731707e-07,
      "loss": 0.0015,
      "step": 403
    },
    {
      "epoch": 4.31,
      "learning_rate": 9.341463414634146e-07,
      "loss": 0.0002,
      "step": 404
    },
    {
      "epoch": 4.32,
      "learning_rate": 9.365853658536586e-07,
      "loss": 0.0149,
      "step": 405
    },
    {
      "epoch": 4.33,
      "learning_rate": 9.390243902439024e-07,
      "loss": 0.0113,
      "step": 406
    },
    {
      "epoch": 4.34,
      "learning_rate": 9.414634146341462e-07,
      "loss": 0.0007,
      "step": 407
    },
    {
      "epoch": 4.35,
      "learning_rate": 9.439024390243901e-07,
      "loss": 0.0067,
      "step": 408
    },
    {
      "epoch": 4.36,
      "learning_rate": 9.463414634146341e-07,
      "loss": 0.0506,
      "step": 409
    },
    {
      "epoch": 4.37,
      "learning_rate": 9.48780487804878e-07,
      "loss": 0.1638,
      "step": 410
    },
    {
      "epoch": 4.38,
      "learning_rate": 9.512195121951218e-07,
      "loss": 0.0132,
      "step": 411
    },
    {
      "epoch": 4.39,
      "learning_rate": 9.536585365853657e-07,
      "loss": 0.0207,
      "step": 412
    },
    {
      "epoch": 4.41,
      "learning_rate": 9.560975609756097e-07,
      "loss": 0.0018,
      "step": 413
    },
    {
      "epoch": 4.42,
      "learning_rate": 9.585365853658535e-07,
      "loss": 0.0112,
      "step": 414
    },
    {
      "epoch": 4.43,
      "learning_rate": 9.609756097560975e-07,
      "loss": 0.0433,
      "step": 415
    },
    {
      "epoch": 4.44,
      "learning_rate": 9.634146341463414e-07,
      "loss": 0.0017,
      "step": 416
    },
    {
      "epoch": 4.45,
      "learning_rate": 9.658536585365854e-07,
      "loss": 0.0251,
      "step": 417
    },
    {
      "epoch": 4.46,
      "learning_rate": 9.682926829268292e-07,
      "loss": 0.0283,
      "step": 418
    },
    {
      "epoch": 4.47,
      "learning_rate": 9.70731707317073e-07,
      "loss": 0.0057,
      "step": 419
    },
    {
      "epoch": 4.48,
      "learning_rate": 9.73170731707317e-07,
      "loss": 0.0022,
      "step": 420
    },
    {
      "epoch": 4.49,
      "learning_rate": 9.756097560975609e-07,
      "loss": 0.0198,
      "step": 421
    },
    {
      "epoch": 4.5,
      "learning_rate": 9.78048780487805e-07,
      "loss": 0.0002,
      "step": 422
    },
    {
      "epoch": 4.51,
      "learning_rate": 9.804878048780487e-07,
      "loss": 0.0094,
      "step": 423
    },
    {
      "epoch": 4.52,
      "learning_rate": 9.829268292682926e-07,
      "loss": 0.002,
      "step": 424
    },
    {
      "epoch": 4.53,
      "learning_rate": 9.853658536585366e-07,
      "loss": 0.0032,
      "step": 425
    },
    {
      "epoch": 4.54,
      "learning_rate": 9.878048780487804e-07,
      "loss": 0.0027,
      "step": 426
    },
    {
      "epoch": 4.55,
      "learning_rate": 9.902439024390242e-07,
      "loss": 0.0003,
      "step": 427
    },
    {
      "epoch": 4.57,
      "learning_rate": 9.926829268292683e-07,
      "loss": 0.0756,
      "step": 428
    },
    {
      "epoch": 4.58,
      "learning_rate": 9.95121951219512e-07,
      "loss": 0.0182,
      "step": 429
    },
    {
      "epoch": 4.59,
      "learning_rate": 9.975609756097561e-07,
      "loss": 0.038,
      "step": 430
    },
    {
      "epoch": 4.6,
      "learning_rate": 1e-06,
      "loss": 0.0478,
      "step": 431
    },
    {
      "epoch": 4.61,
      "learning_rate": 9.999988264446444e-07,
      "loss": 0.0144,
      "step": 432
    },
    {
      "epoch": 4.62,
      "learning_rate": 9.999953057840867e-07,
      "loss": 0.0022,
      "step": 433
    },
    {
      "epoch": 4.63,
      "learning_rate": 9.999894380348535e-07,
      "loss": 0.0826,
      "step": 434
    },
    {
      "epoch": 4.64,
      "learning_rate": 9.999812232244895e-07,
      "loss": 0.0241,
      "step": 435
    },
    {
      "epoch": 4.65,
      "learning_rate": 9.999706613915566e-07,
      "loss": 0.016,
      "step": 436
    },
    {
      "epoch": 4.66,
      "learning_rate": 9.999577525856344e-07,
      "loss": 0.0002,
      "step": 437
    },
    {
      "epoch": 4.67,
      "learning_rate": 9.9994249686732e-07,
      "loss": 0.0074,
      "step": 438
    },
    {
      "epoch": 4.68,
      "learning_rate": 9.999248943082269e-07,
      "loss": 0.0002,
      "step": 439
    },
    {
      "epoch": 4.69,
      "learning_rate": 9.999049449909852e-07,
      "loss": 0.0002,
      "step": 440
    },
    {
      "epoch": 4.7,
      "learning_rate": 9.99882649009242e-07,
      "loss": 0.0198,
      "step": 441
    },
    {
      "epoch": 4.71,
      "learning_rate": 9.99858006467659e-07,
      "loss": 0.112,
      "step": 442
    },
    {
      "epoch": 4.73,
      "learning_rate": 9.998310174819142e-07,
      "loss": 0.0003,
      "step": 443
    },
    {
      "epoch": 4.74,
      "learning_rate": 9.998016821786995e-07,
      "loss": 0.0298,
      "step": 444
    },
    {
      "epoch": 4.75,
      "learning_rate": 9.997700006957213e-07,
      "loss": 0.0117,
      "step": 445
    },
    {
      "epoch": 4.76,
      "learning_rate": 9.997359731816997e-07,
      "loss": 0.0003,
      "step": 446
    },
    {
      "epoch": 4.77,
      "learning_rate": 9.996995997963675e-07,
      "loss": 0.0007,
      "step": 447
    },
    {
      "epoch": 4.78,
      "learning_rate": 9.996608807104691e-07,
      "loss": 0.0007,
      "step": 448
    },
    {
      "epoch": 4.79,
      "learning_rate": 9.996198161057606e-07,
      "loss": 0.0322,
      "step": 449
    },
    {
      "epoch": 4.8,
      "learning_rate": 9.995764061750085e-07,
      "loss": 0.0277,
      "step": 450
    },
    {
      "epoch": 4.81,
      "learning_rate": 9.995306511219882e-07,
      "loss": 0.0002,
      "step": 451
    },
    {
      "epoch": 4.82,
      "learning_rate": 9.994825511614845e-07,
      "loss": 0.0196,
      "step": 452
    },
    {
      "epoch": 4.83,
      "learning_rate": 9.994321065192893e-07,
      "loss": 0.0137,
      "step": 453
    },
    {
      "epoch": 4.84,
      "learning_rate": 9.993793174322006e-07,
      "loss": 0.0373,
      "step": 454
    },
    {
      "epoch": 4.85,
      "learning_rate": 9.993241841480221e-07,
      "loss": 0.0208,
      "step": 455
    },
    {
      "epoch": 4.86,
      "learning_rate": 9.992667069255618e-07,
      "loss": 0.013,
      "step": 456
    },
    {
      "epoch": 4.87,
      "learning_rate": 9.992068860346306e-07,
      "loss": 0.0002,
      "step": 457
    },
    {
      "epoch": 4.89,
      "learning_rate": 9.991447217560407e-07,
      "loss": 0.0287,
      "step": 458
    },
    {
      "epoch": 4.9,
      "learning_rate": 9.99080214381605e-07,
      "loss": 0.0689,
      "step": 459
    },
    {
      "epoch": 4.91,
      "learning_rate": 9.990133642141357e-07,
      "loss": 0.0435,
      "step": 460
    },
    {
      "epoch": 4.92,
      "learning_rate": 9.98944171567442e-07,
      "loss": 0.0283,
      "step": 461
    },
    {
      "epoch": 4.93,
      "learning_rate": 9.9887263676633e-07,
      "loss": 0.0431,
      "step": 462
    },
    {
      "epoch": 4.94,
      "learning_rate": 9.98798760146599e-07,
      "loss": 0.0078,
      "step": 463
    },
    {
      "epoch": 4.95,
      "learning_rate": 9.98722542055043e-07,
      "loss": 0.0033,
      "step": 464
    },
    {
      "epoch": 4.96,
      "learning_rate": 9.986439828494463e-07,
      "loss": 0.0022,
      "step": 465
    },
    {
      "epoch": 4.97,
      "learning_rate": 9.985630828985833e-07,
      "loss": 0.0081,
      "step": 466
    },
    {
      "epoch": 4.98,
      "learning_rate": 9.984798425822163e-07,
      "loss": 0.0002,
      "step": 467
    },
    {
      "epoch": 4.99,
      "learning_rate": 9.983942622910934e-07,
      "loss": 0.0002,
      "step": 468
    },
    {
      "epoch": 4.99,
      "eval_loss": 0.006144232582300901,
      "eval_runtime": 12.6739,
      "eval_samples_per_second": 59.177,
      "eval_steps_per_second": 14.834,
      "eval_wer": 0.0018893387314439945,
      "step": 468
    },
    {
      "epoch": 5.0,
      "learning_rate": 9.98306342426948e-07,
      "loss": 0.0151,
      "step": 469
    },
    {
      "epoch": 5.01,
      "learning_rate": 9.98216083402495e-07,
      "loss": 0.0005,
      "step": 470
    },
    {
      "epoch": 5.02,
      "learning_rate": 9.981234856414305e-07,
      "loss": 0.0805,
      "step": 471
    },
    {
      "epoch": 5.03,
      "learning_rate": 9.980285495784288e-07,
      "loss": 0.1467,
      "step": 472
    },
    {
      "epoch": 5.05,
      "learning_rate": 9.979312756591408e-07,
      "loss": 0.0321,
      "step": 473
    },
    {
      "epoch": 5.06,
      "learning_rate": 9.978316643401916e-07,
      "loss": 0.0035,
      "step": 474
    },
    {
      "epoch": 5.07,
      "learning_rate": 9.97729716089179e-07,
      "loss": 0.0312,
      "step": 475
    },
    {
      "epoch": 5.08,
      "learning_rate": 9.97625431384671e-07,
      "loss": 0.0631,
      "step": 476
    },
    {
      "epoch": 5.09,
      "learning_rate": 9.975188107162024e-07,
      "loss": 0.0046,
      "step": 477
    },
    {
      "epoch": 5.1,
      "learning_rate": 9.974098545842748e-07,
      "loss": 0.0304,
      "step": 478
    },
    {
      "epoch": 5.11,
      "learning_rate": 9.97298563500352e-07,
      "loss": 0.0027,
      "step": 479
    },
    {
      "epoch": 5.12,
      "learning_rate": 9.971849379868593e-07,
      "loss": 0.0557,
      "step": 480
    },
    {
      "epoch": 5.13,
      "learning_rate": 9.970689785771798e-07,
      "loss": 0.0008,
      "step": 481
    },
    {
      "epoch": 5.14,
      "learning_rate": 9.969506858156526e-07,
      "loss": 0.0076,
      "step": 482
    },
    {
      "epoch": 5.15,
      "learning_rate": 9.968300602575706e-07,
      "loss": 0.0584,
      "step": 483
    },
    {
      "epoch": 5.16,
      "learning_rate": 9.967071024691763e-07,
      "loss": 0.014,
      "step": 484
    },
    {
      "epoch": 5.17,
      "learning_rate": 9.96581813027661e-07,
      "loss": 0.0101,
      "step": 485
    },
    {
      "epoch": 5.18,
      "learning_rate": 9.964541925211611e-07,
      "loss": 0.0075,
      "step": 486
    },
    {
      "epoch": 5.19,
      "learning_rate": 9.963242415487556e-07,
      "loss": 0.0001,
      "step": 487
    },
    {
      "epoch": 5.21,
      "learning_rate": 9.961919607204629e-07,
      "loss": 0.0317,
      "step": 488
    },
    {
      "epoch": 5.22,
      "learning_rate": 9.960573506572389e-07,
      "loss": 0.0122,
      "step": 489
    },
    {
      "epoch": 5.23,
      "learning_rate": 9.959204119909725e-07,
      "loss": 0.0097,
      "step": 490
    },
    {
      "epoch": 5.24,
      "learning_rate": 9.957811453644846e-07,
      "loss": 0.0223,
      "step": 491
    },
    {
      "epoch": 5.25,
      "learning_rate": 9.956395514315235e-07,
      "loss": 0.034,
      "step": 492
    },
    {
      "epoch": 5.26,
      "learning_rate": 9.95495630856762e-07,
      "loss": 0.0026,
      "step": 493
    },
    {
      "epoch": 5.27,
      "learning_rate": 9.95349384315796e-07,
      "loss": 0.0027,
      "step": 494
    },
    {
      "epoch": 5.28,
      "learning_rate": 9.952008124951382e-07,
      "loss": 0.0048,
      "step": 495
    },
    {
      "epoch": 5.29,
      "learning_rate": 9.950499160922182e-07,
      "loss": 0.0536,
      "step": 496
    },
    {
      "epoch": 5.3,
      "learning_rate": 9.94896695815377e-07,
      "loss": 0.0399,
      "step": 497
    },
    {
      "epoch": 5.31,
      "learning_rate": 9.947411523838647e-07,
      "loss": 0.0006,
      "step": 498
    },
    {
      "epoch": 5.32,
      "learning_rate": 9.945832865278361e-07,
      "loss": 0.0865,
      "step": 499
    },
    {
      "epoch": 5.33,
      "learning_rate": 9.94423098988349e-07,
      "loss": 0.0002,
      "step": 500
    },
    {
      "epoch": 5.34,
      "learning_rate": 9.942605905173592e-07,
      "loss": 0.0038,
      "step": 501
    },
    {
      "epoch": 5.35,
      "learning_rate": 9.940957618777168e-07,
      "loss": 0.0176,
      "step": 502
    },
    {
      "epoch": 5.37,
      "learning_rate": 9.939286138431646e-07,
      "loss": 0.0068,
      "step": 503
    },
    {
      "epoch": 5.38,
      "learning_rate": 9.937591471983322e-07,
      "loss": 0.0002,
      "step": 504
    },
    {
      "epoch": 5.39,
      "learning_rate": 9.935873627387336e-07,
      "loss": 0.0002,
      "step": 505
    },
    {
      "epoch": 5.4,
      "learning_rate": 9.93413261270763e-07,
      "loss": 0.0026,
      "step": 506
    },
    {
      "epoch": 5.41,
      "learning_rate": 9.932368436116914e-07,
      "loss": 0.0207,
      "step": 507
    },
    {
      "epoch": 5.42,
      "learning_rate": 9.930581105896624e-07,
      "loss": 0.0003,
      "step": 508
    },
    {
      "epoch": 5.43,
      "learning_rate": 9.92877063043688e-07,
      "loss": 0.0353,
      "step": 509
    },
    {
      "epoch": 5.44,
      "learning_rate": 9.92693701823646e-07,
      "loss": 0.011,
      "step": 510
    },
    {
      "epoch": 5.45,
      "learning_rate": 9.925080277902741e-07,
      "loss": 0.0077,
      "step": 511
    },
    {
      "epoch": 5.46,
      "learning_rate": 9.923200418151675e-07,
      "loss": 0.0025,
      "step": 512
    },
    {
      "epoch": 5.47,
      "learning_rate": 9.921297447807743e-07,
      "loss": 0.035,
      "step": 513
    },
    {
      "epoch": 5.48,
      "learning_rate": 9.919371375803905e-07,
      "loss": 0.0066,
      "step": 514
    },
    {
      "epoch": 5.49,
      "learning_rate": 9.91742221118157e-07,
      "loss": 0.0004,
      "step": 515
    },
    {
      "epoch": 5.5,
      "learning_rate": 9.91544996309055e-07,
      "loss": 0.0003,
      "step": 516
    },
    {
      "epoch": 5.51,
      "learning_rate": 9.913454640789012e-07,
      "loss": 0.0362,
      "step": 517
    },
    {
      "epoch": 5.53,
      "learning_rate": 9.911436253643443e-07,
      "loss": 0.0106,
      "step": 518
    },
    {
      "epoch": 5.54,
      "learning_rate": 9.909394811128598e-07,
      "loss": 0.0364,
      "step": 519
    },
    {
      "epoch": 5.55,
      "learning_rate": 9.90733032282746e-07,
      "loss": 0.0251,
      "step": 520
    },
    {
      "epoch": 5.56,
      "learning_rate": 9.905242798431194e-07,
      "loss": 0.0004,
      "step": 521
    },
    {
      "epoch": 5.57,
      "learning_rate": 9.903132247739105e-07,
      "loss": 0.0007,
      "step": 522
    },
    {
      "epoch": 5.58,
      "learning_rate": 9.90099868065858e-07,
      "loss": 0.0617,
      "step": 523
    },
    {
      "epoch": 5.59,
      "learning_rate": 9.89884210720506e-07,
      "loss": 0.0174,
      "step": 524
    },
    {
      "epoch": 5.6,
      "learning_rate": 9.896662537501975e-07,
      "loss": 0.0191,
      "step": 525
    },
    {
      "epoch": 5.61,
      "learning_rate": 9.894459981780709e-07,
      "loss": 0.0165,
      "step": 526
    },
    {
      "epoch": 5.62,
      "learning_rate": 9.892234450380547e-07,
      "loss": 0.0779,
      "step": 527
    },
    {
      "epoch": 5.63,
      "learning_rate": 9.889985953748625e-07,
      "loss": 0.0091,
      "step": 528
    },
    {
      "epoch": 5.64,
      "learning_rate": 9.887714502439884e-07,
      "loss": 0.0211,
      "step": 529
    },
    {
      "epoch": 5.65,
      "learning_rate": 9.88542010711702e-07,
      "loss": 0.0658,
      "step": 530
    },
    {
      "epoch": 5.66,
      "learning_rate": 9.883102778550434e-07,
      "loss": 0.0144,
      "step": 531
    },
    {
      "epoch": 5.67,
      "learning_rate": 9.880762527618176e-07,
      "loss": 0.0664,
      "step": 532
    },
    {
      "epoch": 5.69,
      "learning_rate": 9.878399365305905e-07,
      "loss": 0.0004,
      "step": 533
    },
    {
      "epoch": 5.7,
      "learning_rate": 9.876013302706828e-07,
      "loss": 0.0013,
      "step": 534
    },
    {
      "epoch": 5.71,
      "learning_rate": 9.873604351021647e-07,
      "loss": 0.0085,
      "step": 535
    },
    {
      "epoch": 5.72,
      "learning_rate": 9.87117252155852e-07,
      "loss": 0.0033,
      "step": 536
    },
    {
      "epoch": 5.73,
      "learning_rate": 9.868717825732994e-07,
      "loss": 0.0003,
      "step": 537
    },
    {
      "epoch": 5.74,
      "learning_rate": 9.866240275067947e-07,
      "loss": 0.0033,
      "step": 538
    },
    {
      "epoch": 5.75,
      "learning_rate": 9.863739881193557e-07,
      "loss": 0.0053,
      "step": 539
    },
    {
      "epoch": 5.76,
      "learning_rate": 9.861216655847224e-07,
      "loss": 0.0003,
      "step": 540
    },
    {
      "epoch": 5.77,
      "learning_rate": 9.858670610873528e-07,
      "loss": 0.0304,
      "step": 541
    },
    {
      "epoch": 5.78,
      "learning_rate": 9.856101758224166e-07,
      "loss": 0.0004,
      "step": 542
    },
    {
      "epoch": 5.79,
      "learning_rate": 9.853510109957902e-07,
      "loss": 0.0002,
      "step": 543
    },
    {
      "epoch": 5.8,
      "learning_rate": 9.850895678240507e-07,
      "loss": 0.0109,
      "step": 544
    },
    {
      "epoch": 5.81,
      "learning_rate": 9.8482584753447e-07,
      "loss": 0.0285,
      "step": 545
    },
    {
      "epoch": 5.82,
      "learning_rate": 9.845598513650102e-07,
      "loss": 0.0058,
      "step": 546
    },
    {
      "epoch": 5.83,
      "learning_rate": 9.842915805643156e-07,
      "loss": 0.0002,
      "step": 547
    },
    {
      "epoch": 5.85,
      "learning_rate": 9.840210363917088e-07,
      "loss": 0.0016,
      "step": 548
    },
    {
      "epoch": 5.86,
      "learning_rate": 9.837482201171843e-07,
      "loss": 0.0027,
      "step": 549
    },
    {
      "epoch": 5.87,
      "learning_rate": 9.834731330214016e-07,
      "loss": 0.0468,
      "step": 550
    },
    {
      "epoch": 5.88,
      "learning_rate": 9.831957763956812e-07,
      "loss": 0.0187,
      "step": 551
    },
    {
      "epoch": 5.89,
      "learning_rate": 9.829161515419958e-07,
      "loss": 0.0538,
      "step": 552
    },
    {
      "epoch": 5.9,
      "learning_rate": 9.826342597729671e-07,
      "loss": 0.0044,
      "step": 553
    },
    {
      "epoch": 5.91,
      "learning_rate": 9.823501024118568e-07,
      "loss": 0.0297,
      "step": 554
    },
    {
      "epoch": 5.92,
      "learning_rate": 9.820636807925626e-07,
      "loss": 0.0696,
      "step": 555
    },
    {
      "epoch": 5.93,
      "learning_rate": 9.817749962596114e-07,
      "loss": 0.0571,
      "step": 556
    },
    {
      "epoch": 5.94,
      "learning_rate": 9.814840501681521e-07,
      "loss": 0.0008,
      "step": 557
    },
    {
      "epoch": 5.95,
      "learning_rate": 9.811908438839498e-07,
      "loss": 0.0183,
      "step": 558
    },
    {
      "epoch": 5.96,
      "learning_rate": 9.8089537878338e-07,
      "loss": 0.1011,
      "step": 559
    },
    {
      "epoch": 5.97,
      "learning_rate": 9.805976562534214e-07,
      "loss": 0.0003,
      "step": 560
    },
    {
      "epoch": 5.98,
      "learning_rate": 9.802976776916493e-07,
      "loss": 0.0003,
      "step": 561
    },
    {
      "epoch": 5.99,
      "learning_rate": 9.799954445062296e-07,
      "loss": 0.0637,
      "step": 562
    },
    {
      "epoch": 5.99,
      "eval_loss": 0.0158248208463192,
      "eval_runtime": 13.6472,
      "eval_samples_per_second": 54.956,
      "eval_steps_per_second": 13.776,
      "eval_wer": 0.006072874493927126,
      "step": 562
    },
    {
      "epoch": 6.01,
      "learning_rate": 9.796909581159115e-07,
      "loss": 0.0175,
      "step": 563
    },
    {
      "epoch": 6.02,
      "learning_rate": 9.79384219950022e-07,
      "loss": 0.0005,
      "step": 564
    },
    {
      "epoch": 6.03,
      "learning_rate": 9.790752314484577e-07,
      "loss": 0.0002,
      "step": 565
    },
    {
      "epoch": 6.04,
      "learning_rate": 9.787639940616787e-07,
      "loss": 0.0004,
      "step": 566
    },
    {
      "epoch": 6.05,
      "learning_rate": 9.784505092507029e-07,
      "loss": 0.0029,
      "step": 567
    },
    {
      "epoch": 6.06,
      "learning_rate": 9.781347784870973e-07,
      "loss": 0.0003,
      "step": 568
    },
    {
      "epoch": 6.07,
      "learning_rate": 9.778168032529715e-07,
      "loss": 0.0002,
      "step": 569
    },
    {
      "epoch": 6.08,
      "learning_rate": 9.77496585040972e-07,
      "loss": 0.0017,
      "step": 570
    },
    {
      "epoch": 6.09,
      "learning_rate": 9.77174125354274e-07,
      "loss": 0.0042,
      "step": 571
    },
    {
      "epoch": 6.1,
      "learning_rate": 9.768494257065747e-07,
      "loss": 0.0249,
      "step": 572
    },
    {
      "epoch": 6.11,
      "learning_rate": 9.765224876220858e-07,
      "loss": 0.0057,
      "step": 573
    },
    {
      "epoch": 6.12,
      "learning_rate": 9.761933126355277e-07,
      "loss": 0.0234,
      "step": 574
    },
    {
      "epoch": 6.13,
      "learning_rate": 9.7586190229212e-07,
      "loss": 0.0573,
      "step": 575
    },
    {
      "epoch": 6.14,
      "learning_rate": 9.755282581475767e-07,
      "loss": 0.0004,
      "step": 576
    },
    {
      "epoch": 6.15,
      "learning_rate": 9.75192381768097e-07,
      "loss": 0.0002,
      "step": 577
    },
    {
      "epoch": 6.17,
      "learning_rate": 9.748542747303594e-07,
      "loss": 0.0441,
      "step": 578
    },
    {
      "epoch": 6.18,
      "learning_rate": 9.745139386215126e-07,
      "loss": 0.0334,
      "step": 579
    },
    {
      "epoch": 6.19,
      "learning_rate": 9.741713750391701e-07,
      "loss": 0.0285,
      "step": 580
    },
    {
      "epoch": 6.2,
      "learning_rate": 9.738265855914012e-07,
      "loss": 0.017,
      "step": 581
    },
    {
      "epoch": 6.21,
      "learning_rate": 9.734795718967237e-07,
      "loss": 0.011,
      "step": 582
    },
    {
      "epoch": 6.22,
      "learning_rate": 9.731303355840966e-07,
      "loss": 0.0615,
      "step": 583
    },
    {
      "epoch": 6.23,
      "learning_rate": 9.72778878292913e-07,
      "loss": 0.008,
      "step": 584
    },
    {
      "epoch": 6.24,
      "learning_rate": 9.724252016729908e-07,
      "loss": 0.0078,
      "step": 585
    },
    {
      "epoch": 6.25,
      "learning_rate": 9.720693073845666e-07,
      "loss": 0.0124,
      "step": 586
    },
    {
      "epoch": 6.26,
      "learning_rate": 9.717111970982868e-07,
      "loss": 0.0006,
      "step": 587
    },
    {
      "epoch": 6.27,
      "learning_rate": 9.713508724952005e-07,
      "loss": 0.0002,
      "step": 588
    },
    {
      "epoch": 6.28,
      "learning_rate": 9.709883352667513e-07,
      "loss": 0.0019,
      "step": 589
    },
    {
      "epoch": 6.29,
      "learning_rate": 9.706235871147687e-07,
      "loss": 0.0003,
      "step": 590
    },
    {
      "epoch": 6.3,
      "learning_rate": 9.70256629751462e-07,
      "loss": 0.0085,
      "step": 591
    },
    {
      "epoch": 6.31,
      "learning_rate": 9.698874648994097e-07,
      "loss": 0.0002,
      "step": 592
    },
    {
      "epoch": 6.33,
      "learning_rate": 9.69516094291554e-07,
      "loss": 0.0013,
      "step": 593
    },
    {
      "epoch": 6.34,
      "learning_rate": 9.6914251967119e-07,
      "loss": 0.0003,
      "step": 594
    },
    {
      "epoch": 6.35,
      "learning_rate": 9.687667427919603e-07,
      "loss": 0.0239,
      "step": 595
    },
    {
      "epoch": 6.36,
      "learning_rate": 9.683887654178444e-07,
      "loss": 0.0298,
      "step": 596
    },
    {
      "epoch": 6.37,
      "learning_rate": 9.680085893231522e-07,
      "loss": 0.0002,
      "step": 597
    },
    {
      "epoch": 6.38,
      "learning_rate": 9.67626216292514e-07,
      "loss": 0.0002,
      "step": 598
    },
    {
      "epoch": 6.39,
      "learning_rate": 9.672416481208736e-07,
      "loss": 0.0002,
      "step": 599
    },
    {
      "epoch": 6.4,
      "learning_rate": 9.668548866134795e-07,
      "loss": 0.0087,
      "step": 600
    },
    {
      "epoch": 6.41,
      "learning_rate": 9.664659335858753e-07,
      "loss": 0.0309,
      "step": 601
    },
    {
      "epoch": 6.42,
      "learning_rate": 9.660747908638931e-07,
      "loss": 0.0401,
      "step": 602
    },
    {
      "epoch": 6.43,
      "learning_rate": 9.656814602836434e-07,
      "loss": 0.0316,
      "step": 603
    },
    {
      "epoch": 6.44,
      "learning_rate": 9.652859436915067e-07,
      "loss": 0.0001,
      "step": 604
    },
    {
      "epoch": 6.45,
      "learning_rate": 9.648882429441256e-07,
      "loss": 0.0154,
      "step": 605
    },
    {
      "epoch": 6.46,
      "learning_rate": 9.644883599083957e-07,
      "loss": 0.0035,
      "step": 606
    },
    {
      "epoch": 6.47,
      "learning_rate": 9.640862964614562e-07,
      "loss": 0.0003,
      "step": 607
    },
    {
      "epoch": 6.49,
      "learning_rate": 9.636820544906823e-07,
      "loss": 0.0017,
      "step": 608
    },
    {
      "epoch": 6.5,
      "learning_rate": 9.632756358936748e-07,
      "loss": 0.0172,
      "step": 609
    },
    {
      "epoch": 6.51,
      "learning_rate": 9.62867042578253e-07,
      "loss": 0.0006,
      "step": 610
    },
    {
      "epoch": 6.52,
      "learning_rate": 9.624562764624445e-07,
      "loss": 0.0002,
      "step": 611
    },
    {
      "epoch": 6.53,
      "learning_rate": 9.62043339474476e-07,
      "loss": 0.0272,
      "step": 612
    },
    {
      "epoch": 6.54,
      "learning_rate": 9.616282335527653e-07,
      "loss": 0.0087,
      "step": 613
    },
    {
      "epoch": 6.55,
      "learning_rate": 9.612109606459115e-07,
      "loss": 0.0012,
      "step": 614
    },
    {
      "epoch": 6.56,
      "learning_rate": 9.607915227126862e-07,
      "loss": 0.0139,
      "step": 615
    },
    {
      "epoch": 6.57,
      "learning_rate": 9.603699217220238e-07,
      "loss": 0.0025,
      "step": 616
    },
    {
      "epoch": 6.58,
      "learning_rate": 9.599461596530126e-07,
      "loss": 0.0289,
      "step": 617
    },
    {
      "epoch": 6.59,
      "learning_rate": 9.595202384948858e-07,
      "loss": 0.0004,
      "step": 618
    },
    {
      "epoch": 6.6,
      "learning_rate": 9.590921602470115e-07,
      "loss": 0.0004,
      "step": 619
    },
    {
      "epoch": 6.61,
      "learning_rate": 9.586619269188836e-07,
      "loss": 0.0346,
      "step": 620
    },
    {
      "epoch": 6.62,
      "learning_rate": 9.58229540530113e-07,
      "loss": 0.0915,
      "step": 621
    },
    {
      "epoch": 6.63,
      "learning_rate": 9.577950031104168e-07,
      "loss": 0.0139,
      "step": 622
    },
    {
      "epoch": 6.65,
      "learning_rate": 9.573583166996102e-07,
      "loss": 0.0029,
      "step": 623
    },
    {
      "epoch": 6.66,
      "learning_rate": 9.569194833475956e-07,
      "loss": 0.0044,
      "step": 624
    },
    {
      "epoch": 6.67,
      "learning_rate": 9.56478505114354e-07,
      "loss": 0.104,
      "step": 625
    },
    {
      "epoch": 6.68,
      "learning_rate": 9.56035384069935e-07,
      "loss": 0.0003,
      "step": 626
    },
    {
      "epoch": 6.69,
      "learning_rate": 9.555901222944466e-07,
      "loss": 0.0003,
      "step": 627
    },
    {
      "epoch": 6.7,
      "learning_rate": 9.551427218780465e-07,
      "loss": 0.0956,
      "step": 628
    },
    {
      "epoch": 6.71,
      "learning_rate": 9.546931849209313e-07,
      "loss": 0.0402,
      "step": 629
    },
    {
      "epoch": 6.72,
      "learning_rate": 9.542415135333267e-07,
      "loss": 0.0003,
      "step": 630
    },
    {
      "epoch": 6.73,
      "learning_rate": 9.537877098354784e-07,
      "loss": 0.0154,
      "step": 631
    },
    {
      "epoch": 6.74,
      "learning_rate": 9.533317759576416e-07,
      "loss": 0.0211,
      "step": 632
    },
    {
      "epoch": 6.75,
      "learning_rate": 9.528737140400706e-07,
      "loss": 0.0006,
      "step": 633
    },
    {
      "epoch": 6.76,
      "learning_rate": 9.524135262330098e-07,
      "loss": 0.0002,
      "step": 634
    },
    {
      "epoch": 6.77,
      "learning_rate": 9.519512146966822e-07,
      "loss": 0.0002,
      "step": 635
    },
    {
      "epoch": 6.78,
      "learning_rate": 9.514867816012809e-07,
      "loss": 0.0534,
      "step": 636
    },
    {
      "epoch": 6.79,
      "learning_rate": 9.510202291269575e-07,
      "loss": 0.0002,
      "step": 637
    },
    {
      "epoch": 6.81,
      "learning_rate": 9.505515594638127e-07,
      "loss": 0.0074,
      "step": 638
    },
    {
      "epoch": 6.82,
      "learning_rate": 9.500807748118856e-07,
      "loss": 0.0309,
      "step": 639
    },
    {
      "epoch": 6.83,
      "learning_rate": 9.496078773811437e-07,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 6.84,
      "learning_rate": 9.491328693914722e-07,
      "loss": 0.0234,
      "step": 641
    },
    {
      "epoch": 6.85,
      "learning_rate": 9.486557530726637e-07,
      "loss": 0.0004,
      "step": 642
    },
    {
      "epoch": 6.86,
      "learning_rate": 9.481765306644078e-07,
      "loss": 0.0005,
      "step": 643
    },
    {
      "epoch": 6.87,
      "learning_rate": 9.476952044162809e-07,
      "loss": 0.0336,
      "step": 644
    },
    {
      "epoch": 6.88,
      "learning_rate": 9.472117765877347e-07,
      "loss": 0.0225,
      "step": 645
    },
    {
      "epoch": 6.89,
      "learning_rate": 9.467262494480868e-07,
      "loss": 0.1017,
      "step": 646
    },
    {
      "epoch": 6.9,
      "learning_rate": 9.462386252765087e-07,
      "loss": 0.0047,
      "step": 647
    },
    {
      "epoch": 6.91,
      "learning_rate": 9.457489063620163e-07,
      "loss": 0.003,
      "step": 648
    },
    {
      "epoch": 6.92,
      "learning_rate": 9.452570950034588e-07,
      "loss": 0.017,
      "step": 649
    },
    {
      "epoch": 6.93,
      "learning_rate": 9.447631935095076e-07,
      "loss": 0.0576,
      "step": 650
    },
    {
      "epoch": 6.94,
      "learning_rate": 9.442672041986456e-07,
      "loss": 0.0002,
      "step": 651
    },
    {
      "epoch": 6.95,
      "learning_rate": 9.437691293991563e-07,
      "loss": 0.0386,
      "step": 652
    },
    {
      "epoch": 6.97,
      "learning_rate": 9.432689714491134e-07,
      "loss": 0.1188,
      "step": 653
    },
    {
      "epoch": 6.98,
      "learning_rate": 9.427667326963689e-07,
      "loss": 0.0086,
      "step": 654
    },
    {
      "epoch": 6.99,
      "learning_rate": 9.422624154985427e-07,
      "loss": 0.0438,
      "step": 655
    },
    {
      "epoch": 7.0,
      "learning_rate": 9.417560222230114e-07,
      "loss": 0.0004,
      "step": 656
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.005149130709469318,
      "eval_runtime": 12.5459,
      "eval_samples_per_second": 59.78,
      "eval_steps_per_second": 14.985,
      "eval_wer": 0.0020242914979757085,
      "step": 656
    },
    {
      "epoch": 7.01,
      "learning_rate": 9.412475552468972e-07,
      "loss": 0.0043,
      "step": 657
    },
    {
      "epoch": 7.02,
      "learning_rate": 9.407370169570567e-07,
      "loss": 0.0392,
      "step": 658
    },
    {
      "epoch": 7.03,
      "learning_rate": 9.402244097500695e-07,
      "loss": 0.0142,
      "step": 659
    },
    {
      "epoch": 7.04,
      "learning_rate": 9.397097360322276e-07,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 7.05,
      "learning_rate": 9.391929982195232e-07,
      "loss": 0.0149,
      "step": 661
    },
    {
      "epoch": 7.06,
      "learning_rate": 9.386741987376381e-07,
      "loss": 0.0047,
      "step": 662
    },
    {
      "epoch": 7.07,
      "learning_rate": 9.381533400219317e-07,
      "loss": 0.0022,
      "step": 663
    },
    {
      "epoch": 7.08,
      "learning_rate": 9.376304245174306e-07,
      "loss": 0.0013,
      "step": 664
    },
    {
      "epoch": 7.09,
      "learning_rate": 9.371054546788156e-07,
      "loss": 0.0098,
      "step": 665
    },
    {
      "epoch": 7.1,
      "learning_rate": 9.365784329704114e-07,
      "loss": 0.0304,
      "step": 666
    },
    {
      "epoch": 7.11,
      "learning_rate": 9.360493618661748e-07,
      "loss": 0.0326,
      "step": 667
    },
    {
      "epoch": 7.13,
      "learning_rate": 9.355182438496824e-07,
      "loss": 0.0002,
      "step": 668
    },
    {
      "epoch": 7.14,
      "learning_rate": 9.349850814141203e-07,
      "loss": 0.0024,
      "step": 669
    },
    {
      "epoch": 7.15,
      "learning_rate": 9.344498770622705e-07,
      "loss": 0.0017,
      "step": 670
    },
    {
      "epoch": 7.16,
      "learning_rate": 9.339126333065006e-07,
      "loss": 0.0142,
      "step": 671
    },
    {
      "epoch": 7.17,
      "learning_rate": 9.333733526687523e-07,
      "loss": 0.0428,
      "step": 672
    },
    {
      "epoch": 7.18,
      "learning_rate": 9.328320376805281e-07,
      "loss": 0.0046,
      "step": 673
    },
    {
      "epoch": 7.19,
      "learning_rate": 9.322886908828804e-07,
      "loss": 0.0028,
      "step": 674
    },
    {
      "epoch": 7.2,
      "learning_rate": 9.317433148263993e-07,
      "loss": 0.0538,
      "step": 675
    },
    {
      "epoch": 7.21,
      "learning_rate": 9.311959120712009e-07,
      "loss": 0.0185,
      "step": 676
    },
    {
      "epoch": 7.22,
      "learning_rate": 9.306464851869149e-07,
      "loss": 0.0005,
      "step": 677
    },
    {
      "epoch": 7.23,
      "learning_rate": 9.300950367526727e-07,
      "loss": 0.0002,
      "step": 678
    },
    {
      "epoch": 7.24,
      "learning_rate": 9.295415693570954e-07,
      "loss": 0.0009,
      "step": 679
    },
    {
      "epoch": 7.25,
      "learning_rate": 9.289860855982814e-07,
      "loss": 0.0368,
      "step": 680
    },
    {
      "epoch": 7.26,
      "learning_rate": 9.284285880837946e-07,
      "loss": 0.0029,
      "step": 681
    },
    {
      "epoch": 7.27,
      "learning_rate": 9.278690794306517e-07,
      "loss": 0.0003,
      "step": 682
    },
    {
      "epoch": 7.29,
      "learning_rate": 9.273075622653101e-07,
      "loss": 0.0756,
      "step": 683
    },
    {
      "epoch": 7.3,
      "learning_rate": 9.26744039223656e-07,
      "loss": 0.0006,
      "step": 684
    },
    {
      "epoch": 7.31,
      "learning_rate": 9.261785129509912e-07,
      "loss": 0.0054,
      "step": 685
    },
    {
      "epoch": 7.32,
      "learning_rate": 9.256109861020211e-07,
      "loss": 0.0002,
      "step": 686
    },
    {
      "epoch": 7.33,
      "learning_rate": 9.250414613408425e-07,
      "loss": 0.0002,
      "step": 687
    },
    {
      "epoch": 7.34,
      "learning_rate": 9.244699413409309e-07,
      "loss": 0.0405,
      "step": 688
    },
    {
      "epoch": 7.35,
      "learning_rate": 9.238964287851275e-07,
      "loss": 0.005,
      "step": 689
    },
    {
      "epoch": 7.36,
      "learning_rate": 9.233209263656272e-07,
      "loss": 0.0207,
      "step": 690
    },
    {
      "epoch": 7.37,
      "learning_rate": 9.227434367839659e-07,
      "loss": 0.0514,
      "step": 691
    },
    {
      "epoch": 7.38,
      "learning_rate": 9.221639627510075e-07,
      "loss": 0.0277,
      "step": 692
    },
    {
      "epoch": 7.39,
      "learning_rate": 9.215825069869315e-07,
      "loss": 0.0002,
      "step": 693
    },
    {
      "epoch": 7.4,
      "learning_rate": 9.2099907222122e-07,
      "loss": 0.0533,
      "step": 694
    },
    {
      "epoch": 7.41,
      "learning_rate": 9.204136611926448e-07,
      "loss": 0.0331,
      "step": 695
    },
    {
      "epoch": 7.42,
      "learning_rate": 9.198262766492553e-07,
      "loss": 0.0003,
      "step": 696
    },
    {
      "epoch": 7.43,
      "learning_rate": 9.19236921348364e-07,
      "loss": 0.0172,
      "step": 697
    },
    {
      "epoch": 7.45,
      "learning_rate": 9.186455980565357e-07,
      "loss": 0.0313,
      "step": 698
    },
    {
      "epoch": 7.46,
      "learning_rate": 9.180523095495727e-07,
      "loss": 0.0075,
      "step": 699
    },
    {
      "epoch": 7.47,
      "learning_rate": 9.174570586125025e-07,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 7.48,
      "learning_rate": 9.168598480395651e-07,
      "loss": 0.0337,
      "step": 701
    },
    {
      "epoch": 7.49,
      "learning_rate": 9.162606806341988e-07,
      "loss": 0.0793,
      "step": 702
    },
    {
      "epoch": 7.5,
      "learning_rate": 9.156595592090283e-07,
      "loss": 0.0261,
      "step": 703
    },
    {
      "epoch": 7.51,
      "learning_rate": 9.150564865858506e-07,
      "loss": 0.0003,
      "step": 704
    },
    {
      "epoch": 7.52,
      "learning_rate": 9.14451465595622e-07,
      "loss": 0.0283,
      "step": 705
    },
    {
      "epoch": 7.53,
      "learning_rate": 9.138444990784453e-07,
      "loss": 0.005,
      "step": 706
    },
    {
      "epoch": 7.54,
      "learning_rate": 9.132355898835555e-07,
      "loss": 0.0274,
      "step": 707
    },
    {
      "epoch": 7.55,
      "learning_rate": 9.126247408693071e-07,
      "loss": 0.0002,
      "step": 708
    },
    {
      "epoch": 7.56,
      "learning_rate": 9.120119549031608e-07,
      "loss": 0.0106,
      "step": 709
    },
    {
      "epoch": 7.57,
      "learning_rate": 9.113972348616698e-07,
      "loss": 0.0045,
      "step": 710
    },
    {
      "epoch": 7.58,
      "learning_rate": 9.107805836304657e-07,
      "loss": 0.0004,
      "step": 711
    },
    {
      "epoch": 7.59,
      "learning_rate": 9.101620041042462e-07,
      "loss": 0.0584,
      "step": 712
    },
    {
      "epoch": 7.61,
      "learning_rate": 9.095414991867603e-07,
      "loss": 0.0259,
      "step": 713
    },
    {
      "epoch": 7.62,
      "learning_rate": 9.089190717907956e-07,
      "loss": 0.0097,
      "step": 714
    },
    {
      "epoch": 7.63,
      "learning_rate": 9.082947248381643e-07,
      "loss": 0.0856,
      "step": 715
    },
    {
      "epoch": 7.64,
      "learning_rate": 9.07668461259689e-07,
      "loss": 0.037,
      "step": 716
    },
    {
      "epoch": 7.65,
      "learning_rate": 9.070402839951896e-07,
      "loss": 0.0073,
      "step": 717
    },
    {
      "epoch": 7.66,
      "learning_rate": 9.064101959934694e-07,
      "loss": 0.046,
      "step": 718
    },
    {
      "epoch": 7.67,
      "learning_rate": 9.057782002123011e-07,
      "loss": 0.0129,
      "step": 719
    },
    {
      "epoch": 7.68,
      "learning_rate": 9.051442996184126e-07,
      "loss": 0.0647,
      "step": 720
    },
    {
      "epoch": 7.69,
      "learning_rate": 9.045084971874737e-07,
      "loss": 0.0038,
      "step": 721
    },
    {
      "epoch": 7.7,
      "learning_rate": 9.038707959040819e-07,
      "loss": 0.0082,
      "step": 722
    },
    {
      "epoch": 7.71,
      "learning_rate": 9.03231198761748e-07,
      "loss": 0.0133,
      "step": 723
    },
    {
      "epoch": 7.72,
      "learning_rate": 9.025897087628829e-07,
      "loss": 0.0003,
      "step": 724
    },
    {
      "epoch": 7.73,
      "learning_rate": 9.019463289187825e-07,
      "loss": 0.0536,
      "step": 725
    },
    {
      "epoch": 7.74,
      "learning_rate": 9.013010622496144e-07,
      "loss": 0.0005,
      "step": 726
    },
    {
      "epoch": 7.75,
      "learning_rate": 9.00653911784403e-07,
      "loss": 0.0085,
      "step": 727
    },
    {
      "epoch": 7.77,
      "learning_rate": 9.000048805610159e-07,
      "loss": 0.0887,
      "step": 728
    },
    {
      "epoch": 7.78,
      "learning_rate": 8.993539716261496e-07,
      "loss": 0.0594,
      "step": 729
    },
    {
      "epoch": 7.79,
      "learning_rate": 8.987011880353149e-07,
      "loss": 0.0145,
      "step": 730
    },
    {
      "epoch": 7.8,
      "learning_rate": 8.980465328528218e-07,
      "loss": 0.0106,
      "step": 731
    },
    {
      "epoch": 7.81,
      "learning_rate": 8.973900091517674e-07,
      "loss": 0.0699,
      "step": 732
    },
    {
      "epoch": 7.82,
      "learning_rate": 8.967316200140189e-07,
      "loss": 0.1152,
      "step": 733
    },
    {
      "epoch": 7.83,
      "learning_rate": 8.96071368530201e-07,
      "loss": 0.0045,
      "step": 734
    },
    {
      "epoch": 7.84,
      "learning_rate": 8.954092577996802e-07,
      "loss": 0.0456,
      "step": 735
    },
    {
      "epoch": 7.85,
      "learning_rate": 8.947452909305509e-07,
      "loss": 0.0221,
      "step": 736
    },
    {
      "epoch": 7.86,
      "learning_rate": 8.940794710396204e-07,
      "loss": 0.0007,
      "step": 737
    },
    {
      "epoch": 7.87,
      "learning_rate": 8.93411801252395e-07,
      "loss": 0.0002,
      "step": 738
    },
    {
      "epoch": 7.88,
      "learning_rate": 8.927422847030646e-07,
      "loss": 0.0008,
      "step": 739
    },
    {
      "epoch": 7.89,
      "learning_rate": 8.920709245344877e-07,
      "loss": 0.0053,
      "step": 740
    },
    {
      "epoch": 7.9,
      "learning_rate": 8.913977238981778e-07,
      "loss": 0.0005,
      "step": 741
    },
    {
      "epoch": 7.91,
      "learning_rate": 8.907226859542878e-07,
      "loss": 0.0004,
      "step": 742
    },
    {
      "epoch": 7.93,
      "learning_rate": 8.900458138715954e-07,
      "loss": 0.0398,
      "step": 743
    },
    {
      "epoch": 7.94,
      "learning_rate": 8.893671108274876e-07,
      "loss": 0.0193,
      "step": 744
    },
    {
      "epoch": 7.95,
      "learning_rate": 8.886865800079473e-07,
      "loss": 0.054,
      "step": 745
    },
    {
      "epoch": 7.96,
      "learning_rate": 8.880042246075365e-07,
      "loss": 0.0199,
      "step": 746
    },
    {
      "epoch": 7.97,
      "learning_rate": 8.873200478293825e-07,
      "loss": 0.0199,
      "step": 747
    },
    {
      "epoch": 7.98,
      "learning_rate": 8.866340528851629e-07,
      "loss": 0.0487,
      "step": 748
    },
    {
      "epoch": 7.99,
      "learning_rate": 8.859462429950895e-07,
      "loss": 0.0076,
      "step": 749
    },
    {
      "epoch": 8.0,
      "learning_rate": 8.852566213878946e-07,
      "loss": 0.014,
      "step": 750
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.011690011247992516,
      "eval_runtime": 12.6339,
      "eval_samples_per_second": 59.364,
      "eval_steps_per_second": 14.881,
      "eval_wer": 0.0036437246963562753,
      "step": 750
    },
    {
      "epoch": 8.01,
      "learning_rate": 8.845651913008144e-07,
      "loss": 0.0002,
      "step": 751
    },
    {
      "epoch": 8.02,
      "learning_rate": 8.83871955979575e-07,
      "loss": 0.0002,
      "step": 752
    },
    {
      "epoch": 8.03,
      "learning_rate": 8.831769186783764e-07,
      "loss": 0.0052,
      "step": 753
    },
    {
      "epoch": 8.04,
      "learning_rate": 8.824800826598777e-07,
      "loss": 0.0002,
      "step": 754
    },
    {
      "epoch": 8.05,
      "learning_rate": 8.817814511951813e-07,
      "loss": 0.0322,
      "step": 755
    },
    {
      "epoch": 8.06,
      "learning_rate": 8.810810275638182e-07,
      "loss": 0.0355,
      "step": 756
    },
    {
      "epoch": 8.07,
      "learning_rate": 8.80378815053732e-07,
      "loss": 0.0079,
      "step": 757
    },
    {
      "epoch": 8.09,
      "learning_rate": 8.796748169612633e-07,
      "loss": 0.0065,
      "step": 758
    },
    {
      "epoch": 8.1,
      "learning_rate": 8.789690365911355e-07,
      "loss": 0.0161,
      "step": 759
    },
    {
      "epoch": 8.11,
      "learning_rate": 8.782614772564379e-07,
      "loss": 0.0242,
      "step": 760
    },
    {
      "epoch": 8.12,
      "learning_rate": 8.775521422786103e-07,
      "loss": 0.018,
      "step": 761
    },
    {
      "epoch": 8.13,
      "learning_rate": 8.768410349874286e-07,
      "loss": 0.0073,
      "step": 762
    },
    {
      "epoch": 8.14,
      "learning_rate": 8.761281587209876e-07,
      "loss": 0.0514,
      "step": 763
    },
    {
      "epoch": 8.15,
      "learning_rate": 8.754135168256865e-07,
      "loss": 0.031,
      "step": 764
    },
    {
      "epoch": 8.16,
      "learning_rate": 8.746971126562124e-07,
      "loss": 0.0162,
      "step": 765
    },
    {
      "epoch": 8.17,
      "learning_rate": 8.739789495755252e-07,
      "loss": 0.0019,
      "step": 766
    },
    {
      "epoch": 8.18,
      "learning_rate": 8.732590309548415e-07,
      "loss": 0.0162,
      "step": 767
    },
    {
      "epoch": 8.19,
      "learning_rate": 8.725373601736188e-07,
      "loss": 0.0468,
      "step": 768
    },
    {
      "epoch": 8.2,
      "learning_rate": 8.718139406195393e-07,
      "loss": 0.0083,
      "step": 769
    },
    {
      "epoch": 8.21,
      "learning_rate": 8.710887756884946e-07,
      "loss": 0.013,
      "step": 770
    },
    {
      "epoch": 8.22,
      "learning_rate": 8.703618687845695e-07,
      "loss": 0.0713,
      "step": 771
    },
    {
      "epoch": 8.23,
      "learning_rate": 8.696332233200261e-07,
      "loss": 0.0002,
      "step": 772
    },
    {
      "epoch": 8.25,
      "learning_rate": 8.689028427152873e-07,
      "loss": 0.0002,
      "step": 773
    },
    {
      "epoch": 8.26,
      "learning_rate": 8.681707303989214e-07,
      "loss": 0.0002,
      "step": 774
    },
    {
      "epoch": 8.27,
      "learning_rate": 8.67436889807626e-07,
      "loss": 0.0002,
      "step": 775
    },
    {
      "epoch": 8.28,
      "learning_rate": 8.667013243862112e-07,
      "loss": 0.0018,
      "step": 776
    },
    {
      "epoch": 8.29,
      "learning_rate": 8.659640375875838e-07,
      "loss": 0.0008,
      "step": 777
    },
    {
      "epoch": 8.3,
      "learning_rate": 8.652250328727315e-07,
      "loss": 0.1045,
      "step": 778
    },
    {
      "epoch": 8.31,
      "learning_rate": 8.644843137107057e-07,
      "loss": 0.0005,
      "step": 779
    },
    {
      "epoch": 8.32,
      "learning_rate": 8.637418835786066e-07,
      "loss": 0.0008,
      "step": 780
    },
    {
      "epoch": 8.33,
      "learning_rate": 8.629977459615654e-07,
      "loss": 0.0002,
      "step": 781
    },
    {
      "epoch": 8.34,
      "learning_rate": 8.622519043527289e-07,
      "loss": 0.0003,
      "step": 782
    },
    {
      "epoch": 8.35,
      "learning_rate": 8.615043622532427e-07,
      "loss": 0.004,
      "step": 783
    },
    {
      "epoch": 8.36,
      "learning_rate": 8.60755123172235e-07,
      "loss": 0.0695,
      "step": 784
    },
    {
      "epoch": 8.37,
      "learning_rate": 8.600041906267999e-07,
      "loss": 0.0107,
      "step": 785
    },
    {
      "epoch": 8.38,
      "learning_rate": 8.592515681419812e-07,
      "loss": 0.0002,
      "step": 786
    },
    {
      "epoch": 8.39,
      "learning_rate": 8.584972592507552e-07,
      "loss": 0.0003,
      "step": 787
    },
    {
      "epoch": 8.41,
      "learning_rate": 8.577412674940151e-07,
      "loss": 0.0122,
      "step": 788
    },
    {
      "epoch": 8.42,
      "learning_rate": 8.569835964205536e-07,
      "loss": 0.0016,
      "step": 789
    },
    {
      "epoch": 8.43,
      "learning_rate": 8.562242495870462e-07,
      "loss": 0.053,
      "step": 790
    },
    {
      "epoch": 8.44,
      "learning_rate": 8.554632305580354e-07,
      "loss": 0.0116,
      "step": 791
    },
    {
      "epoch": 8.45,
      "learning_rate": 8.547005429059128e-07,
      "loss": 0.0002,
      "step": 792
    },
    {
      "epoch": 8.46,
      "learning_rate": 8.539361902109032e-07,
      "loss": 0.0022,
      "step": 793
    },
    {
      "epoch": 8.47,
      "learning_rate": 8.531701760610474e-07,
      "loss": 0.0462,
      "step": 794
    },
    {
      "epoch": 8.48,
      "learning_rate": 8.524025040521857e-07,
      "loss": 0.0002,
      "step": 795
    },
    {
      "epoch": 8.49,
      "learning_rate": 8.5163317778794e-07,
      "loss": 0.0098,
      "step": 796
    },
    {
      "epoch": 8.5,
      "learning_rate": 8.508622008796984e-07,
      "loss": 0.0002,
      "step": 797
    },
    {
      "epoch": 8.51,
      "learning_rate": 8.500895769465971e-07,
      "loss": 0.0374,
      "step": 798
    },
    {
      "epoch": 8.52,
      "learning_rate": 8.493153096155041e-07,
      "loss": 0.005,
      "step": 799
    },
    {
      "epoch": 8.53,
      "learning_rate": 8.485394025210015e-07,
      "loss": 0.0008,
      "step": 800
    },
    {
      "epoch": 8.54,
      "learning_rate": 8.477618593053692e-07,
      "loss": 0.0179,
      "step": 801
    },
    {
      "epoch": 8.55,
      "learning_rate": 8.469826836185672e-07,
      "loss": 0.0002,
      "step": 802
    },
    {
      "epoch": 8.57,
      "learning_rate": 8.462018791182184e-07,
      "loss": 0.0002,
      "step": 803
    },
    {
      "epoch": 8.58,
      "learning_rate": 8.454194494695923e-07,
      "loss": 0.0231,
      "step": 804
    },
    {
      "epoch": 8.59,
      "learning_rate": 8.446353983455868e-07,
      "loss": 0.0471,
      "step": 805
    },
    {
      "epoch": 8.6,
      "learning_rate": 8.438497294267116e-07,
      "loss": 0.0003,
      "step": 806
    },
    {
      "epoch": 8.61,
      "learning_rate": 8.430624464010705e-07,
      "loss": 0.0003,
      "step": 807
    },
    {
      "epoch": 8.62,
      "learning_rate": 8.422735529643443e-07,
      "loss": 0.0195,
      "step": 808
    },
    {
      "epoch": 8.63,
      "learning_rate": 8.414830528197736e-07,
      "loss": 0.0002,
      "step": 809
    },
    {
      "epoch": 8.64,
      "learning_rate": 8.406909496781409e-07,
      "loss": 0.0002,
      "step": 810
    },
    {
      "epoch": 8.65,
      "learning_rate": 8.398972472577539e-07,
      "loss": 0.0576,
      "step": 811
    },
    {
      "epoch": 8.66,
      "learning_rate": 8.391019492844274e-07,
      "loss": 0.0294,
      "step": 812
    },
    {
      "epoch": 8.67,
      "learning_rate": 8.383050594914663e-07,
      "loss": 0.001,
      "step": 813
    },
    {
      "epoch": 8.68,
      "learning_rate": 8.375065816196478e-07,
      "loss": 0.0083,
      "step": 814
    },
    {
      "epoch": 8.69,
      "learning_rate": 8.367065194172036e-07,
      "loss": 0.0085,
      "step": 815
    },
    {
      "epoch": 8.7,
      "learning_rate": 8.359048766398031e-07,
      "loss": 0.0444,
      "step": 816
    },
    {
      "epoch": 8.71,
      "learning_rate": 8.351016570505346e-07,
      "loss": 0.0525,
      "step": 817
    },
    {
      "epoch": 8.73,
      "learning_rate": 8.342968644198891e-07,
      "loss": 0.0008,
      "step": 818
    },
    {
      "epoch": 8.74,
      "learning_rate": 8.334905025257413e-07,
      "loss": 0.0398,
      "step": 819
    },
    {
      "epoch": 8.75,
      "learning_rate": 8.326825751533322e-07,
      "loss": 0.0093,
      "step": 820
    },
    {
      "epoch": 8.76,
      "learning_rate": 8.318730860952522e-07,
      "loss": 0.0002,
      "step": 821
    },
    {
      "epoch": 8.77,
      "learning_rate": 8.310620391514219e-07,
      "loss": 0.0137,
      "step": 822
    },
    {
      "epoch": 8.78,
      "learning_rate": 8.302494381290754e-07,
      "loss": 0.0221,
      "step": 823
    },
    {
      "epoch": 8.79,
      "learning_rate": 8.294352868427418e-07,
      "loss": 0.0035,
      "step": 824
    },
    {
      "epoch": 8.8,
      "learning_rate": 8.286195891142274e-07,
      "loss": 0.0015,
      "step": 825
    },
    {
      "epoch": 8.81,
      "learning_rate": 8.27802348772598e-07,
      "loss": 0.0002,
      "step": 826
    },
    {
      "epoch": 8.82,
      "learning_rate": 8.269835696541607e-07,
      "loss": 0.0041,
      "step": 827
    },
    {
      "epoch": 8.83,
      "learning_rate": 8.261632556024461e-07,
      "loss": 0.0002,
      "step": 828
    },
    {
      "epoch": 8.84,
      "learning_rate": 8.253414104681898e-07,
      "loss": 0.0002,
      "step": 829
    },
    {
      "epoch": 8.85,
      "learning_rate": 8.245180381093151e-07,
      "loss": 0.0871,
      "step": 830
    },
    {
      "epoch": 8.86,
      "learning_rate": 8.236931423909138e-07,
      "loss": 0.0101,
      "step": 831
    },
    {
      "epoch": 8.87,
      "learning_rate": 8.228667271852293e-07,
      "loss": 0.0131,
      "step": 832
    },
    {
      "epoch": 8.89,
      "learning_rate": 8.220387963716377e-07,
      "loss": 0.0058,
      "step": 833
    },
    {
      "epoch": 8.9,
      "learning_rate": 8.212093538366292e-07,
      "loss": 0.0039,
      "step": 834
    },
    {
      "epoch": 8.91,
      "learning_rate": 8.20378403473791e-07,
      "loss": 0.0408,
      "step": 835
    },
    {
      "epoch": 8.92,
      "learning_rate": 8.195459491837879e-07,
      "loss": 0.0481,
      "step": 836
    },
    {
      "epoch": 8.93,
      "learning_rate": 8.187119948743449e-07,
      "loss": 0.0028,
      "step": 837
    },
    {
      "epoch": 8.94,
      "learning_rate": 8.178765444602278e-07,
      "loss": 0.0642,
      "step": 838
    },
    {
      "epoch": 8.95,
      "learning_rate": 8.170396018632263e-07,
      "loss": 0.0261,
      "step": 839
    },
    {
      "epoch": 8.96,
      "learning_rate": 8.162011710121339e-07,
      "loss": 0.0219,
      "step": 840
    },
    {
      "epoch": 8.97,
      "learning_rate": 8.15361255842731e-07,
      "loss": 0.0003,
      "step": 841
    },
    {
      "epoch": 8.98,
      "learning_rate": 8.145198602977649e-07,
      "loss": 0.0008,
      "step": 842
    },
    {
      "epoch": 8.99,
      "learning_rate": 8.13676988326933e-07,
      "loss": 0.0004,
      "step": 843
    },
    {
      "epoch": 8.99,
      "eval_loss": 0.02250482141971588,
      "eval_runtime": 12.2721,
      "eval_samples_per_second": 61.114,
      "eval_steps_per_second": 15.319,
      "eval_wer": 0.005398110661268556,
      "step": 843
    },
    {
      "epoch": 9.0,
      "learning_rate": 8.128326438868629e-07,
      "loss": 0.0021,
      "step": 844
    },
    {
      "epoch": 9.01,
      "learning_rate": 8.119868309410943e-07,
      "loss": 0.0198,
      "step": 845
    },
    {
      "epoch": 9.02,
      "learning_rate": 8.111395534600603e-07,
      "loss": 0.0002,
      "step": 846
    },
    {
      "epoch": 9.03,
      "learning_rate": 8.102908154210692e-07,
      "loss": 0.0002,
      "step": 847
    },
    {
      "epoch": 9.05,
      "learning_rate": 8.094406208082852e-07,
      "loss": 0.0026,
      "step": 848
    },
    {
      "epoch": 9.06,
      "learning_rate": 8.085889736127103e-07,
      "loss": 0.0041,
      "step": 849
    },
    {
      "epoch": 9.07,
      "learning_rate": 8.077358778321646e-07,
      "loss": 0.0068,
      "step": 850
    },
    {
      "epoch": 9.08,
      "learning_rate": 8.068813374712687e-07,
      "loss": 0.0002,
      "step": 851
    },
    {
      "epoch": 9.09,
      "learning_rate": 8.060253565414246e-07,
      "loss": 0.0376,
      "step": 852
    },
    {
      "epoch": 9.1,
      "learning_rate": 8.05167939060796e-07,
      "loss": 0.0409,
      "step": 853
    },
    {
      "epoch": 9.11,
      "learning_rate": 8.043090890542904e-07,
      "loss": 0.0118,
      "step": 854
    },
    {
      "epoch": 9.12,
      "learning_rate": 8.0344881055354e-07,
      "loss": 0.0676,
      "step": 855
    },
    {
      "epoch": 9.13,
      "learning_rate": 8.025871075968826e-07,
      "loss": 0.0108,
      "step": 856
    },
    {
      "epoch": 9.14,
      "learning_rate": 8.017239842293426e-07,
      "loss": 0.0002,
      "step": 857
    },
    {
      "epoch": 9.15,
      "learning_rate": 8.008594445026122e-07,
      "loss": 0.024,
      "step": 858
    },
    {
      "epoch": 9.16,
      "learning_rate": 7.999934924750325e-07,
      "loss": 0.0357,
      "step": 859
    },
    {
      "epoch": 9.17,
      "learning_rate": 7.991261322115736e-07,
      "loss": 0.0077,
      "step": 860
    },
    {
      "epoch": 9.18,
      "learning_rate": 7.982573677838172e-07,
      "loss": 0.0002,
      "step": 861
    },
    {
      "epoch": 9.19,
      "learning_rate": 7.973872032699354e-07,
      "loss": 0.0026,
      "step": 862
    },
    {
      "epoch": 9.21,
      "learning_rate": 7.965156427546734e-07,
      "loss": 0.0237,
      "step": 863
    },
    {
      "epoch": 9.22,
      "learning_rate": 7.956426903293292e-07,
      "loss": 0.0485,
      "step": 864
    },
    {
      "epoch": 9.23,
      "learning_rate": 7.947683500917346e-07,
      "loss": 0.0003,
      "step": 865
    },
    {
      "epoch": 9.24,
      "learning_rate": 7.938926261462365e-07,
      "loss": 0.0029,
      "step": 866
    },
    {
      "epoch": 9.25,
      "learning_rate": 7.930155226036769e-07,
      "loss": 0.047,
      "step": 867
    },
    {
      "epoch": 9.26,
      "learning_rate": 7.921370435813741e-07,
      "loss": 0.0055,
      "step": 868
    },
    {
      "epoch": 9.27,
      "learning_rate": 7.91257193203103e-07,
      "loss": 0.0058,
      "step": 869
    },
    {
      "epoch": 9.28,
      "learning_rate": 7.903759755990762e-07,
      "loss": 0.0122,
      "step": 870
    },
    {
      "epoch": 9.29,
      "learning_rate": 7.894933949059244e-07,
      "loss": 0.0315,
      "step": 871
    },
    {
      "epoch": 9.3,
      "learning_rate": 7.886094552666764e-07,
      "loss": 0.0047,
      "step": 872
    },
    {
      "epoch": 9.31,
      "learning_rate": 7.87724160830741e-07,
      "loss": 0.0002,
      "step": 873
    },
    {
      "epoch": 9.32,
      "learning_rate": 7.868375157538861e-07,
      "loss": 0.0036,
      "step": 874
    },
    {
      "epoch": 9.33,
      "learning_rate": 7.859495241982199e-07,
      "loss": 0.0002,
      "step": 875
    },
    {
      "epoch": 9.34,
      "learning_rate": 7.850601903321716e-07,
      "loss": 0.0218,
      "step": 876
    },
    {
      "epoch": 9.35,
      "learning_rate": 7.841695183304713e-07,
      "loss": 0.0008,
      "step": 877
    },
    {
      "epoch": 9.37,
      "learning_rate": 7.832775123741306e-07,
      "loss": 0.0151,
      "step": 878
    },
    {
      "epoch": 9.38,
      "learning_rate": 7.823841766504226e-07,
      "loss": 0.1103,
      "step": 879
    },
    {
      "epoch": 9.39,
      "learning_rate": 7.814895153528635e-07,
      "loss": 0.0189,
      "step": 880
    },
    {
      "epoch": 9.4,
      "learning_rate": 7.805935326811912e-07,
      "loss": 0.0039,
      "step": 881
    },
    {
      "epoch": 9.41,
      "learning_rate": 7.796962328413468e-07,
      "loss": 0.0085,
      "step": 882
    },
    {
      "epoch": 9.42,
      "learning_rate": 7.787976200454545e-07,
      "loss": 0.0053,
      "step": 883
    },
    {
      "epoch": 9.43,
      "learning_rate": 7.778976985118018e-07,
      "loss": 0.0225,
      "step": 884
    },
    {
      "epoch": 9.44,
      "learning_rate": 7.769964724648194e-07,
      "loss": 0.0002,
      "step": 885
    },
    {
      "epoch": 9.45,
      "learning_rate": 7.760939461350622e-07,
      "loss": 0.0062,
      "step": 886
    },
    {
      "epoch": 9.46,
      "learning_rate": 7.751901237591886e-07,
      "loss": 0.0007,
      "step": 887
    },
    {
      "epoch": 9.47,
      "learning_rate": 7.742850095799407e-07,
      "loss": 0.0016,
      "step": 888
    },
    {
      "epoch": 9.48,
      "learning_rate": 7.733786078461251e-07,
      "loss": 0.0013,
      "step": 889
    },
    {
      "epoch": 9.49,
      "learning_rate": 7.724709228125922e-07,
      "loss": 0.0009,
      "step": 890
    },
    {
      "epoch": 9.5,
      "learning_rate": 7.715619587402164e-07,
      "loss": 0.0002,
      "step": 891
    },
    {
      "epoch": 9.51,
      "learning_rate": 7.706517198958764e-07,
      "loss": 0.0004,
      "step": 892
    },
    {
      "epoch": 9.53,
      "learning_rate": 7.697402105524351e-07,
      "loss": 0.0069,
      "step": 893
    },
    {
      "epoch": 9.54,
      "learning_rate": 7.688274349887187e-07,
      "loss": 0.0003,
      "step": 894
    },
    {
      "epoch": 9.55,
      "learning_rate": 7.679133974894982e-07,
      "loss": 0.0264,
      "step": 895
    },
    {
      "epoch": 9.56,
      "learning_rate": 7.669981023454681e-07,
      "loss": 0.0063,
      "step": 896
    },
    {
      "epoch": 9.57,
      "learning_rate": 7.66081553853226e-07,
      "loss": 0.021,
      "step": 897
    },
    {
      "epoch": 9.58,
      "learning_rate": 7.651637563152538e-07,
      "loss": 0.0006,
      "step": 898
    },
    {
      "epoch": 9.59,
      "learning_rate": 7.642447140398964e-07,
      "loss": 0.0012,
      "step": 899
    },
    {
      "epoch": 9.6,
      "learning_rate": 7.633244313413416e-07,
      "loss": 0.0025,
      "step": 900
    },
    {
      "epoch": 9.61,
      "learning_rate": 7.624029125396003e-07,
      "loss": 0.0168,
      "step": 901
    },
    {
      "epoch": 9.62,
      "learning_rate": 7.614801619604856e-07,
      "loss": 0.0001,
      "step": 902
    },
    {
      "epoch": 9.63,
      "learning_rate": 7.605561839355932e-07,
      "loss": 0.004,
      "step": 903
    },
    {
      "epoch": 9.64,
      "learning_rate": 7.596309828022802e-07,
      "loss": 0.0212,
      "step": 904
    },
    {
      "epoch": 9.65,
      "learning_rate": 7.587045629036462e-07,
      "loss": 0.0364,
      "step": 905
    },
    {
      "epoch": 9.66,
      "learning_rate": 7.577769285885108e-07,
      "loss": 0.0358,
      "step": 906
    },
    {
      "epoch": 9.67,
      "learning_rate": 7.568480842113951e-07,
      "loss": 0.0302,
      "step": 907
    },
    {
      "epoch": 9.69,
      "learning_rate": 7.559180341325004e-07,
      "loss": 0.0035,
      "step": 908
    },
    {
      "epoch": 9.7,
      "learning_rate": 7.549867827176873e-07,
      "loss": 0.0278,
      "step": 909
    },
    {
      "epoch": 9.71,
      "learning_rate": 7.540543343384564e-07,
      "loss": 0.0662,
      "step": 910
    },
    {
      "epoch": 9.72,
      "learning_rate": 7.53120693371927e-07,
      "loss": 0.0748,
      "step": 911
    },
    {
      "epoch": 9.73,
      "learning_rate": 7.521858642008163e-07,
      "loss": 0.0039,
      "step": 912
    },
    {
      "epoch": 9.74,
      "learning_rate": 7.512498512134194e-07,
      "loss": 0.0345,
      "step": 913
    },
    {
      "epoch": 9.75,
      "learning_rate": 7.503126588035886e-07,
      "loss": 0.0248,
      "step": 914
    },
    {
      "epoch": 9.76,
      "learning_rate": 7.493742913707128e-07,
      "loss": 0.0002,
      "step": 915
    },
    {
      "epoch": 9.77,
      "learning_rate": 7.48434753319696e-07,
      "loss": 0.0002,
      "step": 916
    },
    {
      "epoch": 9.78,
      "learning_rate": 7.474940490609383e-07,
      "loss": 0.0183,
      "step": 917
    },
    {
      "epoch": 9.79,
      "learning_rate": 7.465521830103136e-07,
      "loss": 0.0057,
      "step": 918
    },
    {
      "epoch": 9.8,
      "learning_rate": 7.456091595891497e-07,
      "loss": 0.0004,
      "step": 919
    },
    {
      "epoch": 9.81,
      "learning_rate": 7.446649832242075e-07,
      "loss": 0.0002,
      "step": 920
    },
    {
      "epoch": 9.82,
      "learning_rate": 7.437196583476596e-07,
      "loss": 0.0013,
      "step": 921
    },
    {
      "epoch": 9.83,
      "learning_rate": 7.427731893970706e-07,
      "loss": 0.0002,
      "step": 922
    },
    {
      "epoch": 9.85,
      "learning_rate": 7.41825580815375e-07,
      "loss": 0.0156,
      "step": 923
    },
    {
      "epoch": 9.86,
      "learning_rate": 7.408768370508576e-07,
      "loss": 0.0014,
      "step": 924
    },
    {
      "epoch": 9.87,
      "learning_rate": 7.399269625571317e-07,
      "loss": 0.0019,
      "step": 925
    },
    {
      "epoch": 9.88,
      "learning_rate": 7.389759617931181e-07,
      "loss": 0.0002,
      "step": 926
    },
    {
      "epoch": 9.89,
      "learning_rate": 7.380238392230256e-07,
      "loss": 0.0002,
      "step": 927
    },
    {
      "epoch": 9.9,
      "learning_rate": 7.370705993163277e-07,
      "loss": 0.0023,
      "step": 928
    },
    {
      "epoch": 9.91,
      "learning_rate": 7.361162465477442e-07,
      "loss": 0.0169,
      "step": 929
    },
    {
      "epoch": 9.92,
      "learning_rate": 7.351607853972179e-07,
      "loss": 0.0067,
      "step": 930
    },
    {
      "epoch": 9.93,
      "learning_rate": 7.342042203498951e-07,
      "loss": 0.0005,
      "step": 931
    },
    {
      "epoch": 9.94,
      "learning_rate": 7.332465558961039e-07,
      "loss": 0.0061,
      "step": 932
    },
    {
      "epoch": 9.95,
      "learning_rate": 7.322877965313334e-07,
      "loss": 0.0002,
      "step": 933
    },
    {
      "epoch": 9.96,
      "learning_rate": 7.313279467562123e-07,
      "loss": 0.0003,
      "step": 934
    },
    {
      "epoch": 9.97,
      "learning_rate": 7.30367011076488e-07,
      "loss": 0.0005,
      "step": 935
    },
    {
      "epoch": 9.98,
      "learning_rate": 7.294049940030053e-07,
      "loss": 0.0252,
      "step": 936
    },
    {
      "epoch": 9.99,
      "learning_rate": 7.284419000516855e-07,
      "loss": 0.0067,
      "step": 937
    },
    {
      "epoch": 9.99,
      "eval_loss": 0.010753940790891647,
      "eval_runtime": 12.5524,
      "eval_samples_per_second": 59.75,
      "eval_steps_per_second": 14.977,
      "eval_wer": 0.0035087719298245615,
      "step": 937
    },
    {
      "epoch": 10.01,
      "learning_rate": 7.274777337435045e-07,
      "loss": 0.0002,
      "step": 938
    },
    {
      "epoch": 10.02,
      "learning_rate": 7.26512499604473e-07,
      "loss": 0.0002,
      "step": 939
    },
    {
      "epoch": 10.03,
      "learning_rate": 7.255462021656131e-07,
      "loss": 0.0015,
      "step": 940
    },
    {
      "epoch": 10.04,
      "learning_rate": 7.245788459629396e-07,
      "loss": 0.0276,
      "step": 941
    },
    {
      "epoch": 10.05,
      "learning_rate": 7.236104355374362e-07,
      "loss": 0.0004,
      "step": 942
    },
    {
      "epoch": 10.06,
      "learning_rate": 7.226409754350361e-07,
      "loss": 0.0025,
      "step": 943
    },
    {
      "epoch": 10.07,
      "learning_rate": 7.216704702065996e-07,
      "loss": 0.0073,
      "step": 944
    },
    {
      "epoch": 10.08,
      "learning_rate": 7.206989244078932e-07,
      "loss": 0.0002,
      "step": 945
    },
    {
      "epoch": 10.09,
      "learning_rate": 7.197263425995681e-07,
      "loss": 0.0749,
      "step": 946
    },
    {
      "epoch": 10.1,
      "learning_rate": 7.187527293471385e-07,
      "loss": 0.0329,
      "step": 947
    },
    {
      "epoch": 10.11,
      "learning_rate": 7.177780892209606e-07,
      "loss": 0.0091,
      "step": 948
    },
    {
      "epoch": 10.12,
      "learning_rate": 7.16802426796211e-07,
      "loss": 0.0078,
      "step": 949
    },
    {
      "epoch": 10.13,
      "learning_rate": 7.158257466528651e-07,
      "loss": 0.0486,
      "step": 950
    },
    {
      "epoch": 10.14,
      "learning_rate": 7.148480533756759e-07,
      "loss": 0.0008,
      "step": 951
    },
    {
      "epoch": 10.15,
      "learning_rate": 7.138693515541519e-07,
      "loss": 0.0034,
      "step": 952
    },
    {
      "epoch": 10.17,
      "learning_rate": 7.128896457825363e-07,
      "loss": 0.0003,
      "step": 953
    },
    {
      "epoch": 10.18,
      "learning_rate": 7.119089406597849e-07,
      "loss": 0.0023,
      "step": 954
    },
    {
      "epoch": 10.19,
      "learning_rate": 7.109272407895448e-07,
      "loss": 0.0003,
      "step": 955
    },
    {
      "epoch": 10.2,
      "learning_rate": 7.099445507801323e-07,
      "loss": 0.0168,
      "step": 956
    },
    {
      "epoch": 10.21,
      "learning_rate": 7.08960875244512e-07,
      "loss": 0.0216,
      "step": 957
    },
    {
      "epoch": 10.22,
      "learning_rate": 7.079762188002749e-07,
      "loss": 0.0014,
      "step": 958
    },
    {
      "epoch": 10.23,
      "learning_rate": 7.069905860696162e-07,
      "loss": 0.0395,
      "step": 959
    },
    {
      "epoch": 10.24,
      "learning_rate": 7.060039816793141e-07,
      "loss": 0.0003,
      "step": 960
    },
    {
      "epoch": 10.25,
      "learning_rate": 7.05016410260708e-07,
      "loss": 0.003,
      "step": 961
    },
    {
      "epoch": 10.26,
      "learning_rate": 7.04027876449677e-07,
      "loss": 0.0027,
      "step": 962
    },
    {
      "epoch": 10.27,
      "learning_rate": 7.030383848866178e-07,
      "loss": 0.0002,
      "step": 963
    },
    {
      "epoch": 10.28,
      "learning_rate": 7.020479402164226e-07,
      "loss": 0.0128,
      "step": 964
    },
    {
      "epoch": 10.29,
      "learning_rate": 7.010565470884582e-07,
      "loss": 0.0203,
      "step": 965
    },
    {
      "epoch": 10.3,
      "learning_rate": 7.000642101565433e-07,
      "loss": 0.0002,
      "step": 966
    },
    {
      "epoch": 10.31,
      "learning_rate": 6.990709340789273e-07,
      "loss": 0.0141,
      "step": 967
    },
    {
      "epoch": 10.33,
      "learning_rate": 6.98076723518268e-07,
      "loss": 0.0041,
      "step": 968
    },
    {
      "epoch": 10.34,
      "learning_rate": 6.970815831416099e-07,
      "loss": 0.0023,
      "step": 969
    },
    {
      "epoch": 10.35,
      "learning_rate": 6.960855176203622e-07,
      "loss": 0.0268,
      "step": 970
    },
    {
      "epoch": 10.36,
      "learning_rate": 6.950885316302772e-07,
      "loss": 0.023,
      "step": 971
    },
    {
      "epoch": 10.37,
      "learning_rate": 6.940906298514277e-07,
      "loss": 0.0637,
      "step": 972
    },
    {
      "epoch": 10.38,
      "learning_rate": 6.930918169681859e-07,
      "loss": 0.0824,
      "step": 973
    },
    {
      "epoch": 10.39,
      "learning_rate": 6.920920976692003e-07,
      "loss": 0.0002,
      "step": 974
    },
    {
      "epoch": 10.4,
      "learning_rate": 6.910914766473747e-07,
      "loss": 0.0123,
      "step": 975
    },
    {
      "epoch": 10.41,
      "learning_rate": 6.900899585998459e-07,
      "loss": 0.0124,
      "step": 976
    },
    {
      "epoch": 10.42,
      "learning_rate": 6.890875482279614e-07,
      "loss": 0.0097,
      "step": 977
    },
    {
      "epoch": 10.43,
      "learning_rate": 6.880842502372572e-07,
      "loss": 0.0484,
      "step": 978
    },
    {
      "epoch": 10.44,
      "learning_rate": 6.870800693374363e-07,
      "loss": 0.0019,
      "step": 979
    },
    {
      "epoch": 10.45,
      "learning_rate": 6.860750102423464e-07,
      "loss": 0.0282,
      "step": 980
    },
    {
      "epoch": 10.46,
      "learning_rate": 6.850690776699573e-07,
      "loss": 0.0002,
      "step": 981
    },
    {
      "epoch": 10.47,
      "learning_rate": 6.840622763423391e-07,
      "loss": 0.0002,
      "step": 982
    },
    {
      "epoch": 10.49,
      "learning_rate": 6.830546109856401e-07,
      "loss": 0.0523,
      "step": 983
    },
    {
      "epoch": 10.5,
      "learning_rate": 6.82046086330065e-07,
      "loss": 0.0594,
      "step": 984
    },
    {
      "epoch": 10.51,
      "learning_rate": 6.810367071098515e-07,
      "loss": 0.0135,
      "step": 985
    },
    {
      "epoch": 10.52,
      "learning_rate": 6.800264780632494e-07,
      "loss": 0.0557,
      "step": 986
    },
    {
      "epoch": 10.53,
      "learning_rate": 6.790154039324974e-07,
      "loss": 0.0713,
      "step": 987
    },
    {
      "epoch": 10.54,
      "learning_rate": 6.780034894638012e-07,
      "loss": 0.0392,
      "step": 988
    },
    {
      "epoch": 10.55,
      "learning_rate": 6.769907394073117e-07,
      "loss": 0.0018,
      "step": 989
    },
    {
      "epoch": 10.56,
      "learning_rate": 6.759771585171016e-07,
      "loss": 0.002,
      "step": 990
    },
    {
      "epoch": 10.57,
      "learning_rate": 6.749627515511442e-07,
      "loss": 0.0318,
      "step": 991
    },
    {
      "epoch": 10.58,
      "learning_rate": 6.739475232712903e-07,
      "loss": 0.0002,
      "step": 992
    },
    {
      "epoch": 10.59,
      "learning_rate": 6.729314784432465e-07,
      "loss": 0.0146,
      "step": 993
    },
    {
      "epoch": 10.6,
      "learning_rate": 6.719146218365519e-07,
      "loss": 0.079,
      "step": 994
    },
    {
      "epoch": 10.61,
      "learning_rate": 6.708969582245567e-07,
      "loss": 0.0008,
      "step": 995
    },
    {
      "epoch": 10.62,
      "learning_rate": 6.698784923843992e-07,
      "loss": 0.0585,
      "step": 996
    },
    {
      "epoch": 10.63,
      "learning_rate": 6.688592290969836e-07,
      "loss": 0.0897,
      "step": 997
    },
    {
      "epoch": 10.65,
      "learning_rate": 6.678391731469575e-07,
      "loss": 0.0289,
      "step": 998
    },
    {
      "epoch": 10.66,
      "learning_rate": 6.668183293226891e-07,
      "loss": 0.0051,
      "step": 999
    },
    {
      "epoch": 10.67,
      "learning_rate": 6.657967024162459e-07,
      "loss": 0.0032,
      "step": 1000
    },
    {
      "epoch": 10.68,
      "learning_rate": 6.647742972233702e-07,
      "loss": 0.0033,
      "step": 1001
    },
    {
      "epoch": 10.69,
      "learning_rate": 6.637511185434587e-07,
      "loss": 0.017,
      "step": 1002
    },
    {
      "epoch": 10.7,
      "learning_rate": 6.627271711795386e-07,
      "loss": 0.0063,
      "step": 1003
    },
    {
      "epoch": 10.71,
      "learning_rate": 6.617024599382456e-07,
      "loss": 0.0183,
      "step": 1004
    },
    {
      "epoch": 10.72,
      "learning_rate": 6.606769896298012e-07,
      "loss": 0.0365,
      "step": 1005
    },
    {
      "epoch": 10.73,
      "learning_rate": 6.596507650679899e-07,
      "loss": 0.015,
      "step": 1006
    },
    {
      "epoch": 10.74,
      "learning_rate": 6.586237910701373e-07,
      "loss": 0.0718,
      "step": 1007
    },
    {
      "epoch": 10.75,
      "learning_rate": 6.575960724570865e-07,
      "loss": 0.001,
      "step": 1008
    },
    {
      "epoch": 10.76,
      "learning_rate": 6.565676140531764e-07,
      "loss": 0.0059,
      "step": 1009
    },
    {
      "epoch": 10.77,
      "learning_rate": 6.555384206862183e-07,
      "loss": 0.0012,
      "step": 1010
    },
    {
      "epoch": 10.78,
      "learning_rate": 6.545084971874736e-07,
      "loss": 0.045,
      "step": 1011
    },
    {
      "epoch": 10.79,
      "learning_rate": 6.534778483916318e-07,
      "loss": 0.0058,
      "step": 1012
    },
    {
      "epoch": 10.81,
      "learning_rate": 6.524464791367861e-07,
      "loss": 0.004,
      "step": 1013
    },
    {
      "epoch": 10.82,
      "learning_rate": 6.514143942644124e-07,
      "loss": 0.0026,
      "step": 1014
    },
    {
      "epoch": 10.83,
      "learning_rate": 6.503815986193455e-07,
      "loss": 0.0239,
      "step": 1015
    },
    {
      "epoch": 10.84,
      "learning_rate": 6.493480970497568e-07,
      "loss": 0.0002,
      "step": 1016
    },
    {
      "epoch": 10.85,
      "learning_rate": 6.483138944071316e-07,
      "loss": 0.0079,
      "step": 1017
    },
    {
      "epoch": 10.86,
      "learning_rate": 6.472789955462459e-07,
      "loss": 0.0003,
      "step": 1018
    },
    {
      "epoch": 10.87,
      "learning_rate": 6.462434053251445e-07,
      "loss": 0.0003,
      "step": 1019
    },
    {
      "epoch": 10.88,
      "learning_rate": 6.452071286051168e-07,
      "loss": 0.0826,
      "step": 1020
    },
    {
      "epoch": 10.89,
      "learning_rate": 6.441701702506754e-07,
      "loss": 0.0046,
      "step": 1021
    },
    {
      "epoch": 10.9,
      "learning_rate": 6.431325351295324e-07,
      "loss": 0.0104,
      "step": 1022
    },
    {
      "epoch": 10.91,
      "learning_rate": 6.420942281125765e-07,
      "loss": 0.0015,
      "step": 1023
    },
    {
      "epoch": 10.92,
      "learning_rate": 6.420942281125765e-07,
      "loss": 0.0352,
      "step": 1024
    },
    {
      "epoch": 10.93,
      "learning_rate": 6.410552540738514e-07,
      "loss": 0.0015,
      "step": 1025
    },
    {
      "epoch": 10.94,
      "learning_rate": 6.400156178905308e-07,
      "loss": 0.0369,
      "step": 1026
    },
    {
      "epoch": 10.95,
      "learning_rate": 6.389753244428971e-07,
      "loss": 0.0003,
      "step": 1027
    },
    {
      "epoch": 10.97,
      "learning_rate": 6.379343786143183e-07,
      "loss": 0.0021,
      "step": 1028
    },
    {
      "epoch": 10.98,
      "learning_rate": 6.368927852912247e-07,
      "loss": 0.0003,
      "step": 1029
    },
    {
      "epoch": 10.99,
      "learning_rate": 6.358505493630856e-07,
      "loss": 0.0239,
      "step": 1030
    },
    {
      "epoch": 11.0,
      "learning_rate": 6.348076757223876e-07,
      "loss": 0.0002,
      "step": 1031
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.012369232252240181,
      "eval_runtime": 12.2978,
      "eval_samples_per_second": 60.986,
      "eval_steps_per_second": 15.287,
      "eval_wer": 0.003913630229419703,
      "step": 1031
    },
    {
      "epoch": 11.01,
      "learning_rate": 6.337641692646106e-07,
      "loss": 0.0247,
      "step": 1032
    },
    {
      "epoch": 11.02,
      "learning_rate": 6.327200348882043e-07,
      "loss": 0.0396,
      "step": 1033
    },
    {
      "epoch": 11.03,
      "learning_rate": 6.316752774945672e-07,
      "loss": 0.0002,
      "step": 1034
    },
    {
      "epoch": 11.04,
      "learning_rate": 6.306299019880216e-07,
      "loss": 0.0002,
      "step": 1035
    },
    {
      "epoch": 11.05,
      "learning_rate": 6.295839132757919e-07,
      "loss": 0.0258,
      "step": 1036
    },
    {
      "epoch": 11.06,
      "learning_rate": 6.285373162679803e-07,
      "loss": 0.0017,
      "step": 1037
    },
    {
      "epoch": 11.07,
      "learning_rate": 6.274901158775453e-07,
      "loss": 0.0002,
      "step": 1038
    },
    {
      "epoch": 11.08,
      "learning_rate": 6.264423170202773e-07,
      "loss": 0.0002,
      "step": 1039
    },
    {
      "epoch": 11.09,
      "learning_rate": 6.253939246147759e-07,
      "loss": 0.0005,
      "step": 1040
    },
    {
      "epoch": 11.1,
      "learning_rate": 6.243449435824276e-07,
      "loss": 0.0009,
      "step": 1041
    },
    {
      "epoch": 11.11,
      "learning_rate": 6.232953788473811e-07,
      "loss": 0.049,
      "step": 1042
    },
    {
      "epoch": 11.13,
      "learning_rate": 6.222452353365259e-07,
      "loss": 0.0157,
      "step": 1043
    },
    {
      "epoch": 11.14,
      "learning_rate": 6.211945179794683e-07,
      "loss": 0.0076,
      "step": 1044
    },
    {
      "epoch": 11.15,
      "learning_rate": 6.201432317085082e-07,
      "loss": 0.0002,
      "step": 1045
    },
    {
      "epoch": 11.16,
      "learning_rate": 6.190913814586161e-07,
      "loss": 0.0144,
      "step": 1046
    },
    {
      "epoch": 11.17,
      "learning_rate": 6.1803897216741e-07,
      "loss": 0.0291,
      "step": 1047
    },
    {
      "epoch": 11.18,
      "learning_rate": 6.169860087751321e-07,
      "loss": 0.0163,
      "step": 1048
    },
    {
      "epoch": 11.19,
      "learning_rate": 6.159324962246257e-07,
      "loss": 0.002,
      "step": 1049
    },
    {
      "epoch": 11.2,
      "learning_rate": 6.148784394613119e-07,
      "loss": 0.0006,
      "step": 1050
    },
    {
      "epoch": 11.21,
      "learning_rate": 6.138238434331667e-07,
      "loss": 0.0357,
      "step": 1051
    },
    {
      "epoch": 11.22,
      "learning_rate": 6.127687130906971e-07,
      "loss": 0.0266,
      "step": 1052
    },
    {
      "epoch": 11.23,
      "learning_rate": 6.117130533869189e-07,
      "loss": 0.0002,
      "step": 1053
    },
    {
      "epoch": 11.24,
      "learning_rate": 6.106568692773323e-07,
      "loss": 0.0061,
      "step": 1054
    },
    {
      "epoch": 11.25,
      "learning_rate": 6.096001657198995e-07,
      "loss": 0.0006,
      "step": 1055
    },
    {
      "epoch": 11.26,
      "learning_rate": 6.085429476750208e-07,
      "loss": 0.0537,
      "step": 1056
    },
    {
      "epoch": 11.27,
      "learning_rate": 6.074852201055121e-07,
      "loss": 0.0002,
      "step": 1057
    },
    {
      "epoch": 11.29,
      "learning_rate": 6.064269879765804e-07,
      "loss": 0.0003,
      "step": 1058
    },
    {
      "epoch": 11.3,
      "learning_rate": 6.053682562558019e-07,
      "loss": 0.0004,
      "step": 1059
    },
    {
      "epoch": 11.31,
      "learning_rate": 6.043090299130977e-07,
      "loss": 0.0004,
      "step": 1060
    },
    {
      "epoch": 11.32,
      "learning_rate": 6.032493139207107e-07,
      "loss": 0.0002,
      "step": 1061
    },
    {
      "epoch": 11.33,
      "learning_rate": 6.021891132531824e-07,
      "loss": 0.036,
      "step": 1062
    },
    {
      "epoch": 11.34,
      "learning_rate": 6.011284328873297e-07,
      "loss": 0.0046,
      "step": 1063
    },
    {
      "epoch": 11.35,
      "learning_rate": 6.000672778022207e-07,
      "loss": 0.0424,
      "step": 1064
    },
    {
      "epoch": 11.36,
      "learning_rate": 5.990056529791528e-07,
      "loss": 0.0006,
      "step": 1065
    },
    {
      "epoch": 11.37,
      "learning_rate": 5.979435634016276e-07,
      "loss": 0.0025,
      "step": 1066
    },
    {
      "epoch": 11.38,
      "learning_rate": 5.968810140553292e-07,
      "loss": 0.0002,
      "step": 1067
    },
    {
      "epoch": 11.39,
      "learning_rate": 5.95818009928099e-07,
      "loss": 0.0165,
      "step": 1068
    },
    {
      "epoch": 11.4,
      "learning_rate": 5.947545560099141e-07,
      "loss": 0.0024,
      "step": 1069
    },
    {
      "epoch": 11.41,
      "learning_rate": 5.936906572928624e-07,
      "loss": 0.0097,
      "step": 1070
    },
    {
      "epoch": 11.42,
      "learning_rate": 5.926263187711202e-07,
      "loss": 0.0283,
      "step": 1071
    },
    {
      "epoch": 11.43,
      "learning_rate": 5.915615454409281e-07,
      "loss": 0.0082,
      "step": 1072
    },
    {
      "epoch": 11.45,
      "learning_rate": 5.90496342300568e-07,
      "loss": 0.0011,
      "step": 1073
    },
    {
      "epoch": 11.46,
      "learning_rate": 5.894307143503392e-07,
      "loss": 0.0318,
      "step": 1074
    },
    {
      "epoch": 11.47,
      "learning_rate": 5.883646665925352e-07,
      "loss": 0.0002,
      "step": 1075
    },
    {
      "epoch": 11.48,
      "learning_rate": 5.872982040314205e-07,
      "loss": 0.0337,
      "step": 1076
    },
    {
      "epoch": 11.49,
      "learning_rate": 5.862313316732063e-07,
      "loss": 0.0004,
      "step": 1077
    },
    {
      "epoch": 11.5,
      "learning_rate": 5.851640545260275e-07,
      "loss": 0.0303,
      "step": 1078
    },
    {
      "epoch": 11.51,
      "learning_rate": 5.840963775999198e-07,
      "loss": 0.0002,
      "step": 1079
    },
    {
      "epoch": 11.52,
      "learning_rate": 5.830283059067947e-07,
      "loss": 0.027,
      "step": 1080
    },
    {
      "epoch": 11.53,
      "learning_rate": 5.819598444604174e-07,
      "loss": 0.0131,
      "step": 1081
    },
    {
      "epoch": 11.54,
      "learning_rate": 5.808909982763825e-07,
      "loss": 0.0022,
      "step": 1082
    },
    {
      "epoch": 11.55,
      "learning_rate": 5.798217723720904e-07,
      "loss": 0.0003,
      "step": 1083
    },
    {
      "epoch": 11.56,
      "learning_rate": 5.787521717667246e-07,
      "loss": 0.0019,
      "step": 1084
    },
    {
      "epoch": 11.57,
      "learning_rate": 5.776822014812271e-07,
      "loss": 0.0004,
      "step": 1085
    },
    {
      "epoch": 11.58,
      "learning_rate": 5.766118665382753e-07,
      "loss": 0.0033,
      "step": 1086
    },
    {
      "epoch": 11.59,
      "learning_rate": 5.755411719622583e-07,
      "loss": 0.0002,
      "step": 1087
    },
    {
      "epoch": 11.61,
      "learning_rate": 5.744701227792538e-07,
      "loss": 0.0164,
      "step": 1088
    },
    {
      "epoch": 11.62,
      "learning_rate": 5.733987240170035e-07,
      "loss": 0.0033,
      "step": 1089
    },
    {
      "epoch": 11.63,
      "learning_rate": 5.723269807048906e-07,
      "loss": 0.0017,
      "step": 1090
    },
    {
      "epoch": 11.64,
      "learning_rate": 5.712548978739154e-07,
      "loss": 0.0002,
      "step": 1091
    },
    {
      "epoch": 11.65,
      "learning_rate": 5.701824805566722e-07,
      "loss": 0.0075,
      "step": 1092
    },
    {
      "epoch": 11.66,
      "learning_rate": 5.691097337873252e-07,
      "loss": 0.02,
      "step": 1093
    },
    {
      "epoch": 11.67,
      "learning_rate": 5.680366626015855e-07,
      "loss": 0.0576,
      "step": 1094
    },
    {
      "epoch": 11.68,
      "learning_rate": 5.669632720366867e-07,
      "loss": 0.0004,
      "step": 1095
    },
    {
      "epoch": 11.69,
      "learning_rate": 5.658895671313618e-07,
      "loss": 0.0002,
      "step": 1096
    },
    {
      "epoch": 11.7,
      "learning_rate": 5.648155529258194e-07,
      "loss": 0.0181,
      "step": 1097
    },
    {
      "epoch": 11.71,
      "learning_rate": 5.6374123446172e-07,
      "loss": 0.0008,
      "step": 1098
    },
    {
      "epoch": 11.72,
      "learning_rate": 5.626666167821521e-07,
      "loss": 0.0013,
      "step": 1099
    },
    {
      "epoch": 11.73,
      "learning_rate": 5.615917049316094e-07,
      "loss": 0.0095,
      "step": 1100
    },
    {
      "epoch": 11.74,
      "learning_rate": 5.60516503955966e-07,
      "loss": 0.0122,
      "step": 1101
    },
    {
      "epoch": 11.75,
      "learning_rate": 5.594410189024532e-07,
      "loss": 0.0003,
      "step": 1102
    },
    {
      "epoch": 11.77,
      "learning_rate": 5.583652548196362e-07,
      "loss": 0.0057,
      "step": 1103
    },
    {
      "epoch": 11.78,
      "learning_rate": 5.572892167573896e-07,
      "loss": 0.0356,
      "step": 1104
    },
    {
      "epoch": 11.79,
      "learning_rate": 5.562129097668746e-07,
      "loss": 0.0391,
      "step": 1105
    },
    {
      "epoch": 11.8,
      "learning_rate": 5.551363389005144e-07,
      "loss": 0.0557,
      "step": 1106
    },
    {
      "epoch": 11.81,
      "learning_rate": 5.540595092119708e-07,
      "loss": 0.0028,
      "step": 1107
    },
    {
      "epoch": 11.82,
      "learning_rate": 5.529824257561212e-07,
      "loss": 0.0009,
      "step": 1108
    },
    {
      "epoch": 11.83,
      "learning_rate": 5.519050935890335e-07,
      "loss": 0.0182,
      "step": 1109
    },
    {
      "epoch": 11.84,
      "learning_rate": 5.508275177679435e-07,
      "loss": 0.0008,
      "step": 1110
    },
    {
      "epoch": 11.85,
      "learning_rate": 5.497497033512308e-07,
      "loss": 0.0002,
      "step": 1111
    },
    {
      "epoch": 11.86,
      "learning_rate": 5.48671655398395e-07,
      "loss": 0.0993,
      "step": 1112
    },
    {
      "epoch": 11.87,
      "learning_rate": 5.475933789700314e-07,
      "loss": 0.0546,
      "step": 1113
    },
    {
      "epoch": 11.88,
      "learning_rate": 5.465148791278091e-07,
      "loss": 0.0002,
      "step": 1114
    },
    {
      "epoch": 11.89,
      "learning_rate": 5.454361609344444e-07,
      "loss": 0.0028,
      "step": 1115
    },
    {
      "epoch": 11.9,
      "learning_rate": 5.4435722945368e-07,
      "loss": 0.0457,
      "step": 1116
    },
    {
      "epoch": 11.91,
      "learning_rate": 5.432780897502588e-07,
      "loss": 0.0458,
      "step": 1117
    },
    {
      "epoch": 11.93,
      "learning_rate": 5.421987468899014e-07,
      "loss": 0.0023,
      "step": 1118
    },
    {
      "epoch": 11.94,
      "learning_rate": 5.411192059392827e-07,
      "loss": 0.0002,
      "step": 1119
    },
    {
      "epoch": 11.95,
      "learning_rate": 5.400394719660063e-07,
      "loss": 0.0003,
      "step": 1120
    },
    {
      "epoch": 11.96,
      "learning_rate": 5.389595500385829e-07,
      "loss": 0.0222,
      "step": 1121
    },
    {
      "epoch": 11.97,
      "learning_rate": 5.378794452264053e-07,
      "loss": 0.036,
      "step": 1122
    },
    {
      "epoch": 11.98,
      "learning_rate": 5.367991625997242e-07,
      "loss": 0.0003,
      "step": 1123
    },
    {
      "epoch": 11.99,
      "learning_rate": 5.357187072296258e-07,
      "loss": 0.0661,
      "step": 1124
    },
    {
      "epoch": 12.0,
      "learning_rate": 5.346380841880067e-07,
      "loss": 0.0002,
      "step": 1125
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.014612920582294464,
      "eval_runtime": 12.4422,
      "eval_samples_per_second": 60.279,
      "eval_steps_per_second": 15.11,
      "eval_wer": 0.0024291497975708503,
      "step": 1125
    },
    {
      "epoch": 12.01,
      "learning_rate": 5.33557298547551e-07,
      "loss": 0.0002,
      "step": 1126
    },
    {
      "epoch": 12.02,
      "learning_rate": 5.324763553817053e-07,
      "loss": 0.0314,
      "step": 1127
    },
    {
      "epoch": 12.03,
      "learning_rate": 5.313952597646567e-07,
      "loss": 0.027,
      "step": 1128
    },
    {
      "epoch": 12.04,
      "learning_rate": 5.303140167713071e-07,
      "loss": 0.0022,
      "step": 1129
    },
    {
      "epoch": 12.05,
      "learning_rate": 5.292326314772505e-07,
      "loss": 0.0759,
      "step": 1130
    },
    {
      "epoch": 12.06,
      "learning_rate": 5.28151108958749e-07,
      "loss": 0.0019,
      "step": 1131
    },
    {
      "epoch": 12.07,
      "learning_rate": 5.270694542927088e-07,
      "loss": 0.0004,
      "step": 1132
    },
    {
      "epoch": 12.09,
      "learning_rate": 5.259876725566563e-07,
      "loss": 0.0004,
      "step": 1133
    },
    {
      "epoch": 12.1,
      "learning_rate": 5.249057688287146e-07,
      "loss": 0.0013,
      "step": 1134
    },
    {
      "epoch": 12.11,
      "learning_rate": 5.238237481875795e-07,
      "loss": 0.0192,
      "step": 1135
    },
    {
      "epoch": 12.12,
      "learning_rate": 5.227416157124951e-07,
      "loss": 0.0054,
      "step": 1136
    },
    {
      "epoch": 12.13,
      "learning_rate": 5.216593764832311e-07,
      "loss": 0.0103,
      "step": 1137
    },
    {
      "epoch": 12.14,
      "learning_rate": 5.20577035580058e-07,
      "loss": 0.0489,
      "step": 1138
    },
    {
      "epoch": 12.15,
      "learning_rate": 5.194945980837237e-07,
      "loss": 0.0008,
      "step": 1139
    },
    {
      "epoch": 12.16,
      "learning_rate": 5.184120690754295e-07,
      "loss": 0.0194,
      "step": 1140
    },
    {
      "epoch": 12.17,
      "learning_rate": 5.173294536368062e-07,
      "loss": 0.0225,
      "step": 1141
    },
    {
      "epoch": 12.18,
      "learning_rate": 5.162467568498903e-07,
      "loss": 0.0304,
      "step": 1142
    },
    {
      "epoch": 12.19,
      "learning_rate": 5.151639837971003e-07,
      "loss": 0.0168,
      "step": 1143
    },
    {
      "epoch": 12.2,
      "learning_rate": 5.140811395612128e-07,
      "loss": 0.0142,
      "step": 1144
    },
    {
      "epoch": 12.21,
      "learning_rate": 5.129982292253384e-07,
      "loss": 0.0303,
      "step": 1145
    },
    {
      "epoch": 12.22,
      "learning_rate": 5.119152578728979e-07,
      "loss": 0.0011,
      "step": 1146
    },
    {
      "epoch": 12.23,
      "learning_rate": 5.108322305875987e-07,
      "loss": 0.0015,
      "step": 1147
    },
    {
      "epoch": 12.25,
      "learning_rate": 5.097491524534106e-07,
      "loss": 0.0051,
      "step": 1148
    },
    {
      "epoch": 12.26,
      "learning_rate": 5.086660285545421e-07,
      "loss": 0.0002,
      "step": 1149
    },
    {
      "epoch": 12.27,
      "learning_rate": 5.075828639754167e-07,
      "loss": 0.0182,
      "step": 1150
    },
    {
      "epoch": 12.28,
      "learning_rate": 5.064996638006489e-07,
      "loss": 0.0137,
      "step": 1151
    },
    {
      "epoch": 12.29,
      "learning_rate": 5.054164331150199e-07,
      "loss": 0.0068,
      "step": 1152
    },
    {
      "epoch": 12.3,
      "learning_rate": 5.043331770034547e-07,
      "loss": 0.0004,
      "step": 1153
    },
    {
      "epoch": 12.31,
      "learning_rate": 5.032499005509971e-07,
      "loss": 0.0024,
      "step": 1154
    },
    {
      "epoch": 12.32,
      "learning_rate": 5.021666088427867e-07,
      "loss": 0.0002,
      "step": 1155
    },
    {
      "epoch": 12.33,
      "learning_rate": 5.010833069640347e-07,
      "loss": 0.0004,
      "step": 1156
    },
    {
      "epoch": 12.34,
      "learning_rate": 5e-07,
      "loss": 0.0041,
      "step": 1157
    },
    {
      "epoch": 12.35,
      "learning_rate": 4.989166930359652e-07,
      "loss": 0.0361,
      "step": 1158
    },
    {
      "epoch": 12.36,
      "learning_rate": 4.978333911572132e-07,
      "loss": 0.108,
      "step": 1159
    },
    {
      "epoch": 12.37,
      "learning_rate": 4.967500994490029e-07,
      "loss": 0.0231,
      "step": 1160
    },
    {
      "epoch": 12.38,
      "learning_rate": 4.956668229965454e-07,
      "loss": 0.0161,
      "step": 1161
    },
    {
      "epoch": 12.39,
      "learning_rate": 4.945835668849801e-07,
      "loss": 0.0041,
      "step": 1162
    },
    {
      "epoch": 12.41,
      "learning_rate": 4.935003361993511e-07,
      "loss": 0.0048,
      "step": 1163
    },
    {
      "epoch": 12.42,
      "learning_rate": 4.924171360245833e-07,
      "loss": 0.012,
      "step": 1164
    },
    {
      "epoch": 12.43,
      "learning_rate": 4.91333971445458e-07,
      "loss": 0.0342,
      "step": 1165
    },
    {
      "epoch": 12.44,
      "learning_rate": 4.902508475465895e-07,
      "loss": 0.0206,
      "step": 1166
    },
    {
      "epoch": 12.45,
      "learning_rate": 4.891677694124013e-07,
      "loss": 0.0508,
      "step": 1167
    },
    {
      "epoch": 12.46,
      "learning_rate": 4.88084742127102e-07,
      "loss": 0.0272,
      "step": 1168
    },
    {
      "epoch": 12.47,
      "learning_rate": 4.870017707746616e-07,
      "loss": 0.0493,
      "step": 1169
    },
    {
      "epoch": 12.48,
      "learning_rate": 4.859188604387872e-07,
      "loss": 0.0011,
      "step": 1170
    },
    {
      "epoch": 12.49,
      "learning_rate": 4.848360162028997e-07,
      "loss": 0.003,
      "step": 1171
    },
    {
      "epoch": 12.5,
      "learning_rate": 4.837532431501098e-07,
      "loss": 0.0262,
      "step": 1172
    },
    {
      "epoch": 12.51,
      "learning_rate": 4.826705463631939e-07,
      "loss": 0.0302,
      "step": 1173
    },
    {
      "epoch": 12.52,
      "learning_rate": 4.815879309245707e-07,
      "loss": 0.0032,
      "step": 1174
    },
    {
      "epoch": 12.53,
      "learning_rate": 4.805054019162764e-07,
      "loss": 0.0089,
      "step": 1175
    },
    {
      "epoch": 12.54,
      "learning_rate": 4.79422964419942e-07,
      "loss": 0.0005,
      "step": 1176
    },
    {
      "epoch": 12.55,
      "learning_rate": 4.783406235167689e-07,
      "loss": 0.0125,
      "step": 1177
    },
    {
      "epoch": 12.57,
      "learning_rate": 4.772583842875049e-07,
      "loss": 0.0003,
      "step": 1178
    },
    {
      "epoch": 12.58,
      "learning_rate": 4.761762518124207e-07,
      "loss": 0.0784,
      "step": 1179
    },
    {
      "epoch": 12.59,
      "learning_rate": 4.7509423117128546e-07,
      "loss": 0.0196,
      "step": 1180
    },
    {
      "epoch": 12.6,
      "learning_rate": 4.7401232744334373e-07,
      "loss": 0.0014,
      "step": 1181
    },
    {
      "epoch": 12.61,
      "learning_rate": 4.7293054570729126e-07,
      "loss": 0.0618,
      "step": 1182
    },
    {
      "epoch": 12.62,
      "learning_rate": 4.7184889104125107e-07,
      "loss": 0.0007,
      "step": 1183
    },
    {
      "epoch": 12.63,
      "learning_rate": 4.7076736852274957e-07,
      "loss": 0.0167,
      "step": 1184
    },
    {
      "epoch": 12.64,
      "learning_rate": 4.6968598322869297e-07,
      "loss": 0.0102,
      "step": 1185
    },
    {
      "epoch": 12.65,
      "learning_rate": 4.686047402353433e-07,
      "loss": 0.0011,
      "step": 1186
    },
    {
      "epoch": 12.66,
      "learning_rate": 4.6752364461829454e-07,
      "loss": 0.0378,
      "step": 1187
    },
    {
      "epoch": 12.67,
      "learning_rate": 4.664427014524492e-07,
      "loss": 0.0534,
      "step": 1188
    },
    {
      "epoch": 12.68,
      "learning_rate": 4.653619158119933e-07,
      "loss": 0.003,
      "step": 1189
    },
    {
      "epoch": 12.69,
      "learning_rate": 4.642812927703742e-07,
      "loss": 0.0015,
      "step": 1190
    },
    {
      "epoch": 12.7,
      "learning_rate": 4.6320083740027583e-07,
      "loss": 0.0473,
      "step": 1191
    },
    {
      "epoch": 12.71,
      "learning_rate": 4.621205547735948e-07,
      "loss": 0.0002,
      "step": 1192
    },
    {
      "epoch": 12.73,
      "learning_rate": 4.610404499614171e-07,
      "loss": 0.007,
      "step": 1193
    },
    {
      "epoch": 12.74,
      "learning_rate": 4.5996052803399377e-07,
      "loss": 0.0168,
      "step": 1194
    },
    {
      "epoch": 12.75,
      "learning_rate": 4.5888079406071745e-07,
      "loss": 0.0024,
      "step": 1195
    },
    {
      "epoch": 12.76,
      "learning_rate": 4.578012531100985e-07,
      "loss": 0.0573,
      "step": 1196
    },
    {
      "epoch": 12.77,
      "learning_rate": 4.567219102497412e-07,
      "loss": 0.0425,
      "step": 1197
    },
    {
      "epoch": 12.78,
      "learning_rate": 4.556427705463201e-07,
      "loss": 0.0263,
      "step": 1198
    },
    {
      "epoch": 12.79,
      "learning_rate": 4.545638390655555e-07,
      "loss": 0.0266,
      "step": 1199
    },
    {
      "epoch": 12.8,
      "learning_rate": 4.53485120872191e-07,
      "loss": 0.0558,
      "step": 1200
    },
    {
      "epoch": 12.81,
      "learning_rate": 4.524066210299685e-07,
      "loss": 0.0016,
      "step": 1201
    },
    {
      "epoch": 12.82,
      "learning_rate": 4.513283446016052e-07,
      "loss": 0.0218,
      "step": 1202
    },
    {
      "epoch": 12.83,
      "learning_rate": 4.5025029664876923e-07,
      "loss": 0.0002,
      "step": 1203
    },
    {
      "epoch": 12.84,
      "learning_rate": 4.4917248223205653e-07,
      "loss": 0.0208,
      "step": 1204
    },
    {
      "epoch": 12.85,
      "learning_rate": 4.4809490641096646e-07,
      "loss": 0.0025,
      "step": 1205
    },
    {
      "epoch": 12.86,
      "learning_rate": 4.4701757424387876e-07,
      "loss": 0.0002,
      "step": 1206
    },
    {
      "epoch": 12.87,
      "learning_rate": 4.459404907880292e-07,
      "loss": 0.0005,
      "step": 1207
    },
    {
      "epoch": 12.89,
      "learning_rate": 4.448636610994857e-07,
      "loss": 0.0079,
      "step": 1208
    },
    {
      "epoch": 12.9,
      "learning_rate": 4.4378709023312534e-07,
      "loss": 0.0352,
      "step": 1209
    },
    {
      "epoch": 12.91,
      "learning_rate": 4.4271078324261025e-07,
      "loss": 0.0169,
      "step": 1210
    },
    {
      "epoch": 12.92,
      "learning_rate": 4.416347451803637e-07,
      "loss": 0.0085,
      "step": 1211
    },
    {
      "epoch": 12.93,
      "learning_rate": 4.405589810975468e-07,
      "loss": 0.003,
      "step": 1212
    },
    {
      "epoch": 12.94,
      "learning_rate": 4.3948349604403406e-07,
      "loss": 0.1,
      "step": 1213
    },
    {
      "epoch": 12.95,
      "learning_rate": 4.384082950683906e-07,
      "loss": 0.0016,
      "step": 1214
    },
    {
      "epoch": 12.96,
      "learning_rate": 4.3733338321784777e-07,
      "loss": 0.0003,
      "step": 1215
    },
    {
      "epoch": 12.97,
      "learning_rate": 4.362587655382802e-07,
      "loss": 0.0081,
      "step": 1216
    },
    {
      "epoch": 12.98,
      "learning_rate": 4.351844470741807e-07,
      "loss": 0.0005,
      "step": 1217
    },
    {
      "epoch": 12.99,
      "learning_rate": 4.3411043286863826e-07,
      "loss": 0.0435,
      "step": 1218
    },
    {
      "epoch": 12.99,
      "eval_loss": 0.00937693752348423,
      "eval_runtime": 12.6011,
      "eval_samples_per_second": 59.519,
      "eval_steps_per_second": 14.919,
      "eval_wer": 0.0031039136302294197,
      "step": 1218
    },
    {
      "epoch": 13.0,
      "learning_rate": 4.330367279633133e-07,
      "loss": 0.006,
      "step": 1219
    },
    {
      "epoch": 13.01,
      "learning_rate": 4.3196333739841443e-07,
      "loss": 0.0069,
      "step": 1220
    },
    {
      "epoch": 13.02,
      "learning_rate": 4.3089026621267475e-07,
      "loss": 0.0003,
      "step": 1221
    },
    {
      "epoch": 13.03,
      "learning_rate": 4.2981751944332785e-07,
      "loss": 0.035,
      "step": 1222
    },
    {
      "epoch": 13.05,
      "learning_rate": 4.287451021260846e-07,
      "loss": 0.0242,
      "step": 1223
    },
    {
      "epoch": 13.06,
      "learning_rate": 4.276730192951094e-07,
      "loss": 0.0361,
      "step": 1224
    },
    {
      "epoch": 13.07,
      "learning_rate": 4.2660127598299644e-07,
      "loss": 0.1118,
      "step": 1225
    },
    {
      "epoch": 13.08,
      "learning_rate": 4.2552987722074637e-07,
      "loss": 0.0094,
      "step": 1226
    },
    {
      "epoch": 13.09,
      "learning_rate": 4.244588280377417e-07,
      "loss": 0.0002,
      "step": 1227
    },
    {
      "epoch": 13.1,
      "learning_rate": 4.233881334617247e-07,
      "loss": 0.0368,
      "step": 1228
    },
    {
      "epoch": 13.11,
      "learning_rate": 4.223177985187728e-07,
      "loss": 0.0079,
      "step": 1229
    },
    {
      "epoch": 13.12,
      "learning_rate": 4.2124782823327536e-07,
      "loss": 0.0002,
      "step": 1230
    },
    {
      "epoch": 13.13,
      "learning_rate": 4.2017822762790957e-07,
      "loss": 0.0724,
      "step": 1231
    },
    {
      "epoch": 13.14,
      "learning_rate": 4.1910900172361763e-07,
      "loss": 0.0259,
      "step": 1232
    },
    {
      "epoch": 13.15,
      "learning_rate": 4.1804015553958263e-07,
      "loss": 0.0002,
      "step": 1233
    },
    {
      "epoch": 13.16,
      "learning_rate": 4.1697169409320524e-07,
      "loss": 0.0232,
      "step": 1234
    },
    {
      "epoch": 13.17,
      "learning_rate": 4.1590362240008036e-07,
      "loss": 0.0331,
      "step": 1235
    },
    {
      "epoch": 13.18,
      "learning_rate": 4.148359454739725e-07,
      "loss": 0.0403,
      "step": 1236
    },
    {
      "epoch": 13.19,
      "learning_rate": 4.137686683267938e-07,
      "loss": 0.0112,
      "step": 1237
    },
    {
      "epoch": 13.21,
      "learning_rate": 4.1270179596857946e-07,
      "loss": 0.0005,
      "step": 1238
    },
    {
      "epoch": 13.22,
      "learning_rate": 4.116353334074647e-07,
      "loss": 0.0004,
      "step": 1239
    },
    {
      "epoch": 13.23,
      "learning_rate": 4.105692856496609e-07,
      "loss": 0.0071,
      "step": 1240
    },
    {
      "epoch": 13.24,
      "learning_rate": 4.095036576994321e-07,
      "loss": 0.0081,
      "step": 1241
    },
    {
      "epoch": 13.25,
      "learning_rate": 4.084384545590719e-07,
      "loss": 0.0003,
      "step": 1242
    },
    {
      "epoch": 13.26,
      "learning_rate": 4.0737368122887983e-07,
      "loss": 0.0003,
      "step": 1243
    },
    {
      "epoch": 13.27,
      "learning_rate": 4.0630934270713755e-07,
      "loss": 0.0204,
      "step": 1244
    },
    {
      "epoch": 13.28,
      "learning_rate": 4.052454439900861e-07,
      "loss": 0.0005,
      "step": 1245
    },
    {
      "epoch": 13.29,
      "learning_rate": 4.04181990071901e-07,
      "loss": 0.0283,
      "step": 1246
    },
    {
      "epoch": 13.3,
      "learning_rate": 4.031189859446708e-07,
      "loss": 0.012,
      "step": 1247
    },
    {
      "epoch": 13.31,
      "learning_rate": 4.0205643659837216e-07,
      "loss": 0.0286,
      "step": 1248
    },
    {
      "epoch": 13.32,
      "learning_rate": 4.0099434702084727e-07,
      "loss": 0.0002,
      "step": 1249
    },
    {
      "epoch": 13.33,
      "learning_rate": 3.999327221977793e-07,
      "loss": 0.0512,
      "step": 1250
    },
    {
      "epoch": 13.34,
      "learning_rate": 3.988715671126704e-07,
      "loss": 0.0386,
      "step": 1251
    },
    {
      "epoch": 13.35,
      "learning_rate": 3.9781088674681764e-07,
      "loss": 0.0002,
      "step": 1252
    },
    {
      "epoch": 13.37,
      "learning_rate": 3.967506860792893e-07,
      "loss": 0.0082,
      "step": 1253
    },
    {
      "epoch": 13.38,
      "learning_rate": 3.9569097008690245e-07,
      "loss": 0.0083,
      "step": 1254
    },
    {
      "epoch": 13.39,
      "learning_rate": 3.946317437441982e-07,
      "loss": 0.0002,
      "step": 1255
    },
    {
      "epoch": 13.4,
      "learning_rate": 3.9357301202341963e-07,
      "loss": 0.0294,
      "step": 1256
    },
    {
      "epoch": 13.41,
      "learning_rate": 3.9251477989448795e-07,
      "loss": 0.0002,
      "step": 1257
    },
    {
      "epoch": 13.42,
      "learning_rate": 3.9145705232497905e-07,
      "loss": 0.0008,
      "step": 1258
    },
    {
      "epoch": 13.43,
      "learning_rate": 3.903998342801006e-07,
      "loss": 0.0342,
      "step": 1259
    },
    {
      "epoch": 13.44,
      "learning_rate": 3.8934313072266775e-07,
      "loss": 0.0026,
      "step": 1260
    },
    {
      "epoch": 13.45,
      "learning_rate": 3.8828694661308115e-07,
      "loss": 0.0006,
      "step": 1261
    },
    {
      "epoch": 13.46,
      "learning_rate": 3.872312869093029e-07,
      "loss": 0.0869,
      "step": 1262
    },
    {
      "epoch": 13.47,
      "learning_rate": 3.8617615656683356e-07,
      "loss": 0.0774,
      "step": 1263
    },
    {
      "epoch": 13.48,
      "learning_rate": 3.851215605386883e-07,
      "loss": 0.0312,
      "step": 1264
    },
    {
      "epoch": 13.49,
      "learning_rate": 3.8406750377537446e-07,
      "loss": 0.0292,
      "step": 1265
    },
    {
      "epoch": 13.5,
      "learning_rate": 3.8301399122486794e-07,
      "loss": 0.0019,
      "step": 1266
    },
    {
      "epoch": 13.51,
      "learning_rate": 3.8196102783258996e-07,
      "loss": 0.0002,
      "step": 1267
    },
    {
      "epoch": 13.53,
      "learning_rate": 3.8090861854138397e-07,
      "loss": 0.0044,
      "step": 1268
    },
    {
      "epoch": 13.54,
      "learning_rate": 3.798567682914918e-07,
      "loss": 0.0215,
      "step": 1269
    },
    {
      "epoch": 13.55,
      "learning_rate": 3.7880548202053167e-07,
      "loss": 0.0012,
      "step": 1270
    },
    {
      "epoch": 13.56,
      "learning_rate": 3.777547646634741e-07,
      "loss": 0.0003,
      "step": 1271
    },
    {
      "epoch": 13.57,
      "learning_rate": 3.7670462115261904e-07,
      "loss": 0.018,
      "step": 1272
    },
    {
      "epoch": 13.58,
      "learning_rate": 3.7565505641757266e-07,
      "loss": 0.0002,
      "step": 1273
    },
    {
      "epoch": 13.59,
      "learning_rate": 3.7460607538522417e-07,
      "loss": 0.0002,
      "step": 1274
    },
    {
      "epoch": 13.6,
      "learning_rate": 3.7355768297972275e-07,
      "loss": 0.0065,
      "step": 1275
    },
    {
      "epoch": 13.61,
      "learning_rate": 3.725098841224546e-07,
      "loss": 0.0002,
      "step": 1276
    },
    {
      "epoch": 13.62,
      "learning_rate": 3.714626837320195e-07,
      "loss": 0.0002,
      "step": 1277
    },
    {
      "epoch": 13.63,
      "learning_rate": 3.704160867242082e-07,
      "loss": 0.0014,
      "step": 1278
    },
    {
      "epoch": 13.64,
      "learning_rate": 3.693700980119784e-07,
      "loss": 0.0662,
      "step": 1279
    },
    {
      "epoch": 13.65,
      "learning_rate": 3.683247225054329e-07,
      "loss": 0.0162,
      "step": 1280
    },
    {
      "epoch": 13.66,
      "learning_rate": 3.6727996511179577e-07,
      "loss": 0.0018,
      "step": 1281
    },
    {
      "epoch": 13.67,
      "learning_rate": 3.6623583073538965e-07,
      "loss": 0.006,
      "step": 1282
    },
    {
      "epoch": 13.69,
      "learning_rate": 3.6519232427761236e-07,
      "loss": 0.0009,
      "step": 1283
    },
    {
      "epoch": 13.7,
      "learning_rate": 3.6414945063691425e-07,
      "loss": 0.0713,
      "step": 1284
    },
    {
      "epoch": 13.71,
      "learning_rate": 3.6310721470877523e-07,
      "loss": 0.0267,
      "step": 1285
    },
    {
      "epoch": 13.72,
      "learning_rate": 3.6206562138568153e-07,
      "loss": 0.0002,
      "step": 1286
    },
    {
      "epoch": 13.73,
      "learning_rate": 3.6102467555710294e-07,
      "loss": 0.0183,
      "step": 1287
    },
    {
      "epoch": 13.74,
      "learning_rate": 3.5998438210946936e-07,
      "loss": 0.037,
      "step": 1288
    },
    {
      "epoch": 13.75,
      "learning_rate": 3.5894474592614865e-07,
      "loss": 0.0074,
      "step": 1289
    },
    {
      "epoch": 13.76,
      "learning_rate": 3.579057718874233e-07,
      "loss": 0.0013,
      "step": 1290
    },
    {
      "epoch": 13.77,
      "learning_rate": 3.5686746487046765e-07,
      "loss": 0.0324,
      "step": 1291
    },
    {
      "epoch": 13.78,
      "learning_rate": 3.558298297493246e-07,
      "loss": 0.0108,
      "step": 1292
    },
    {
      "epoch": 13.79,
      "learning_rate": 3.547928713948832e-07,
      "loss": 0.0002,
      "step": 1293
    },
    {
      "epoch": 13.8,
      "learning_rate": 3.5375659467485555e-07,
      "loss": 0.0003,
      "step": 1294
    },
    {
      "epoch": 13.81,
      "learning_rate": 3.5272100445375395e-07,
      "loss": 0.0033,
      "step": 1295
    },
    {
      "epoch": 13.82,
      "learning_rate": 3.516861055928686e-07,
      "loss": 0.0472,
      "step": 1296
    },
    {
      "epoch": 13.83,
      "learning_rate": 3.506519029502433e-07,
      "loss": 0.0291,
      "step": 1297
    },
    {
      "epoch": 13.85,
      "learning_rate": 3.496184013806546e-07,
      "loss": 0.0589,
      "step": 1298
    },
    {
      "epoch": 13.86,
      "learning_rate": 3.4858560573558757e-07,
      "loss": 0.003,
      "step": 1299
    },
    {
      "epoch": 13.87,
      "learning_rate": 3.4755352086321384e-07,
      "loss": 0.0046,
      "step": 1300
    },
    {
      "epoch": 13.88,
      "learning_rate": 3.465221516083682e-07,
      "loss": 0.0001,
      "step": 1301
    },
    {
      "epoch": 13.89,
      "learning_rate": 3.454915028125263e-07,
      "loss": 0.0075,
      "step": 1302
    },
    {
      "epoch": 13.9,
      "learning_rate": 3.4446157931378183e-07,
      "loss": 0.0213,
      "step": 1303
    },
    {
      "epoch": 13.91,
      "learning_rate": 3.4343238594682367e-07,
      "loss": 0.0747,
      "step": 1304
    },
    {
      "epoch": 13.92,
      "learning_rate": 3.4240392754291344e-07,
      "loss": 0.0385,
      "step": 1305
    },
    {
      "epoch": 13.93,
      "learning_rate": 3.413762089298628e-07,
      "loss": 0.0219,
      "step": 1306
    },
    {
      "epoch": 13.94,
      "learning_rate": 3.4034923493201007e-07,
      "loss": 0.0114,
      "step": 1307
    },
    {
      "epoch": 13.95,
      "learning_rate": 3.3932301037019883e-07,
      "loss": 0.0004,
      "step": 1308
    },
    {
      "epoch": 13.96,
      "learning_rate": 3.3829754006175434e-07,
      "loss": 0.0002,
      "step": 1309
    },
    {
      "epoch": 13.97,
      "learning_rate": 3.372728288204613e-07,
      "loss": 0.054,
      "step": 1310
    },
    {
      "epoch": 13.98,
      "learning_rate": 3.3624888145654136e-07,
      "loss": 0.0008,
      "step": 1311
    },
    {
      "epoch": 13.99,
      "learning_rate": 3.3522570277662984e-07,
      "loss": 0.0845,
      "step": 1312
    },
    {
      "epoch": 13.99,
      "eval_loss": 0.010672726668417454,
      "eval_runtime": 12.2885,
      "eval_samples_per_second": 61.033,
      "eval_steps_per_second": 15.299,
      "eval_wer": 0.002968960863697706,
      "step": 1312
    },
    {
      "epoch": 14.01,
      "learning_rate": 3.342032975837542e-07,
      "loss": 0.0017,
      "step": 1313
    },
    {
      "epoch": 14.02,
      "learning_rate": 3.331816706773107e-07,
      "loss": 0.0002,
      "step": 1314
    },
    {
      "epoch": 14.03,
      "learning_rate": 3.321608268530427e-07,
      "loss": 0.0002,
      "step": 1315
    },
    {
      "epoch": 14.04,
      "learning_rate": 3.3114077090301645e-07,
      "loss": 0.0183,
      "step": 1316
    },
    {
      "epoch": 14.05,
      "learning_rate": 3.301215076156008e-07,
      "loss": 0.0022,
      "step": 1317
    },
    {
      "epoch": 14.06,
      "learning_rate": 3.291030417754433e-07,
      "loss": 0.0041,
      "step": 1318
    },
    {
      "epoch": 14.07,
      "learning_rate": 3.2808537816344807e-07,
      "loss": 0.0003,
      "step": 1319
    },
    {
      "epoch": 14.08,
      "learning_rate": 3.2706852155675355e-07,
      "loss": 0.0036,
      "step": 1320
    },
    {
      "epoch": 14.09,
      "learning_rate": 3.260524767287096e-07,
      "loss": 0.0002,
      "step": 1321
    },
    {
      "epoch": 14.1,
      "learning_rate": 3.2503724844885576e-07,
      "loss": 0.0002,
      "step": 1322
    },
    {
      "epoch": 14.11,
      "learning_rate": 3.240228414828984e-07,
      "loss": 0.0239,
      "step": 1323
    },
    {
      "epoch": 14.12,
      "learning_rate": 3.2300926059268827e-07,
      "loss": 0.0179,
      "step": 1324
    },
    {
      "epoch": 14.13,
      "learning_rate": 3.2199651053619885e-07,
      "loss": 0.0271,
      "step": 1325
    },
    {
      "epoch": 14.14,
      "learning_rate": 3.209845960675027e-07,
      "loss": 0.002,
      "step": 1326
    },
    {
      "epoch": 14.15,
      "learning_rate": 3.1997352193675066e-07,
      "loss": 0.0004,
      "step": 1327
    },
    {
      "epoch": 14.17,
      "learning_rate": 3.1896329289014843e-07,
      "loss": 0.0348,
      "step": 1328
    },
    {
      "epoch": 14.18,
      "learning_rate": 3.1795391366993505e-07,
      "loss": 0.0027,
      "step": 1329
    },
    {
      "epoch": 14.19,
      "learning_rate": 3.1694538901435985e-07,
      "loss": 0.0817,
      "step": 1330
    },
    {
      "epoch": 14.2,
      "learning_rate": 3.15937723657661e-07,
      "loss": 0.0051,
      "step": 1331
    },
    {
      "epoch": 14.21,
      "learning_rate": 3.1493092233004277e-07,
      "loss": 0.006,
      "step": 1332
    },
    {
      "epoch": 14.22,
      "learning_rate": 3.1392498975765354e-07,
      "loss": 0.0251,
      "step": 1333
    },
    {
      "epoch": 14.23,
      "learning_rate": 3.129199306625637e-07,
      "loss": 0.001,
      "step": 1334
    },
    {
      "epoch": 14.24,
      "learning_rate": 3.1191574976274283e-07,
      "loss": 0.0773,
      "step": 1335
    },
    {
      "epoch": 14.25,
      "learning_rate": 3.1091245177203863e-07,
      "loss": 0.0152,
      "step": 1336
    },
    {
      "epoch": 14.26,
      "learning_rate": 3.0991004140015397e-07,
      "loss": 0.0181,
      "step": 1337
    },
    {
      "epoch": 14.27,
      "learning_rate": 3.089085233526252e-07,
      "loss": 0.0131,
      "step": 1338
    },
    {
      "epoch": 14.28,
      "learning_rate": 3.0790790233079985e-07,
      "loss": 0.0002,
      "step": 1339
    },
    {
      "epoch": 14.29,
      "learning_rate": 3.069081830318142e-07,
      "loss": 0.0009,
      "step": 1340
    },
    {
      "epoch": 14.3,
      "learning_rate": 3.0590937014857223e-07,
      "loss": 0.0627,
      "step": 1341
    },
    {
      "epoch": 14.31,
      "learning_rate": 3.049114683697227e-07,
      "loss": 0.0002,
      "step": 1342
    },
    {
      "epoch": 14.33,
      "learning_rate": 3.039144823796378e-07,
      "loss": 0.0255,
      "step": 1343
    },
    {
      "epoch": 14.34,
      "learning_rate": 3.029184168583902e-07,
      "loss": 0.0002,
      "step": 1344
    },
    {
      "epoch": 14.35,
      "learning_rate": 3.019232764817321e-07,
      "loss": 0.0324,
      "step": 1345
    },
    {
      "epoch": 14.36,
      "learning_rate": 3.009290659210727e-07,
      "loss": 0.0007,
      "step": 1346
    },
    {
      "epoch": 14.37,
      "learning_rate": 2.9993578984345666e-07,
      "loss": 0.0191,
      "step": 1347
    },
    {
      "epoch": 14.38,
      "learning_rate": 2.98943452911542e-07,
      "loss": 0.0136,
      "step": 1348
    },
    {
      "epoch": 14.39,
      "learning_rate": 2.979520597835775e-07,
      "loss": 0.0015,
      "step": 1349
    },
    {
      "epoch": 14.4,
      "learning_rate": 2.9696161511338226e-07,
      "loss": 0.0072,
      "step": 1350
    },
    {
      "epoch": 14.41,
      "learning_rate": 2.9597212355032296e-07,
      "loss": 0.0009,
      "step": 1351
    },
    {
      "epoch": 14.42,
      "learning_rate": 2.9498358973929195e-07,
      "loss": 0.0198,
      "step": 1352
    },
    {
      "epoch": 14.43,
      "learning_rate": 2.939960183206861e-07,
      "loss": 0.0022,
      "step": 1353
    },
    {
      "epoch": 14.44,
      "learning_rate": 2.9300941393038394e-07,
      "loss": 0.0599,
      "step": 1354
    },
    {
      "epoch": 14.45,
      "learning_rate": 2.9202378119972507e-07,
      "loss": 0.0692,
      "step": 1355
    },
    {
      "epoch": 14.46,
      "learning_rate": 2.91039124755488e-07,
      "loss": 0.0002,
      "step": 1356
    },
    {
      "epoch": 14.47,
      "learning_rate": 2.900554492198677e-07,
      "loss": 0.0932,
      "step": 1357
    },
    {
      "epoch": 14.49,
      "learning_rate": 2.8907275921045527e-07,
      "loss": 0.0013,
      "step": 1358
    },
    {
      "epoch": 14.5,
      "learning_rate": 2.8809105934021514e-07,
      "loss": 0.0336,
      "step": 1359
    },
    {
      "epoch": 14.51,
      "learning_rate": 2.8711035421746363e-07,
      "loss": 0.0004,
      "step": 1360
    },
    {
      "epoch": 14.52,
      "learning_rate": 2.8613064844584813e-07,
      "loss": 0.0002,
      "step": 1361
    },
    {
      "epoch": 14.53,
      "learning_rate": 2.8515194662432416e-07,
      "loss": 0.0003,
      "step": 1362
    },
    {
      "epoch": 14.54,
      "learning_rate": 2.8417425334713497e-07,
      "loss": 0.0013,
      "step": 1363
    },
    {
      "epoch": 14.55,
      "learning_rate": 2.83197573203789e-07,
      "loss": 0.0026,
      "step": 1364
    },
    {
      "epoch": 14.56,
      "learning_rate": 2.8222191077903943e-07,
      "loss": 0.0117,
      "step": 1365
    },
    {
      "epoch": 14.57,
      "learning_rate": 2.812472706528614e-07,
      "loss": 0.0046,
      "step": 1366
    },
    {
      "epoch": 14.58,
      "learning_rate": 2.8027365740043185e-07,
      "loss": 0.0782,
      "step": 1367
    },
    {
      "epoch": 14.59,
      "learning_rate": 2.7930107559210674e-07,
      "loss": 0.01,
      "step": 1368
    },
    {
      "epoch": 14.6,
      "learning_rate": 2.783295297934003e-07,
      "loss": 0.0002,
      "step": 1369
    },
    {
      "epoch": 14.61,
      "learning_rate": 2.7735902456496393e-07,
      "loss": 0.0045,
      "step": 1370
    },
    {
      "epoch": 14.62,
      "learning_rate": 2.763895644625637e-07,
      "loss": 0.049,
      "step": 1371
    },
    {
      "epoch": 14.63,
      "learning_rate": 2.754211540370606e-07,
      "loss": 0.0188,
      "step": 1372
    },
    {
      "epoch": 14.65,
      "learning_rate": 2.7445379783438683e-07,
      "loss": 0.0022,
      "step": 1373
    },
    {
      "epoch": 14.66,
      "learning_rate": 2.734875003955272e-07,
      "loss": 0.0002,
      "step": 1374
    },
    {
      "epoch": 14.67,
      "learning_rate": 2.7252226625649536e-07,
      "loss": 0.0015,
      "step": 1375
    },
    {
      "epoch": 14.68,
      "learning_rate": 2.715580999483146e-07,
      "loss": 0.0276,
      "step": 1376
    },
    {
      "epoch": 14.69,
      "learning_rate": 2.7059500599699477e-07,
      "loss": 0.0002,
      "step": 1377
    },
    {
      "epoch": 14.7,
      "learning_rate": 2.696329889235119e-07,
      "loss": 0.0338,
      "step": 1378
    },
    {
      "epoch": 14.71,
      "learning_rate": 2.6867205324378775e-07,
      "loss": 0.0293,
      "step": 1379
    },
    {
      "epoch": 14.72,
      "learning_rate": 2.6771220346866646e-07,
      "loss": 0.0003,
      "step": 1380
    },
    {
      "epoch": 14.73,
      "learning_rate": 2.6675344410389624e-07,
      "loss": 0.0002,
      "step": 1381
    },
    {
      "epoch": 14.74,
      "learning_rate": 2.65795779650105e-07,
      "loss": 0.0075,
      "step": 1382
    },
    {
      "epoch": 14.75,
      "learning_rate": 2.6483921460278225e-07,
      "loss": 0.0018,
      "step": 1383
    },
    {
      "epoch": 14.76,
      "learning_rate": 2.638837534522558e-07,
      "loss": 0.0007,
      "step": 1384
    },
    {
      "epoch": 14.77,
      "learning_rate": 2.629294006836722e-07,
      "loss": 0.0115,
      "step": 1385
    },
    {
      "epoch": 14.78,
      "learning_rate": 2.6197616077697455e-07,
      "loss": 0.0665,
      "step": 1386
    },
    {
      "epoch": 14.79,
      "learning_rate": 2.6102403820688174e-07,
      "loss": 0.0002,
      "step": 1387
    },
    {
      "epoch": 14.81,
      "learning_rate": 2.600730374428684e-07,
      "loss": 0.0009,
      "step": 1388
    },
    {
      "epoch": 14.82,
      "learning_rate": 2.591231629491423e-07,
      "loss": 0.0008,
      "step": 1389
    },
    {
      "epoch": 14.83,
      "learning_rate": 2.581744191846249e-07,
      "loss": 0.0168,
      "step": 1390
    },
    {
      "epoch": 14.84,
      "learning_rate": 2.572268106029295e-07,
      "loss": 0.0002,
      "step": 1391
    },
    {
      "epoch": 14.85,
      "learning_rate": 2.5628034165234045e-07,
      "loss": 0.0027,
      "step": 1392
    },
    {
      "epoch": 14.86,
      "learning_rate": 2.553350167757925e-07,
      "loss": 0.0021,
      "step": 1393
    },
    {
      "epoch": 14.87,
      "learning_rate": 2.5439084041085023e-07,
      "loss": 0.0002,
      "step": 1394
    },
    {
      "epoch": 14.88,
      "learning_rate": 2.534478169896864e-07,
      "loss": 0.0231,
      "step": 1395
    },
    {
      "epoch": 14.89,
      "learning_rate": 2.525059509390616e-07,
      "loss": 0.0002,
      "step": 1396
    },
    {
      "epoch": 14.9,
      "learning_rate": 2.5156524668030397e-07,
      "loss": 0.0019,
      "step": 1397
    },
    {
      "epoch": 14.91,
      "learning_rate": 2.5062570862928715e-07,
      "loss": 0.0372,
      "step": 1398
    },
    {
      "epoch": 14.92,
      "learning_rate": 2.4968734119641127e-07,
      "loss": 0.0955,
      "step": 1399
    },
    {
      "epoch": 14.93,
      "learning_rate": 2.4875014878658064e-07,
      "loss": 0.0024,
      "step": 1400
    },
    {
      "epoch": 14.94,
      "learning_rate": 2.478141357991838e-07,
      "loss": 0.0018,
      "step": 1401
    },
    {
      "epoch": 14.95,
      "learning_rate": 2.46879306628073e-07,
      "loss": 0.0008,
      "step": 1402
    },
    {
      "epoch": 14.97,
      "learning_rate": 2.459456656615436e-07,
      "loss": 0.0002,
      "step": 1403
    },
    {
      "epoch": 14.98,
      "learning_rate": 2.450132172823126e-07,
      "loss": 0.0964,
      "step": 1404
    },
    {
      "epoch": 14.99,
      "learning_rate": 2.440819658674996e-07,
      "loss": 0.0198,
      "step": 1405
    },
    {
      "epoch": 15.0,
      "learning_rate": 2.431519157886049e-07,
      "loss": 0.082,
      "step": 1406
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.011542873457074165,
      "eval_runtime": 12.2415,
      "eval_samples_per_second": 61.267,
      "eval_steps_per_second": 15.358,
      "eval_wer": 0.004453441295546558,
      "step": 1406
    },
    {
      "epoch": 15.01,
      "learning_rate": 2.4222307141148906e-07,
      "loss": 0.0003,
      "step": 1407
    },
    {
      "epoch": 15.02,
      "learning_rate": 2.4129543709635374e-07,
      "loss": 0.0002,
      "step": 1408
    },
    {
      "epoch": 15.03,
      "learning_rate": 2.403690171977197e-07,
      "loss": 0.0327,
      "step": 1409
    },
    {
      "epoch": 15.04,
      "learning_rate": 2.39443816064407e-07,
      "loss": 0.0003,
      "step": 1410
    },
    {
      "epoch": 15.05,
      "learning_rate": 2.3851983803951445e-07,
      "loss": 0.013,
      "step": 1411
    },
    {
      "epoch": 15.06,
      "learning_rate": 2.3759708746039976e-07,
      "loss": 0.0158,
      "step": 1412
    },
    {
      "epoch": 15.07,
      "learning_rate": 2.3667556865865824e-07,
      "loss": 0.0002,
      "step": 1413
    },
    {
      "epoch": 15.08,
      "learning_rate": 2.3575528596010352e-07,
      "loss": 0.0017,
      "step": 1414
    },
    {
      "epoch": 15.09,
      "learning_rate": 2.3483624368474613e-07,
      "loss": 0.0015,
      "step": 1415
    },
    {
      "epoch": 15.1,
      "learning_rate": 2.3391844614677386e-07,
      "loss": 0.0457,
      "step": 1416
    },
    {
      "epoch": 15.11,
      "learning_rate": 2.3300189765453193e-07,
      "loss": 0.0004,
      "step": 1417
    },
    {
      "epoch": 15.13,
      "learning_rate": 2.3208660251050156e-07,
      "loss": 0.0004,
      "step": 1418
    },
    {
      "epoch": 15.14,
      "learning_rate": 2.3117256501128135e-07,
      "loss": 0.0142,
      "step": 1419
    },
    {
      "epoch": 15.15,
      "learning_rate": 2.3025978944756496e-07,
      "loss": 0.0003,
      "step": 1420
    },
    {
      "epoch": 15.16,
      "learning_rate": 2.293482801041236e-07,
      "loss": 0.0057,
      "step": 1421
    },
    {
      "epoch": 15.17,
      "learning_rate": 2.2843804125978356e-07,
      "loss": 0.0072,
      "step": 1422
    },
    {
      "epoch": 15.18,
      "learning_rate": 2.2752907718740804e-07,
      "loss": 0.004,
      "step": 1423
    },
    {
      "epoch": 15.19,
      "learning_rate": 2.2662139215387494e-07,
      "loss": 0.0962,
      "step": 1424
    },
    {
      "epoch": 15.2,
      "learning_rate": 2.257149904200592e-07,
      "loss": 0.0021,
      "step": 1425
    },
    {
      "epoch": 15.21,
      "learning_rate": 2.2480987624081143e-07,
      "loss": 0.0319,
      "step": 1426
    },
    {
      "epoch": 15.22,
      "learning_rate": 2.2390605386493756e-07,
      "loss": 0.0568,
      "step": 1427
    },
    {
      "epoch": 15.23,
      "learning_rate": 2.230035275351806e-07,
      "loss": 0.0264,
      "step": 1428
    },
    {
      "epoch": 15.24,
      "learning_rate": 2.221023014881982e-07,
      "loss": 0.0284,
      "step": 1429
    },
    {
      "epoch": 15.25,
      "learning_rate": 2.2120237995454549e-07,
      "loss": 0.0003,
      "step": 1430
    },
    {
      "epoch": 15.26,
      "learning_rate": 2.2030376715865312e-07,
      "loss": 0.0008,
      "step": 1431
    },
    {
      "epoch": 15.27,
      "learning_rate": 2.1940646731880885e-07,
      "loss": 0.0002,
      "step": 1432
    },
    {
      "epoch": 15.29,
      "learning_rate": 2.185104846471366e-07,
      "loss": 0.0002,
      "step": 1433
    },
    {
      "epoch": 15.3,
      "learning_rate": 2.1761582334957746e-07,
      "loss": 0.0542,
      "step": 1434
    },
    {
      "epoch": 15.31,
      "learning_rate": 2.167224876258695e-07,
      "loss": 0.0011,
      "step": 1435
    },
    {
      "epoch": 15.32,
      "learning_rate": 2.1583048166952872e-07,
      "loss": 0.0026,
      "step": 1436
    },
    {
      "epoch": 15.33,
      "learning_rate": 2.1493980966782826e-07,
      "loss": 0.014,
      "step": 1437
    },
    {
      "epoch": 15.34,
      "learning_rate": 2.140504758017801e-07,
      "loss": 0.0002,
      "step": 1438
    },
    {
      "epoch": 15.35,
      "learning_rate": 2.1316248424611405e-07,
      "loss": 0.0331,
      "step": 1439
    },
    {
      "epoch": 15.36,
      "learning_rate": 2.12275839169259e-07,
      "loss": 0.0012,
      "step": 1440
    },
    {
      "epoch": 15.37,
      "learning_rate": 2.1139054473332357e-07,
      "loss": 0.0642,
      "step": 1441
    },
    {
      "epoch": 15.38,
      "learning_rate": 2.1050660509407576e-07,
      "loss": 0.0059,
      "step": 1442
    },
    {
      "epoch": 15.39,
      "learning_rate": 2.0962402440092386e-07,
      "loss": 0.0284,
      "step": 1443
    },
    {
      "epoch": 15.4,
      "learning_rate": 2.0874280679689698e-07,
      "loss": 0.0002,
      "step": 1444
    },
    {
      "epoch": 15.41,
      "learning_rate": 2.07862956418626e-07,
      "loss": 0.0002,
      "step": 1445
    },
    {
      "epoch": 15.42,
      "learning_rate": 2.0698447739632302e-07,
      "loss": 0.002,
      "step": 1446
    },
    {
      "epoch": 15.43,
      "learning_rate": 2.0610737385376348e-07,
      "loss": 0.0077,
      "step": 1447
    },
    {
      "epoch": 15.45,
      "learning_rate": 2.0523164990826543e-07,
      "loss": 0.0432,
      "step": 1448
    },
    {
      "epoch": 15.46,
      "learning_rate": 2.0435730967067078e-07,
      "loss": 0.0414,
      "step": 1449
    },
    {
      "epoch": 15.47,
      "learning_rate": 2.034843572453266e-07,
      "loss": 0.0005,
      "step": 1450
    },
    {
      "epoch": 15.48,
      "learning_rate": 2.026127967300645e-07,
      "loss": 0.0498,
      "step": 1451
    },
    {
      "epoch": 15.49,
      "learning_rate": 2.0174263221618303e-07,
      "loss": 0.0177,
      "step": 1452
    },
    {
      "epoch": 15.5,
      "learning_rate": 2.0087386778842642e-07,
      "loss": 0.0062,
      "step": 1453
    },
    {
      "epoch": 15.51,
      "learning_rate": 2.0000650752496774e-07,
      "loss": 0.0255,
      "step": 1454
    },
    {
      "epoch": 15.52,
      "learning_rate": 1.9914055549738772e-07,
      "loss": 0.0578,
      "step": 1455
    },
    {
      "epoch": 15.53,
      "learning_rate": 1.9827601577065744e-07,
      "loss": 0.0112,
      "step": 1456
    },
    {
      "epoch": 15.54,
      "learning_rate": 1.9741289240311754e-07,
      "loss": 0.0512,
      "step": 1457
    },
    {
      "epoch": 15.55,
      "learning_rate": 1.9655118944646e-07,
      "loss": 0.0009,
      "step": 1458
    },
    {
      "epoch": 15.56,
      "learning_rate": 1.9569091094570966e-07,
      "loss": 0.0002,
      "step": 1459
    },
    {
      "epoch": 15.57,
      "learning_rate": 1.9483206093920402e-07,
      "loss": 0.0024,
      "step": 1460
    },
    {
      "epoch": 15.58,
      "learning_rate": 1.939746434585756e-07,
      "loss": 0.0654,
      "step": 1461
    },
    {
      "epoch": 15.59,
      "learning_rate": 1.9311866252873127e-07,
      "loss": 0.0004,
      "step": 1462
    },
    {
      "epoch": 15.61,
      "learning_rate": 1.9226412216783555e-07,
      "loss": 0.0236,
      "step": 1463
    },
    {
      "epoch": 15.62,
      "learning_rate": 1.9141102638728978e-07,
      "loss": 0.0469,
      "step": 1464
    },
    {
      "epoch": 15.63,
      "learning_rate": 1.9055937919171477e-07,
      "loss": 0.0002,
      "step": 1465
    },
    {
      "epoch": 15.64,
      "learning_rate": 1.8970918457893087e-07,
      "loss": 0.024,
      "step": 1466
    },
    {
      "epoch": 15.65,
      "learning_rate": 1.8886044653993966e-07,
      "loss": 0.0002,
      "step": 1467
    },
    {
      "epoch": 15.66,
      "learning_rate": 1.880131690589058e-07,
      "loss": 0.1296,
      "step": 1468
    },
    {
      "epoch": 15.67,
      "learning_rate": 1.8716735611313704e-07,
      "loss": 0.0395,
      "step": 1469
    },
    {
      "epoch": 15.68,
      "learning_rate": 1.8632301167306692e-07,
      "loss": 0.0003,
      "step": 1470
    },
    {
      "epoch": 15.69,
      "learning_rate": 1.854801397022351e-07,
      "loss": 0.0055,
      "step": 1471
    },
    {
      "epoch": 15.7,
      "learning_rate": 1.8463874415726915e-07,
      "loss": 0.0558,
      "step": 1472
    },
    {
      "epoch": 15.71,
      "learning_rate": 1.8379882898786602e-07,
      "loss": 0.0023,
      "step": 1473
    },
    {
      "epoch": 15.72,
      "learning_rate": 1.8296039813677372e-07,
      "loss": 0.0103,
      "step": 1474
    },
    {
      "epoch": 15.73,
      "learning_rate": 1.821234555397722e-07,
      "loss": 0.0196,
      "step": 1475
    },
    {
      "epoch": 15.74,
      "learning_rate": 1.812880051256551e-07,
      "loss": 0.021,
      "step": 1476
    },
    {
      "epoch": 15.75,
      "learning_rate": 1.8045405081621212e-07,
      "loss": 0.0215,
      "step": 1477
    },
    {
      "epoch": 15.77,
      "learning_rate": 1.7962159652620896e-07,
      "loss": 0.0002,
      "step": 1478
    },
    {
      "epoch": 15.78,
      "learning_rate": 1.7879064616337075e-07,
      "loss": 0.0002,
      "step": 1479
    },
    {
      "epoch": 15.79,
      "learning_rate": 1.7796120362836238e-07,
      "loss": 0.0006,
      "step": 1480
    },
    {
      "epoch": 15.8,
      "learning_rate": 1.7713327281477074e-07,
      "loss": 0.0226,
      "step": 1481
    },
    {
      "epoch": 15.81,
      "learning_rate": 1.763068576090862e-07,
      "loss": 0.0002,
      "step": 1482
    },
    {
      "epoch": 15.82,
      "learning_rate": 1.7548196189068503e-07,
      "loss": 0.0446,
      "step": 1483
    },
    {
      "epoch": 15.83,
      "learning_rate": 1.746585895318101e-07,
      "loss": 0.0007,
      "step": 1484
    },
    {
      "epoch": 15.84,
      "learning_rate": 1.738367443975539e-07,
      "loss": 0.0003,
      "step": 1485
    },
    {
      "epoch": 15.85,
      "learning_rate": 1.7301643034583936e-07,
      "loss": 0.0343,
      "step": 1486
    },
    {
      "epoch": 15.86,
      "learning_rate": 1.7219765122740198e-07,
      "loss": 0.0208,
      "step": 1487
    },
    {
      "epoch": 15.87,
      "learning_rate": 1.7138041088577266e-07,
      "loss": 0.0004,
      "step": 1488
    },
    {
      "epoch": 15.88,
      "learning_rate": 1.705647131572583e-07,
      "loss": 0.0129,
      "step": 1489
    },
    {
      "epoch": 15.89,
      "learning_rate": 1.6975056187092467e-07,
      "loss": 0.0053,
      "step": 1490
    },
    {
      "epoch": 15.9,
      "learning_rate": 1.6893796084857803e-07,
      "loss": 0.0479,
      "step": 1491
    },
    {
      "epoch": 15.91,
      "learning_rate": 1.6812691390474788e-07,
      "loss": 0.0071,
      "step": 1492
    },
    {
      "epoch": 15.93,
      "learning_rate": 1.673174248466677e-07,
      "loss": 0.0113,
      "step": 1493
    },
    {
      "epoch": 15.94,
      "learning_rate": 1.665094974742588e-07,
      "loss": 0.003,
      "step": 1494
    },
    {
      "epoch": 15.95,
      "learning_rate": 1.6570313558011095e-07,
      "loss": 0.0002,
      "step": 1495
    },
    {
      "epoch": 15.96,
      "learning_rate": 1.648983429494653e-07,
      "loss": 0.0252,
      "step": 1496
    },
    {
      "epoch": 15.97,
      "learning_rate": 1.6409512336019699e-07,
      "loss": 0.0018,
      "step": 1497
    },
    {
      "epoch": 15.98,
      "learning_rate": 1.6329348058279623e-07,
      "loss": 0.0131,
      "step": 1498
    },
    {
      "epoch": 15.99,
      "learning_rate": 1.624934183803523e-07,
      "loss": 0.0002,
      "step": 1499
    },
    {
      "epoch": 16.0,
      "learning_rate": 1.616949405085336e-07,
      "loss": 0.0558,
      "step": 1500
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.019238872453570366,
      "eval_runtime": 12.5953,
      "eval_samples_per_second": 59.546,
      "eval_steps_per_second": 14.926,
      "eval_wer": 0.005802968960863698,
      "step": 1500
    },
    {
      "epoch": 16.01,
      "learning_rate": 1.6089805071557255e-07,
      "loss": 0.0067,
      "step": 1501
    },
    {
      "epoch": 16.02,
      "learning_rate": 1.6010275274224604e-07,
      "loss": 0.0003,
      "step": 1502
    },
    {
      "epoch": 16.03,
      "learning_rate": 1.5930905032185908e-07,
      "loss": 0.0002,
      "step": 1503
    },
    {
      "epoch": 16.04,
      "learning_rate": 1.5851694718022652e-07,
      "loss": 0.0003,
      "step": 1504
    },
    {
      "epoch": 16.05,
      "learning_rate": 1.5772644703565564e-07,
      "loss": 0.0002,
      "step": 1505
    },
    {
      "epoch": 16.06,
      "learning_rate": 1.5693755359892952e-07,
      "loss": 0.0002,
      "step": 1506
    },
    {
      "epoch": 16.07,
      "learning_rate": 1.561502705732883e-07,
      "loss": 0.0009,
      "step": 1507
    },
    {
      "epoch": 16.09,
      "learning_rate": 1.5536460165441323e-07,
      "loss": 0.0481,
      "step": 1508
    },
    {
      "epoch": 16.1,
      "learning_rate": 1.545805505304077e-07,
      "loss": 0.0002,
      "step": 1509
    },
    {
      "epoch": 16.11,
      "learning_rate": 1.5379812088178168e-07,
      "loss": 0.0141,
      "step": 1510
    },
    {
      "epoch": 16.12,
      "learning_rate": 1.5301731638143284e-07,
      "loss": 0.0015,
      "step": 1511
    },
    {
      "epoch": 16.13,
      "learning_rate": 1.5223814069463075e-07,
      "loss": 0.0004,
      "step": 1512
    },
    {
      "epoch": 16.14,
      "learning_rate": 1.5146059747899848e-07,
      "loss": 0.0002,
      "step": 1513
    },
    {
      "epoch": 16.15,
      "learning_rate": 1.5068469038449583e-07,
      "loss": 0.0285,
      "step": 1514
    },
    {
      "epoch": 16.16,
      "learning_rate": 1.4991042305340286e-07,
      "loss": 0.0108,
      "step": 1515
    },
    {
      "epoch": 16.17,
      "learning_rate": 1.4913779912030156e-07,
      "loss": 0.0099,
      "step": 1516
    },
    {
      "epoch": 16.18,
      "learning_rate": 1.4836682221205998e-07,
      "loss": 0.0406,
      "step": 1517
    },
    {
      "epoch": 16.19,
      "learning_rate": 1.475974959478144e-07,
      "loss": 0.0009,
      "step": 1518
    },
    {
      "epoch": 16.2,
      "learning_rate": 1.4682982393895256e-07,
      "loss": 0.0015,
      "step": 1519
    },
    {
      "epoch": 16.21,
      "learning_rate": 1.460638097890967e-07,
      "loss": 0.0045,
      "step": 1520
    },
    {
      "epoch": 16.22,
      "learning_rate": 1.4529945709408725e-07,
      "loss": 0.0094,
      "step": 1521
    },
    {
      "epoch": 16.23,
      "learning_rate": 1.4453676944196475e-07,
      "loss": 0.0863,
      "step": 1522
    },
    {
      "epoch": 16.25,
      "learning_rate": 1.4377575041295392e-07,
      "loss": 0.0008,
      "step": 1523
    },
    {
      "epoch": 16.26,
      "learning_rate": 1.430164035794465e-07,
      "loss": 0.0476,
      "step": 1524
    },
    {
      "epoch": 16.27,
      "learning_rate": 1.4225873250598496e-07,
      "loss": 0.0002,
      "step": 1525
    },
    {
      "epoch": 16.28,
      "learning_rate": 1.4150274074924474e-07,
      "loss": 0.0126,
      "step": 1526
    },
    {
      "epoch": 16.29,
      "learning_rate": 1.4074843185801882e-07,
      "loss": 0.0168,
      "step": 1527
    },
    {
      "epoch": 16.3,
      "learning_rate": 1.399958093732001e-07,
      "loss": 0.0002,
      "step": 1528
    },
    {
      "epoch": 16.31,
      "learning_rate": 1.3924487682776493e-07,
      "loss": 0.0175,
      "step": 1529
    },
    {
      "epoch": 16.32,
      "learning_rate": 1.3849563774675727e-07,
      "loss": 0.0002,
      "step": 1530
    },
    {
      "epoch": 16.33,
      "learning_rate": 1.3774809564727102e-07,
      "loss": 0.0002,
      "step": 1531
    },
    {
      "epoch": 16.34,
      "learning_rate": 1.370022540384347e-07,
      "loss": 0.0002,
      "step": 1532
    },
    {
      "epoch": 16.35,
      "learning_rate": 1.362581164213934e-07,
      "loss": 0.0163,
      "step": 1533
    },
    {
      "epoch": 16.36,
      "learning_rate": 1.3551568628929432e-07,
      "loss": 0.0501,
      "step": 1534
    },
    {
      "epoch": 16.37,
      "learning_rate": 1.347749671272686e-07,
      "loss": 0.0063,
      "step": 1535
    },
    {
      "epoch": 16.38,
      "learning_rate": 1.340359624124162e-07,
      "loss": 0.0587,
      "step": 1536
    },
    {
      "epoch": 16.39,
      "learning_rate": 1.332986756137889e-07,
      "loss": 0.082,
      "step": 1537
    },
    {
      "epoch": 16.41,
      "learning_rate": 1.3256311019237388e-07,
      "loss": 0.0882,
      "step": 1538
    },
    {
      "epoch": 16.42,
      "learning_rate": 1.3182926960107849e-07,
      "loss": 0.0096,
      "step": 1539
    },
    {
      "epoch": 16.43,
      "learning_rate": 1.3109715728471267e-07,
      "loss": 0.002,
      "step": 1540
    },
    {
      "epoch": 16.44,
      "learning_rate": 1.303667766799741e-07,
      "loss": 0.0017,
      "step": 1541
    },
    {
      "epoch": 16.45,
      "learning_rate": 1.2963813121543048e-07,
      "loss": 0.0357,
      "step": 1542
    },
    {
      "epoch": 16.46,
      "learning_rate": 1.2891122431150547e-07,
      "loss": 0.0004,
      "step": 1543
    },
    {
      "epoch": 16.47,
      "learning_rate": 1.2818605938046069e-07,
      "loss": 0.0003,
      "step": 1544
    },
    {
      "epoch": 16.48,
      "learning_rate": 1.2746263982638122e-07,
      "loss": 0.0004,
      "step": 1545
    },
    {
      "epoch": 16.49,
      "learning_rate": 1.2674096904515845e-07,
      "loss": 0.0604,
      "step": 1546
    },
    {
      "epoch": 16.5,
      "learning_rate": 1.260210504244747e-07,
      "loss": 0.0003,
      "step": 1547
    },
    {
      "epoch": 16.51,
      "learning_rate": 1.2530288734378763e-07,
      "loss": 0.0002,
      "step": 1548
    },
    {
      "epoch": 16.52,
      "learning_rate": 1.2458648317431348e-07,
      "loss": 0.0149,
      "step": 1549
    },
    {
      "epoch": 16.53,
      "learning_rate": 1.238718412790124e-07,
      "loss": 0.0223,
      "step": 1550
    },
    {
      "epoch": 16.54,
      "learning_rate": 1.2315896501257145e-07,
      "loss": 0.0002,
      "step": 1551
    },
    {
      "epoch": 16.55,
      "learning_rate": 1.2244785772138971e-07,
      "loss": 0.0002,
      "step": 1552
    },
    {
      "epoch": 16.57,
      "learning_rate": 1.2173852274356217e-07,
      "loss": 0.0002,
      "step": 1553
    },
    {
      "epoch": 16.58,
      "learning_rate": 1.210309634088645e-07,
      "loss": 0.0003,
      "step": 1554
    },
    {
      "epoch": 16.59,
      "learning_rate": 1.2032518303873674e-07,
      "loss": 0.0004,
      "step": 1555
    },
    {
      "epoch": 16.6,
      "learning_rate": 1.1962118494626811e-07,
      "loss": 0.0002,
      "step": 1556
    },
    {
      "epoch": 16.61,
      "learning_rate": 1.1891897243618183e-07,
      "loss": 0.0333,
      "step": 1557
    },
    {
      "epoch": 16.62,
      "learning_rate": 1.1821854880481857e-07,
      "loss": 0.0066,
      "step": 1558
    },
    {
      "epoch": 16.63,
      "learning_rate": 1.1751991734012228e-07,
      "loss": 0.0073,
      "step": 1559
    },
    {
      "epoch": 16.64,
      "learning_rate": 1.168230813216236e-07,
      "loss": 0.0586,
      "step": 1560
    },
    {
      "epoch": 16.65,
      "learning_rate": 1.1612804402042508e-07,
      "loss": 0.0004,
      "step": 1561
    },
    {
      "epoch": 16.66,
      "learning_rate": 1.1543480869918554e-07,
      "loss": 0.0344,
      "step": 1562
    },
    {
      "epoch": 16.67,
      "learning_rate": 1.1474337861210543e-07,
      "loss": 0.0385,
      "step": 1563
    },
    {
      "epoch": 16.68,
      "learning_rate": 1.1405375700491038e-07,
      "loss": 0.0789,
      "step": 1564
    },
    {
      "epoch": 16.69,
      "learning_rate": 1.133659471148371e-07,
      "loss": 0.0493,
      "step": 1565
    },
    {
      "epoch": 16.7,
      "learning_rate": 1.1267995217061749e-07,
      "loss": 0.0668,
      "step": 1566
    },
    {
      "epoch": 16.71,
      "learning_rate": 1.1199577539246346e-07,
      "loss": 0.0014,
      "step": 1567
    },
    {
      "epoch": 16.73,
      "learning_rate": 1.1131341999205274e-07,
      "loss": 0.0002,
      "step": 1568
    },
    {
      "epoch": 16.74,
      "learning_rate": 1.1063288917251234e-07,
      "loss": 0.0002,
      "step": 1569
    },
    {
      "epoch": 16.75,
      "learning_rate": 1.0995418612840473e-07,
      "loss": 0.0003,
      "step": 1570
    },
    {
      "epoch": 16.76,
      "learning_rate": 1.0927731404571211e-07,
      "loss": 0.0002,
      "step": 1571
    },
    {
      "epoch": 16.77,
      "learning_rate": 1.086022761018222e-07,
      "loss": 0.0005,
      "step": 1572
    },
    {
      "epoch": 16.78,
      "learning_rate": 1.0792907546551228e-07,
      "loss": 0.1182,
      "step": 1573
    },
    {
      "epoch": 16.79,
      "learning_rate": 1.0725771529693545e-07,
      "loss": 0.0003,
      "step": 1574
    },
    {
      "epoch": 16.8,
      "learning_rate": 1.0658819874760494e-07,
      "loss": 0.0006,
      "step": 1575
    },
    {
      "epoch": 16.81,
      "learning_rate": 1.0592052896037945e-07,
      "loss": 0.0012,
      "step": 1576
    },
    {
      "epoch": 16.82,
      "learning_rate": 1.0525470906944916e-07,
      "loss": 0.0002,
      "step": 1577
    },
    {
      "epoch": 16.83,
      "learning_rate": 1.0459074220031971e-07,
      "loss": 0.0341,
      "step": 1578
    },
    {
      "epoch": 16.84,
      "learning_rate": 1.0392863146979902e-07,
      "loss": 0.0014,
      "step": 1579
    },
    {
      "epoch": 16.85,
      "learning_rate": 1.0326837998598103e-07,
      "loss": 0.0103,
      "step": 1580
    },
    {
      "epoch": 16.86,
      "learning_rate": 1.0260999084823263e-07,
      "loss": 0.0003,
      "step": 1581
    },
    {
      "epoch": 16.87,
      "learning_rate": 1.0195346714717812e-07,
      "loss": 0.011,
      "step": 1582
    },
    {
      "epoch": 16.89,
      "learning_rate": 1.0129881196468526e-07,
      "loss": 0.0002,
      "step": 1583
    },
    {
      "epoch": 16.9,
      "learning_rate": 1.0064602837385034e-07,
      "loss": 0.0004,
      "step": 1584
    },
    {
      "epoch": 16.91,
      "learning_rate": 9.999511943898398e-08,
      "loss": 0.0407,
      "step": 1585
    },
    {
      "epoch": 16.92,
      "learning_rate": 9.934608821559704e-08,
      "loss": 0.0598,
      "step": 1586
    },
    {
      "epoch": 16.93,
      "learning_rate": 9.869893775038557e-08,
      "loss": 0.0206,
      "step": 1587
    },
    {
      "epoch": 16.94,
      "learning_rate": 9.805367108121759e-08,
      "loss": 0.0161,
      "step": 1588
    },
    {
      "epoch": 16.95,
      "learning_rate": 9.741029123711709e-08,
      "loss": 0.0701,
      "step": 1589
    },
    {
      "epoch": 16.96,
      "learning_rate": 9.676880123825199e-08,
      "loss": 0.0019,
      "step": 1590
    },
    {
      "epoch": 16.97,
      "learning_rate": 9.612920409591813e-08,
      "loss": 0.0002,
      "step": 1591
    },
    {
      "epoch": 16.98,
      "learning_rate": 9.549150281252632e-08,
      "loss": 0.0116,
      "step": 1592
    },
    {
      "epoch": 16.99,
      "learning_rate": 9.485570038158747e-08,
      "loss": 0.0169,
      "step": 1593
    },
    {
      "epoch": 16.99,
      "eval_loss": 0.011339528486132622,
      "eval_runtime": 12.3567,
      "eval_samples_per_second": 60.696,
      "eval_steps_per_second": 15.214,
      "eval_wer": 0.0035087719298245615,
      "step": 1593
    },
    {
      "epoch": 17.0,
      "learning_rate": 9.422179978769889e-08,
      "loss": 0.0004,
      "step": 1594
    },
    {
      "epoch": 17.01,
      "learning_rate": 9.358980400653049e-08,
      "loss": 0.018,
      "step": 1595
    },
    {
      "epoch": 17.02,
      "learning_rate": 9.295971600481028e-08,
      "loss": 0.0141,
      "step": 1596
    },
    {
      "epoch": 17.03,
      "learning_rate": 9.233153874031102e-08,
      "loss": 0.0003,
      "step": 1597
    },
    {
      "epoch": 17.05,
      "learning_rate": 9.170527516183573e-08,
      "loss": 0.0058,
      "step": 1598
    },
    {
      "epoch": 17.06,
      "learning_rate": 9.108092820920438e-08,
      "loss": 0.0067,
      "step": 1599
    },
    {
      "epoch": 17.07,
      "learning_rate": 9.04585008132397e-08,
      "loss": 0.0007,
      "step": 1600
    },
    {
      "epoch": 17.08,
      "learning_rate": 8.983799589575392e-08,
      "loss": 0.0003,
      "step": 1601
    },
    {
      "epoch": 17.09,
      "learning_rate": 8.921941636953434e-08,
      "loss": 0.0073,
      "step": 1602
    },
    {
      "epoch": 17.1,
      "learning_rate": 8.86027651383302e-08,
      "loss": 0.0008,
      "step": 1603
    },
    {
      "epoch": 17.11,
      "learning_rate": 8.79880450968391e-08,
      "loss": 0.0003,
      "step": 1604
    },
    {
      "epoch": 17.12,
      "learning_rate": 8.737525913069276e-08,
      "loss": 0.0559,
      "step": 1605
    },
    {
      "epoch": 17.13,
      "learning_rate": 8.676441011644453e-08,
      "loss": 0.0002,
      "step": 1606
    },
    {
      "epoch": 17.14,
      "learning_rate": 8.615550092155477e-08,
      "loss": 0.0002,
      "step": 1607
    },
    {
      "epoch": 17.15,
      "learning_rate": 8.554853440437804e-08,
      "loss": 0.0043,
      "step": 1608
    },
    {
      "epoch": 17.16,
      "learning_rate": 8.494351341414946e-08,
      "loss": 0.017,
      "step": 1609
    },
    {
      "epoch": 17.17,
      "learning_rate": 8.434044079097175e-08,
      "loss": 0.0826,
      "step": 1610
    },
    {
      "epoch": 17.18,
      "learning_rate": 8.373931936580114e-08,
      "loss": 0.0576,
      "step": 1611
    },
    {
      "epoch": 17.19,
      "learning_rate": 8.3140151960435e-08,
      "loss": 0.0059,
      "step": 1612
    },
    {
      "epoch": 17.21,
      "learning_rate": 8.25429413874974e-08,
      "loss": 0.0128,
      "step": 1613
    },
    {
      "epoch": 17.22,
      "learning_rate": 8.194769045042732e-08,
      "loss": 0.0263,
      "step": 1614
    },
    {
      "epoch": 17.23,
      "learning_rate": 8.135440194346415e-08,
      "loss": 0.0002,
      "step": 1615
    },
    {
      "epoch": 17.24,
      "learning_rate": 8.076307865163579e-08,
      "loss": 0.0319,
      "step": 1616
    },
    {
      "epoch": 17.25,
      "learning_rate": 8.017372335074484e-08,
      "loss": 0.0467,
      "step": 1617
    },
    {
      "epoch": 17.26,
      "learning_rate": 7.958633880735511e-08,
      "loss": 0.0002,
      "step": 1618
    },
    {
      "epoch": 17.27,
      "learning_rate": 7.900092777878003e-08,
      "loss": 0.0599,
      "step": 1619
    },
    {
      "epoch": 17.28,
      "learning_rate": 7.841749301306844e-08,
      "loss": 0.0003,
      "step": 1620
    },
    {
      "epoch": 17.29,
      "learning_rate": 7.783603724899257e-08,
      "loss": 0.0055,
      "step": 1621
    },
    {
      "epoch": 17.3,
      "learning_rate": 7.725656321603413e-08,
      "loss": 0.0574,
      "step": 1622
    },
    {
      "epoch": 17.31,
      "learning_rate": 7.667907363437287e-08,
      "loss": 0.0224,
      "step": 1623
    },
    {
      "epoch": 17.32,
      "learning_rate": 7.610357121487254e-08,
      "loss": 0.0009,
      "step": 1624
    },
    {
      "epoch": 17.33,
      "learning_rate": 7.553005865906914e-08,
      "loss": 0.0003,
      "step": 1625
    },
    {
      "epoch": 17.34,
      "learning_rate": 7.495853865915746e-08,
      "loss": 0.0296,
      "step": 1626
    },
    {
      "epoch": 17.35,
      "learning_rate": 7.43890138979788e-08,
      "loss": 0.0431,
      "step": 1627
    },
    {
      "epoch": 17.37,
      "learning_rate": 7.382148704900881e-08,
      "loss": 0.0018,
      "step": 1628
    },
    {
      "epoch": 17.38,
      "learning_rate": 7.325596077634383e-08,
      "loss": 0.057,
      "step": 1629
    },
    {
      "epoch": 17.39,
      "learning_rate": 7.269243773468975e-08,
      "loss": 0.0219,
      "step": 1630
    },
    {
      "epoch": 17.4,
      "learning_rate": 7.213092056934834e-08,
      "loss": 0.0002,
      "step": 1631
    },
    {
      "epoch": 17.41,
      "learning_rate": 7.157141191620548e-08,
      "loss": 0.028,
      "step": 1632
    },
    {
      "epoch": 17.42,
      "learning_rate": 7.101391440171855e-08,
      "loss": 0.0052,
      "step": 1633
    },
    {
      "epoch": 17.43,
      "learning_rate": 7.045843064290463e-08,
      "loss": 0.0955,
      "step": 1634
    },
    {
      "epoch": 17.44,
      "learning_rate": 6.990496324732736e-08,
      "loss": 0.0187,
      "step": 1635
    },
    {
      "epoch": 17.45,
      "learning_rate": 6.935351481308504e-08,
      "loss": 0.0032,
      "step": 1636
    },
    {
      "epoch": 17.46,
      "learning_rate": 6.880408792879905e-08,
      "loss": 0.0313,
      "step": 1637
    },
    {
      "epoch": 17.47,
      "learning_rate": 6.825668517360056e-08,
      "loss": 0.0232,
      "step": 1638
    },
    {
      "epoch": 17.48,
      "learning_rate": 6.771130911711954e-08,
      "loss": 0.0273,
      "step": 1639
    },
    {
      "epoch": 17.49,
      "learning_rate": 6.716796231947186e-08,
      "loss": 0.0367,
      "step": 1640
    },
    {
      "epoch": 17.5,
      "learning_rate": 6.662664733124767e-08,
      "loss": 0.0005,
      "step": 1641
    },
    {
      "epoch": 17.51,
      "learning_rate": 6.60873666934993e-08,
      "loss": 0.0044,
      "step": 1642
    },
    {
      "epoch": 17.53,
      "learning_rate": 6.555012293772966e-08,
      "loss": 0.0002,
      "step": 1643
    },
    {
      "epoch": 17.54,
      "learning_rate": 6.501491858587977e-08,
      "loss": 0.0017,
      "step": 1644
    },
    {
      "epoch": 17.55,
      "learning_rate": 6.448175615031748e-08,
      "loss": 0.0002,
      "step": 1645
    },
    {
      "epoch": 17.56,
      "learning_rate": 6.395063813382524e-08,
      "loss": 0.0002,
      "step": 1646
    },
    {
      "epoch": 17.57,
      "learning_rate": 6.34215670295885e-08,
      "loss": 0.0009,
      "step": 1647
    },
    {
      "epoch": 17.58,
      "learning_rate": 6.289454532118444e-08,
      "loss": 0.0002,
      "step": 1648
    },
    {
      "epoch": 17.59,
      "learning_rate": 6.236957548256944e-08,
      "loss": 0.0136,
      "step": 1649
    },
    {
      "epoch": 17.6,
      "learning_rate": 6.184665997806831e-08,
      "loss": 0.0168,
      "step": 1650
    },
    {
      "epoch": 17.61,
      "learning_rate": 6.132580126236198e-08,
      "loss": 0.0837,
      "step": 1651
    },
    {
      "epoch": 17.62,
      "learning_rate": 6.080700178047687e-08,
      "loss": 0.0003,
      "step": 1652
    },
    {
      "epoch": 17.63,
      "learning_rate": 6.029026396777237e-08,
      "loss": 0.0002,
      "step": 1653
    },
    {
      "epoch": 17.64,
      "learning_rate": 5.977559024993045e-08,
      "loss": 0.023,
      "step": 1654
    },
    {
      "epoch": 17.65,
      "learning_rate": 5.9262983042943357e-08,
      "loss": 0.0027,
      "step": 1655
    },
    {
      "epoch": 17.66,
      "learning_rate": 5.87524447531027e-08,
      "loss": 0.0603,
      "step": 1656
    },
    {
      "epoch": 17.67,
      "learning_rate": 5.824397777698858e-08,
      "loss": 0.0003,
      "step": 1657
    },
    {
      "epoch": 17.69,
      "learning_rate": 5.773758450145721e-08,
      "loss": 0.0002,
      "step": 1658
    },
    {
      "epoch": 17.7,
      "learning_rate": 5.723326730363115e-08,
      "loss": 0.1213,
      "step": 1659
    },
    {
      "epoch": 17.71,
      "learning_rate": 5.6731028550886515e-08,
      "loss": 0.0008,
      "step": 1660
    },
    {
      "epoch": 17.72,
      "learning_rate": 5.6230870600843636e-08,
      "loss": 0.0002,
      "step": 1661
    },
    {
      "epoch": 17.73,
      "learning_rate": 5.573279580135437e-08,
      "loss": 0.0005,
      "step": 1662
    },
    {
      "epoch": 17.74,
      "learning_rate": 5.523680649049234e-08,
      "loss": 0.0332,
      "step": 1663
    },
    {
      "epoch": 17.75,
      "learning_rate": 5.474290499654116e-08,
      "loss": 0.0178,
      "step": 1664
    },
    {
      "epoch": 17.76,
      "learning_rate": 5.425109363798358e-08,
      "loss": 0.0002,
      "step": 1665
    },
    {
      "epoch": 17.77,
      "learning_rate": 5.3761374723491294e-08,
      "loss": 0.0068,
      "step": 1666
    },
    {
      "epoch": 17.78,
      "learning_rate": 5.327375055191313e-08,
      "loss": 0.0085,
      "step": 1667
    },
    {
      "epoch": 17.79,
      "learning_rate": 5.278822341226519e-08,
      "loss": 0.0456,
      "step": 1668
    },
    {
      "epoch": 17.8,
      "learning_rate": 5.230479558371903e-08,
      "loss": 0.0369,
      "step": 1669
    },
    {
      "epoch": 17.81,
      "learning_rate": 5.182346933559212e-08,
      "loss": 0.0664,
      "step": 1670
    },
    {
      "epoch": 17.82,
      "learning_rate": 5.13442469273363e-08,
      "loss": 0.052,
      "step": 1671
    },
    {
      "epoch": 17.83,
      "learning_rate": 5.0867130608527875e-08,
      "loss": 0.0004,
      "step": 1672
    },
    {
      "epoch": 17.85,
      "learning_rate": 5.039212261885634e-08,
      "loss": 0.0002,
      "step": 1673
    },
    {
      "epoch": 17.86,
      "learning_rate": 4.9919225188114365e-08,
      "loss": 0.0414,
      "step": 1674
    },
    {
      "epoch": 17.87,
      "learning_rate": 4.9448440536187296e-08,
      "loss": 0.0195,
      "step": 1675
    },
    {
      "epoch": 17.88,
      "learning_rate": 4.897977087304245e-08,
      "loss": 0.0784,
      "step": 1676
    },
    {
      "epoch": 17.89,
      "learning_rate": 4.851321839871908e-08,
      "loss": 0.0113,
      "step": 1677
    },
    {
      "epoch": 17.9,
      "learning_rate": 4.8048785303317797e-08,
      "loss": 0.0003,
      "step": 1678
    },
    {
      "epoch": 17.91,
      "learning_rate": 4.758647376699032e-08,
      "loss": 0.0122,
      "step": 1679
    },
    {
      "epoch": 17.92,
      "learning_rate": 4.712628595992929e-08,
      "loss": 0.0191,
      "step": 1680
    },
    {
      "epoch": 17.93,
      "learning_rate": 4.6668224042358374e-08,
      "loss": 0.0203,
      "step": 1681
    },
    {
      "epoch": 17.94,
      "learning_rate": 4.621229016452155e-08,
      "loss": 0.0069,
      "step": 1682
    },
    {
      "epoch": 17.95,
      "learning_rate": 4.575848646667324e-08,
      "loss": 0.0163,
      "step": 1683
    },
    {
      "epoch": 17.96,
      "learning_rate": 4.5306815079068806e-08,
      "loss": 0.0108,
      "step": 1684
    },
    {
      "epoch": 17.97,
      "learning_rate": 4.485727812195339e-08,
      "loss": 0.0125,
      "step": 1685
    },
    {
      "epoch": 17.98,
      "learning_rate": 4.440987770555332e-08,
      "loss": 0.0107,
      "step": 1686
    },
    {
      "epoch": 17.99,
      "learning_rate": 4.3964615930065115e-08,
      "loss": 0.0177,
      "step": 1687
    },
    {
      "epoch": 17.99,
      "eval_loss": 0.012349044904112816,
      "eval_runtime": 12.8072,
      "eval_samples_per_second": 58.561,
      "eval_steps_per_second": 14.679,
      "eval_wer": 0.0031039136302294197,
      "step": 1687
    },
    {
      "epoch": 18.01,
      "learning_rate": 4.352149488564605e-08,
      "loss": 0.0009,
      "step": 1688
    },
    {
      "epoch": 18.02,
      "learning_rate": 4.308051665240442e-08,
      "loss": 0.0162,
      "step": 1689
    },
    {
      "epoch": 18.03,
      "learning_rate": 4.2641683300389866e-08,
      "loss": 0.005,
      "step": 1690
    },
    {
      "epoch": 18.04,
      "learning_rate": 4.2204996889583063e-08,
      "loss": 0.0011,
      "step": 1691
    },
    {
      "epoch": 18.05,
      "learning_rate": 4.1770459469887e-08,
      "loss": 0.0005,
      "step": 1692
    },
    {
      "epoch": 18.06,
      "learning_rate": 4.1338073081116364e-08,
      "loss": 0.0031,
      "step": 1693
    },
    {
      "epoch": 18.07,
      "learning_rate": 4.090783975298856e-08,
      "loss": 0.0019,
      "step": 1694
    },
    {
      "epoch": 18.08,
      "learning_rate": 4.047976150511423e-08,
      "loss": 0.0002,
      "step": 1695
    },
    {
      "epoch": 18.09,
      "learning_rate": 4.0053840346987276e-08,
      "loss": 0.0182,
      "step": 1696
    },
    {
      "epoch": 18.1,
      "learning_rate": 3.9630078277976265e-08,
      "loss": 0.0091,
      "step": 1697
    },
    {
      "epoch": 18.11,
      "learning_rate": 3.920847728731375e-08,
      "loss": 0.001,
      "step": 1698
    },
    {
      "epoch": 18.12,
      "learning_rate": 3.878903935408845e-08,
      "loss": 0.014,
      "step": 1699
    },
    {
      "epoch": 18.13,
      "learning_rate": 3.837176644723472e-08,
      "loss": 0.0736,
      "step": 1700
    },
    {
      "epoch": 18.14,
      "learning_rate": 3.795666052552415e-08,
      "loss": 0.0317,
      "step": 1701
    },
    {
      "epoch": 18.15,
      "learning_rate": 3.754372353755558e-08,
      "loss": 0.0005,
      "step": 1702
    },
    {
      "epoch": 18.17,
      "learning_rate": 3.713295742174694e-08,
      "loss": 0.0003,
      "step": 1703
    },
    {
      "epoch": 18.18,
      "learning_rate": 3.672436410632512e-08,
      "loss": 0.0325,
      "step": 1704
    },
    {
      "epoch": 18.19,
      "learning_rate": 3.6317945509317715e-08,
      "loss": 0.0193,
      "step": 1705
    },
    {
      "epoch": 18.2,
      "learning_rate": 3.591370353854378e-08,
      "loss": 0.0017,
      "step": 1706
    },
    {
      "epoch": 18.21,
      "learning_rate": 3.551164009160429e-08,
      "loss": 0.0268,
      "step": 1707
    },
    {
      "epoch": 18.22,
      "learning_rate": 3.5111757055874326e-08,
      "loss": 0.0149,
      "step": 1708
    },
    {
      "epoch": 18.23,
      "learning_rate": 3.471405630849328e-08,
      "loss": 0.0035,
      "step": 1709
    },
    {
      "epoch": 18.24,
      "learning_rate": 3.431853971635662e-08,
      "loss": 0.011,
      "step": 1710
    },
    {
      "epoch": 18.25,
      "learning_rate": 3.3925209136106804e-08,
      "loss": 0.0012,
      "step": 1711
    },
    {
      "epoch": 18.26,
      "learning_rate": 3.3534066414124594e-08,
      "loss": 0.0151,
      "step": 1712
    },
    {
      "epoch": 18.27,
      "learning_rate": 3.3145113386520486e-08,
      "loss": 0.0002,
      "step": 1713
    },
    {
      "epoch": 18.28,
      "learning_rate": 3.275835187912629e-08,
      "loss": 0.0386,
      "step": 1714
    },
    {
      "epoch": 18.29,
      "learning_rate": 3.237378370748606e-08,
      "loss": 0.0002,
      "step": 1715
    },
    {
      "epoch": 18.3,
      "learning_rate": 3.199141067684785e-08,
      "loss": 0.0002,
      "step": 1716
    },
    {
      "epoch": 18.31,
      "learning_rate": 3.1611234582155533e-08,
      "loss": 0.0051,
      "step": 1717
    },
    {
      "epoch": 18.33,
      "learning_rate": 3.1233257208039655e-08,
      "loss": 0.0005,
      "step": 1718
    },
    {
      "epoch": 18.34,
      "learning_rate": 3.0857480328809915e-08,
      "loss": 0.0002,
      "step": 1719
    },
    {
      "epoch": 18.35,
      "learning_rate": 3.048390570844611e-08,
      "loss": 0.0579,
      "step": 1720
    },
    {
      "epoch": 18.36,
      "learning_rate": 3.01125351005902e-08,
      "loss": 0.0153,
      "step": 1721
    },
    {
      "epoch": 18.37,
      "learning_rate": 2.9743370248538015e-08,
      "loss": 0.0009,
      "step": 1722
    },
    {
      "epoch": 18.38,
      "learning_rate": 2.9376412885231238e-08,
      "loss": 0.0504,
      "step": 1723
    },
    {
      "epoch": 18.39,
      "learning_rate": 2.9011664733248785e-08,
      "loss": 0.0301,
      "step": 1724
    },
    {
      "epoch": 18.4,
      "learning_rate": 2.864912750479942e-08,
      "loss": 0.0733,
      "step": 1725
    },
    {
      "epoch": 18.41,
      "learning_rate": 2.828880290171315e-08,
      "loss": 0.0251,
      "step": 1726
    },
    {
      "epoch": 18.42,
      "learning_rate": 2.793069261543335e-08,
      "loss": 0.0101,
      "step": 1727
    },
    {
      "epoch": 18.43,
      "learning_rate": 2.7574798327009095e-08,
      "loss": 0.0022,
      "step": 1728
    },
    {
      "epoch": 18.44,
      "learning_rate": 2.722112170708696e-08,
      "loss": 0.0525,
      "step": 1729
    },
    {
      "epoch": 18.45,
      "learning_rate": 2.686966441590327e-08,
      "loss": 0.0002,
      "step": 1730
    },
    {
      "epoch": 18.46,
      "learning_rate": 2.6520428103276315e-08,
      "loss": 0.0007,
      "step": 1731
    },
    {
      "epoch": 18.47,
      "learning_rate": 2.6173414408598826e-08,
      "loss": 0.0561,
      "step": 1732
    },
    {
      "epoch": 18.49,
      "learning_rate": 2.582862496082977e-08,
      "loss": 0.0262,
      "step": 1733
    },
    {
      "epoch": 18.5,
      "learning_rate": 2.54860613784873e-08,
      "loss": 0.0002,
      "step": 1734
    },
    {
      "epoch": 18.51,
      "learning_rate": 2.514572526964065e-08,
      "loss": 0.0002,
      "step": 1735
    },
    {
      "epoch": 18.52,
      "learning_rate": 2.4807618231902805e-08,
      "loss": 0.0003,
      "step": 1736
    },
    {
      "epoch": 18.53,
      "learning_rate": 2.4471741852423233e-08,
      "loss": 0.0154,
      "step": 1737
    },
    {
      "epoch": 18.54,
      "learning_rate": 2.4138097707879836e-08,
      "loss": 0.0422,
      "step": 1738
    },
    {
      "epoch": 18.55,
      "learning_rate": 2.380668736447239e-08,
      "loss": 0.0588,
      "step": 1739
    },
    {
      "epoch": 18.56,
      "learning_rate": 2.3477512377914066e-08,
      "loss": 0.0002,
      "step": 1740
    },
    {
      "epoch": 18.57,
      "learning_rate": 2.3150574293425375e-08,
      "loss": 0.0017,
      "step": 1741
    },
    {
      "epoch": 18.58,
      "learning_rate": 2.282587464572594e-08,
      "loss": 0.0237,
      "step": 1742
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.2503414959027967e-08,
      "loss": 0.0486,
      "step": 1743
    },
    {
      "epoch": 18.6,
      "learning_rate": 2.2183196747028565e-08,
      "loss": 0.0162,
      "step": 1744
    },
    {
      "epoch": 18.61,
      "learning_rate": 2.1865221512902764e-08,
      "loss": 0.0004,
      "step": 1745
    },
    {
      "epoch": 18.62,
      "learning_rate": 2.1549490749296963e-08,
      "loss": 0.0159,
      "step": 1746
    },
    {
      "epoch": 18.63,
      "learning_rate": 2.123600593832109e-08,
      "loss": 0.0055,
      "step": 1747
    },
    {
      "epoch": 18.65,
      "learning_rate": 2.092476855154246e-08,
      "loss": 0.0132,
      "step": 1748
    },
    {
      "epoch": 18.66,
      "learning_rate": 2.0615780049978048e-08,
      "loss": 0.009,
      "step": 1749
    },
    {
      "epoch": 18.67,
      "learning_rate": 2.0309041884088495e-08,
      "loss": 0.0004,
      "step": 1750
    },
    {
      "epoch": 18.68,
      "learning_rate": 2.0004555493770448e-08,
      "loss": 0.0145,
      "step": 1751
    },
    {
      "epoch": 18.69,
      "learning_rate": 1.970232230835067e-08,
      "loss": 0.0111,
      "step": 1752
    },
    {
      "epoch": 18.7,
      "learning_rate": 1.9402343746578563e-08,
      "loss": 0.0167,
      "step": 1753
    },
    {
      "epoch": 18.71,
      "learning_rate": 1.9104621216619875e-08,
      "loss": 0.0084,
      "step": 1754
    },
    {
      "epoch": 18.72,
      "learning_rate": 1.880915611605016e-08,
      "loss": 0.1407,
      "step": 1755
    },
    {
      "epoch": 18.73,
      "learning_rate": 1.85159498318479e-08,
      "loss": 0.0536,
      "step": 1756
    },
    {
      "epoch": 18.74,
      "learning_rate": 1.8225003740388545e-08,
      "loss": 0.0002,
      "step": 1757
    },
    {
      "epoch": 18.75,
      "learning_rate": 1.793631920743727e-08,
      "loss": 0.0067,
      "step": 1758
    },
    {
      "epoch": 18.76,
      "learning_rate": 1.7649897588143226e-08,
      "loss": 0.0074,
      "step": 1759
    },
    {
      "epoch": 18.77,
      "learning_rate": 1.736574022703291e-08,
      "loss": 0.0866,
      "step": 1760
    },
    {
      "epoch": 18.78,
      "learning_rate": 1.7083848458004036e-08,
      "loss": 0.0263,
      "step": 1761
    },
    {
      "epoch": 18.79,
      "learning_rate": 1.6804223604318824e-08,
      "loss": 0.0142,
      "step": 1762
    },
    {
      "epoch": 18.81,
      "learning_rate": 1.652686697859823e-08,
      "loss": 0.0188,
      "step": 1763
    },
    {
      "epoch": 18.82,
      "learning_rate": 1.6251779882815786e-08,
      "loss": 0.0011,
      "step": 1764
    },
    {
      "epoch": 18.83,
      "learning_rate": 1.597896360829115e-08,
      "loss": 0.0019,
      "step": 1765
    },
    {
      "epoch": 18.84,
      "learning_rate": 1.570841943568446e-08,
      "loss": 0.0094,
      "step": 1766
    },
    {
      "epoch": 18.85,
      "learning_rate": 1.5440148634989825e-08,
      "loss": 0.0158,
      "step": 1767
    },
    {
      "epoch": 18.86,
      "learning_rate": 1.5174152465529777e-08,
      "loss": 0.0033,
      "step": 1768
    },
    {
      "epoch": 18.87,
      "learning_rate": 1.4910432175949285e-08,
      "loss": 0.0118,
      "step": 1769
    },
    {
      "epoch": 18.88,
      "learning_rate": 1.46489890042098e-08,
      "loss": 0.0029,
      "step": 1770
    },
    {
      "epoch": 18.89,
      "learning_rate": 1.4389824177583388e-08,
      "loss": 0.0145,
      "step": 1771
    },
    {
      "epoch": 18.9,
      "learning_rate": 1.4132938912647218e-08,
      "loss": 0.0639,
      "step": 1772
    },
    {
      "epoch": 18.91,
      "learning_rate": 1.3878334415277582e-08,
      "loss": 0.0285,
      "step": 1773
    },
    {
      "epoch": 18.92,
      "learning_rate": 1.3626011880644273e-08,
      "loss": 0.0055,
      "step": 1774
    },
    {
      "epoch": 18.93,
      "learning_rate": 1.3375972493205267e-08,
      "loss": 0.0004,
      "step": 1775
    },
    {
      "epoch": 18.94,
      "learning_rate": 1.3128217426700727e-08,
      "loss": 0.0346,
      "step": 1776
    },
    {
      "epoch": 18.95,
      "learning_rate": 1.288274784414789e-08,
      "loss": 0.0117,
      "step": 1777
    },
    {
      "epoch": 18.97,
      "learning_rate": 1.2639564897835187e-08,
      "loss": 0.0027,
      "step": 1778
    },
    {
      "epoch": 18.98,
      "learning_rate": 1.2398669729317357e-08,
      "loss": 0.0002,
      "step": 1779
    },
    {
      "epoch": 18.99,
      "learning_rate": 1.2160063469409509e-08,
      "loss": 0.072,
      "step": 1780
    },
    {
      "epoch": 19.0,
      "learning_rate": 1.1923747238182403e-08,
      "loss": 0.0073,
      "step": 1781
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.007691233418881893,
      "eval_runtime": 12.8355,
      "eval_samples_per_second": 58.432,
      "eval_steps_per_second": 14.647,
      "eval_wer": 0.002699055330634278,
      "step": 1781
    }
  ],
  "max_steps": 1860,
  "num_train_epochs": 20,
  "total_flos": 1.350477381109678e+19,
  "trial_name": null,
  "trial_params": null
}
