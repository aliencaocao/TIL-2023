2023-06-08 23:35:10 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}}
2023-06-08 23:35:10 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_62adb2d0
2023-06-08 23:35:10 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 23:35:10 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 23:35:11 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 23:35:11 INFO Model input size: [80, 608]
2023-06-08 23:35:11 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 23:35:11 INFO [CLS] token?: False
2023-06-08 23:35:11 INFO training_mask: 0.0
2023-06-08 23:35:11 INFO flat_features: False
2023-06-08 23:35:11 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 23:35:11 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-08 23:35:14 INFO  using spectrogram norimalization stats: [-12.897504    4.4194508]
2023-06-08 23:35:14 INFO Head = TaskHead(
  (norm): BatchNorm1d(3840, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  (mlp): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=3840, out_features=2, bias=True)
    )
  )
)
2023-06-08 23:35:14 INFO Using loss_nll, eval_acc, and SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.001
    lr: 0
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
2023-06-08 23:35:14 INFO  using mixup with alpha=0.5
2023-06-08 23:35:14 INFO  using SpecAugmentation with 0, 192.
2023-06-08 23:35:14 INFO  using RandomResizeCrop(virtual_crop_size=(1.0, 1.5), time_scale=(0.6, 1.5), freq_scale=(0.6, 1.5))
2023-06-08 23:38:14 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}}
2023-06-08 23:38:14 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_62adb2d0
2023-06-08 23:38:14 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 23:38:14 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 23:38:15 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 23:38:15 INFO Model input size: [80, 608]
2023-06-08 23:38:15 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 23:38:15 INFO [CLS] token?: False
2023-06-08 23:38:15 INFO training_mask: 0.0
2023-06-08 23:38:15 INFO flat_features: False
2023-06-08 23:38:15 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 23:38:15 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-09 16:59:37 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}}
2023-06-09 16:59:37 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_62adb2d0
2023-06-09 16:59:37 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-09 16:59:37 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-09 16:59:38 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 0, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_62adb2d0', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 0, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '80149c68'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-09 16:59:38 INFO Model input size: [80, 608]
2023-06-09 16:59:38 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-09 16:59:38 INFO [CLS] token?: False
2023-06-09 16:59:38 INFO training_mask: 0.0
2023-06-09 16:59:38 INFO flat_features: False
2023-06-09 16:59:38 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-09 16:59:38 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
