2023-06-08 21:15:37 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}}
2023-06-08 21:15:37 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_64f5263c
2023-06-08 21:15:37 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 21:15:37 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 21:15:38 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 21:15:38 INFO Model input size: [80, 608]
2023-06-08 21:15:38 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 21:15:38 INFO [CLS] token?: False
2023-06-08 21:15:38 INFO training_mask: 0.0
2023-06-08 21:15:38 INFO flat_features: False
2023-06-08 21:15:38 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 21:15:38 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-08 21:15:42 INFO  using spectrogram norimalization stats: [-12.897504    4.4194508]
2023-06-08 21:15:42 INFO Head = TaskHead(
  (norm): BatchNorm1d(3840, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  (mlp): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=3840, out_features=2, bias=True)
    )
  )
)
2023-06-08 21:15:42 INFO Using loss_nll, eval_acc, and SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.001
    lr: 0
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
2023-06-08 21:15:42 INFO  using mixup with alpha=0.5
2023-06-08 21:15:42 INFO  using SpecAugmentation with 30, 192.
2023-06-08 21:15:42 INFO  using RandomResizeCrop(virtual_crop_size=(1.0, 1.5), time_scale=(0.6, 1.5), freq_scale=(0.6, 1.5))
2023-06-08 21:15:43 INFO Epoch [0] iter: 0/1, elapsed: 0.901s, lr: 0.00000000 loss: 0.33650255
2023-06-08 21:15:43 INFO Saved weight as logs/til_ar_m2d.AR_M2D_64f5263c/weights_ep0it0-0.66667_loss0.3365.pth
2023-06-08 21:15:43 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 0/0: val acc: 0.66667, loss: 0.33650, best: 0.66667@0
2023-06-08 21:15:44 INFO Epoch [1] iter: 0/1, elapsed: 1.567s, lr: 0.00020000 loss: 0.32646990
2023-06-08 21:15:45 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 1/0: val acc: 0.66667, loss: 0.32647, best: 0.66667@0
2023-06-08 21:15:46 INFO Epoch [2] iter: 0/1, elapsed: 1.328s, lr: 0.00040000 loss: 0.44117191
2023-06-08 21:15:46 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 2/0: val acc: 0.66667, loss: 0.44117, best: 0.66667@0
2023-06-08 21:15:47 INFO Epoch [3] iter: 0/1, elapsed: 1.326s, lr: 0.00060000 loss: 0.36490464
2023-06-08 21:15:48 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 3/0: val acc: 0.66667, loss: 0.36490, best: 0.66667@0
2023-06-08 21:15:49 INFO Epoch [4] iter: 0/1, elapsed: 1.323s, lr: 0.00080000 loss: 0.36535993
2023-06-08 21:15:49 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 4/0: val acc: 0.66667, loss: 0.36536, best: 0.66667@0
2023-06-08 21:15:50 INFO Epoch [5] iter: 0/1, elapsed: 1.325s, lr: 0.00099846 loss: 0.25633150
2023-06-08 23:11:26 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}}
2023-06-08 23:11:26 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_64f5263c
2023-06-08 23:11:26 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 23:12:56 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}}
2023-06-08 23:12:56 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_64f5263c
2023-06-08 23:12:56 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 23:12:56 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 23:12:57 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 23:12:57 INFO Model input size: [80, 608]
2023-06-08 23:12:57 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 23:12:57 INFO [CLS] token?: False
2023-06-08 23:12:57 INFO training_mask: 0.0
2023-06-08 23:12:57 INFO flat_features: False
2023-06-08 23:12:57 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 23:12:57 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-08 23:17:02 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}}
2023-06-08 23:17:02 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_64f5263c
2023-06-08 23:17:02 INFO Train:3, valid:3, test:1, multi label:False, balanced:True
2023-06-08 23:17:02 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 23:17:02 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 44, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_64f5263c', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 44, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 2, 'id': '92c93b1f'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 23:17:02 INFO Model input size: [80, 608]
2023-06-08 23:17:02 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 23:17:02 INFO [CLS] token?: False
2023-06-08 23:17:02 INFO training_mask: 0.0
2023-06-08 23:17:02 INFO flat_features: False
2023-06-08 23:17:02 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 23:17:02 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-08 23:17:06 INFO  using spectrogram norimalization stats: [-12.897504    4.4194508]
2023-06-08 23:17:06 INFO Head = TaskHead(
  (norm): BatchNorm1d(3840, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  (mlp): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=3840, out_features=2, bias=True)
    )
  )
)
2023-06-08 23:17:06 INFO Using loss_nll, eval_acc, and SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.001
    lr: 0
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
2023-06-08 23:17:06 INFO  using mixup with alpha=0.5
2023-06-08 23:17:06 INFO  using SpecAugmentation with 30, 192.
2023-06-08 23:17:06 INFO  using RandomResizeCrop(virtual_crop_size=(1.0, 1.5), time_scale=(0.6, 1.5), freq_scale=(0.6, 1.5))
2023-06-08 23:17:07 INFO Epoch [0] iter: 0/1, elapsed: 0.856s, lr: 0.00000000 loss: 0.33650255
2023-06-08 23:17:08 INFO Saved weight as logs/til_ar_m2d.AR_M2D_64f5263c/weights_ep0it0-0.66667_loss0.3365.pth
2023-06-08 23:17:08 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 0/0: val acc: 0.66667, loss: 0.33650, best: 0.66667@0
2023-06-08 23:17:09 INFO Epoch [1] iter: 0/1, elapsed: 1.560s, lr: 0.00020000 loss: 0.32646990
2023-06-08 23:17:09 INFO til_ar_m2d.AR_M2D_64f5263c-lr001mu5fm30tm192balR | epoch/iter 1/0: val acc: 0.66667, loss: 0.32647, best: 0.66667@0
