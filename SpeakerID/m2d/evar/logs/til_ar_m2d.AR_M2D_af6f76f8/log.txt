2023-06-08 17:06:39 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 128, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_af6f76f8', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 128, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 1, 'id': 'a73136b7'}}
2023-06-08 17:06:39 INFO 
ðŸš€ Start fine-tuning  with logging in logs/til_ar_m2d.AR_M2D_af6f76f8
2023-06-08 17:06:39 INFO Train:1, valid:1, test:1, multi label:False, balanced:True
2023-06-08 17:06:40 INFO Creating model: msm_mae_vit_base(input=[80, 608], patch=[16, 16], decoder_depth=4)
2023-06-08 17:06:40 INFO {'audio_repr': 'ar_m2d.AR_M2D', 'weight_file': '../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth', 'feature_d': 3840, 'sample_rate': 16000, 'n_fft': 400, 'window_size': 400, 'hop_size': 160, 'n_mels': 80, 'f_min': 50, 'f_max': 8000, 'window': 'hanning', 'cls_token': False, 'output_layers': [-1], 'training_mask': 0.0, 'flat_features': False, 'batch_size': 128, 'lr_lineareval': 3e-05, 'report_per_epochs': 50, 'early_stop_epochs': 20, 'warmup_epochs': 5, 'mixup': 0.5, 'ft_bs': 128, 'ft_lr': 0.001, 'ft_early_stop_epochs': -1, 'ft_epochs': 200, 'ft_freq_mask': 30, 'ft_time_mask': 192, 'ft_noise': 0.0, 'ft_rrc': True, 'name': '', 'task_metadata': 'evar/metadata/til.csv', 'task_data': 'work/16k/til', 'unit_samples': 240000, 'id': 'til_ar_m2d.AR_M2D_af6f76f8', 'optim': 'sgd', 'unit_sec': None, 'runtime_cfg': {'lr': 0.001, 'seed': 42, 'hidden': [], 'mixup': 0.5, 'bs': 128, 'freq_mask': 30, 'time_mask': 192, 'rrc': True, 'epochs': 200, 'early_stop_epochs': -1, 'n_class': 1, 'id': 'a73136b7'}, 'input_size': [80, 608], 'patch_size': [16, 16], 'model': 'msm_mae_vit_base', 'decoder_depth': 4}
2023-06-08 17:06:40 INFO Model input size: [80, 608]
2023-06-08 17:06:40 INFO Using weights: ../weights/msm_mae_vit_base-80x608p16x16-220924-mr75/checkpoint-300.pth
2023-06-08 17:06:40 INFO [CLS] token?: False
2023-06-08 17:06:40 INFO training_mask: 0.0
2023-06-08 17:06:40 INFO flat_features: False
2023-06-08 17:06:40 INFO Runtime MelSpectrogram(16000, 400, 400, 160, 80, 50, 8000):
2023-06-08 17:06:40 INFO MelSpectrogram(
  Mel filter banks size = (80, 201), trainable_mel=False
  (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)
)
2023-06-08 17:06:45 INFO  using spectrogram norimalization stats: [-11.814139    4.6646237]
2023-06-08 17:06:45 INFO Head = TaskHead(
  (norm): BatchNorm1d(3840, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  (mlp): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=3840, out_features=1, bias=True)
    )
  )
)
2023-06-08 17:06:45 INFO Using loss_nll, eval_acc, and SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    initial_lr: 0.001
    lr: 0
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
2023-06-08 17:06:45 INFO  using mixup with alpha=0.5
2023-06-08 17:06:45 INFO  using SpecAugmentation with 30, 192.
2023-06-08 17:06:45 INFO  using RandomResizeCrop(virtual_crop_size=(1.0, 1.5), time_scale=(0.6, 1.5), freq_scale=(0.6, 1.5))
